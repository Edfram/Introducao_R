
# *Tidy Data*: Uma abordagem para organizar os seus dados



```{r,include = F}
library(readxl)
library(tidyverse)
library(nycflights13)
```

## Introdução e pré-requisitos

Em qualquer análise, o formato no qual os seus dados se encontram, é muito importante. O que vamos discutir neste capítulo, será como reformatar as suas tabelas, corrigir valores não disponíveis, ou "vazios" que se encontram no formato incorreto, ou então, como preencher as suas colunas que estão incompletas de acordo com um certo padrão. 

Você rapidamente descobre a importância que o formato de sua tabela carrega para o seu trabalho, na medida em que você possui pensamentos como: "Uhmm...se essa coluna estivesse na forma x, eu poderia simplesmente aplicar a função `y()` e todos os meus problemas estariam resolvidos"; ou então: "Se o Arnaldo não tivesse colocado os totais junto dos dados desagregados, eu não teria todo esse trabalho!"; ou talvez: "Qual é o sentido de colocar o nome dos países nas colunas? Assim fica muito mais difícil de acompanhar os meus dados!".

Para corrigir o formato das nossas tabelas, vamos utilizar neste capítulo as funções do pacote `tidyr` que está incluso no `tidyverse`. Pelo próprio nome do pacote (*tidy*, que significa "arrumar"), já sabemos que ele inclui diversas funções que tem como propósito, organizar os seus dados. Portanto, lembre-se de chamar pelo pacote (seja pelo *tidyr* diretamente, ou pelo *tidyverse*) antes de prosseguir:

```{r}
library(tidyverse)
## Ou
library(tidyr)
```


## O que é *tidy data*?

Em geral, nós passamos grande parte do tempo, reorganizando os nossos dados, para que eles fiquem em um formato adequado para a nossa análise. Logo, aprender técnicas que facilitem o seu trabalho nesta atividade, pode economizar uma grande parte de seu tempo.

Isso é muito importante, pois uma base de dados que está bagunçada, é em geral bagunçada em sua própria maneira. Como resultado, cada base irá exigir um conjunto de operações e técnicas diferentes das outras bases, para que ela seja arrumada. Algumas delas, vão enfrentar problemas simples de serem resolvidos, já outras, podem estar desarrumadas em um padrão não muito bem definido, e por isso, vão dar mais trabalho para você. Por essas razões, aprender técnicas voltadas para esses problemas, se torna uma atividade necessária. 

>*"Tidy datasets are all alike, but every messy dataset is messy in its own way"*. [@wickham2014, p. 2]

Toda essa problemática, ocorre não apenas pelo erro humano, mas também porque podemos representar os nossos dados de diversas maneiras em uma tabela. Sendo que essas maneiras, podem tanto facilitar muito o seu trabalho, quanto tornar o trabalho de outros, num inferno. Veja por exemplo, as tabelas abaixo. Ambas, apresentam os mesmos dados, mas em estruturas diferentes.

```{r}
table2

table3
```


Antes de partirmos para a prática, vou lhe fornecer uma base teórica que irá sustentar as suas decisões sobre como padronizar e estruturar os seus dados. Eu expliquei anteriormente, que o `tidyverse` é um conjunto de pacotes que dividem uma mesma filosofia. Isso significa, que esses pacotes possuem uma conexão forte entre si. Por exemplo, as funções desses pacotes, retornam os seus resultados em `tibble`'s, e todas as suas funções foram construídas de forma a trabalharem bem com o operador *pipe* (` %>% `). Todas essas funções também foram projetadas seguindo as melhores práticas e técnicas em análise de dados. Sendo uma dessas práticas, o que é comumente chamado na comunidade de *tidy data*.

O conceito de *tidy data* foi definido por @wickham2014, e remete a forma como você está guardando os dados em sua tabela. Eu não estou dizendo aqui que todas as funções do `tidyverse` que apresentei até aqui, trabalham apenas com *tidy data*, mas sim, que essas funções são mais eficientes com essa estrutura *tidy*. Uma base de dados que está no formato *tidy*, compartilha das três seguintes características:

1) Cada variável de sua tabela, deve possuir a sua própria coluna.

2) Cada observação de sua tabela, deve possuir a sua própria linha.

3) Cada valor de sua tabela, deve possuir a sua própria célula.


Eu posso pressupor que essas definições acima, já são claras o suficiente para que você entenda o que são dados *tidy*. Porém, deixar as coisas no ar, é com certeza uma prática tão ruim quanto incluir totais junto de seus dados desagregados. Por isso, vou passar os próximos parágrafos definindo com maior precisão cada parte que compõe essas características.

Primeiro, vou definir o que quero dizer exatamente com linhas, colunas e células de sua tabela. Abaixo temos uma representação de uma base qualquer. O interesse nessa representação, não se trata dos valores e nomes inclusos nessa tabela, mas sim as áreas sombreadas dessa tabela, que estão lhe apresentando cada um dos componentes supracitados.

```{r, echo = FALSE, out.width="90%", fig.cap="Definindo colunas, linhas e células de uma tabela"}
knitr::include_graphics("Figuras/coluna_linha_celula.png")
```


Agora, vamos definir o que são variáveis, observações e valores. Você já deve ter percebido, que toda base de dados, possui uma unidade básica que está sendo descrita ao longo dela. Ou seja, toda base lhe apresenta dados sobre um grupo específico (ou uma amostra) de algo. Esse algo pode ser um conjunto de municípios, empresas, sequências genéticas, animais, clientes, realizações de um evento estocástico, dentre outros.

Logo, se a minha base contém dados sobre os municípios do estado de Minas Gerais (MG), cada um desses municípios são uma observação de minha base. Ao dizer que cada observação deve possuir a sua própria linha, eu estou dizendo que todas as informações referentes a um município específico, devem estar em uma única linha. Em outras palavras, cada uma das 853 (total de municípios em MG) linhas da minha base, contém os dados de um município diferente do estado.

Entretanto, se a minha base descreve a evolução do PIB desses mesmos municípios nos anos de 2010 a 2020, eu não possuo mais um valor para cada município, ao longo da base. Neste momento, eu possuo 10 valores diferentes, para cada município, e mesmo que eu ainda esteja falando dos mesmos municípios, a unidade básica da minha base, se alterou. Cada um desses 10 valores, representa uma observação do PIB deste município em um ano distinto. Logo, cada um desses 10 valores para cada município, deve possuir a sua própria linha. Se o estado de Minas Gerais possui 853 municípios diferentes, isso significa que nossa base deveria ter $10 \times 853 = 8.530$ linhas. Por isso, é importante que você preste atenção em seus dados, e identifique qual é a unidade básica que está sendo tratada.

Agora, quando eu me referir as variáveis de sua base, eu geralmente estou me referindo as colunas de sua base, porque ambos os termos são sinônimos em análises de dados. Porém, alguns cuidados são necessários, pois as variáveis de sua base podem não se encontrar nas colunas de sua tabela. Como eu disse anteriormente, há diversas formas de representar os seus dados, e por isso, há diversas formas de alocar os componentes de seus dados ao longo de sua tabela. 

Uma variável de sua base de dados, não é apenas um elemento que (como o próprio nome dá a entender) varia ao longo de sua base, mas é um elemento que lhe apresenta uma característica das suas observação. Cada variável me descreve uma característica (cor de pele, população, receita, ...) de cada observação (pessoa, município, empresa, ...) da minha base. O que é ou não, uma característica de sua unidade básica, irá depender de qual é essa unidade básica que está sendo descrita na base.

A população total, é uma característica geralmente associada a regiões geográficas (municípios, países, etc.), já a cor de pele pode ser uma característica de uma amostra de pessoas entrevistadas em uma pesquisa de campo (como a PNAD contínua), enquanto o número total de empresas é uma característica associada a setores da atividade econômica (CNAE - Classificação Nacional de Atividades Econômicas).

Por último, os valores de sua base, correspondem aos registros das características de cada observação de sua base. Como esse talvez seja o ponto mais claro e óbvio de todos, não vou me prolongar mais sobre ele. Pois as três características de *tidy data* que citamos anteriormente são interrelacionadas, de forma que você não pode satisfazer apenas duas delas. Logo, se você está satisfazendo as duas primeiras, você não precisa se preocupar com a característica que diz respeito aos valores.

```{r, out.width="90%", fig.cap="Três propriedades que caracterizam o formato *tidy data*", echo = FALSE}
knitr::include_graphics("Figuras/tidy_data.png")
```

Portanto, sempre inicie o seu trabalho, identificando a unidade básica de sua base. Em seguida, tente encontrar quais são as suas variáveis, ou as características dessa unidade básica que estão sendo descritas na base. Após isso, basta alocar cada variável em uma coluna, e reservar uma linha para cada observação diferente de sua base, que você automaticamente estará deixando uma célula para cada valor da base.




### Será que você entendeu o que é tidy data?

Nessa seção vamos fazer um teste rápido, para saber se você entendeu o que é uma tabela no formato *tidy*. Olhe por algum tempo para os exemplos abaixo, e reflita sobre qual dessas tabelas está no formato *tidy*. Tente também descobrir quais são os problemas que as tabelas "não *tidy*" apresentam, ou em outras palavras, qual das três definições que apresentamos anteriormente, que essas tabelas "não *tidy*" acabam rompendo.

```{r}
table1

table2

table3
```


Como eu disse anteriormente, a primeira coisa que você deve fazer, é identificar a unidade básica que está sendo tratada na tabela. Nos exemplos acima, essas tabelas dizem respeito à dados de três países (Brasil, China e Afeganistão) em dois anos diferentes (1999 e 2000). Logo, a nossa tabela possui $3 \times 2 = 6$ observações diferentes. Se uma das regras, impõe que todas as linhas devem possuir informações de uma única observação, a nossa tabela deveria possuir 6 linhas. Com isso, nós já sabemos que algo está errado com a tabela 2, pois ela possui o dobro de linhas.

Na verdade, o problema na tabela 2 é que ela está quebrando a regra de que cada variável na tabela deve possuir a sua própria coluna. Por causa dessa regra, a tabela 2 acaba extrapolando o número de linhas necessárias. Olhe para as colunas `type` e `count`. A coluna `count` lhe apresenta os principais valores que estamos interessados nessa tabela. Porém, a coluna `type`, está lhe apresentando duas variáveis diferentes.

Lembre-se de que variáveis, representam características da unidade básica de sua tabela. No nosso caso, essa unidade básica são dados anuais de países, logo, `cases` e `population`, são variáveis ou características diferentes desses países. Uma dessas variáveis está lhe apresentando um dado demográfico (população total), já a outra, está lhe trazendo um indicador epidemiológico (número de casos de alguma doença). Por isso, ambas variáveis deveriam possuir a sua própria coluna.

Ok, mas e as tabelas 1 e 3? Qual delas é a *tidy*? Talvez, para responder essa pergunta, você deveria primeiro procurar pela tabela "não *tidy*". Veja a tabela 3, e se pergunte: "onde se encontram os valores de população e de casos de cada país nessa tabela?". Ao se fazer essa pergunta, você provavelmente já irá descobrir qual é o problema nessa tabela.

A tabela 3, também rompe com a regra de que cada variável deve possuir a sua própria coluna. Pois o número de casos e a população total, estão guardados em uma mesma coluna! Ao separar os valores de população e de número de casos na tabela 3, em duas colunas diferentes, você chega na tabela 1, que é um exemplo de tabela *tidy*, pois agora todas as três definições estão sendo respeitadas.



### Uma breve definição de formas

Apenas para que os exemplos das próximas seções, fiquem mais claros e fáceis de se visualizar mentalmente, vou definir dois formatos gerais que a sua tabela pode assumir, que são: *long* (longa) e *wide* (larga)^[Esses são termos comuns na comunidade de R, mas estes formatos também são conhecidos, ou chamados por *indexed data* (*long*) e por *cartesian data* (*wide*).]. Ou seja, qualquer que seja a sua tabela, ela vai em geral, estar em algum desses dois formatos, de uma forma ou de outra.

Esses termos (*long* e *wide*) são bem descritivos por si só. A ideia é que se uma tabela qualquer, está no formato *long*, ela adquire um aspecto visual de longa, ou em outras palavras, visualmente ela aparenta ter muitas linhas, e poucas colunas. Já uma tabela que está no formato *wide*, adquire um aspecto visual de larga, como se essa tabela possuísse mais colunas do que o necessário, e poucas linhas. Perceba pelos exemplos apresentados na figura 7.3, que estamos apresentando exatamente os mesmos dados, eles apenas estão organizados de formas diferentes ao longo das duas tabelas.

```{r, echo = FALSE, fig.cap = "Formas gerais que a sua tabela pode adquirir"}
knitr::include_graphics("Figuras/long_wide.png")
```





## Operações de pivô

As operações de pivô são as principais operações que você irá utilizar para reformatar a sua tabela. O que essas operações fazem, é basicamente alterar as dimensões de sua tabela, ou dito de outra maneira, essas operações buscam transformar colunas em linhas, ou vice-versa. Para exemplificar essas operações, vamos utilizar as tabelas que vem do próprio pacote `tidyr`. Logo, se você chamou pelo `tidyverse` através de `library()`, você tem acesso a tabela abaixo. Basta chamar no console pelo objeto `relig_income`.

```{r}
relig_income
```

Essa tabela está nos apresentando o salário médio de pessoas pertencentes a diferentes religiões. Veja que em cada coluna dessa tabela, você possui os dados de um nível (ou faixa) salarial específico. Essa é uma estrutura que pode ser fácil e intuitiva em alguns momentos, mas certamente irá trazer limites importantes para você dentro do R. Devido a especialidade que o R possui sobre operações vetorizadas, o ideal seria transformarmos essa tabela para o formato *tidy*. 

A unidade básica dessa tabela, são os grupos religiosos, e a faixa salarial representa uma característica desses grupos. Há diferentes níveis salariais na tabela, que estão sendo distribuídos ao longo de diferentes colunas. Tendo em vista isso, uma das regras não está sendo respeita, pois todos esses diferentes níveis salarias, representam uma única característica, ou em outras palavras, eles transmitem o mesmo tipo de informação, que é um nível salarial daquele grupo religioso. Por isso, todas essas características da tabela, deve estar em uma única coluna. Em uma representação visual resumida, é isso o que precisamos fazer:

```{r, echo = FALSE, fig.cap="Representação de uma operação de pivô"}
knitr::include_graphics("Figuras/pivo1.png")
```


Por isso, quando você estiver em um momento como este, em que você deseja reformatar a sua tabela, ou em outras palavras, transformar as suas linhas em colunas, ou vice-versa, você está na verdade, procurando realizar uma operação de pivô. 

Nestas situações, você deve primeiro pensar como a sua tabela ficará, após a operação de pivô que você deseja aplicar. Ou seja, após essa operação, a sua tabela ficará com mais linhas/colunas? Ou menos linhas/colunas? Em outras palavras, você precisa identificar se você deseja tornar a sua tabela mais longa (aumentar o número de linhas, e reduzir o número de colunas), ou então, se você deseja torná-la mais larga (reduzir o número de linhas, e aumentar o número de colunas).







### Adicionando linhas à sua tabela com `pivot_longer()`


Atualmente, a tabela `relig_income` possui poucas linhas e muitas colunas, e por isso, ela adquire um aspecto visual de "larga". Como eu disse, seria muito interessante para você, que transformasse essa tabela, de modo a agrupar as diferentes faixas de níveis salarias em menos colunas. Logo, se estamos falando em reduzir o número de colunas, estamos querendo alongar a base, ou dito de outra forma, aumentar o número de linhas da base. Para fazermos isso, devemos utilizar a função `pivot_longer()`.

Essa função possui três argumentos principais: 1) `cols`, os nomes das colunas que você deseja transformar em linhas; 2) `names_to`, o nome da nova coluna onde serão alocados os nomes, ou os rótulos das colunas que você definiu em `cols`; 3) `values_to`, o nome da nova coluna onde serão alocados os valores da sua tabela, que se encontram nas colunas que você definiu em `cols`. Como nós queremos transformar todas as colunas da tabela `relig_income`, que contém faixas salariais, eu posso simplesmente colocar no argumento `cols`, um símbolo de menos antes do nome da coluna `religion`, que é a única coluna da tabela, que não possui esse tipo de informação. Ou seja, dessa forma, eu estou dizendo à `pivot_longer()`, para transformar todas as colunas (exceto a coluna `religion`).

```{r}
relig_income %>% 
  pivot_longer(
    cols = -religion,
    names_to = "income",
    values_to = "values"
  )
```

Vale destacar, que você pode selecionar as colunas que você deseja transformar em linhas (argumento `cols`), através dos mesmos mecanismos que utilizamos na função `select()`. Ao eliminarmos a coluna `religion` com um sinal de menos (`-`) estávamos utilizando justamente um desses métodos. Mas podemos também, por exemplo, selecionar todas as colunas, que possuem dados de tipo numérico, com a função `is.numeric()`, atingindo o mesmo resultado anterior. Ou então, poderíamos selecionar todas as colunas que possuem em seu nome, algum dígito numérico, através da expressão regular `"\\d"` (*digit*) na função `matches()`.

```{r, eval=FALSE}
relig_income %>% 
  pivot_longer(
    cols = is.numeric,
    names_to = "income",
    values_to = "values"
  )

relig_income %>% 
  pivot_longer(
    cols = matches("\\d"),
    names_to = "income",
    values_to = "values"
  )
```



Portanto, sempre que utilizar a função `pivot_longer()`, duas novas colunas serão criadas. Em uma dessas colunas (`values_to`), a função irá guardar os valores que se encontravam nas colunas que você transformou em linhas. Já na outra coluna (`names_to`), a função irá criar rótulos em cada linha, que lhe informam de qual coluna (que você transformou em linhas) veio o valor disposto na coluna anterior (`values_to`). Você sempre deve definir o nome dessas duas novas colunas, como texto, isto é, sempre forneça os nomes dessas colunas, entre aspas duplas ou simples.



Um outro exemplo, seria a tabela `billboard`, que também está disponível no pacote `tidyr`. Nessa tabela, temos a posição que diversas músicas ocuparam na lista da Billboard das 100 músicas mais populares no mundo, durante o ano de 2000. Portanto a posição que cada uma dessas músicas ocuparam nessa lista, ao longo do tempo, é a unidade básica que está sendo tratada nessa tabela. Agora, repare que a tabela possui muitas colunas (79 no total), onde em cada uma delas, temos a posição de uma música em uma dada semana desde a sua entrada na lista.

```{r}
billboard
```

Repare também, que temos nessa tabela, mais semanas do que o total de semanas contidas em um ano corrido ($365/7 \approx 52$ semanas). Pela descrição das colunas restantes, que se encontra logo abaixo da tabela, vemos que a tabela possui dados até a 76° semana (`wk76`). Isso provavelmente ocorre, porque algumas músicas que estão sendo descritas nessa tabela, entraram para a lista da Billboard no meio do ano anterior (1999), e portanto, permaneceram na lista mesmo durante o ano de 2000, ultrapassando o período de 1 ano, e portanto, de 52 semanas.

Agora, está claro que a forma como essa tabela está organizada, pode lhe trazer um trabalho imenso. Especialmente se você precisar aplicar uma função sobre cada uma dessas 76 colunas separadamente. Por isso, o ideal seria transformarmos todas essas 76 colunas, em novas linhas de sua tabela. 

Porém, você não vai querer digitar o nome de cada uma dessas 76 colunas, no argumento `cols` de `pivot_longer()`. Novamente, quando há um conjunto muito grande de colunas que desejamos selecionar, podemos utilizar os métodos alternativos de seleção que vimos em `select()`. Por exemplo, podemos selecionar todas essas colunas pelo seus índices. No primeiro exemplo abaixo, estamos fazendo justamente isso, ao dizer à função em `cols`, que desejamos tranformar todas as colunas entre a 4° e a 79° coluna. Uma outra alternativa, seria selecionarmos todas as colunas que possuem nomes que começam por "wk", com a função `starts_with()`. Ambas alternativas, geram o mesmo resultado.

```{r}
billboard_long <- billboard %>% 
  pivot_longer(
    cols = 4:79,
    names_to = "week",
    values_to = "position"
  )

billboard_long <- billboard %>% 
  pivot_longer(
    cols = starts_with("wk"),
    names_to = "week",
    values_to = "position"
  )

billboard_long
```


Tais métodos de seleção são muito eficazes, e trazem grande otimização para o seu trabalho. Entretanto, em muitas ocasiões que utilizar essas funções de pivô, você vai precisar transformar apenas um conjunto pequeno de colunas em sua tabela. Nestes casos, talvez seja mais simples, definir diretamente os nomes das colunas que você deseja transformar, em `cols`. Veja por exemplo, a tabela `df` que eu crio logo abaixo.

```{r}
df <- tibble(
  nome = c("Ana", "Eduardo", "Paulo"),
  `2005` = c(1800, 2100, 1230),
  `2006` = c(2120, 2100, 1450),
  `2007` = c(2120, 2100, 1980),
  `2008` = c(3840, 2100, 2430)
)

df
```


Essa tabela contém os salários médios de três indivíduos hipotéticos, ao longo de quatro anos diferentes. Note que esses quatro anos, estão distribuídos ao longo de quatro colunas dessa tabela. Nesse exemplo, podemos utilizar novamente a função `pivot_longer()`, para transformarmos essas colunas em linhas. Dessa forma, temos o seguinte resultado:


```{r}
df %>% 
  pivot_longer(
    cols = c("2005", "2006", "2007", "2008"),
    names_to = "ano",
    values_to = "salario"
  )
```







### Adicionando colunas à sua tabela com `pivot_wider()`

Por outro lado, você talvez deseje realizar a operação contrária. Ou seja, se você deseja transformar linhas de sua tabela, em novas colunas, você deve utilizar a função `pivot_wider()`, que possui argumentos muito parecidos com os de `pivot_longer()`.

Vamos começar com um exemplo simples. Veja a tabela `df` que estou criando logo abaixo. Nessa tabela, temos dados como o peso, a idade e a altura de cinco pessoas diferentes. Porém, perceba que essa tabela, não está no formato *tidy*. Pois temos três informações (peso, idade e altura) que representam características diferentes da unidade básica da tabela (pessoas), que estão em uma mesma coluna (`variavel`). 


```{r}
df <- structure(list(nome = c("Ana", "Ana", "Ana", "Eduardo", "Eduardo", 
"Eduardo", "Paulo", "Paulo", "Paulo", "Henrique", "Henrique", 
"Henrique", "Letícia", "Letícia", "Letícia"), variavel = c("idade", 
"peso", "altura", "idade", "peso", "altura", "idade", "peso", 
"altura", "idade", "peso", "altura", "idade", "peso", "altura"
), valor = c(20, 61, 1.67, 18, 90, 1.89, 19, 68, 1.67, 23, 82, 
1.72, 27, 56, 1.58)), row.names = c(NA, -15L), class = c("tbl_df", 
"tbl", "data.frame"))

df
```


Portanto, tendo identificado o problema, precisamos agora, separar as três variáveis contidas na coluna `variavel`, em três novas colunas da tabela `df`. Logo, precisamos alargar a nossa base, pois estamos eliminando linhas e adicionando colunas à tabela.

Já sabemos que podemos utilizar a função `pivot_wider()` para esse trabalho, mas eu ainda não descrevi os seus argumentos, que são os seguintes: 1) `id_cols`, sendo as colunas que são suficientes para, ou capazes de, identificar uma única observação de sua base; 2) `names_from`, qual a coluna de sua tabela que contém as linhas a serem dividas, ou transformadas, em várias outras colunas; 3) `values_from`, qual a coluna, que contém os valores a serem posicionados nas novas células, que serão criadas durante o processo de "alargamento" da sua tabela.

Antes de prosseguirmos para os exemplos práticos, é provavelmente uma boa ideia, refletirmos sobre o que o argumento `id_cols` significa. Para que você identifique as colunas a serem estipuladas no argumento `id_cols`, você precisa primeiro identificar a unidade básica que está sendo tratada em sua tabela. No nosso caso, a tabela `df`, contém dados sobre características físicas ou biológicas, de cinco pessoas diferentes. Logo, a unidade básica dessa tabela, são as pessoas que estão sendo descritas nela, e por isso, a coluna `nome` é capaz de identificar cada unidade básica, pois ela nos traz justamente um código social de identificação, isto é, o nome dessas pessoas.

Porém, repare que cada pessoa descrita na tabela `df`, não possui a sua própria linha na tabela. Veja por exemplo, as informações referentes à Ana, que estão definidas ao longo das três primeiras linhas da tabela. Com isso, eu quero apenas destacar que cada unidade básica, ou cada observação de sua tabela, não necessariamente vai se encontrar em um única linha, e que isso não deve ser uma regra (ou um guia) para selecionarmos as colunas de `id_cols`. Até porque, nós estamos utilizando uma operação de pivô sobre a nossa tabela, justamente pelo fato dela não estar no formato *tidy*. Ou seja, se uma das características que definem o formato *tidy*, não estão sendo respeitados, é muito provável, que cada observação de sua base, não se encontre em uma única linha.

Pensando em um outro exemplo, se você dispõe de uma base que descreve o PIB de cada município do estado de Minas Gerais, você precisa definir em `id_cols`, a coluna (ou o conjunto de colunas) que é capaz de identificar cada um dos 853 municípios de MG, pois esses municípios são a unidade básica da tabela. Porém, se a sua base está descrevendo o PIB desses mesmos municípios, mas agora ao longo dos anos de 2010 a 2020, a sua unidade básica passa a ter um componente temporal, e se torna a evolução desses municípios ao longo do tempo. Dessa forma, você precisaria não apenas de uma coluna que seja capaz de identificar qual o município que está sendo descrito na base, mas também de uma outra coluna que possa identificar qual o ano que a informação desse município se refere.

Tendo isso em mente, vamos partir para os próximos dois argumentos. No nosso caso, queremos pegar as três variáveis que estão ao longo da coluna `variavel`, e separá-las em três colunas diferentes. Isso é exatamente o que devemos definir em `names_from`. O que este argumento está pedindo, é o nome da coluna que contém os valores que vão servir de nome para as novas colunas que `pivot_wider()` irá criar. Ou seja, ao fornecermos a coluna `variavel` para `names_from`, `pivot_wider()` irá criar uma nova coluna para cada valor único que se encontra na coluna `variavel`. Como ao longo da coluna `variavel`, temos três valores diferentes (peso, altura e idade), `pivot_wider()` irá criar três novas colunas que possuem os nomes de `peso`, `altura` e `idade`.

Ao criar as novas colunas, você precisa preenchê-las de alguma forma, a menos que você deseja deixá-las vazias. Em outras palavras, a função `pivot_wider()` irá lhe perguntar: "Ok, eu criei as colunas que você me pediu para criar, mas eu devo preenchê-las com que valores?". Você deve responder essa pergunta, através do argumento `values_from`, onde você irá definir qual é a coluna que contém os valores que você deseja alocar ao longo dessas novas colunas (que foram criadas de acordo com os valores contidos na coluna que você definiu em `names_from`). Na nossa tabela `df`, é a coluna `valor` que contém os registros, ou os valores que cada variável (idade, altura e peso) assume nessa amostra. Logo, é essa coluna que devemos conectar à `values_from`.

```{r}
df %>% 
  pivot_wider(
    id_cols = nome,
    names_from = variavel,
    values_from = valor
  )
```


Esse foi um exemplo simples de como utilizar a função, e que vai lhe servir de base para praticamente qualquer aplicação de `pivot_wider()`. Porém, em algumas situações que você utilizar `pivot_wider()`, pode ser que a sua tabela não possua colunas o suficiente, que possam identificar unicamente cada observação de sua base, e isso, ficará mais claro com um outro exemplo.

Com o código abaixo, você é capaz de recriar a tabela `vendas`, em seu R. Lembre-se de executar a função `set.seed()` antes de criar a tabela `vendas`, pois é essa função que garante que você irá recriar exatamente a mesma tabela que a minha. Nessa tabela `vendas`, possuímos vendas hipóteticas de diversos produtos (identificados por `produtoid`), realizadas por alguns vendedores (identificados por `usuario`) que arrecadaram em cada venda os valores descritos na coluna `valor`. Perceba também, que essas vendas são diárias, pois possuímos outras três colunas (`ano`, `mes` e `dia`) que definem o dia em que a venda ocorreu.

```{r}
nomes <- c("Ana", "Eduardo", "Paulo", "Henrique", "Letícia")
produto <- c("10032", "10013", "10104", "10555", "10901")

set.seed(1)
vendas <- tibble(
    ano = sample(2010:2020, size = 10000, replace = TRUE),
    mes = sample(1:12, size = 10000, replace = TRUE),
    dia = sample(1:31, size = 10000, replace = TRUE),
    usuario = sample(nomes, size = 10000, replace = TRUE),
    valor = rnorm(10000, mean = 5000, sd = 1600),
    produtoid = sample(produto, size = 10000, replace = TRUE)
  ) %>% 
  arrange(ano, mes, dia, usuario)

vendas
```


Vou antes de mais nada, identificar os níveis (ou valores únicos) contidos nas duas colunas que vão servir de objeto de estudo, para os próximos exemplos. Caso você queira visualizar todos os valores únicos contidos em uma coluna, você pode realizar tal ação através da função `unique()`. Perceba pelos resultados abaixo, que nós temos cinco vendedores e cinco produtos diferentes que estão sendo descritos ao longo da tabela `vendas`.

```{r}
unique(vendas$usuario)

unique(vendas$produtoid)
```



Portanto, vamos para o exemplo. Já adianto, que se você tentar distribuir tanto os vendedores (`usuario`), quanto os produtos vendidos (`produtoid`), em novas colunas de nossa tabela, utilizando `pivot_wider()`, um aviso será levantado, e o resultado dessa operação (apesar de correto) será provavelmente, muito estranho para você. Primeiro, veja com os seus próprios olhos, qual é o resultado dessa aplicação, com a coluna `usuario`:


```{r}
vendas_wide <- vendas %>% 
  pivot_wider(
    id_cols = c("ano", "mes", "dia", "produtoid"),
    names_from = usuario,
    values_from = valor
  )

vendas_wide
```

Como podemos ver pelo resultado acima, uma mensagem de aviso apareceu, nos informando que os valores não podem ser unicamente identificados através das colunas que fornecemos em `id_cols` (*Values are not uniquely identified*), e que por isso, a função `pivot_wider()`, acabou transformando as novas colunas que criamos, em listas (*output will contain list-cols.*).

Ou seja, cada uma das colunas que acabamos de criar com `pivot_wider()`, estão na estrutura de um vetor recursivo (i.e. listas). Isso pode ser estranho para muitos usuários, pois na maioria das vezes, as colunas de suas tabelas serão vetores atômicos^[Apesar de serem um caso raro no R, as tabelas que possuem listas como colunas, tem se tornado cada vez mais comuns ao longo de diversas análises, e são comumente chamadas pela comunidade de *nested tables*, ou de *nested data*. Alguns pacotes tem se desenvolvido, de maneira muito forte nessa área, e por isso, essas estruturas tem se tornado de grande utilidade em diversas aplicações. Alguns desses pacotes incluem o próprio `tidyr`, além do pacote `broom`.]. Um outro motivo que provavelmente levantou bastante dúvida em sua cabeça é: "Como assim as colunas que forneci não são capazes de identificar unicamente os valores? Em que sentido elas não são capazes de realizar tal ação?". Bem, essa questão ficará mais clara, se nos questionarmos como, ou por que motivo essas colunas foram transformadas para listas.

Antes de continuarmos, vale ressaltar que as novas colunas criadas por `pivot_wider()` nunca chegaram a ser colunas comuns, formadas por vetores atômicos. Logo, desde a sua criação, elas já eram listas. Mas se partirmos do pressuposto que inicialmente, essas colunas eram vetores atômicos, tal pensamento se torna útil para identificarmos os motivos para o uso de listas. Estes motivos serão identificados a seguir.

Primeiro, precisamos transformar novamente essas colunas em vetores atômicos, para tentarmos compreender como essas colunas ficariam como simples vetores atômicos. Para isso, vou pegar um pedaço da tabela `vendas`, mais especificamente, as 10 primeiras linhas da tabela, através da função `head()`. Em seguida, vou me preocupar em transformar essas colunas novamente em vetores, através dos comandos abaixo.


```{r}
pedaco <- head(vendas_wide, 10)

for(i in 5:9){
  
  id <- vapply(pedaco[[i]], FUN = is.null, FUN.VALUE = TRUE)
  
  pedaco[[i]][id] <- NA_real_
}

pedaco <- pedaco %>% mutate(across(5:9, unlist))
```


Após executarmos as transformações acima, possuímos agora, uma tabela comum, como qualquer outra que você encontra normalmente no R. Veja o resultado abaixo, quando chamamos pelo nome da tabela no console. Dessa vez, nas células que possuíam uma lista nula `<NULL>`(uma lista vazia) temos um valor de `NA` (não disponível). Já nas células que possuíam uma lista com algum valor, vemos agora, o valor exato que estava contido nessa lista, ao invés da descrição `<dbl [1]>`.


```{r}
pedaco
```


Portanto, se observarmos a primeira linha dessa nova tabela `pedaco`, vemos que a vendedora Ana, vendeu no dia 01/01/2010, o produto de ID 10104, no valor de 3907 reais (e alguns centavos). Neste mesmo dia, o Henrique vendeu o mesmo produto, por quase 2 mil reais a mais que Ana, totalizando 6139 reais de receita. Podemos perceber também pelas outras colunas, que nenhum outro vendedor conseguiu vender uma unidade do produto de ID 10104, no dia 01/01/2010.

Neste ponto, se pergunte: "Ok, Ana vendeu uma unidade do produto 10104, no dia 01. Mas e se ela tivesse vendido duas unidades desse mesmo produto 10104, no dia 01?". Tente imaginar, como os dados dessas duas vendas ficariam na tabela. Isso não é uma questão trivial, pois temos agora dados de duas vendas diferentes...mas apenas uma célula disponível em nossa tabela, para guardar esses dados. É a partir deste choque, que podemos identificar qual foi o motivo para o uso de listas nas novas colunas.

Dito de outra forma, temos uma única célula na tabela (localizada na primeira linha, e quinta coluna da tabela), que deve conter o valor arrecadado na venda do produto 10104, realizada pela vendedora Ana no dia 01/01/2010. Você poderia pensar: "Bem, por que não somar os valores dessas duas vendas? Dessa forma, temos apenas um valor para encaixar nessa célula". Essa é uma alternativa possível, porém, ela gera perda de informação, especialmente se o valor arrecadado nas duas operações forem diferentes. Por exemplo, se a receita da primeira venda foi de 3907, e da segunda, de 4530. Com essa alternativa, nós sabemos que a soma das duas vendas ocorridas naquele dia, geraram 8437 reais de receita, mas nós não sabemos mais, qual foi o menor valor arrecadado nas duas operações. 

Isso é particularmente importante, pois podemos gerar o mesmo valor (8437 reais) de múltiplas formas. Pode ser que a Ana tenha vendido cinco unidades do produto 10104, tendo arrecadado em cada venda, o valor de 1687,4 reais. Mas ela poderia atingir o mesmo valor, ao vender dez unidades do produto 10104, dessa vez, arrecandando um valor médio bem menor, de 843,7 reais. Portanto, se utilizarmos a soma desses valores, como forma de contornarmos o problema posto anteriormente, os administradores da loja não poderão mais inferir da tabela `vendas`, se as suas vendas tem se reduzido em quantidade, ou se o valor arrecadado em cada venda, tem caído ao longo dos últimos anos.


Apesar de ser uma alternativa ruim para muitos casos, pode ser desejável agregar as informações dessas vendas em uma só para o seu caso.  Nesta situação, as versões mais recentes do pacote `tidyr`, oferecem na função `pivot_wider()` o argumento `values_fn`, onde você pode fornecer o nome de uma função a ser aplicada sobre os valores dispostos em cada célula. Logo, se quiséssemos somar os valores de vendas dispostos em cada célula criadas na tabela `vendas_wide`, poderíamos realizar os comandos abaixo:

```{r}
vendas %>% 
  pivot_wider(
    id_cols = c("ano", "mes", "dia", "produtoid"),
    names_from = usuario,
    values_from = valor,
    values_fn = sum
  )
```




Recapitulando, nossa hipótese, é de que tenha ocorrido mais de uma venda de um mesmo produto, por um mesmo vendedor, em um mesmo dia na tabela `vendas`. Para comprovar se essa hipótese ocorre ou não em nossa tabela, podemos coletar o número de observações contidas em cada célula da coluna `Ana`, por exemplo, e verificarmos se há algum valor acima de 1. Vale ressaltar que as colunas criadas por `pivot_wider()` em `vendas_wide`, são agora listas, e principalmente, que desejamos coletar o número de observações contidas em cada um dos elementos da lista que representa a coluna `Ana`. Para isso, precisamos de algo como os comandos abaixo:


```{r, eval = T}
vec <- vector(mode = "double", length = nrow(vendas_wide))

for(i in seq_along(vendas_wide$Ana)){
  
  vec[i] <- length(vendas_wide$Ana[[i]])

}

vec[vec > 1]
```

Podemos ver pelo resultado acima, que sim, possuímos dias em que a vendedora Ana, vendeu mais de uma vez, o mesmo produto. É neste sentido que a função `pivot_wider()` gerou aquele aviso para nós. A função estava nos informando que ela não possuía meios de identificar cada venda realizada pela vendedora Ana desse mesmo produto, nesses dias que foram provavelmente movimentados na loja. Nós fornecemos ao argumento `id_cols`, as colunas `ano`, `mes`, `dia` e `produtoid`. Porém, essas colunas em conjunto não são capazes de diferenciar as três vendas de Ana do produto 10013 que ocorreram no dia 29/02/2010, por exemplo, nem as duas vendas de Henrique do produto 10104 no dia 18/01/2010, e muitas outras. Foi por esse motivo, que listas foram utilizadas nas novas colunas de `pivot_wider()`.


Você talvez pense: "Por que não fornecemos então todas as colunas da tabela para `id_cols`?". Primeiro, esse questionamento carrega um pressuposto que não necessariamente se confirma, que é o de que os valores das vendas realizadas por um mesmo vendedor, de um mesmo produto, e no mesmo dia, são diferentes em todas as ocasiões. Algo que é possível, mas não necessariamente ocorre ao longo de toda a base. O segundo problema, é que a coluna `valor` não está mais disponível para ser utilizada por `id_cols`, pois se você se lembrar, nós conectamos essa coluna a `values_from`. Isso significa, que essa coluna já está sendo utilizada para preencher as novas células que estão sendo criadas por `pivot_wider()`, e portanto, ela não pode ocupar dois espaços ao mesmo tempo. Tanto que se você tentar adicionar a coluna `valor` a `id_cols`, você irá perceber que nada se altera, e o mesmo resultado é gerado.


Portanto, não há uma resposta fácil para uma situação como essa, onde mesmo fornecendo todas as colunas para `id_cols` em `pivot_wider()`, a função ainda não é capaz de identificar unicamente cada valor da coluna que você forneceu em `value_from`. Você pode utilizar uma solução que gera perda de informação, ao aplicar uma função sumária, ou seja, uma função para agregar esses valores de forma que eles se tornem únicos, dados os conjuntos de colunas que você forneceu em `id_cols`. Uma outra possibilidade, é que você esteja utilizando a operação de pivô errada. Ou seja, a melhor alternativa seria alongar (`pivot_longer()`) a sua base, ao invés de alargá-la.

Agora, uma última possibilidade mais promissora, é que você esteja realizando a operação correta, e que faz sentido manter essas colunas como listas de acordo com o que você deseja realizar com a base. Isso inclui o uso de um ferramental que está um pouco além desse capítulo. Por outro lado, lidar com *nested data*, é mais uma questão de experiência, de se acostumar com tal estrutura, e saber as funções adequadas, do que aprender algo muito diferente do que mostramos aqui. Um outro conhecimento que é de extrema importância nessas situações, é conhecer muito bem como as listas funcionam no R. Se você conhecer bem essa estrutura, você não terá dificuldades em navegar por *nested data*. Para uma visão melhor do potencial que *nested data* pode trazer para sua análise, eu recomendo que você procure por uma excelente palestra de Hadley Wickham, entitulada *"Managing many models with R"*^[https://www.youtube.com/watch?v=rz3_FDVt9eg&ab_channel=PsychologyattheUniversityofEdinburgh].






















## Completando e expandindo a sua tabela

A operação que vou mostrar a seguir, serve para completar, ou inserir linhas que estão faltando em sua tabela. Em outras palavras, essa operação busca tornar os valores que estão implicitamente faltando em sua tabela, em valores não disponíveis explícitos. Você também pode enxergar esse processo, como uma forma rápida de expandir a sua tabela, a partir de combinações de valores. Um exemplo lógico do uso dessa operação, seriam datas que você gostaria que estivessem em sua tabela, mas que não se encontram nela no momento. Vamos supor por exemplo, que você possua a tabela abaixo:

```{r}
library(tidyverse)

dias <- c("2020-09-01", "2020-09-05", "2020-09-07", "2020-09-10")

set.seed(1)
vendas <- tibble(
  datas = as.Date(dias),
  nome = c("Ana", "Julia", "Joao", "Julia"),
  valor = rnorm(4, mean = 500, sd = 150)
)

vendas
```


Portanto, temos nessa tabela `vendas`, o nome de alguns vendedores e os valores de suas vendas efetuadas em alguns dias diferentes. No momento, temos vendas explicítas apenas nos dias 01, 05, 07 e 10 de Setembro de 2020, mas o que ocorreu nos dias que estão entre essas datas (dias 02, 03, 04, 06, 08 e 09 de Setembro de 2020)? Caso você estivesse apresentando esses dados para o seu chefe, por exemplo, essa seria uma questão que ele provavelmente faria a você. 


Bem, vamos supor que não tenham ocorrido vendas durante esses dias, e que por isso eles não estão sendo descritos na tabela `vendas`. Talvez seja de seu desejo, introduzir esses dias na tabela para que ninguém fique em dúvida a respeito desses dias. Com isso, precisamos então completar a tabela `vendas`, com linhas que estão implicitamente faltando nela. 



### Encontrando possíveis combinações com a função `expand()`

Apesar não ser exatamente o que desejamos para a tabela `vendas`, o processo em que buscamos encontrar possíveis combinações de dados que não estão presentes em nossa tabela, também envolve a procura por todas as combinações possíveis dos dados presentes nessa tabela. Nessa seção, vamos introduzir alguns métodos para encontrarmos todas as combinações possíveis de seus dados.

Para isso, podemos utilizar a função `expand()` do pacote `tidyr`. Essa função busca expandir uma tabela, de forma que ela inclua todas as possíveis combinações de certos valores. Em maiores detalhes, essa função irá criar (com base nos dados que você fornecer a ela) uma nova tabela, ou um novo `tibble`, que irá incluir todas as combinações únicas e possíveis dos valores que você definiu. Portanto, se eu fornecer a tabela `vendas` à função, e pedir a ela que encontre todas as combinações possíveis entre os valores contidos nas colunas `datas` e `nomes`, esse será o resultado:

```{r}
expand(vendas, datas, nome)
```

Portanto, `expand()` irá criar uma nova tabela, contendo todas as possíveis combinações entre os valores das colunas `datas` e `nomes` da tabela `vendas`. Incluindo aquelas combinações que não aparecem na tabela inicial. Por exemplo, as combinações `(2020-09-01, Julia)`, ou `(2020-09-05, Joao)` e `(2020-09-10, Joao)` não estão presentes na tabela `vendas`, e mesmo assim foram introduzidas no resultado de `expand()`.

Porém, `expand()` não definiu novas combinações com as datas que estão faltando na tabela `vendas` (por exemplo, os dias 02, 03, 04 e 08 de Setembro de 2020). Ou seja, em nenhum momento `expand()` irá adicionar algum dado à sua tabela, seja antes ou depois de encontrar todas as combinações únicas. Em outras palavras, `expand()` irá sempre encontrar todas as combinações possíveis, se baseando nos valores que já se encontram nas variáveis que você forneceu a ela. Por isso, mesmo que a combinação `(2020-09-01, Julia)` não esteja definida na tabela `vendas`, ela é uma combinação possível, pois os valores `2020-09-01` e `Julia` estão presentes na tabela `vendas`.


Vale destacar, que você pode combinar as variáveis de sua tabela, com vetores externos. Por exemplo, eu posso utilizar `seq.Date()` para gerar todas as datas que estão entre o dia 01 e 10 de Setembro de 2020. No exemplo abaixo, perceba que `expand()` pega cada um dos 3 nomes únicos definidos na coluna `nome` de `vendas`, e combina eles com cada uma das 10 datas guardadas no vetor `vec_d`, gerando assim, uma nova tabela com 30 linhas ($3$ nomes $\times 10$ datas $= 30$ combinações).

```{r}
vec_d <- seq.Date(min(vendas$datas), max(vendas$datas), by = "day")

expand(vendas, nome, vec_d)
```




Além disso, a função `expand()` conta com uma função auxiliar útil (`nesting()`), que restringe quais combinações serão válidas para `expand()`. Ao incluir variáveis dentro da função `nesting()`, você está dizendo à `expand()`, que encontre apenas as combinações únicas (entre os valores dessas variáveis) que já estão presentes em sua base. Ou seja, se eu colocar as colunas `datas` e `nome` dentro de `nesting()`, a função `expand()` irá basicamente repetir a tabela `vendas`. Pois cada uma das 4 linhas (ou 4 combinações entre `datas` e `nome`), aparecem uma única vez nessa tabela.

```{r}
expand(vendas, nesting(datas, nome))
```

Dessa maneira, o uso de `nesting()` acima, é análogo ao uso da função `unique()` que vêm dos pacotes básicos do R. Logo, poderíamos atingir exatamente o mesmo resultado, utilizando qualquer uma das duas funções. Podemos por exemplo, adicionarmos uma quinta linha à tabela `vendas`, que repete os valores contidos na quarta linha da tabela. Perceba abaixo, que ao utilizarmos `unique()` ou `nesting()`, em ambos os casos, essa quinta linha repetida desaparece. Pois ambas as funções buscam encontrar todas as combinações **únicas** que aparecem ao longo da tabela `vendas`.

```{r}
vendas[5, ] <- data.frame(as.Date("2020-09-10"), "Julia", 739.29)

vendas

# Estou aplicando unique() sobre a
# primeira e segunda coluna de vendas
unique(vendas[ , 1:2]) 

# O mesmo resultado pode ser
# atingido com o uso de nesting() em expand()
expand(vendas, nesting(datas, nome))
```

Vale destacar que você pode combinar o comportamento restrito e irrestrito de `expand()`. Ou seja, você pode restringir as combinações com o uso de `nesting()` para algumas variáveis, enquanto outras permanecem de fora dessa função, permitindo uma gama maior de combinações. No exemplo abaixo, `expand()` vai encontrar primeiro, cada combinação única entre `nome` e `valor` que está presente na tabela `vendas`, em seguida, a função irá encontrar **todas** as combinações possíveis entre as combinações anteriores (entre `nome` e `valor`) e todas as datas descritas na base. 

Em outras palavras, nós podemos encontrar no resultado abaixo, uma combinação como `(2020-09-01, Julia, 528.)`. Pois a combinação `(Julia, 528.)` existe nas colunas `nome` e `valor` da tabela `vendas`, e como deixamos a coluna `datas` de fora de `nesting()`, `expand()` irá combinar `(Julia, 528.)` com toda e qualquer data disponível na tabela `vendas`.

Porém, nós não podemos encontrar no resultado abaixo, uma combinação como `(2020-09-01, Ana, 739.)`. Pois a única combinação entre as colunas `nome` e `valor`, presente na tabela `vendas`, que possui o valor 739 na coluna `valor`, é a linha que contém a combinação `(Julia, 739.)`. Logo, se não há nas colunas `nome` e `valor` alguma combinação entre `Ana` e o valor `739.`, `expand()` não irá combinar esses valores com todas as datas disponíveis na base. Pois as combinações entre as colunas `nome` e `valor` estão sendo restringidas por `nesting()`.

```{r, include = FALSE}
set.seed(1)
vendas <- tibble(
  datas = as.Date(dias),
  nome = c("Ana", "Julia", "Joao", "Julia"),
  valor = rnorm(4, mean = 500, sd = 150)
)
```



```{r}
vendas %>% 
  expand(datas, nesting(nome, valor))
```






### A metodologia por detrás do processo

Apesar de próximo, a função `expand()` não é suficiente para produzirmos o resultado que desejamos. Lembre-se que nós temos a tabela abaixo, e que desejamos completá-la com os dados referentes aos dias 02, 03, 04, 06, 08 e 09 de Setembro de 2020, que estão no momento faltando nessa tabela.

```{r}
vendas
```


Primeiro, precisamos encontrar todos valores possíveis da variável que está incompleta na tabela `vendas`. Ou seja, queremos encontrar todas as datas possíveis entre os dias 01 e 10 de Setembro de 2020, pois esses dias são os limites da tabela. Dito de outra forma, a tabela `vendas` descreve dados de vendas que ocorreram do dia 01 até o dia 10 de Setembro de 2020. Por isso, queremos encontrar todos os dias possíveis entre esse intervalo de tempo.

Para isso, podemos utilizar a função `seq.Date()` em conjunto com `tibble()`. Dessa forma, nos criamos uma nova tabela, que contém uma sequência de datas que vai do dia 01 até o dia 10 de Setembro. O mesmo resultado, poderia ser atingido, caso utilizássemos `seq.Date()` dentro de `expand()`, já que `expand()` cria por padrão uma nova tabela com todas as combinações possíveis dos dados que você fornece a ela.

```{r}
nova_tab <- tibble(
  datas = seq.Date(min(vendas$datas), max(vendas$datas), by = "day")
)


nova_tab
```
```{r, eval = F}
# O mesmo resultado poderia ser atingido com:
nova_tab <- expand(
  datas = seq.Date(min(vendas$datas), max(vendas$datas), by = "day")
)
```


Em seguida, podemos utilizar a função `full_join()`^[Caso você não conheça a função `full_join()`, lembre-se que ela é descrita em detalhes no capítulo entitulado "Introdução a base de dados relacionais".] do pacote `dplyr`, para trazermos os dados disponíveis na tabela `vendas` para essa nova tabela `nova_tab`. Agora, nós temos uma nova tabela, que contém todos os dados que já estão definidos na tabela `vendas`, além dos dias que estavam faltando anteriormente, e que agora também estão definidos. 

```{r}
nova_tab <- nova_tab %>% 
  full_join(vendas, by = "datas")

nova_tab
```

O que resta agora, é preenchermos os campos com valores não-disponíveis (`NA`) com algum outro valor que seja mais claro, ou que indique de um forma melhor, que não houve vendas realizadas naquele dia. Visando esse objetivo, temos a função `replace_na()` do pacote `tidyr`. Nessa função, você irá fornecer uma lista (`list()`) contendo os valores que vão substituir os valores `NA` em cada coluna de sua tabela. Essa lista precisa ser nomeada. Basta nomear cada valor substituto com o nome da coluna em que você deseja utilizar esse valor. Logo, se eu quero substituir todos os valores `NA` na coluna `valor`, por um zero, basta eu nomear esse zero com o nome dessa coluna, dentro da lista (`list()`) que eu forneci à `replace_na()`.

```{r}
nova_tab %>% 
  replace_na(
    list(nome = "Não houve vendas", valor = 0)
  )
```














### A função `complete()` como um atalho útil


A função `complete()` é um *wrapper*, ou uma função auxiliar do pacote `tidyr`, que engloba as funções `expand()`, `full_join()`, e `replace_na()`. Ou seja, a função `complete()` é um atalho para aplicarmos a metodologia que acabamos de descrever na seção anterior. A função possui três argumentos principais: 1) `data`, o nome do objeto onde a sua tabela está salva; 2) `...`, a especificação das colunas a serem completadas, ou "expandidas" por `complete()`; 3) `fill`, uma lista nomeada (como a que fornecemos em `replace_na()`), que atribui para cada variável (ou coluna) de sua tabela, um valor a ser utilizado (ao invés de `NA`) para as combinações faltantes.

Vou explicar o argumento `fill` mais a frente, por isso, vamos nos concentrar nos outros dois. A tabela que contém os nossos dados se chama `vendas`, e por isso, é esse valor que devemos atribuir ao argumento `data`. Porém, como estamos utilizando o *pipe* (` %>% `) no exemplo abaixo, ele já está realizando esse serviço para nós. Já o segundo argumento (`...`), diz respeita a lista de especificações que vão definir como a função `complete()` deve completar cada coluna da nossa tabela. 


Em outras palavras, o segundo argumento (`...`) é a parte da função `complete()` que diz respeito ao uso de `expand()`. Você deve portanto, preencher este argumento, da mesma forma que você faria com a função `expand()`. No exemplo abaixo, o primeiro argumento (`data`), já está sendo definido pelo operador *pipe* (` %>% `). Perceba que eu preencho a função `complete()`, da mesma forma em que preenchi a função `expand()` na seção anterior. Perceba também, que `complete()` já me retorna como resultado, a tabela expandida após o uso de `full_join()`.

```{r}
vendas %>% 
  complete(
    datas = seq.Date(min(datas), max(datas), by = "day")
  )
```

O último passo que resta agora, seria o uso de `replace_na()` para preencher os valores não-disponíveis por algum outro valor mais claro. Nós ainda podemos utilizar a função `complete()` para executarmos esse passo. Basta você fornecer à `complete()` através de seu terceiro argumento (`fill`), a mesma lista que você forneceria à `replace_na()`. Dessa forma, temos:

```{r}
vendas %>% 
  complete(
    datas = seq.Date(min(datas), max(datas), by = "day"),
    fill = list(nome = "Não houve vendas", valor = 0)
  )
```


























## Preenchendo valores não-disponíveis (`NA`)


### Utilizando-se de valores anteriores ou posteriores

As operações que vou mostrar a seguir, servem para preencher linhas com dados não-disponíveis (`NA`), com valores anteriores ou posteriores que estão disponíveis em sua tabela. Vamos começar com um exemplo simples através da tabela `df`, que você pode criar em seu R utilizando os comandos abaixo. Nessa tabela, temos algumas vendas anuais hipotéticas. Agora, perceba que por algum motivo, o ano em que as vendas ocorreram, só foram guardadas na primeira linha de cada ID (`id`). Isso é algo que devemos corrigir nessa tabela.

```{r}
library(tidyverse)

v <- 2001:2004

set.seed(1)
df <- tibble(
  id = rep(1:4, each = 3),
  ano = NA_real_,
  valor = rnorm(12, mean = 1000, sd = 560)
)

df[seq(1, 12, by = 3), "ano"] <- v

df
```

Portanto, o que queremos fazer, é completar as linhas de `NA`'s, com o ano correspondente a essas vendas. Pelo fato dos anos estarem separados por um número constante de linhas, ou seja, a cada 3 linhas de `NA`'s, temos um novo ano, podemos pensar em algumas soluções relativamente simples como a definida abaixo. Porém, a simplicidade do problema, depende dos intervalos entre cada valor, serem constantes. A partir do momento em que esses valores começarem a se dispersar em distâncias inconcistentes, uma solução como a definida abaixo, não servirá.

```{r}
niveis <- unique(df$ano)
niveis <- niveis[!is.na(niveis)]
repair_vec <- df$ano
repair_vec[is.na(repair_vec)] <- rep(niveis, each = 2)

df$ano <- repair_vec

df
```

```{r, include = FALSE}
set.seed(1)
df <- tibble(
  id = rep(1:4, each = 3),
  ano = NA_real_,
  valor = rnorm(12, mean = 1000, sd = 560)
)

df[seq(1, 12, by = 3), "ano"] <- v

df
```

Apesar de ser um problema simples, podemos alcançar uma solução ainda mais simples, ao utilizarmos funções que são especializadas nesses problemas. Esse é o caso da função `fill()` do pacote `tidyr`, que foi criada justamente para esse propósito. Portanto, sempre que você possuir em sua tabela, uma coluna onde você deseja substituir uma sequência de `NA`'s pelo último (ou próximo) valor disponível, você pode utilizar essa função para tal tarefa.

A função `fill()` possui três argumentos: 1) `data`, o objeto onde a tabela com que deseja trabalhar, está salva; 2) `...`, a lista de colunas em que você deseja aplicar a função; 3) `.direction`, define a direção que a função deve seguir na hora de preencher os valores.


```{r}
library(tidyverse)

df %>% fill(ano)
```


A função `fill()` trabalha a partir de uma dada direção vertical em sua tabela.
Por padrão, a função `fill()` irá preencher os valores indo para baixo, ou seja, partindo do topo da tabela, até a sua base. Logo, a função irá substituir qualquer `NA` com o último valor disponível, ou em outras palavras, com o valor disponível anterior ao `NA` em questão. A função lhe oferece o argumento `.direction`, caso você deseja alterar esse comportamento. Logo, se você deseja preencher esses valores `NA`'s com o próximo valor disponível em relação ao `NA` em questão. Isto é, preencher os valores para cima, partindo da base da tabela, e seguindo para o seu topo. Você precisa definir o argumento da seguinte maneira:

```{r}
df %>% fill(ano, .direction = "up")

# Caso prefira não utilizar o pipe ( %>% ),
# ficaria dessa forma:

# fill(df, ano, .direction = "up")
```


Portanto, se tivéssemos que colocar essas operações em uma representação visual, teríamos algo como a figura 7.5. Lembrando que a função usa por padrão, a direção *down*, logo, no primeiro caso mostrado na figura, você não precisaria definir explicitamente o argumento `.direction`.

```{r, fig.cap="Representação do processo executado pela função `fill`", echo = F}
knitr::include_graphics("Figuras/fill_1.png")
```



Apesar de serem os exemplos mais claros de aplicação, serão raras as ocasiões em que você terá esse problema posto claramente já de ínicio em sua tabela. Com isso, eu quero dizer que serão raros os momentos em que você desde o início terá uma tabela, onde por algum motivo, os registros aparecem apenas na primeira (ou na última) linha que diz respeito aquele registro. 

Usualmente, você irá utilizar a função `fill()` quando você já estiver realizando diversas outras transformações em sua tabela, para se chegar aonde deseja. Um exemplo claro dessa ideia, seria uma tabela onde os valores são registrados no primeiro dia de cada semana (basicamente você possui dados semanais), mas você precisa calcular uma média móvel diária. Isso significa que para calcular essa média móvel, você teria que completar os dias faltantes de cada semana, e ainda utilizar o `fill()` para transportar o valor do primeiro dia, para os dias restantes da semana.


Vale ressaltar, que você pode utilizar em `fill()`, todos os mecanismos de seleção que introduzimos em `select()`, para selecionar as colunas em que você deseja aplicar a função `fill()`. Isso também significa, que com `fill()` você pode preencher várias colunas ao mesmo tempo. Agora, para relembrarmos esses mecanismos, vamos criar uma tabela inicialmente vazia, que contém o total de vendas realizadas nos 6 primeiros meses de 2020, por cada funcionário de uma loja.

```{r}
set.seed(2)
funcionarios <- tibble(
  mes = rep(1:6, times = 4),
  vendas = floor(rnorm(24, mean = 60, sd = 24)),
  nome = NA_character_,
  salario = NA_real_,
  mes_ent = NA_real_,
  ano_ent = NA_real_,
  unidade = NA_character_
)

funcionarios
```


Em seguida, vamos preencher as colunas vazias (`nome`, `salario`, `mes_ent`, ...) de forma com que as informações de cada vendedor, apareçam apenas na última linha que diz respeito aquele vendedor. Como exemplo, as informações do vendedor Henrique, aparecem apenas na sexta linha da tabela, que é a última linha da tabela que se refere a ele. 

```{r}
valores <- list(
  salario = c(1560, 2120, 1745, 1890),
  nome = c("Henrique", "Ana", "João", "Milena"),
  ano_ent = c(2000, 2001, 2010, 2015),
  mes_ent = c(2, 10, 5, 8),
  unidade = c("Afonso Pena", "Savassi", "São Paulo", "Amazonas")
)

colunas <- colnames(funcionarios)[3:7]

for(i in colunas){
  
  funcionarios[1:4 * 6, i] <- valores[[i]]
  
}


# Com isso, temos o seguinte resultado:
funcionarios %>% print(n = 12)
```


Portanto, o que precisamos é aplicar a função `fill()` usando `.direction = "up"`, em cada uma dessas colunas vazias, de forma a preencher o restante das linhas com as informações de cada vendedor. Dada a natureza dessa tabela, os dois melhores mecanismos que aprendemos em `select()`, para selecionarmos essas colunas vazias, são: 1) usar os índices dessas colunas; 2) nos basearmos nos tipos de dados contidos em cada coluna; 3) usar um vetor externo com os nomes das colunas que desejamos.

Para utilizar o método 3 que citei acima, podemos utilizar o vetor `colunas` que criamos agora a pouco ao preenchermos a tabela, e já contém os nomes das colunas que desejamos. Porém, para o exemplo abaixo do método 2, você talvez se pergunte: "Se estamos aplicando a função `fill()` sobre todas as colunas que contém ou dados de texto (`character`), ou dados numéricos (`numeric`), nós também estamos aplicando a função sobre as colunas `mes` e `vendas`, das quais não necessitam de ajuste. O que acontece?". Nada irá ocorrer com as colunas `mes` e `vendas`, caso elas já estejam corretamente preenchidas, portanto, podemos aplicar a função sobre elas sem medo.


```{r, eval=F}
# Todas as três alternativas abaixo
# geram o mesmo resultado:

funcionarios %>% 
  fill(
    3:7,
    .direction = "up"
  )

funcionarios %>% 
  fill(
    all_of(colunas),
    .direction = "up"
  )
```
```{r}
funcionarios %>% 
  fill(
    where(is.character),
    where(is.numeric),
    .direction = "up"
  )
```





## Um estudo de caso sobre médias móveis com `complete()` e `fill()`

### A metodologia de uma média móvel no R

Uma média móvel é calculada ao aplicarmos o cálculo da média aritmética, sobre uma sequência de partes (ou *subsets*) de seus dados. De certa forma, esse processo se parece com uma rolagem, como se estivéssemos "rolando" o cálculo da média ao longo dos nossos dados. Veja por exemplo, o cálculo abaixo, onde utilizamos a função `roll_mean()` do pacote `RcppRoll` para calcularmos uma média móvel que possui uma janela de 3 valores.

```{r, include=F}
library(RcppRoll)
```

```{r, eval = F}
library(RcppRoll)
```
```{r}
vec <- c(2.7, 3.0, 1.5, 3.2, 1.6, 2.5)

roll_mean(vec, n = 3)
```


A janela (ou *window*) de uma média móvel, representa o número de observações que serão utilizadas no cálculo da média a cada "transição", ou a cada "rolagem". No exemplo acima, aplicamos uma média móvel com uma janela de 3 valores. Isso significa que a cada "rolagem", são utilizados 3 valores no cálculo da média. Na primeiro rolagem, temos a média do vetor `(2.7, 3.0, 1.5)`. Já na segunda rolagem, temos a média do vetor `(3.0, 2.5, 3.2)`. E assim por diante. Portanto, em uma representação visual, o cálculo da média móvel aplicada por `roll_mean()`, é apresentado na figura 7.6.

Perceba também que o cálculo de uma média móvel implica em perda de observações. Pois no exemplo anterior, o vetor `vec` possui 6 valores, já o resultado de `roll_mean()` possui apenas 4 valores. Diversas operações estatísticas como essa, possuem o mesmo efeito. Um outro exemplo, seriam as operações de diferenciação, que são muito utilizadas em análises de séries temporais, e produzem essa mesma perda de informação. Por outro lado, no caso exposto aqui, essa perda de observações, ocorre devido ao tamanho da janela para o cálculo da média móvel.

Ou seja, pelo fato de que definimos uma janela de 3 observações para o cálculo da média móvel acima, as duas primeiras observações do vetor `vec`, não podem gerar a sua própria média móvel. Dito de outra forma, a função `roll_mean()` não pode calcular uma média nas duas primeiras rolagens sobre o vetor `vec`. Pois na primeira rolagem sobre o vetor, `roll_mean()` possui apenas uma observação (`2.7`). Já na segunda rolagem, `roll_mean()` acumula ainda duas observações (`2.7, 3.0`). Apenas a partir da terceira rolagem, que `roll_mean()` poderá calcular uma média segundo o tamanho da janela que definimos para ela, pois ela agora possui três observações (`2.7, 3.0, 1.5`) disponíveis para o cálculo. A partir daí, `roll_mean()` vai continuar rolando e calculando as médias móveis, até atingir o conjunto final de três observações do vetor `vec` (`3.2, 1.6, 2.5`). 


Logo, sendo $j$ o número de observações presentes em cada janela de cálculo de sua média móvel, e $lvec$ sendo o número de valores presentes em seu vetor inicial, sobre o qual você irá calcular a sua média móvel. O número de médias móveis resultantes de `roll_mean()` ($obs$), será equivalente a: $obs = lvec - (j - 1)$. Em outras palavras, o número de observações que você irá perder ($perda$), no cálculo de sua média móvel será equivalente a: $perda = j - 1$.

```{r, echo = F, fig.cap="Representação do cálculo de uma média móvel"}

knitr::include_graphics("Figuras/media_movel.png")

```

Agora, pode ser de seu desejo, contornar essa perda de observações de alguma maneira. Especialmente se você está calculando essa média móvel com base em uma coluna de sua tabela, pois sendo este o caso, provavelmente será de seu interesse, guardar essas médias calculadas em uma nova coluna dessa tabela. Entretanto, se você criar uma tabela, alocando por exemplo o vetor `vec` em uma coluna, e tentasse adicionar uma nova coluna contendo as médias móveis de cada ponto do vetor, o R lhe retornaria o erro abaixo. Caso você se lembre das propriedades dos `data.frame`'s no R, você irá entender o porquê que está motivando esse erro. Pois todas as colunas de um `data.frame` devem possuir obrigatoriamente o mesmo número de observações. Como nós perdemos duas das seis observações de `vec`, no cálculo da média móvel, o R não permite alocarmos diretamente essas médias em nossa tabela `df`.

```{r, eval = FALSE}
df <- data.frame(x = vec)

df$media_movel <- roll_mean(df$x, n = 3)
```
```{r, highlight = F, eval = F}
Error in `$<-.data.frame`(`*tmp*`, media_movel, value = c(2.4, 
2.56666666666667, : replacement has 4 rows, data has 6.
```



A função `roll_mean()` oferece duas formas de contornar esse problema: 1) definir o alinhamento da função, para preencher as observações faltantes com valores não-disponíveis (`NA`); 2) ou preencher essas observações faltantes com um valor pré-definido, através de seu argumento `fill`. Ambas formas são válidas e possivelmente são o que você deseja. 

O primeiro método que citei, envolve o alinhamento da função, que você irá definir através do sufixos `r` e `l` no nome da função. A diferença entre os dois tipos de alinhamento, decide em que parte (no início, ou no final) do vetor resultante de `roll_mean()`, os valores não-disponíveis (`NA`) serão posicionados. Se você deseja utilizar o alinhamento à direita (*right* - `r`), você deve utilizar a função `roll_meanr()`. Mas se você quer utilizar o alinhamento à esquerda (*left* - `l`), você deve utilizar a função `roll_meanl()`. 

Quanto ao segundo método que citei, que envolve o argumento `fill`, você pode utilizar o argumento `align`, para definir em que partes do vetor resultante, o valor que você definiu em `fill` será posicionado. Por exemplo, caso eu use o valor *center* em `align`, o valor definido em `fill` vai aparecer tanto no início quanto ao fim do vetor que resulta da função `roll_mean()`. Mas se eu utilizar o valor *right* em `align`, esse valor irá aparecer ao início do vetor resultante.

```{r}
roll_meanr(vec, n = 3)
roll_meanl(vec, n = 3)

roll_mean(vec, n = 3, fill = 0, align = "center")
roll_mean(vec, n = 3, fill = 0, align = "right")
roll_mean(vec, n = 3, fill = 0, align = "left")
```




### Os dados da Covid-19 {#sec:dados_covid}

Na próxima seção, busco dar um exemplo prático de como as funções `complete()` e `fill()` que vimos nas seções anteriores, podem ser utilizadas em conjunto em um problema real. Para isso, vamos utilizar parte dos dados sobre a Covid-19 (SARS-COV-2) no Brasil. Ao utilizar o código abaixo, lembre-se de renomear a primeira coluna da tabela para `dia`. Dessa forma, nós evitamos confusões com qualquer função que possua um argumento chamado `data` (funções como `mutate()`, `select()`, `complete()`, `lm()` e muitas outras possuem tal argumento).

```{r, include = FALSE}
github <- "https://raw.githubusercontent.com/pedropark99/"
arquivo <- "Curso-R/master/Dados/covid.csv"

covid <- read_csv2(paste0(github, arquivo))

colnames(covid)[1] <- "dia"
```


```{r, eval = FALSE}
library(tidyverse)

github <- "https://raw.githubusercontent.com/pedropark99/"
arquivo <- "Curso-R/master/Dados/covid.csv"

covid <- read_csv2(paste0(github, arquivo))

colnames(covid)[1] <- "dia"
```


A Fundação João Pinheiro (FJP-MG) tem dado apoio técnico ao governo de Minas Gerais, no acompanhamento da pandemia de COVID-19, ao gerar estatísticas e estimações epidemiológicas para o estado. Eu fiz parte desse esforço por algum tempo, e uma demanda real que havia chegado para mim na época, concistia no cálculo de uma média móvel dos novos casos diários da doença para cada estado do Brasil. Pois era de desejo da Secretaria Estadual de Saúde, comparar a curva dessa média móvel do estado de Minas Gerais, com a de outros estados brasileiros. 

Na época em que trabalhei com a base `covid`, ela possuía algumas barreiras, que superei com o uso de `complete()` e `fill()`. São essas barreiras, e suas resoluções que busco mostrar nessa seção, como um exemplo real de uso dessas funções. Porém, a base `covid` que está disponível hoje, e que você acaba de importar através dos comandos acima, é a base já corrigida e reformatada e, por isso, ela já se encontra em um formato ideal para o cálculo de uma média móvel. Portanto, antes de partirmos para a prática, vou aplicar algumas transformações, com o objetivo de "corromper" a base `covid` até o seu ponto inicial. Pois o foco nessa seção, se encontra na demonstração dos problemas de formatação da base, e em suas possíveis soluções.


O primeiro ponto a ser discutido, são as datas iniciais da pandemia em cada estado brasileiro. No Brasil, a pandemia de Covid-19 atingiu primeiramente o estado de São Paulo, e chegou posteriormente aos demais estados. Como podemos ver pelo resultado abaixo, a data inicial de cada estado, ao longo da base `covid` é difusa. Em alguns estados, os registros se iniciam a partir da data do primeiro registro de casos da doença (como os estados do Acre, Alagoas, Bahia, Amazonas e Espírito Santo). Alguns estados, registraram mais de um caso já no primeiro dia (como o Acre, que registrou três casos no dia 17 de Março, e o Ceará, que reportou nove casos no dia 16 de Março). Porém, outros estados (como a Paraíba) não seguem esse padrão, pois no seu primeiro dia de registro, o número de casos reportados foi igual a zero. Ou seja, a pandemia no estado da Paraíba não se iniciou oficialmente no dia 12 de Março, pois não havia casos reportados até este dia.

```{r}
data_inicial <- covid %>% 
  group_by(estado) %>% 
  summarise(
    data_inicial = min(dia),
    casos_inicial = min(casos)
  )

data_inicial %>% print(n = 15)
```


Isso não representa um grande problema, mas antes das próximas transformações, devemos iniciar os dados de cada estado, no dia de primeiro registro de casos da doença. Isto é, os dados da Paraíba, por exemplo, devem se iniciar no dia em que houve pela primeira vez, um registro de casos maior do que zero. Como a coluna `casos`, representa o número acumulado de casos da doença, nós podemos realizar esse "nivelamento" entre os estados, ao eliminarmos da base, todas as linhas que possuem um número acumulado de casos igual a zero. Porém, vale a pena olharmos mais atentamente sobre essas linhas antes de eliminá-las, para termos certeza de que não estamos causando mais danos ao processo.

Perceba pelo resultado abaixo, que todos as linhas em que o número acumulado de casos se iguala a zero, pertencem ao estado da Paraíba. Todas essas seis datas, são "inúteis" para o propósito da base `covid`, pois apresentam um cenário anterior à pandemia no estado da Paraíba. Portanto, antes de prosseguirmos, vamos eliminar essas linhas, com o uso de `filter()`.

```{r}
covid %>% filter(casos == 0)

covid <- filter(covid, casos != 0)
```


A base `covid` atualmente possui os números de casos diários acumulados de cada estado brasileiro. Mas vamos supor, que a base `covid` registrasse o número de casos acumulados, somente nos dias em que esse número se alterasse. Ou seja, se o número de casos acumulados da doença em uma segunda-feira qualquer do ano, era de 300, e esse número se manteve constante ao longo da semana, até que na sexta-feira, esse número subiu para 301 casos, a base `covid` irá registrar os números de casos acumulados apenas para as datas da segunda e da sexta dessa semana. Tal resultado pode ser atingido com os comandos abaixo. Como nós filtramos anteriormente a base, de forma a retirar as linhas com valores iguais a zero na coluna `casos`, temos que reconstruir o objeto `data_inicial`, como exposto abaixo.

```{r}
data_inicial <- covid %>% 
  group_by(estado) %>% 
  summarise(
    data_inicial = min(dia),
    casos_inicial = min(casos)
  ) %>% 
  mutate(
    dia = as.Date(data_inicial - 1),
    casos = NA_real_,
    mortes = NA_real_
  )

covid <- covid %>% 
  bind_rows(
    data_inicial %>% select(dia, estado, casos, mortes)
  ) %>% 
  group_by(estado) %>% 
  arrange(
    dia,
    estado,
    .by_group = TRUE
  ) %>% 
  mutate(
    teste = lead(casos) == casos
  ) %>% 
  filter(teste == FALSE) %>% 
  ungroup() %>% 
  select(-teste)
```


Portanto, temos agora a tabela abaixo, onde podemos perceber que no dia 21 de Março de 2020 não houve alteração no número de casos acumulados no estado do Acre. Pois esse dia (`2020-03-21`) não está mais presente na tabela `covid`. Dito de outra forma, o número de novos casos de Covid-19 que surgiram no dia 21 de Março, foi igual a zero. O mesmo ocorre com os dias 25 e 27 de Março no estado, que também não estão mais presentes na base.

```{r}
covid
```

Quando trabalhei anteriormente com a base `covid` anteriormente, ela se encontrava inicialmente em um formato muito próximo deste. Por isso, a base necessitava de ajustes para o cálculo da média móvel. O intuito da próxima seção, é demonstrar como eu fiz esses ajustes necessários, através das funções `complete()` e `fill()`.


### Buscando soluções com `complete()` e `fill()`

Considerando que você aplicou as transformações expostas na seção anterior ([Os dados da Covid-19](#sec:dados_covid)), você está apto a aplicar os comandos apresentados nessa seção. Agora, em que sentido essa nova tabela que temos, é inapropriada para o cálculo da média móvel diária de novos casos? Porque agora faltam os registros dos dias em que não houve alteração no número acumulado de casos em cada estado. Ou seja, nós retiramos na seção anterior, justamente aquilo que queremos recuperar nessa seção. Como eu disse, o intuito dessas seções, está nos exemplos de uso das funções `complete()` e `fill()`, e não no caminho que temos que percorrer para estarmos aptos para a aplicação desses exemplos.


Portanto, o problema que possuímos agora no cálculo da média móvel sobre a base `covid`, é que faltam os dias onde o número de casos acumulados permaneceu constante. Isso significa que agora temos uma quebra no cálculo da média móvel. Caso o vetor `vec` abaixo, representasse uma parte da coluna `casos` da nossa base `covid`, se aplicássemos uma média móvel, com uma janela de 3 valores, as médias dos dias 03 e 04 não poderiam ser calculadas (ou no mínimo, estariam incorretas), tendo em vista as transformações que aplicamos na seção anterior. 


Ou seja, considerando que nós eliminamos na seção anterior, todas as linhas de `covid`, onde o número acumulado de casos permaneceu constante em relação ao seu valor anterior; se aplicarmos a mesma transformação ao vetor `vec` abaixo, o valor referente ao dia 02 seria eliminado, e por isso, uma quebra ocorreria sobre o cálculo das médias móveis dos dias 03 e 04. Pois, dentre os valores dos 3 dias anteriores aos dias 03 e 04, estaria faltando o valor referente ao dia 02. 


```{r}
vec <- c("Dia 01" = 1, "Dia 02" = 1, "Dia 03" = 3, 
         "Dia 04" = 5, "Dia 05" = 7)

vec
```


São por essas razões, que devemos recuperar os dias perdidos na tabela `covid`, mesmo que o número de casos nesses dias tenham permanecido constantes. No nosso caso, não podemos utilizar diretamente as colunas da base `covid`, para expandirmos a tabela, e recuperarmos as datas que foram perdidas. Pois essas datas não se encontram mais na tabela `covid`. Lembre-se que a função `complete()` irá sempre trabalhar com as observações que estão presentes em sua base, caso você não forneça algo a mais, com a qual ela possa trabalhar. Por isso, teremos que gerar na função `complete()`, um vetor externo à base `covid`, de forma a incluirmos todas as datas que faltam.









```{r grafico monstruoso, include = F}
library(readxl)
estados_siglas <- read_excel("C:/Users/Pedro/Documents/estados_siglas.xlsx")

set.seed(1)
n <- rnorm(nrow(covid), 1500, 500)

teste <- covid %>% 
  mutate(
    dia_quebra = if_else(n > 800, dia, as.Date(NA_real_))
  ) %>% 
  right_join(
    data_inicial[c("data_inicial", "estado")],
    by = "estado"
  ) %>% 
  mutate(
    quebra_inicial = dia <= data_inicial,
    quebra_posterior = dia > data_inicial
  ) %>% 
  filter(
    estado %in% c("SP", "MG", "RJ", "CE", "BA", "RS")
  ) 


menor_data <- min(data_inicial$data_inicial)
maior_data <- max(covid$dia)

grafico <- teste %>% 
  inner_join(
    estados_siglas[c("Sigla", "Nome")],
    by = c("estado" = "Sigla")
  ) %>% 
  ggplot() +
  geom_linerange(
    aes(xmin = data_inicial, xmax = maior_data, y = Nome, color = "Quebras atuais na série"),
    size = 1
  ) +
  geom_linerange(
    aes(xmin = menor_data, xmax = data_inicial, y = Nome, color = "Fase inicial da pandemia"),
    size = 1
  ) +
  geom_path(
    aes(x = dia_quebra, y = Nome),
    size = 1
  ) +
  labs(color = NULL) +
  theme(
    axis.title = element_blank(),
    panel.background = element_rect(fill = "white", colour = NA),
    panel.grid = element_line(colour = "grey92"), 
    panel.grid.minor = element_line(size = rel(0.5)),
    #axis.ticks = element_blank(),
    legend.position = "bottom"
  )
```



```{r, echo = FALSE, out.width="90%", warning=F, fig.cap="Representação das séries temporais da base `covid` pré e pós-transformações"}
print(grafico)
```







Antes de prosseguir, vamos compreender exatamente qual é o estado atual da base `covid`. Nós eliminamos (na seção anterior) parte dos dias da base. Mais especificamente aqueles dias em que o número acumulado de casos da doença, permaneceu constante em relação a seu valor anterior. Portanto, neste momento, as séries temporais do número de casos de cada estado apresentam quebras. Em uma representação visual, essas séries se assemelham no momento às linhas em cor preta, apresentadas no gráfico da figura 7.7. São essas quebras que nos impedem de calcularmos uma média móvel desses casos.





O primeiro passo, será expandir essas séries com a função `complete()`. Utilizando-se de um vetor (construído pela função `seq.Date()`), contendo desde o dia 1 da pandemia no país (dia dos primeiros casos no estado de São Paulo, onde a pandemia se iniciou) até o último dia da base. Com isso, a função `complete()` irá combinar cada uma dessas datas, com cada um dos 27 estados. Após essa expansão da tabela `covid`, as séries de cada estado vão incluir todas as datas possíveis, incluindo aquelas que originalmente não pertenciam aquele estado. Dessa forma, as séries de cada estado, vão ser equivalentes à junção das linhas pretas, azuis e vermelhas no gráfico da figura 7.7. Formando assim novamente uma série "sólida", ou completa.



```{r}
menor_data <- min(data_inicial$data_inicial)
maior_data <- max(covid$dia)

novo_covid <- covid %>% 
  complete(
    dia = seq.Date(menor_data, maior_data, by = "day"),
    estado
  ) %>% 
  group_by(estado) %>% 
  arrange(dia, estado, .by_group = T) %>% 
  ungroup()

novo_covid
```



O segundo passo, será "nivelar" as séries de acordo com o período inicial de cada estado. Pois, como resultado do passo anterior, as séries de todos os estados serão iguais em comprimento (ou em número de observações). Pois as séries de todos os estados, estarão incluindo desde o dia 1 da pandemia, até o último dia da pandemia. Portanto, seguindo o gráfico da figura 7.7, no segundo passo estaremos eliminando a área vermelha de cada série, de forma que as séries de cada estado vão se equivaler à junção das linhas em preto e azul. Para isso, podemos aplicar os comandos abaixo:

```{r}
novo_covid <- novo_covid %>% 
  right_join(
    data_inicial[c("estado", "data_inicial")],
    by = "estado"
  )

teste <- novo_covid$dia >= novo_covid$data_inicial

novo_covid <- novo_covid[teste, ]

novo_covid
```


O terceiro passo, envolve o uso de `fill()` para completarmos o número de casos em cada data recuperada. Lembre-se que ao expandirmos a tabela com `complete()`, a função preecheu os campos das colunas `casos` e `mortes` com valores não-disponíveis (`NA`), na linha de cada data que não estava presente anteriormente na base `covid` (ou seja, as datas que foram perdidas anteriormente). Portanto, todas as linhas que possuem um valor `NA` nessas colunas, são as linhas que correspondem aos dias em que o número acumulado de casos se manteve constante. Como esse número se manteve constante, tudo o que precisamos fazer, é utilizar `fill()` para puxar os valores disponíveis anteriores para esses campos.

```{r}
novo_covid <- novo_covid %>% 
  fill(casos, mortes, .direction = "up")

novo_covid
```


Dessa forma, temos novamente, a tabela corretamente formatada, e pronta para o cálculo de uma média móvel. O número acumulado de casos certamente tende a aumentar com o tempo, mas será que a variação desse número, segue o mesmo padrão? Para calcularmos essa variação, podemos utilizar a função `lag()` para utilizarmos o valor da linha anterior de uma coluna. Com isso, podemos subtrair o valor da linha anterior, sobre o valor da linha atual, tirando assim, a diferença ou a variação entre elas. Em seguida, basta aplicarmos a função `roll_meanr()` sobre esta variação, para adquirirmos uma média móvel do número de novos casos diários.

```{r}
library(RcppRoll)

novo_covid <- novo_covid %>% 
  group_by(estado) %>% 
  mutate(
    novos_casos = casos - lag(casos),
    media_casos = roll_meanr(novos_casos, n = 5)
  )

novo_covid
```



```{r, out.width="90%"}
t <- "Média móvel de 5 dias para os novos casos de Covid-19 nos estados
da região Sudeste"

novo_covid %>% 
  filter(estado %in% c("SP", "MG", "RJ", "ES")) %>% 
  ggplot() +
  geom_line(
    aes(x = dia, y = log(media_casos), color = estado),
    size = 1
  ) +
  theme(
    legend.position = "bottom",
    axis.title.y = element_blank(),
    plot.title = element_text(face = "bold")
  ) +
  labs(
    title = t,
    subtitle = "Escala logarítmica",
    x = "Tempo",
    color = "Unidade da Federação"
  )
```








```{r, child = "Exercícios/exec_cap7.Rmd"}

```





