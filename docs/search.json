[{"path":"index.html","id":"bem-vindo","chapter":"Bem vindo!","heading":"Bem vindo!","text":" Olá! Este é o site livro “Introdução à Linguagem R: seus fundamentos e sua prática.” Aqui você pode ler o conteúdo livro de maneira eficiente e gratuita. Para mais, você também pode baixar uma versão em PDF deste livro de forma gratuita, através da página de publicação livro.","code":""},{"path":"sobre-os-autores.html","id":"sobre-os-autores","chapter":"Sobre os autores","heading":"Sobre os autores","text":"Pedro Duarte FariaPedro Duarte Faria é graduando em Economia pela Universidade Federal de\nOuro Preto - UFOP. Atualmente é Analista de Performance e Inteligência de Negócios na Take Blip. Como pesquisador, tem atuado em especial na área de Economia da Ciência e da Tecnologia, tendo\nganhado recentemente um prêmio por sua pesquisa apresentada XXI\nSeminário de Economia Industrial (SEI), realizado pelo\nGEEIN/FClAr-UNESP.Lattes: http://lattes.cnpq.br/0308632529554550Site pessoal: https://pedro-faria.netlify.app/Twitter: @PedroPark9João Pedro Figueira Amorim PargaJoão Pedro Figueira Amorim Parga é mestre em Economia pelo CEDEPLAR-UFMG\n(2020), e possui graduação em Economia pela mesma instituição. Atualmente é Pesquisador Assistente\nInstituto de Pesquisa Econômica Aplicada (IPEA). Possui\nexperiência em Economia Regional e Urbana, especialmente nos seguintes\ntemas: distribuição espacial de atividades econômicas, setor de\nserviços, ciência de dados, habitação, aglomeração espacial e geografia\neconômica.Lattes: http://lattes.cnpq.br/8639351648030747","code":""},{"path":"prefácio.html","id":"prefácio","chapter":"Prefácio","heading":"Prefácio","text":"","code":""},{"path":"prefácio.html","id":"o-que-é-esse-livro","chapter":"Prefácio","heading":"O que é esse livro?","text":"Este livro surgiu inicialmente, como um material de apoio aos pesquisadores e alunos Curso Introdutório de R, que foi realizado durante o primeiro semestre de 2020, na Fundação João Pinheiro1 (FJP-MG). O projeto foi idealizado na época, por um conjunto de três pessoas, dentre elas, estão os autores desta obra: Pedro Duarte Faria e João Pedro Figueira Amorim Parga. Portanto, esse material é resultado dessa experiência de ensino, onde buscamos compartilhar conhecimentos sobre essa linguagem com outras pessoas. Eu como professor, aluno e economista, sou muito grato por ter compartilhado essas experiências, com meu querido colega João Pedro Figueira Amorim Parga, que ajudou montar esse livro.origens da linguagem R, remetem um dos mais importantes laboratórios de pesquisa mundo, Bell Labs, localizada nos EUA. Por sua origem, enorme maioria dos materiais de referência respeito da linguagem, estão em inglês, incluindo principais fontes de ajuda da linguagem, como o StackOverflow, ou páginas e manuais internos CRAN R.Entretanto, comunidade de R Brasil, tem se expandido constantemente nos últimos anos. Brasileiros tem desenvolvido importantes pacotes para linguagem, que trazem grande apoio à produção científica país. Apenas para citar alguns desses excelentes trabalhos, estão (Pereira et al. 2020; Petruzalek 2016; McDonnell, Oliveira, Giannotti 2020; Siqueira 2020; Braga, Assuncao, Hidalgo 2020). Como resultado, bons materiais em português, de referência e apoio à linguagem tem surgido. Exemplos são: os materiais curtos montados pelo Curso R; os trabalhos realizados pelos capítulos brasileiros grupo R-Ladies, como os posts capítulo de Belo Horizonte, e os encontros desenvolvidos pelo capítulo de São Paulo; além de alguns materias produzidos pelo Departamento de Estatística da UFPR, como um site de apoio ao seu curso, ou este produzido por um dos professores departamento, o Dr. Walmes Marques Zeviani.Porém, mesmo com esse avanço, grande parte desses conteúdos em português geralmente caem em algum desses dois problemas: 1) carecem de profundidade, ou de detalhamento sobre o que está “ocorrendo nos bastidores.” Em outras palavras, esses materiais são um pouco abstratos, pois tentam abordar muita coisa em um espaço muito curto, sem dar o devido tempo cada um dos componentes por trás da linguagem; 2) ou são especializados demais. Por exemplo, materiais que ensinam como estimar modelos específicos (ex: regressão linear sobre dados em painel), ou trabalhar com bases de dados específicas (ex: PNAD contínua). Em outras palavras, esses materiais concedem em geral, uma visão muito restrita sobre linguagem, e que é de difícil transposição para outros cenários e necessidades práticas.Esses problemas emergem próprio objetivo que esses materiais buscam cumprir. Como exemplo, os materiais escritos pelo Curso-R carregam certa abstração, pois em nenhum momento esses materiais pretendem oferecer uma revisão completa e profunda sobre o tema, mas sim, tutoriais rápidos e úteis, que lhe mostram o básico. Tendo isso em mente, esta obra em específico, representa nossa tentativa de combater esses dois problemas. Ao discutir pacotes largamente utilizados nas mais diversas aplicações, além de fornecer uma visão aprofundada sobre os fundamentos (ou teoria) da linguagem R. Por isso, o público-alvo deste livro são os brasileiros que desejam obter uma base mais sólida e uma visão mais abrangente da linguagem, de forma que eles possam identificar mais facilmente, possíveis soluções que o R oferece para vários problemas diferentes de seu trabalho.Por essas razões, este material é até certo ponto, prolixo em muitos assuntos aos quais são comumente tratados como simples e rápidos de se compreender (e.g. Objetos). Ao mesmo tempo, este material certamente busca ser descritivo, e não poupa detalhes em assuntos que são complexos e de difícil compreensão (e.g. Funções e Loops). Para mais, fornecemos ao longo da obra, diversos diagramas e representações visuais, que ajudam o leitor, formar um modelo mental sobre como linguagem R funciona. obra também oferece exercícios ao final de cada capítulo, além de suas respostas ao final livro.Vários exemplos são fornecidos em cada tópico. Alguns desses exemplos são reais e retirados diretamente de nosso dia--dia com linguagem. Já uma outra parte desses exemplos, buscam evidenciar ou demonstrar problemas práticos que podem emergir de seu trabalho com linguagem e, portanto, mostrar quais são possíveis soluções serem empregadas. Dessa forma, podemos construir um workflow, ou um modelo mental de trabalho com linguagem, ao longo de diferentes tópicos importantes para sua aplicação prática em análise de dados.Você sempre pode encontrar uma versão atualizada dessa obra, em sua página de publicação. Este documento foi criado dentro RStudio, por meio pacote rmarkdown e sistema . Grande parte conhecimento exposto aqui, está baseado em diversas referências sobre linguagem R, em especial os trabalhos de (Wickham 2015a; Peng 2015; Wickham Grolemund 2017; Long Teetor 2019),\nassim como documentação oficial da linguagem R (R Core Team 2020b, 2020a).\nPedro Duarte Faria\n06/06/2021\nBelo Horizonte - MG\nBrasil\n","code":""},{"path":"prefácio.html","id":"novidades-desta-segunda-edição-e-o-futuro-desta-obra","chapter":"Prefácio","heading":"Novidades desta segunda edição e o futuro desta obra","text":"Esta segunda edição traz dois importantes complementos que aproximam esta obra de seu objetivo principal (ser um livro técnico e introdutório sobre linguagem R). Primeiro, esta edição traz dois novos capítulos ao leitor, os quais buscam descrever os dois tipos de vetor S3 mais importantes da linguagem R, isto é, os fatores (factor) e os tipos focados em variáveis de tempo (Date, POSIXct, POSIXlt e difftime). Tais capítulos são “Capítulo 11 - Introduzindo fatores (factor’s) com forcats” e “Capítulo 12 - Introduzindo variáveis de tempo com lubridate.”Já segunda novidade (e na minha visão, mais importante) desta edição conciste na introdução de exercícios ao final de cada capítulo, além de suas respostas ao final livro. Exercícios estão presentes em praticamente todo livro técnico, e representam uma etapa muito importante aprendizado, ao ajudarem o leitor aplicar e apreender o conhecimento adquirido. Por esses motivos, essa adição representa um passo extremamente importante para este livro.Mesmo com essas alterações, ainda existem diversas outras adições programadas para próximas edições. Em outras palavras, este livro ainda está início de sua vida e possui um longo caminho pela frente. Por exemplo, ele ainda carece de alguns assuntos muito importantes para linguagem em sua atualidade, como ferramentas para functional programming e meta-programming, os quais são certamente os próximos passos livro.","code":""},{"path":"prefácio.html","id":"porque-aprender-r-quais-são-as-suas-vantagens","chapter":"Prefácio","heading":"Porque aprender R? Quais são as suas vantagens?","text":"","code":""},{"path":"prefácio.html","id":"computadores-e-linguagens-de-programação","chapter":"Prefácio","heading":"Computadores e linguagens de programação","text":"O R é um ambiente para computação e análise estatística, que possui uma linguagem de programação própria. Para realizar suas atividades R, você escreve comandos que estão semanticamente de acordo com regras e padrões dessa linguagem.Nós como seres humanos, nos comunicamos uns com os outros através da fala, da escrita, da arte, conhecimento, e de várias outras ferramentas ao nosso dispor, e sempre que estamos utilizando alguma dessas ferramentas, estamos sempre utilizando uma linguagem, ou uma língua específica. Essa língua pode ser algo como o português ou o inglês, mas também pode ser algo como jargões, ou até o estilo de pintura (aquarela, tinta óleo, etc.) que confere diferentes pesos e gera diferentes sensações nos observadores de sua obra de arte.Apesar dessas várias opções, nós não podemos utilizar diretamente essas ferramentas para nos comunicarmos com os nossos computadores, pois eles entendem apenas uma língua (bytes), e essa língua é extremamente difícil para nós seres humanos. Por essa razão, diversas linguagens de programação existentes são uma ferramenta de comunicação, criadas justamente com o intuito de facilitar essa comunicação entre você (como usuário) e o seu computador.Este livro busca lhe ensinar os fundamentos da linguagem R, e como você pode utilizá-la para se comunicar com o seu computador. Entretanto, essa linguagem é uma ferramenta de comunicação não apenas para o seu computador, mas também para pessoas que trabalham com você, ou que acompanham o seu trabalho. Pois o código que você escreve R, carrega sua metodologia e os seus resultados, e portanto, pode ser utilizado para comunicar suas intenções e suas conclusões em uma análise.Com isso, é natural pensarmos trabalho necessário para compreensão de uma língua completamente nova. Entretanto, linguagens de programação mais populares, hoje, para análise de dados (Python e R) são linguagens fáceis de se aprender. Pois essas linguagens fizeram escolhas (ao serem criadas) que reduzem muito o seu trabalho, e agilizam o seu aprendizado. Por exemplo, nessas linguagens, você não precisa se preocupar em especificar como você deseja alocar os seus dados em memória (algo que é comumente chamado por memory management em ciência da computação), ambas fazem este trabalho por você. Essas linguagens também são linguagens interpretadas, logo, você não precisa se preocupar em compilar o seu código antes de executá-lo.","code":""},{"path":"prefácio.html","id":"velocidade-e-capacidade-de-processamento","chapter":"Prefácio","heading":"Velocidade e capacidade de processamento","text":"Em resumo, linguagens como Python e R possuem um nível de abstração mínimo, que facilita muito sua compreensão e o seu trabalho com elas. Por outro lado, devido essas escolhas, essas linguagens (Python e R) não são particularmente rápidas se comparadas com outras linguagens que lhe obrigam especificar cada componente de sua análise, como linguagens C e C++. Pois o computador tem de reservar um tempo para calcular e compilar essas especificações por você.Porém, essas linguagens ainda assim são muito mais rápidas que programas como Excel, e lidam muito melhor com grandes quantidades de dados. Por exemplo, se você usa o Excel em seu trabalho, você provavelmente sabe que suas versões mais recentes são capazes de abrir arquivos com mais de 1 milhão de linhas. Mas se você já tentou, por exemplo, adicionar uma nova coluna este arquivo, você rapidamente percebeu que o Excel não foi feito para lidar eficientemente com arquivos desta magnitude.Com linguagens como o R, você possui uma capacidade de processamento maior, e os seus problemas geralmente se limitam quantidade de memória que você possui em seu computador. Se você possui memória suficiente para alocar uma tabela com mais de 1 milhão de linhas, o seu trabalho com esses dados será muito mais rápido e eficiente R. E como os componentes de computadores tem ficado cada vez mais baratos, essa vantagem tende aumentar com o tempo. Hoje, um cartucho de 16GB de RAM (que já é uma quantidade muito boa de memória) é muito mais barato, que ele era 10 anos atrás.","code":""},{"path":"prefácio.html","id":"reproducibilidade-automatizando-processos-e-reduzindo-riscos","chapter":"Prefácio","heading":"Reproducibilidade: automatizando processos e reduzindo riscos","text":"Vamos um exemplo prático! Eu comecei aplicar linguagem R, quando ainda trabalhava na Diretoria de Estatística e Informações da Fundação João Pinheiro (FJP) como estagiário. FJP é uma instituição de pesquisa ligada à Secretaria de Estado de Planejamento e Gestão de Minas Gerais, e é responsável pela produção e divulgação das principais estatísticas econômicas e demográficas estado de Minas Gerais.Na época, uma de minhas responsabilidades era produção de mapas temáticos para os informativos mensais de PIB das regiões intermediárias estado. Eu poderia facilmente gerar esses mapas, utilizando programas especializados como o QGis. Porém, o QGis possui uma desvantagem fundamental em relação ao R, especialmente em uma tarefa simples como essa. Onde cada uma das etapas processo (importando os dados de PIB, importanto os shapefiles, escolhendo cores mapa, escolhendo os títulos e rótulos, criando uma legenda, etc.) não são salvas em algum lugar. Com isso, eu quero destacar que o mapa que eu crio QGis, não é reproduzível!Essas considerações são muito importantes, pois quase sempre eu tinha que reconstruir o mapa. Seja porque o editorial sugeriu o uso de novas cores, ou porque o tamanho da fonte está pequena, ou principalmente, porque erros podem surgir processo! Se o mapa gerado pelo QGis possui um erro, seja por falha humana ou computador, eu tenho que recomeçar o trabalho zero, pois etapas processo não foram salvas de alguma forma.É tendo essas preocupações em mente, que eu possuo um script R, que guarda todos os comandos necessários para produzirmos esses mapas. Dessa maneira, não apenas cada etapa processo é contida e salva em cada comando R utilizado, mas eu também posso reproduzir cada uma dessas etapas (ou comandos), com muita facilidade, ao longo de vários pontos diferentes. Isso significa, por exemplo, que eu posso criar um mapa com mesmas especificações, para cada uma das 13 regiões intermediárias, em questão de segundos, e utilizando apenas 1 comando.figura abaixo, é uma representação deste script, onde delimito cada uma das etapas que o R realiza para construir esses mapas por mim. Se nossa equipe descobre um erro mapa, eu posso voltar ao script, e executá-lo parte por parte, e descobrir em qual delas o erro surge. Será que eu errei ao filtrar os dados? Ou o R não conseguiu gerar o gráfico corretamente? Ou será que o erro aparece antes mesmo de eu importar os dados para o R?\nFigure 0.1: Um exemplo de script contendo comandos R\npartir momento em que eu descubro em qual parte de meu script o erro ocorre, eu posso corrigir o erro naquele local em específico, e após assegurar de que tudo está ok, eu posso executar todo o script novamente, e assim, o novo mapa contendo correções aplicadas é gerado em questão de segundos. Dessa forma, eu estou automatizando etapas repetitivas que possuo em meu trabalho, e não preciso começar zero caso algum erro ocorra durante o processo.Neste caso, eu posso inclusive criar alguns processos automatizados que conferem robustez dos dados, para evitar que erros humanos gerem mais dor de cabeça que o necessário. Por exemplo, se na minha base de dados, cada linha representa um município de Minas Gerais, eu posso criar um sistema que confere se esta base possui 853 linhas (número total de municípios estado de Minas Gerais). Como os mapas são geralmente produzidos para cada região intermediária estado, eu posso também, certificar que o número de linhas (ou o número de municípios) que compõe cada região intermediária dessa base, estão corretos.","code":""},{"path":"prefácio.html","id":"conexões-e-apis","chapter":"Prefácio","heading":"Conexões e API’s","text":"linguagem R possui vários pacotes e interfaces que facilitam sua conexão com servidores e outras linguagens. Exemplos são os pacotes DBI e odbc, que são muito utilizados para conexão de sua sessão R, com servidores SQL (Structured Query Language). Com essa conexão, você pode puxar resultados de queries direto servidor para sua sessão R.Outro exemplo, é o pacote Rcpp que provê uma boa interface entre o R e linguagem C++. Com este pacote, você pode misturar comandos em C++ com os seus comandos em R, com o objetivo de utilizar uma linguagem mais rápida (C++) em processos que são, por natureza, muito trabalhosos para o seu computador. Além disso, tanto o Python quanto o R, possuem interfaces para se comunicar um com o outro. Isto é uma ferramenta muito poderosa! Pois você pode se aproveitar melhor que duas principais linguagens utilizadas em análise de dados podem oferecer. O R possui um arsenal estatístico melhor que o Python, porém, ele não possui conectividade e amplitude de aplicações que o Python oferece. Logo, caso R, você pode utilizar o pacote reticulate, que fornece uma boa interface para o interpretador Python.Para mais, grande desenvolvimento tem sido empregado em serviços web. Uma área que até pouco tempo, possuia pouco suporte dentro da linguagem R. Hoje, você já pode criar sites (pacote blogdown) e dashboards interativos (pacote shiny) com os recursos disponíveis. Também há pacotes como httr e rvest, que possibilitam realização de atividades de web scrapping. Além dos pacotes xml2 e jsonlite, que permitem leitura de dados em XML e JSON, respectivamente. Para esse tópico, você pode descobrir mais pacotes na seção de Web Technologies CRAN R.Por útlimo, o time da Microsoft, também tem desenvolvido interfaces em seus serviços da Azure Cloud Computing, permitindo que você utilize R em seus projetos na plataforma. Caso esteja interessado nisso, você pode consultar página da empresa sobre este serviço2.","code":""},{"path":"prefácio.html","id":"comunidade","chapter":"Prefácio","heading":"Comunidade","text":"O R é uma linguagem gratuita e open source e, por isso, o seu crescimento como linguagem depende não apenas da fundação que mantém e atualiza (R Foundation), mas também depende de sua comunidade que está o tempo todo discutindo, inovando e abrindo novos caminhos, tudo isso de forma aberta e gratuita. Esta obra é uma contribuição essa comunidade e um convite você. Venha para comunidade de R!Portanto, comunidade é um dos principais ativos da linguagem R (e também Python). Grande parte dessa comunidade, está concentrada Twitter. Mas essa comunidade também está muito presente em blogs, comentando novas soluções e recursos para linguagem (sendo o Tidyverse blog, Rweekly e ROpensci os principais exemplos) e, com isso, você pode se manter atualizado sobre o que linguagem oferece. Por outro lado, parte desses blogs, possuem um foco maior em tutoriais, e representam assim, um local em que você sempre pode aprender mais sobre o R (o principal exemplo dessa categoria se trata R-Bloggers).Recentemente, um novo e excelente centro de discussão foi criado pela comunidade, denominado R4DS Online Learning Community, um nome que claramente se refere obra de Wickham Grolemund (2017). Esse é um ótimo local para criar conversas com membros da comunidade, e pedir por ajuda em algum problema que você esteja enfrentando.Além disso, comunidade de R também possui forte presença StackOverflow, que é comumente caracterizado como o principal canal de dúvidas e de ajuda em diversas linguagens de programação. Logo, se você não sabe como realizar um processo, ou não consegue descobrir de onde um erro está surgindo em seu script, você pode pedir por ajuda da comunidade ao postar uma pergunta, ou encontrar uma pergunta parecida com o seu problema que já foi respondida StackOverflow.caso Brasil, principal força motriz de nossa comunidade provavelmente se encontra nos capítulos brasileiros R-Ladies global, além blog Curso-R. Por exemplo, temos os encontros mensais online realizados pelo capítulo de São Paulo, além dos bons tutoriais escritos pelo capítulo de Belo Horizonte. Existem também, outros capítulos Brasil3, que também realizam alguns encontros.\nFigure 0.2: Code Hero por Allison Horst\n","code":""},{"path":"noções-básicas-do-r.html","id":"noções-básicas-do-r","chapter":"Capítulo 1 Noções Básicas do R","heading":"Capítulo 1 Noções Básicas do R","text":"","code":""},{"path":"noções-básicas-do-r.html","id":"uma-descrição-do-r","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.1 Uma descrição do R","text":"","code":""},{"path":"noções-básicas-do-r.html","id":"história-do-r","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.1.1 História do R","text":"linguagem R, nasceu durante década de 90, inicialmente como um projeto de pesquisa de Ross Ihaka e Robert Gentleman, ambos estatísticos e pesquisadores associados na época ao departamento de estatística da Universidade de Auckland (Ihaka Gentleman 1996). Porém, origens da linguagem R retornam década de 70, com o desenvolvimento da linguagem S, em um dos mais importantes laboratórios de pesquisa mundo, Bell Labs (Peng 2015).Pois como foi descrito por Ihaka Gentleman (1996), linguagem R foi desenvolvida com fortes influências das linguagens S e Scheme. Sendo que própria sintaxe da linguagem R, se assemelha muito da linguagem S. Por isso, muitos autores como Peng (2015) e Chambers (2008), caracterizam linguagem R como um dialeto da linguagem S. Segundo Ihaka Gentleman (1996) linguagem S representava uma forma concisa de se expressar idéias e operações estatísticas para um computador e, por isso, foi uma fonte de inspiração importante para o R. Em outras palavras, comparado às demais linguagens, linguagem S oferecia uma sintaxe mais atrativa e confortável para estatísticos executarem suas ideias, e grande parte dessa sintaxe, foi transportada para o R.","code":""},{"path":"noções-básicas-do-r.html","id":"r","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.1.2 R","text":"R é um software estatístico que oferece um ambiente para análise interativa de dados, e que conta com uma poderosa linguagem de programação, e é dessa linguagem que vamos tratar neste livro. Diferente de outras linguagens como C e C++, que são linguagens compiladas, linguagem R é uma linguagem interpretada. Isso significa, que para trabalharmos R, vamos estar constantemente enviando comandos escritos para o Console programa, e esse Console vai avaliar os comandos que enviarmos (segundo “regras gramaticais” da linguagem R), antes de executá-los.Logo, o console é o coração R, e mais importante ferramenta programa (Adler 2010, p 11), pois é nele que se encontra o interpretador que vai avaliar e executar todos os nossos comandos. O uso de uma linguagem de programação, representa uma maneira extremamente eficiente de se analisar dados, e que de certa forma, adquire um aspecto interativo R, ou cria uma sensação de que estamos construindo (interativamente) uma conversa com o console. Ou seja, o trabalho R funciona da seguinte maneira: 1) você envia um comando para o console; 2) o comando é avaliado pelo console e é executado; 3) o resultado desse comando é retornado pelo console; 4) ao olhar para o resultado, você analisa se ele satisfaz os seus desejos; 5) caso não, você faz ajustes em seu comando (ou utiliza um comando completamente diferente), e o envia novamente para o console; e assim, todo o ciclo recomeça.","code":""},{"path":"noções-básicas-do-r.html","id":"sec:sistema_universo_r","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.1.3 O sistema e universo do R","text":"O universo R pode ser divido em duas partes, sendo elas:O sistema “básico” R, que é composto pelos pacotes básicos da linguagem. Esses pacotes são base da linguagem R, e são comumente chamados pela comunidade, por base R. Pois diversas das funções básicas R, advém de um pacote chamado base. Lembrando que você pode baixar e instalar esses pacotes básicos, pelo site Comprehensive R Archive Network (CRAN R).O sistema “básico” R, que é composto pelos pacotes básicos da linguagem. Esses pacotes são base da linguagem R, e são comumente chamados pela comunidade, por base R. Pois diversas das funções básicas R, advém de um pacote chamado base. Lembrando que você pode baixar e instalar esses pacotes básicos, pelo site Comprehensive R Archive Network (CRAN R).Todo o resto, ou mais especificamente, todos os pacotes externos ao sistema “básico,” desenvolvidos pelo público em geral da linguagem. grande maioria desses pacotes também estão disponíveis através Comprehensive R Archive Network (CRAN R), mas alguns outros estão presentes apenas em outras plataformas, como o GitHub.Todo o resto, ou mais especificamente, todos os pacotes externos ao sistema “básico,” desenvolvidos pelo público em geral da linguagem. grande maioria desses pacotes também estão disponíveis através Comprehensive R Archive Network (CRAN R), mas alguns outros estão presentes apenas em outras plataformas, como o GitHub.Todas funcionalidades e operações disponíveis R, são executadas através de suas funções, e essas funções são divididas em “pacotes.” O sistema “básico” R, contém um conjunto de pacotes que oferecem funcionalidades básicas da linguagem. Alguns desses pacotes básicos, são base (fornece funções de uso geral) e stats (fornece funções para análises e operações estatísticas). Caso você precise de funcionalidades que vão além que está disponível neste sistema “básico,” ou neste conjunto de pacotes “básicos” R, é neste momento em que você precisa instalar outros pacotes que estão fora desse sistema “básico,” e que oferecem funções que possam executar funcionalidades que você deseja. Vamos dissecar alguns desses pacotes “externos” ao longo deste material, com especial atenção ao conjunto de pacotes fornecidos pelo tidyverse.Pelo fato R ser gratuito e open source, várias pessoas estão constantemente desenvolvendo novas funcionalidades, e efetivamente expandindo o universo da linguagem R. Esses pacotes desenvolvidos pelos próprios usuários da linguagem, servem como grande apoio ao trabalho de outros usuários. Ou seja, se você possui um problema sua frente, é muito provável que alguém tenha enfrentado o mesmo problema, ou algo próximo, e que tenha desenvolvido uma solução para aquele problema formato de um pacote R. Assim, você pode resolver os seus problemas, com ajuda trabalho de outras pessoas que passaram pelas mesmas dificuldades.","code":""},{"path":"noções-básicas-do-r.html","id":"rstudio","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.1.4 RStudio","text":"O RStudio, é um Ambiente de Desenvolvimento Integrado (Integrated Development Environment - IDE, em inglês) para o R. Em síntese, esse programa oferece um ambiente com diversas melhorias, atalhos e ferramentas que facilitam de maneira expressiva, o seu trabalho com o R. Algumas dessas funcionalidades incluem: indentação automática, realçes de código, menus rápidos para importação e exportação de arquivos, além de diversos atalhos de teclado úteis. Sendo portanto, uma ferramenta muito recomendada para qualquer usuário que venha trabalhar com linguagem R (Gillespie Lovelace 2017).Para encontrar mais detalhes sobre o programa, você pode consultar o site oficial RStudio.","code":""},{"path":"noções-básicas-do-r.html","id":"introdução-ao-r-e-rstudio-noções-básicas","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.2 Introdução ao R e RStudio: noções básicas","text":"","code":""},{"path":"noções-básicas-do-r.html","id":"sec:console","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.2.1 Executando comandos: Console","text":"Você trabalha R através de sua linguagem de programação. Você importa os seus dados, remove ou acrescenta colunas, reordena sua base, constrói gráficos, e estima os seus parâmetros, através de comandos escritos que devem ser interpretados e executados pelo Console. Qual o porquê de tudo isso? Por que precisamos de um console para interpretar os nossos comandos? resposta se encontra fato de que o seu computador não fala sua língua!Ou seja, o seu computador não sabe o que os verbos “ordenar” e “selecionar” significam, estejam eles em qualquer língua humana que você conseguir imaginar agora. Pois o seu computador, só fala e compreende uma única língua, que é extremamente difícil para nós seres humanos, que são os bits ou bytes de informação. Se quisermos nos comunicar com o nosso computador, e passarmos instruções e comandos para serem executados por ele, nós devemos repassar essas informações como bits de informação. Com isso, o trabalho Console, e principalmente interpretador presente nele, é o de traduzir os seus comandos escritos na linguagem R (que nós seres humanos conseguimos entender), para comandos em bits, de forma que o seu computador possa compreender o que você está pedindo ele que faça.Tanto programa padrão R, quanto RStudio, o console se localiza esquerda de sua tela, como mostrada na figura 1.1:Ao olhar para o Console, você pode perceber que em sua parte inferior, nós temos início da linha um símbolo de “maior que” (>). Esse símbolo, significa que o Console está pronto e esperando por novos comandos serem interpretados. Ou seja, você coloca os seus comandos à frente deste símbolo, e em seguida, você aperta Enter para confirmar o envio dos comandos. Assim, os comandos serão avaliados, e o console vai lhe retornar o resultado destes comandos. Há algumas ocasiões em que o console vai apenas executar os comandos, e não irá lhe mostrar automaticamente o resultado. Isso geralmente ocorre quando você está salvando os resultados desses comandos em um objeto (iremos aprender sobre eles mais frente).Como um exemplo clássico, eu posso utilizar o R como uma simples calculadora, ao escrever o comando “1 + 3” Console (e apertar tecla Enter), e como não estou salvando o resultado dessa soma em algum objeto, o console mostra automaticamente o resultado dessa operação.Vale destacar, que todo comando que você escrever Console, deve estar completo para ser avaliado. Dito de outra forma, quando você escreve Console, algum comando que ainda está incompleto de alguma forma (por exemplo, que ainda está faltando fechar algum par de parênteses, ou está faltando uma vírgula, ou está faltando algum valor ser fornecido), e você aperta Enter para ele ser avaliado, o símbolo > Console, será substituído por um +, te indicando que ainda falta algo em sua expressão. Neste caso, o Console ficará esperando até que você escreva o restante, e complete o comando, como mostrado na figura 1.2. Em uma situação como essa, você pode abortar operação, e reescrever início o seu comando, ao apertar tecla Esc de seu computador.\nFigure 1.1: Expressões incompletas\n","code":"\n1 + 3## [1] 4"},{"path":"noções-básicas-do-r.html","id":"comentários","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.2.2 Comentários","text":"O R possui diversos caracteres especiais, e que sofrem ou geram efeitos distintos ao serem avaliados. Um desses carateres, é hash (#), que R, representa o início de um comentário. Ou seja, todo e qualquer comando, letra ou expressão escrita após o símbolo # (incluindo o próprio símbolo #), será completamente ignorado pelo Console. Portanto, o símbolo # constitui uma forma útil de incluirmos anotações e comentários em nossos comandos. Por exemplo, você talvez tenha dificuldade de lembrar o que cada função faz, e por isso, você pode utilizar o símbolo # para inserir pequenas descrições e lembretes ao longo de seus comandos, para relembrá-lo o que cada função faz.","code":"\n# A função sum() serve para somar um\n# conjunto de números.\nsum(1,2,3,4,5)## [1] 15"},{"path":"noções-básicas-do-r.html","id":"comandos-e-resultados","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.2.3 Comandos e resultados","text":"O símbolo de “maior que” (>) Console, também representa uma forma útil de você diferenciar o que é um comando ser interpretado pelo R, e o que foi retornado pelo R como o resultado desse comando. Ou seja, todo bloco de texto em seu Console, que estiver logo à direita símbolo >, representa um bloco de comandos serem avaliados (ou que já foram avaliados) pelo R. Em contrapartida, todo texto que não possuir o símbolo > à sua esquerda, representa o resultado comando anterior, ou então, uma mensagem de erro referente esse comando anterior.Uma outra forma útil de identificar os resultados de seus comandos, é perceber que eles sempre vem acompanhados por algum índice numérico início de cada linha. Esse índice pode estar dentro de um par de colchetes (como [1]), ou pode estar livre, como resultado da função data.frame() apresentado na figura 1.3. Perceba que esses números são apenas índices, logo, eles não fazem parte resultado de seus comandos, e são apenas valores que marcam o início cada linha de seu resultado.\nFigure 1.2: Comandos e seus respectivos resultados Console\n","code":""},{"path":"noções-básicas-do-r.html","id":"histórico-de-comandos","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.2.4 Histórico de comandos","text":"O Console possui uma memória dos comandos que você executou anteriormente. Tanto que esses comandos e seus resultados, permanecem visíveis ao navegarmos pelo Console. Porém, você também pode navegar pelos comandos previamente executados, ao utilizar seta para cima (\\(\\uparrow\\)) de seu teclado, quando estiver Console. Através dessa tecla, os comandos executados anteriormente são apresentados na linha de inserção de códigos própio Console.Porém, você também pode visualizar de forma mais eficiente o seu histórico de comandos, ao acessar janela History RStudio, que fica na parte direita e superior de sua tela, como mostrado na figura 1.4. Uma outra forma de abrirmos essa janela, está na função history(). Com essa função, você pode determinar até quantos comandos anteriores devem ser exibidos nessa janela.\nFigure 1.3: Aba History - Quadrante superior direito\nPara mais, você também pode visualizar esse histórico de comandos, por meio de uma pequena janela aberta em seu Console, como na figura 1.5. Quando estiver console, você pode acessar essa janela, ao pressionar teclas Ctrl + \\(\\uparrow\\).\nFigure 1.4: Histórico de comandos - Console\n","code":"\n# Exibir os últimos 10 comandos executados\nhistory(10)"},{"path":"noções-básicas-do-r.html","id":"sec:operacoes_matematicas","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.2.5 Operações matemáticas básicas","text":"O R pode ser utilizado como uma simples calculadora, através de seus operadores aritméticos.Você irá rapidamente perceber que esses operadores são extremamente úteis e estão por toda parte, sendo utilizados em diversas outras operações muito mais complexas. Por isso, é importante que você leve um tempo se familiarizando com esses operadores. Temos na tabela 1.1, uma lista dos principais operadores aritméticos, além de alguns comandos R, que exemplificam o seu uso.\nFigure 1.5: Operadores aritméticos R\n","code":"\n# Simples Adição\n3 + 15## [1] 18\n# Multiplicação\n3 * 125## [1] 375\n# Potenciação\n3 ^ 4## [1] 81\n# Miscelânia de operadores\n((4.505 * 100)/ 5) + 0.015 ## [1] 90.115"},{"path":"noções-básicas-do-r.html","id":"introdução-a-objetos","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.3 Introdução a objetos","text":"Uma das principais características R, é que ele é uma linguagem orientada objetos (object oriented). Objetos são o método que o R possui para guardar os valores, funções e resultados que você produz. Como foi posto por Adler (2010, p 50), todo código R, busca utilizar, manipular ou modificar de alguma forma, um objeto R. Logo, quando você estiver trabalhando com seus dados R, você estará constantemente aplicando operações e transformações sobre os objetos onde seus dados estão guardados, de uma forma interativa e dinâmica.Para que um objeto seja criado, o R necessita de uma forma de referenciar aquele objeto, ou em outras palavras, uma forma de reconhecer o objeto ao qual você está requisitando. Esse mecanismo conciste fundamentalmente de um nome (Chambers 2008, p 24). Ou seja, todo objeto R, possui um nome, e será através desse nome, que você será capaz de acessar esse objeto. Portanto, para você salvar todo e qualquer resultado ou valor R, você precisa obrigatoriamente salvâ-lo dentro de um objeto, isto é, dar um nome esse resultado ou valor que você está gerando.exemplo abaixo, eu estou guardando minha idade em um objeto chamado idade_pedro. Dessa forma, quando eu precisar deste número em algum momento de minha análise, eu preciso apenas chamar pelo nome onde guardei este número, ou nos termos R, pelo nome dei ao objeto onde guardei este número.Após criarmos o objeto de nome idade_pedro, eu posso acessar o valor que foi salvo nele, ao chamar pelo nome objeto Console.Sempre que você estiver criando um objeto, ele irá seguir essa estrutura acima. Você possui primeiro o nome objeto, depois o símbolo de assignment (<-), e por último, o valor (ou o conjunto de valores) que você quer guardar dentro deste objeto. Independente quê, ou, porquê, o código à direita símbolo de assignment faz, ao ver essa estrutura, você sabe de antemão que esses comandos estão criando um objeto.\nFigure 1.6: Estrutura necessária para criar um objeto\nNós podemos sobrepor o valor guardado em um objeto, ao atribuir um novo valor este objeto. Neste caso, estaríamos perdendo o valor que salvamos anteriormente neste objeto. Como exemplo, se eu atribuir o texto “Importado” ao objeto idade_pedro. Após este novo comando, se chamarmos pelo nome objeto, o R irá lhe mostrar o novo texto que acabamos de guardar, e o número 22 que estava anteriormente guardado nele, se perdeu.Caso você tenha que sobrepor o valor de um objeto, mas você não quer perder o valor que está salvo em nele, você deve conectar este valor um novo objeto. Se um valor não está conectado um nome, o R vai jogar este valor fora, por isso, precisamos de uma nova conexão até ele, ou em outras palavras, precisamos conectá-lo um novo nome. Dessa forma, podemos tranquilamente sobrepor o valor guardado em idade_pedro, pois agora, o valor 22 está guardado em um outro objeto.","code":"\nidade_pedro <- 22\nidade_pedro## [1] 22\nidade_pedro <- \"Importado\"\n\nidade_pedro## [1] \"Importado\"\nidade_pedro <- 22\n\nnumero_importante <- idade_pedro\n\nidade_pedro <- \"Importado\"\n\n# Ao chamar pelo nome de\n# ambos os objetos, temos dois valores\n# diferentes\n\nidade_pedro## [1] \"Importado\"\nnumero_importante## [1] 22"},{"path":"noções-básicas-do-r.html","id":"como-nomear-um-objeto","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.3.1 Como nomear um objeto","text":"Como foi destacado por Wickham Grolemund (2017), existem regras sobre como você pode nomear os seus objetos R. Segundo R Core Team (2020a, p 4), o nome de um objeto, pode conter qualquer símbolo alfanumérico (qualquer letra ou número), inclusive letras acentuadas. Sendo que o nome desse objeto, deve obrigatoriamente se iniciar por uma letra, ou por um ponto (.), como por exemplo, os nomes: População; dados.2007; .abc; media_1990. Porém, um nome não pode começar por um número, logo, um nome como 1995populacao, não é permitido. Também não é possível, que se inicie um nome por um ponto (.) caso ele seja seguido por um número. Logo, você não pode criar um objeto com o nome .2media, mas você pode criar um objeto que possua o nome .m2edia ou .media2.Em suma, o nome de um objeto pode conter os seguintes tipos de caractere:Letras.Números._ (underline).. (ponto).Além disso, o nome de um objeto pode se iniciar com um:Letra.. (ponto, desde que não seja seguido por um número).Porém, o nome de qualquer objeto, não deve começar por um:_ (underline).Número.. (ponto) seguido de um número.Pode ser difícil pensar em um nome para os seus objetos. Mas melhor alternativa, é sempre dar um nome claro e descritivo aos seus objetos, mesmo que esse nome possa ficar muito extenso. Por exemplo, microdados_pnad_2020 para uma base de dados contendo os microdados da PNAD de 2020; ou vetor_idade, para um vetor que contém idades das pessoas que foram entrevistadas em uma pesquisa.","code":""},{"path":"noções-básicas-do-r.html","id":"o-r-é-case-sensitive","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.3.2 O R é case-sensitive","text":"O R é uma linguagem case-sensitive. Isso significa, que ele é capaz de diferenciar capitalização de sua escrita. Logo, um objeto chamado , é um objeto completamente diferente de um objeto chamado . Veja o exemplo abaixo.Como visto, os objetos casa e cAsa contêm valores diferentes, e portanto, representam objetos distintos.","code":"\ncasa <- 10 ^ 2\ncAsa <- 2 + 2\n\ncasa## [1] 100\ncAsa## [1] 4"},{"path":"noções-básicas-do-r.html","id":"como-utilizar-objetos","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.3.3 Como utilizar objetos","text":"Um objeto é de certa forma, uma referência até um certo conjunto de valores, e você utiliza, ou acessa essa referência, através nome que você deu esse objeto. Logo, sempre que você quiser utilizar os valores que estão guardados em algum objeto (seja dentro de alguma função ou em alguma operação específica), você precisa apenas utilizar o nome que você deu esse objeto.Por exemplo, se eu quero somar um conjunto de valores guardados em um objeto chamado vec_num, eu posso fornecer o nome deste objeto à função sum().","code":"\nvec_num <- c(2.5, 5.8, 10.1, 25.2, 4.4)\n\nsoma <- sum(vec_num)\n\nsoma## [1] 48"},{"path":"noções-básicas-do-r.html","id":"sec:funcoes","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.4 Funções (noções básicas)","text":"Como destacado por Chambers (2016), até funções que você utiliza, são objetos R. grande maioria das funções são escritas e utilizadas, segundo o formato abaixo. Portanto, sempre que você utilizar uma função R, você deve escrever o nome dessa função, e em em seguida, abrir um par de parênteses. Dentro destes parênteses, você irá fornecer os argumentos (ou input’s) que serão utilizados pela função para gerar o seu resultado.Os operadores aritméticos utilizados até aqui (+, -, *, etc.) também são funções para o R, porém, eles representam um tipo especial de função. Pois nós podemos posicionar os seus argumentos, ao redor desses operadores (Ex: 2 + 3). Por outro lado, nós podemos escrever esses operadores (ou essas funções), da forma “tradicional,” ou como demais funções R são escritas, o que é demonstrado logo abaixo. Perceba que pelo fato nome da função (função que representa o operador +), se iniciar por um símbolo que não respeita regras que definimos anteriormente (sobre como nomear um objeto), para nos referirmos esse objeto, ou essa função, nós devemos contornar o nome dessa função por acentos graves.Os argumentos da função identificam os dados que serão transformados, ou representam especificações que vão modificar o comportamento da função, ou modificar metodologia de cálculo utilizada. Dessa forma, nós definimos os argumentos das funções (.e., incluímos especificações desejadas) para que possamos obter os resultados de acordo com nossas necessidades. Sendo que lista_de_argumentos, corresponde uma lista onde cada argumento é separado por uma vírgula (,), como exemplo abaixo.Um argumento pode ser um símbolo, que contém um valor específico (ex.: argumento1 = valor_argumento1) ou o argumento especial ‘...’ que pode conter qualquer número de argumentos (geralmente, o argumento especial é encontrado em funções em que quantidade de argumentos que será passada é desconhecida). Algumas funções possuem valores padrões em seus argumentos. Em outras palavras, caso você não defina algum valor específico para este tipo de argumento, função vai utilizar um valor pré-definido para esse argumento. Usualmente, os valores padrão são os valores mais comuns, que utilizam metodologias mais conservadoras ou tradicionais de cálculo da função.Por exemplo, função sum() possui o argumento na.rm, que define se os valores NA presentes em um objeto, devem ser ignorados ou não durante o cálculo da soma. Por padrão, esse argumento é configurado para FALSE (falso). Isso significa, que qualquer valor NA que estiver presente objeto ser somado, vai alterar o comportamento da soma executada por sum(). Por isso, se quisermos ignorar os valores NA durante o cálculo da soma, nós precisamos definir explicitamente o argumento na.rm para TRUE (verdadeiro).Ao definirmos os valores serem utilizados em cada argumento de uma função, nós não precisamos determinar o nome argumento ser utilizado. Como exemplo, veja função rnorm() abaixo. O primeiro argumento (n) da função, define o número de observações serem geradas; o segundo (mean), define média desses valores; e o terceiro (sd), define o desvio padrão que esses valores vão seguir ao serem gerados.Quando nós não definimos explicitamente o nome argumento que estamos utilizando, o R vai conectar o valor que fornecemos, de acordo com ordem que os argumentos aparecem na função. Ou seja, o primeiro valor, será conectado ao primeiro argumento da função. Já o segundo valor, será conectado ao segundo argumento da função. E assim por diante. Isso significa, que se quisermos configurar algum argumento, fora da ordem em que ele aparece na função, nós teremos que explicitar o nome argumento ser utilizado.","code":"nome_da_função(lista_de_argumentos)\n# O mesmo que 2 + 3\n`+`(2, 3)## [1] 5\n# O mesmo que 12 + 8\n`+`(12, 8)## [1] 20exemplo_função(argumento1 = valor_argumento1, argumento2 = valor_argumento2)\nvec <- c(1.2, 2.5, 3, NA_real_, 7.6)\n\nsum(vec)## [1] NA\nsum(vec, na.rm = TRUE)## [1] 14.3\n# A função rnorm() e seus argumentos\nrnorm(n, mean, sd)\nrnorm(10, 15, 2.5)##  [1] 10.48760 18.66389 15.38313 20.43153 16.18877 13.22513 16.52682\n##  [8] 12.66476 11.86592 15.72862\nrnorm(n = 10, sd = 2.5, mean = 15)##  [1] 13.89177 15.00276 15.18585 13.52620 13.57833 14.66205 17.94522\n##  [8] 11.19108 16.48487 15.83238"},{"path":"noções-básicas-do-r.html","id":"sec:erros_ajuda","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.5 Erros e ajuda: como e onde obter","text":"Ao começar aplicar o conhecimento exposto neste livro, você rapidamente irá enfrentar situações adversas, onde vão surgir muitas perguntas das quais eu não ofereço uma resposta aqui. Por isso, é muito importante que você conheça o máximo de recursos possíveis, dos quais você pode consultar e pedir por ajuda (Wickham Grolemund 2017).Hoje, comunidade internacional de R, é muito grande, e há diversos locais onde você pode encontrar ajuda, e aprender cada vez mais sobre linguagem. Nessa seção, vamos explicar como utilizar os guias internos R e RStudio, além de algumas técnicas de pesquisa e de perguntas que podem te ajudar responder suas dúvidas.","code":""},{"path":"noções-básicas-do-r.html","id":"ajuda-interna-do-r-help-e","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.5.1 Ajuda Interna do R: help e ?","text":"Toda função R, possui uma documentação interna, que contém uma descrição completa (ou quase sempre completa) da função. Essas documentações são muitas vezes úteis, especialmente para descobrirmos os argumentos de uma função, ou para compreendermos que tipo de valores devemos utilizar em um certo argumento, ou então, em ocasiões mais específicas, para adquirirmos um conhecimento mais completo sobre o comportamento de uma função. Para acessar essa documentação, você pode anteceder o nome da função com o operador ?, ou então, utilizar função help() sobre o nome da função de interesse. Como exemplo, com os comandos abaixo, você pode consultar documentação interna da função mean().Se você estiver programa padrão R, ao executar um desses comandos, um arquivo HTML contendo documentação será aberto em seu navegador. Mas se você estiver RStudio, documentação será aberta na janela de Help próprio RStudio, localizada quadrante direito e inferior de sua tela, como mostrado na figura 1.7.\nFigure 1.7: Documentação interna da função de média RStudio\ndocumentação interna de uma função, lhe dá uma descrição completa sobre quais tipos de valores devem (ou podem) ser inseridos em cada argumento da função. Entretanto, caso você esteja apenas em dúvida sobre os nomes dos argumentos de uma função, você pode rapidamente sanar essa dúvida, ao utilizar função args() sobre o nome da função. Com essa função, uma estrutura é retornada, contendo palavra chave function, e lista de argumentos da função dentro de um par de parênteses. Porém, se função de interesse possui diferentes métodos (como é o caso da função mean(), e de muitas outras funções), é muito provável que o resultado da função args() será de pouca utilidade, menos que você pesquise por um método específico da função.Veja exemplo abaixo, que ao selecionarmos o “método padrão” da função de média (mean.default()), dois novos argumentos foram retornados (trim e na.rm) pela função args().Por esses motivos, documentação interna representa uma fonte mais completa e segura de consulta sobre uma função. Como exemplo, na figura 1.8 podemos ver seção de Arguments, da documentação interna da função mean(). Nessa seção, podemos encontrar uma descrição sobre o que cada argumento faz e, principalmente, sobre que tipo de valor cada um desses argumentos é capaz de receber. Vemos abaixo, pela descrição argumento x, que função mean() possui métodos específicos para vetores numéricos, lógicos, de data, de data-hora e de intervalos de tempo. Com essas informações, nós sabemos, por exemplo, que função não possui métodos para vetores de texto. Também podemos deduzir dessa descrição, que função mean() é capaz de lidar apenas com vetores, e portanto, o uso de data.frame’s e listas está fora de cogitação.\nFigure 1.8: Seção de argumentos da documentação interna da função de média\n","code":"\n# Usando `help()`\nhelp(\"mean\")\n# Usando `?`\n?mean\nargs(\"mean\")## function (x, ...) \n## NULL\nargs(\"mean.default\")## function (x, trim = 0, na.rm = FALSE, ...) \n## NULL"},{"path":"noções-básicas-do-r.html","id":"um-exemplo-clássico-de-ajuda-interna","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.5.2 Um exemplo clássico de ajuda interna","text":"Um exemplo clássico em que ajuda interna R é bem útil, se encontra na função round(), que utilizamos para arredondar valores numéricos de acordo com um número de casas decimais.Porém, há diversas maneiras de se arredondar um número, e você talvez se pergunte quais desses métodos estão disponíveis R. Para responder essa pergunta, você talvez pense em procurar por mais detalhes sobre função round() em sua documentação interna. Temos o início dessa documentação na figura 1.9, e primeira coisa que chama atenção é lista de funções irmãs de round(). Ou seja, possuímos nessa lista, 5 funções diferentes (ceiling(), floor(), trunc(), round() e signif()), que buscam aplicar diferentes métodos de arredondamento.\nFigure 1.9: Documentação interna da função round()\nAo olharmos para descrição da função floor() (“takes largest integer greater corresponding value x”, ou “seleciona o maior número inteiro que não é maior que o valor correspondente em x”), podemos compreender que essa função busca sempre arredondar um número para baixo, independentemente de qual número esteja presente na última casa decimal. Também podemos entender pela descrição da função ceiling(), que ela executa justamente o processo contrário (“takes smallest integer less corresponding value x”, ou “seleciona o menor número inteiro que não é menor que o valor correspondente de x”), e arredonda qualquer número sempre para cima.seção de detalhes dessa documentação (mostrada na figura 1.10) é particularmente útil. Pois ela nos oferece uma boa descrição das implicações padrão adotado pela função (IEC 60559). Além disso, descrição presente na seção de detalhes também nos aponta uma particularidade importante sobre função round(). Pois ao arredondar um decimal igual ao número 5, função round() normalmente irá buscar o número inteiro par mais próximo.\nFigure 1.10: Seção de detalhes da documentação interna da função round()\nimportância deste ponto, emerge fato de que algumas funções de arredondamento muito utilizadas possuem um comportamento diferente de round(), em uma situação como essa. Um exemplo está na função ARRED() Excel, que sempre arrendonda um número para cima, partir momento em que sua última casa decimal atinge um valor igual ou acima de 5. Se os nossos números são arredondados de formas distintas ao longo de certos programas, diferentes valores ou resultados podem ser estimados. Em geral, nós desejamos evitar isso.Para que essa diferença fique clara, se eu arrendondar os números 9,5 e 6,5, função round() vai gerar como resultado, os números 10 e 6. Pois durante o processo de arredondamento, função round() está preocupada em encontrar o número par mais próximo valor em questão, e não sobre qual direção o arredondamento vai assumir.","code":"\n# Arredondar 3.1455 para duas casas decimais\nround(3.1455, digits = 2)## [1] 3.15\nvec <- c(0.4, 2.5, 3.7, 3.2, 1.8)\n\nfloor(vec)## [1] 0 2 3 3 1\nceiling(vec)## [1] 1 3 4 4 2\nvec <- c(9.5, 6.5, 4.5, 1.5, 2.5)\n\nround(vec, digits = 0)## [1] 10  6  4  2  2"},{"path":"noções-básicas-do-r.html","id":"ajuda-externa-referências-documentação-oficial-e-canais-úteis","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.5.3 Ajuda Externa: referências, documentação oficial e canais úteis","text":"Apesar de útil, documentação interna de uma função é limitada. Essa situação tende se confirmar especialmente em pacotes externos aos pacotes básicos R, ao encontrarmos em suas documentações, seções de Details rasas e de pouca utilidade. Por isso, é interessante se aprofundar e conhecer outras referências externas ao R, produzidas por autores/usuários (livros-texto, cursos online, etc) que oferecem o seu conhecimento sobre linguagem como um suporte à comunidade.Ao longo desse livro, vamos descrever diversas funções que provêm dos pacotes tidyverse. Por isso, é interessante que você se familiarize com os sites desses pacotes4. Uma outra fonte rápida de informação, são “colas” produzidas pela equipe RStudio, chamadas de RStudio Cheatsheets.Além disso, temos diversos livros-textos importantes sobre linguagem, que oferecem diversos conhecimentos extremamente valiosos, como obras de (Wickham Grolemund 2017; Gillespie Lovelace 2017; Peng 2015; Grolemund 2014; Chambers 2008; Adler 2010), além da documentação oficial da linguagem presente em (R Core Team 2020a, 2020b).Também há diversos cursos e materiais disponíveis, que podem ser boas fontes de informação. Dentre eles, temos o curso Introduction R, da plataforma Datacamp. Além disso, temos um bom material de consulta em português, construído pela equipe Curso-R, além material produzido pelo professor Walmes Marques Zeviani, entitulado Manipulação e Visualização de Dados.Para mais, temos alguns blogs que fazem boas reflexões e sempre trazem um bom conteúdo sobre linguagem. Esse é o caso site R-Bloggers, que possui uma boa discussão sobre os mais diversos assuntos R. Um outro exemplo, é o blog Tidyverse, que constantemente descreve novos pacotes, novas funções disponíveis e novas aplicações para o R que podem ser muito interessantes para o seu trabalho.Além dessas referências, é muito importante que você se familiarize com os canais de dúvida disponíveis, como o Stackoverflow. Pois esses canais serão, com certeza, sua principal fonte de ajuda R. Em síntese, o StackOverflow funciona da seguinte maneira: 1) alguém envia uma pergunta; 2) cada pergunta, é marcada por um conjunto de tags, que definem linguagem de programação, ou pacote, ou assunto específico que se refere dúvida; 3) qualquer pessoa, pode postar uma resposta nessa pergunta, ou algum comentário que seja útil; 4) respostas mais úteis e completas, serão votadas para cima, pelos próprios usuários site; 5) dessa forma, respostas mais úteis e completas, vão sempre aparecer primeiro na postagem da dúvida em questão.Para encontrar perguntas especificamente voltadas para linguagem R StackOverflow, você deve sempre procurar por perguntas marcadas com tag [r], ou por algum pacote específico da linguagem. Por exemplo, o StackOverflow contém um estoque enorme de dúvidas marcadas com tag ggplot2, que se refere ao pacote ggplot2, que vamos discutir mais frente. Logo, o StackOverflow representa uma fonte extremamente importante sobre esse pacote.Além StackOverflow, nós também possuímos o RStudio Community, que também é um canal de dúvidas bastante ativo, e que funciona de maneira muito similar ao StackOverflow. Onde pessoas fazem uma pergunta, que é marcada por tags que definem o pacote ou o assunto específico que pergunta se refere. Porém, perguntas RStudio Community, tendem assumir um aspecto mais parecido com uma discussão (ao invés de um caráter de pergunta-resposta presente StackOverflow). Ou seja, uma pergunta abre de certa forma, uma discussão. Uma pessoa fornece uma resposta, depois outra fornece um outro olhar sobre pergunta, o autor descreve novas dúvidas, novas respostas surgem, podendo assim, criar uma discussão infindável em torno da dúvida inicial.fontes de ajuda externas ao R, serão sua maior ajuda, e sua principal referência. Pois como foi destacado por Chase (2020), ninguém é completamente autodidata. Todos nós cometemos erros, e uma das grandes vantagens de uma comunidade como R, é que muito conhecimento é produzido e compartilhado em torno desses erros. Por essa razão, Chase (2020), assim como os autores desta obra, prefirímos nos caracterizar como seres instruídos pela comunidade (community-taught).","code":""},{"path":"noções-básicas-do-r.html","id":"um-exemplo-clássico-de-ajuda-externa","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.5.4 Um exemplo clássico de ajuda externa","text":"Uma das primeiras dúvidas que atingem os iniciantes, diz respeito aos objetos criados, ou melhor dizendo, aos objetos não criados em sua sessão. Você já viu na seção Introdução objetos, qual estrutura básica necessária para criarmos um objeto (nome_do_objeto <- valor_do_objeto). Porém, você pode acabar se perdendo durante o seu trabalho, de forma não saber quais objetos você criou em sua sessão. Em situações como essa, você pode executar função ls(). Essa função irá listar o nome de todos os objetos que estão criados em sua sessão atual R.Com isso, caso você esteja em dúvida se você já criou ou não, um certo objeto em sua sessão, você pode conferir se o nome deste objeto aparece nessa lista resultante da função ls(). Caso o nome objeto não se encontre nela, você sabe que o objeto em questão ainda não foi criado.Por outro lado, você pode estar interessado em apagar um certo objeto de sua sessão. Tal resultado, pode ser atingido através da função rm(). Logo, se eu possuo um objeto chamado dados_2007, e eu desejo eliminá-lo de minha sessão, eu preciso apenas fornecer o nome deste objeto à função rm().Na próxima seção, vamos abordar o uso de scripts R, e um erro muito comum quando se está iniciando com os scripts, é o de se esquecer de efetuar os comandos para criar um objeto. Ou seja, muitos iniciantes escrevem script, os comandos necessários para criar o seu objeto, mas acabam se esquecendo de enviar esses comandos para o Console, onde eles serão avaliados e executados.função ls() oferece uma forma rápida de consulta, que pode sanar sua dúvida em ocasiões como essa. Mas uma outra forma ainda mais efetiva de sanarmos essa dúvida, conciste em chamar pelo nome deste objeto console. Se algum erro retornado, há grandes chances de que você ainda não criou esse objeto em sua sessão. Veja o exemplo abaixo na figura 1.11, em que chamo por um objeto chamado microdados_pnad_2020, e um erro é retornado.\nFigure 1.11: Mensagem de erro - Console\nSempre que você não souber o que um erro significa, ou que termo ele está se referindo, faça uma pesquisa rápida sobre esse erro Google. Se o seu erro está sendo gerado, ao executar uma função específica, você pode anteceder o erro gerado, por um “R” e pelo nome da função utilizada, na barra de pesquisa Google. nosso caso, talvez seja melhor pesquisarmos apenas pelo erro antecedido por um “R,” como na figura abaixo. Há alguma chance de você encontrar referências de ajuda em português. Porém, chances são infinitamente maiores se você pesquisar por artigos e perguntas escritas em inglês. Por isso, se sua mensagem de erro estiver em português (como é o caso da mensagem na figura acima), é melhor que você tente traduzí-la para o inglês, caso você tente pesquisar por ela Google.Podemos encontrar primeiro link da página mostrada na figura 1.12, uma pergunta postada StackOverflow. Como o StackOverflow é geralmente uma boa referência de ajuda, há uma boa chance de encontrarmos o que estamos necessitando nesse link.\nFigure 1.12: Pesquisa Google sobre mensagem de erro\nAo acessarmos uma pergunta StackOverflow, primeira parte que aparece em sua tela, é pergunta em si. Perguntas que são muito úteis, e que traduzem uma dúvida muito comum dos usuários, tendem ser “votadas para cima.” pergunta exposta na figura 1.13, possui 37 votos, o que indica ser uma pergunta comum e útil o suficiente para ajudar mínimo 37 pessoas.\nFigure 1.13: Pergunta StackOverflow - Parte 1\nLogo abaixo da pergunta em si, temos respostas de usuários que se dispuseram respondê-la. respostas mais úteis para pergunta em questão, tendem ter maiores votos dos usuários e, por isso, tendem aparecer primeiro na página em relação outras respostas menos úteis. Como podemos ver na figura 1.14, primeira resposta possui 33 votos.\nFigure 1.14: Pergunta StackOverflow - Parte 2\nresposta mostrada na figura 1.14, é bem esclarecedora. Como o autor pontua, um erro tipo “objeto x não foi encontrado” (ou “object x found”) ocorre quando tentamos utilizar um objeto que ainda não existe, um objeto que ainda não foi definido. partir momento em que voce definir esse objeto, este erro não ocorre mais.Como pontuei anteriormente, é muito comum de um aluno escrever os comandos necessários para criar um objeto em seu script, mas se esquecer de enviar esses comandos script para o Console, onde serão avaliados e executados. Por isso, sempre que ocorrer esse erro, confira se você conseguiu enviar os comandos para o Console. Também confira se os comandos utilizados para criar o objeto, foram de fato executados, isto é, confirme se nenhum erro apareceu durante execução desses comandos. Pois depender da gravidade erro gerado, execução dos comandos pode ter sido comprometida e, portanto, o objeto não pôde ser criado.Por isso, sempre que enfrentar algum erro R, tente fazer uma pesquisa rápida Google. Em geral, você pode copiar e colar diretamente mensagem, ou citar apenas trechos, ou oração principal da mensagem de erro na pesquisa. É interessante sempre colocar um “r” antes da mensagem de erro, para definir um pouco melhor sua pesquisa e encontrar links referentes à linguagem R. Uma boa referência externa para compreender e solucionar erros R, é o StackOverflow.","code":"\nls()##   [1] \"a\"                      \"Abril_2019\"            \n##   [3] \"ajuste\"                 \"ano\"                   \n##   [5] \"anos\"                   \"anotacao\"              \n##   [7] \"arquivo\"                \"arquivo1\"              \n##   [9] \"arquivo2\"               \"arquivos_rmds\"         \n##  [11] \"band_instruments\"       \"billboard_long\"        \n##  [13] \"billboard_sel\"          \"calc_lucro\"            \n##  [15] \"calc_stats\"             \"caminhos\"              \n##  [17] \"casa\"                   \"cAsa\"                  \n##  [19] \"Censo_2010\"             \"centro\"                \n##  [21] \"children\"               \"chines\"                \n##  [23] \"codes\"                  \"codigos\"               \n##  [25] \"col\"                    \"col_width\"             \n##  [27] \"colocacoes\"             \"cols_c\"                \n##  [29] \"cols_desejadas\"         \"cols_para_key\"         \n##  [31] \"colunas\"                \"como_texto\"            \n##  [33] \"compras\"                \"conc_vec\"              \n##  [35] \"conj\"                   \"consumidores\"          \n##  [37] \"contagens\"              \"coord_arrow\"           \n##  [39] \"coord_text\"             \"cost\"                  \n##  [41] \"covid\"                  \"covid_novo\"            \n##  [43] \"cpf\"                    \"custo\"                 \n##  [45] \"custos\"                 \"d\"                     \n##  [47] \"dados\"                  \"dados_excel\"           \n##  [49] \"data\"                   \"data_aniversario\"      \n##  [51] \"data_frame\"             \"data_inicial\"          \n##  [53] \"datas\"                  \"datasus\"               \n##  [55] \"datasus_agrup\"          \"date_vec\"              \n##  [57] \"datetime_no_excel\"      \"def.chunk.hook\"        \n##  [59] \"desvio_padrao\"          \"desvios\"               \n##  [61] \"df\"                     \"dias\"                  \n##  [63] \"double_vec\"             \"doubles\"               \n##  [65] \"dt\"                     \"dt1\"                   \n##  [67] \"dt2\"                    \"dts\"                   \n##  [69] \"economista_1\"           \"economista_anterior\"   \n##  [71] \"entrevista\"             \"env\"                   \n##  [73] \"estados_siglas\"         \"estatisticas\"          \n##  [75] \"estilos_backref\"        \"estilos_inside\"        \n##  [77] \"exerc_rmds\"             \"expressao_completa\"    \n##  [79] \"extrair\"                \"f\"                     \n##  [81] \"f_env\"                  \"filmes\"                \n##  [83] \"filmes_receita\"         \"fim\"                   \n##  [85] \"fim_intervalo\"          \"fix_begin_center\"      \n##  [87] \"fix_chapter\"            \"fix_citations\"         \n##  [89] \"fix_exerc_tex_file\"     \"fix_exercises\"         \n##  [91] \"fix_image_files\"        \"fix_latex_cmds\"        \n##  [93] \"fix_verbatim\"           \"flights\"               \n##  [95] \"funcao_soma\"            \"funcionarios\"          \n##  [97] \"github\"                 \"grafico\"               \n##  [99] \"horario\"                \"horario_brasil\"        \n## [101] \"horario_japao\"          \"horas\"                 \n## [103] \"hr\"                     \"i\"                     \n## [105] \"id\"                     \"idade_pedro\"           \n## [107] \"idcompra\"               \"identidade\"            \n## [109] \"idproduto\"              \"index\"                 \n## [111] \"info\"                   \"inicio\"                \n## [113] \"inicio_intervalo\"       \"integers\"              \n## [115] \"j\"                      \"janeiro\"               \n## [117] \"ler_excel\"              \"LETTERS\"               \n## [119] \"lista\"                  \"livros\"                \n## [121] \"load_packages\"          \"logica\"                \n## [123] \"los_medanos\"            \"lst\"                   \n## [125] \"lst_sem_estado\"         \"maior_data\"            \n## [127] \"marcas\"                 \"marco\"                 \n## [129] \"matriz\"                 \"media\"                 \n## [131] \"medias\"                 \"medidas\"               \n## [133] \"menor_data\"             \"mensagem\"              \n## [135] \"mes\"                    \"meses\"                 \n## [137] \"minas_pop\"              \"mt\"                    \n## [139] \"n\"                      \"n_indicadores\"         \n## [141] \"n_niveis\"               \"n_paises\"              \n## [143] \"n1\"                     \"n2\"                    \n## [145] \"nao_e_NA\"               \"niveis\"                \n## [147] \"niveis_atuais\"          \"niveis_sexo\"           \n## [149] \"nome\"                   \"nome_arquivo\"          \n## [151] \"nomes\"                  \"nomes_planilhas\"       \n## [153] \"norm\"                   \"nova_tab\"              \n## [155] \"novo_covid\"             \"novos_niveis\"          \n## [157] \"nudge\"                  \"numero_importante\"     \n## [159] \"numero_no_excel\"        \"ordem\"                 \n## [161] \"Oxboys\"                 \"pac1\"                  \n## [163] \"pac2\"                   \"palavras\"              \n## [165] \"parte\"                  \"pasta\"                 \n## [167] \"path_rmd\"               \"pckgs\"                 \n## [169] \"pedaco\"                 \"per\"                   \n## [171] \"periodo\"                \"pesquisa\"              \n## [173] \"pib\"                    \"PIB\"                   \n## [175] \"PIB_remodelado\"         \"planilhas\"             \n## [177] \"plot_exemplo\"           \"plot_medanos\"          \n## [179] \"ponto\"                  \"ponto_dis\"             \n## [181] \"pontos\"                 \"pontos_br\"             \n## [183] \"pop_total\"              \"prado\"                 \n## [185] \"preço\"                  \"produto\"               \n## [187] \"produtos_vendas\"        \"raw\"                   \n## [189] \"read_rmds\"              \"receita_diaria\"        \n## [191] \"registro\"               \"registros\"             \n## [193] \"relig\"                  \"repair_vec\"            \n## [195] \"replace_mult_citations\" \"resp_rdm\"              \n## [197] \"resp_rmd\"               \"resposta\"              \n## [199] \"resultado\"              \"salario\"               \n## [201] \"salary\"                 \"salary_potential\"      \n## [203] \"savassi\"                \"segundos\"              \n## [205] \"sem_minuto_e_segundo\"   \"sem_segundo\"           \n## [207] \"setas\"                  \"soma\"                  \n## [209] \"somatorios\"             \"t\"                     \n## [211] \"tab\"                    \"tab_tibble\"            \n## [213] \"tab_tidy\"               \"tab1\"                  \n## [215] \"tab2\"                   \"tabela\"                \n## [217] \"tema\"                   \"tema_imagem\"           \n## [219] \"teste\"                  \"text\"                  \n## [221] \"texto\"                  \"tibble\"                \n## [223] \"tipos\"                  \"tipos_col\"             \n## [225] \"totais\"                 \"total_caracteres\"      \n## [227] \"total_desvio\"           \"transf\"                \n## [229] \"tuition_cost\"           \"unidades\"              \n## [231] \"usuarios\"               \"v\"                     \n## [233] \"v_Date\"                 \"v_letras\"              \n## [235] \"v_POSIXct\"              \"v_POSIXlt\"             \n## [237] \"v_rep\"                  \"v_seq\"                 \n## [239] \"valor\"                  \"valores\"               \n## [241] \"valores_x\"              \"valores_y\"             \n## [243] \"vec\"                    \"vec_colors\"            \n## [245] \"vec_d\"                  \"vec_fator\"             \n## [247] \"vec_num\"                \"vendas\"                \n## [249] \"vendas_wide\"            \"vendedores\"            \n## [251] \"vetor\"                  \"vetor_d\"               \n## [253] \"vetor_l\"                \"vlog\"                  \n## [255] \"x\"                      \"y\"                     \n## [257] \"y_resposta\"\n# Removendo o objeto chamado\n# dados_2007 de minha sessão\nrm(dados_2007)"},{"path":"noções-básicas-do-r.html","id":"sec:scripts","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.6 Scripts","text":"Até o momento, estivemos utilizando diretamente o Console para executarmos os nossos comandos. Porém, você provavelmente se sentiu um pouco perdido ao procurar os últimos comandos que você executou console e, se sentiu um pouco frustrado ao ter de digitar novamente o comando caso queira executá-lo uma segunda vez. Por essa razão, medida que você trabalha com o R, necessidade de guardar os seus comandos anteriores em algum lugar, se torna cada vez mais urgente. Para isso, você pode utilizar um script.Um script é um simples arquivo de texto, que contém extensão .R, para indicar que todo o texto contido neste arquivo, representam comandos R. Portanto, um script contém um conjunto de códigos e comandos R que podem ser facilmente acessados, editados e executados através das ferramentas e atalhos RStudio, tornando o seu fluxo de trabalho com o R mais eficiente. Ao utilizar o RStudio, os códigos contidos nos scripts podem ser executados individualmente ou em conjunto.Para criar um script RStudio, você possui duas opções: 1) clicar em File \\(\\rightarrow\\) New File \\(\\rightarrow\\) R Script; ou 2) utilizar o atalho Ctrl + Shift + N. Após criar o script, o quadrante esquerdo RStudio será dividido verticalmente em dois: parte superior comporta o editor de script’s e inferior o Console. Como resultado, o seu ambiente RStudio ficará semelhante ao ambiente exibido na figura 1.15.\n(#fig:FIG criar script)Quadrantes da área de trabalho RStudio, após abertura de um script\nVocê pode criar títulos que delimitam áreas, ou etapas de seu script, e é uma forma muito eficiente de navegar pelo seu script, caso ele seja muito grande. Na figura 1.16, um exemplo destes títulos está identificado pela seta azul. Também na figura 1.16, temos uma caixa vermelha, e dentro dela podemos ver uma referência que aponta qual seção, ou melhor, qual o título da seção qual o nosso cursor se encontra atualmente. O meu cursor se encontra momento, na seção “Importando os dados para o R.” Ao clicar sobre esta referência especificada na caixa vermelha, uma nova caixa de seleção irá aparecer contendo cada um dos títulos que você criou em seu script, e ao clicar sobre um destes títulos, você será redirecionado para o início desta seção script.\nFigure 1.15: Títulos e comentários em scripts\nEsses títulos especiais, são formados pela união entre o caractere de comentário R (# - hashtag), o texto que você quer inserir neste título, e vários sinais de menos (-) em sequência, formando assim seguinte estrutura: ### <título desejado> -------. O número de hashtag’s e de sinais de menos que você insere, são arbitrários. Ao invés de escrevê-los mão, o RStudio oferece um atalho que cria automaticamente esses títulos, através das teclas Ctrl + Shift + R.Lembre-se que você também pode adicionar pequenas anotações e comentários em seu script com hashtags (#). Nós definimos em seções anteriores, que este é um caractere especial da linguagem, e que qualquer texto que você colocar frente dele, será ignorado pelo console. Na figura 1.16, temos um exemplo deste comentário que está marcado por uma seta verde.Esses comentários são uma boa forma de descrever o que os comandos abaixo dele fazem, ou então de apontar configurações e cuidados importantes que você deve ter com esses comandos. Isso é importante especialmente com aquelas funções que você raramente utiliza, pois é menos provável que você se lembre de como elas funcionam, ou de como elas se comportam.","code":""},{"path":"noções-básicas-do-r.html","id":"executando-comandos-de-um-script","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.6.1 Executando comandos de um script","text":"essa altura, você já sabe que para executarmos qualquer comando R, ele precisa ser enviado para o console, onde será avaliado e executado. Por isso, ao utilizarmos um script, desejamos uma forma rápida de enviarmos esses comandos que estão guardados neste script, para o console R. O RStudio oferece um atalho para isso, que é o Ctrl + Enter. Veja figura 1.17, se o cursor de seu mouse estiver sobre o retângulo vermelho desenhado script, ao apertar o atalho Ctrl + Enter, o RStudio enviará todo o bloco de comandos que criam o objeto dados_selecionados, para o console. Agora, se o cursor de seu mouse estivesse sobre o retângulo verde desenhado script, o RStudio enviaria o bloco de comandos que formam o objeto media_estados.\nFigure 1.16: Executando comandos de um script\nApós enviar um bloco de comandos para o console, através deste atalho, o RStudio irá automaticamente mover o cursor de seu mouse para o próximo bloco de comandos. Desta maneira, você pode executar parte por parte de seu script em sequência e, conferir os resultados de cada bloco console.Além disso, o RStudio também oferece um outro atalho para caso você queira executar todos os comandos de um script de uma vez só. Para isso, você pode apertar teclas Crtl + Alt + R.","code":""},{"path":"noções-básicas-do-r.html","id":"salvando-um-script","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.6.2 Salvando um script","text":"Ao salvar o seu script, você está salvandos os comandos necessários para gerar os seus resultados. Isto é, através de script’s você possui uma poderosa ferramenta para reproducibilidade de sua análise. Em outras palavras, com um script, você é capaz de salvar os comandos necessários para se obter o resultado desejado, lugar dos própios resultados em si. Dito de outra forma, é muito mais prático carregarmos metodologia necessária para se obter um resultado, que o resultado em si. Pois você pode gerar repetidamente os mesmos resultados através dos comandos salvos em seu script, quantas vezes forem necessárias. Por outro lado, você não é capaz de gerar o script, ou os comandos necessários, ou metodologia de cálculo utilizada, partir de seus resultados.Para salvar um script que está aberto em seu RStudio, você pode clicar em File \\(\\rightarrow\\) Save …, e escolher o diretório em que o arquivo será guardado. Você também pode salvar esse script, ao clicar sobre o símbolo de disquete, presente logo abaixo nome desse script, canto superior direito. Uma vez definido o nome script e o local onde ele será guardado, você pode clicar em File \\(\\rightarrow\\) Save, ou utilizar o atalho Ctrl + S para salvar o script corrente medida em que você editando ele.Além desses pontos, lembre-se que um script é nada mais que um arquivo de texto com uma extensão .R e, por isso, ele pode ser aberto normalmente por editores de texto padrão (como o Bloco de Notas Windows, ou por programas como Notepad ++ e Sublime Text).","code":""},{"path":"noções-básicas-do-r.html","id":"sec:pacotes","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.7 Pacotes","text":"Como descrevemos anteriormente na seção O sistema e universo R, o R pode ser divido em duas partes: os pacotes básicos da linguagem; e todos os demais pacotes externos que foram criados e ofertados pela comunidade R. Um pacote (package) corresponde unidade fundamental de compartilhamento de códigos e funções R (Wickham 2015b). Dito de outra forma, segundo palavras de Wickham Grolemund (2017), um pacote R é uma coleção de funções, dados e documentação que extendem funcionalidades R.momento de escrita desta obra (novembro de 2020), existem mais de 16.000 pacotes disponíveis CRAN. Segundo Wickham (2015b), esta grande variedade de pacotes representa uma das principais razões para o sucesso R nos anos recentes, e ressalta o seguinte pessamento: é bastante provável que algum usuário já tenha enfrentado o mesmo problema que você, e após solucioná-lo, tenha ofertado um pacote que possa auxiliar você, na busca dessa solução. Logo, você pode obter enormes benefícios ao utilizar o conjunto de funções desenvolvidas por outros usuários para resolver os seus problemas.","code":""},{"path":"noções-básicas-do-r.html","id":"como-utilizar-um-pacote","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.7.1 Como utilizar um pacote","text":"Como é descrito por Adler (2010), para utilizarmos um pacote R, precisamos “carregá-lo” para nossa sessão. Porém, para “carregarmos” um pacote para nossa sessão, esse pacote precisa estar instalado em nosso computador. Logo, em resumo, nós devemos realizar os seguintes passos:5Instalar o pacote partir servidor CRAN: install.packages(\"nome_do_pacote\").Carregar o pacote em cada sessão R: library(nome_do_pacote).Você precisa executar o primeiro passo (instalar o pacote com função install.packages()) apenas uma vez. Após instalar o pacote em sua máquina, você precisa carregar esse pacote através da função library() em toda sessão R que você desejar utilizar funções desse pacote. Ou seja, toda vez que iniciar o R, você precisa carregar o pacote para ter acesso às suas funções.Por exemplo, se você desejasse utilizar funções disponíveis pacote ggplot2, que possui um conjunto de funções voltadas para composição de gráficos, você precisaria dos comandos abaixo. Repare que o nome pacote é fornecido como string à função install.packages(). Logo, sempre que instalar um pacote, lembre-se de contornar o nome pacote por aspas (simples ou duplas).Como Gillespie Lovelace (2017) destaca, uma boa prática ser adotada é carregar todos os pacotes necessários sempre início de seu script. Dessa forma, você está acoplando sua sessão, todas dependências necessárias para aplicar todas funções dispostas ao longo de seu script.","code":"\n# Instalar o pacote `ggplot2` em seu computador\ninstall.packages(\"ggplot2\")\n# Carregar o pacote `ggplot2` em sua sessão atual do R\nlibrary(ggplot2)"},{"path":"noções-básicas-do-r.html","id":"identificando-os-pacotes-instalados-em-sua-máquina-e-aqueles-que-foram-carregados-para-a-sua-sessão","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.7.2 Identificando os pacotes instalados em sua máquina e aqueles que foram carregados para a sua sessão","text":"Um dos métodos mais diretos de se identificar se um determinado pacote está ou não carregado em sua sessão, conciste em você tentar utilizar uma das funções desse pacote. Se um erro aperecer durante esse processo, indicando que tal função não foi encontrada ou que ela não existe, há grandes chances de que o pacote pelo qual você está preocupado, não se encontra disponível em sua sessão atual.Por exemplo, eu posso tentar utilizar função mutate() pacote dplyr como eu normalmente faria. Pela mensagem de erro abaixo, sabemos que o R não pôde encontrar função mutate(), logo, o pacote dplyr provavelmente não foi carregado para minha sessão até o momento.Apesar de rápido, este método é um pouco inseguro. Pois talvez um dos pacotes que já estão carregados em minha sessão, possua uma função com o nome mutate(). Em outras palavras, ao tentar rodar função mutate() em minha sessão, pode ser que o R encontre uma função mutate() diferente da que estou procurando. Por isso, um método mais seguro é necessário.resposta para tal necessidade se encontra na lista de environments conectados. Cada pacote carregado para sua sessão, é representado por um environment que está acoplado ao seu environment principal. Logo, ao descobrirmos todos os environments presentes em nossa sessão, nós podemos identificar todos os pacotes que foram carregados. Para obtermos uma lista dos environments presentes em nossa sessão, nós podemos executar função search(), como abaixo:Os valores que estiverem na forma package:nome_do_pacote indicam o environment de um pacote que está carregado em sua sessão atual R. Já o valor denominado .GlobalEnv, representa o global environment, que é o seu environment principal de trabalho, onde todos os seus objetos criados são salvos. Os environments R, representam os “espaços,” ou “ambientes” onde os seus objetos são guardados. Portanto, os objetos que você cria em sua sessão R, são guardados nesse environment denominado .GlobalEnv. Enquanto isso, todas funções e objetos disponíveis, por exemplo, pacote tibble, estão guardados environment chamado package:tibble. Vamos descrever em mais detalhes esses pontos, na seção Noções básicas de environments.Por outro lado, você talvez enfrente algum erro ao tentar carregar o pacote de seu interesse. Nesse caso, um bom movimento seria se certificar que esse pacote está instalado em sua máquina. Segundo Adler (2010), se você precisa identificar todos os pacotes instalados em sua máquina, você pode executar função library() sem definir nenhum argumento ou pacote em específico.","code":"\nmutate()Error in mutate() : não foi possível encontrar a função \"mutate\"\nsearch()##  [1] \".GlobalEnv\"             \"package:rmarkdown\"     \n##  [3] \"package:yaml\"           \"package:extrafont\"     \n##  [5] \"package:palmerpenguins\" \"package:magrittr\"      \n##  [7] \"package:RcppRoll\"       \"package:glue\"          \n##  [9] \"package:nycflights13\"   \"package:SAScii\"        \n## [11] \"package:haven\"          \"package:readxl\"        \n## [13] \"package:vctrs\"          \"package:lobstr\"        \n## [15] \"package:lubridate\"      \"package:knitr\"         \n## [17] \"package:forcats\"        \"package:stringr\"       \n## [19] \"package:dplyr\"          \"package:purrr\"         \n## [21] \"package:readr\"          \"package:tidyr\"         \n## [23] \"package:tibble\"         \"package:ggplot2\"       \n## [25] \"package:tidyverse\"      \"package:fs\"            \n## [27] \"package:bslib\"          \"package:bookdown\"      \n## [29] \"tools:rstudio\"          \"package:stats\"         \n## [31] \"package:graphics\"       \"package:grDevices\"     \n## [33] \"package:utils\"          \"package:datasets\"      \n## [35] \"package:methods\"        \"Autoloads\"             \n## [37] \"package:base\"\n# Uma nova janela será aberta em seu RStudio\n# contendo uma lista de todos os pacotes instalados\nlibrary()"},{"path":"noções-básicas-do-r.html","id":"acessando-as-funções-de-um-pacote-sem-carregá-lo-para-sua-sessão","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.7.3 Acessando as funções de um pacote sem carregá-lo para sua sessão","text":"Apesar de ser uma prática ideal na maioria das situações, você talvez não queira carregar um pacote específico e, mesmo assim, utilizar uma de suas funções. Tal opção pode gerar uma importante economia de espaço em sua memória RAM, durante sua análise. Até porque, se você irá utilizar apenas uma função pacote, talvez não haja necessidade de carregar o pacote inteiro.Para acessarmos uma função de um pacote que não foi carregado ainda em nossa sessão, precisamos chamar primeiro pelo pacote de onde estamos tirando função, como na estrutura abaixo.Logo, se você quisesse acessar função filter() pacote dplyr, por exemplo, você precisa primeiro chamar pelo pacote dplyr e, em seguida, posicionar duas vezes dois pontos (:) para acessar uma função ou objeto presente neste pacote. Por último, basta digitar o nome da função de interesse.","code":"# Acessar uma função de um pacote sem carregá-lo\nnome_do_pacote::nome_da_função()\n# Para acessar a função filter() sem chamar\n# pelo pacote dplyr\ndplyr::filter()"},{"path":"noções-básicas-do-r.html","id":"atualizando-pacotes","chapter":"Capítulo 1 Noções Básicas do R","heading":"1.7.4 Atualizando pacotes","text":"linguagem R está o tempo todo evoluindo e se aprimorando e, por essa razão, muitos dos pacotes disponíveis hoje, são constantemente atualizados, com o objetivo de implementar novas funcionalidades e/ou aperfeiçoar eficiência de suas funções. Logo, é uma boa prática que você mantenha os pacotes instalados em seu computador, constantemente atualizados. Para atualizar um pacote, você precisa apenas instalá-lo novamente, através da função install.packages(\"nome_do_pacote\"), ou acessar opção Tools \\(\\rightarrow\\) Check Packages Updates… RStudio, como está demonstrado na figura 1.18. Através dessa opção, o RStudio irá listar todos os pacotes que possuem versões mais recentes e, portanto, podem ser atualizados. grande vantagem é que você pode atualizar todos os pacotes presentes nessa lista de uma vez só.\nFigure 1.17: RStudio: Opção para atualização de pacotes\n","code":""},{"path":"noções-básicas-do-r.html","id":"exercícios","chapter":"Capítulo 1 Noções Básicas do R","heading":"Exercícios","text":"Questão 1.1. Tente calcular algumas operações básicas:1.1.) Qual é soma entre 32397 e 55405?1.1.B) Calcule soma total conjunto de valores dispostos vetor conj abaixo.1.1.C) Considerando que, \\(y = 3x^3 - 12x^2 + \\frac{1}{15}x+ 25\\), calcule o valor de \\(y\\) quando \\(x\\) é igual 5.Questão 1.2. Em cada item abaixo, temos uma mensagen de erro específica que supostamente apareceu em seu console. Tente explicar como ou porque essas mensagens podem aparecer em seu console. Em outras palavras, tente explicar o que essas mensagens significam, e qual foi o fato ocorrido que gerou esses erros:1.2.) Erro: objeto 'logica' não encontrado.1.2.B) Error bind_rows() : não foi possível encontrar função \"bind_rows\"1.2.C) Error library(dplyr) : package called ‘dplyr’Questão 1.3. próximas questões vão implicitamente esperar que você utilize algumas dessas funções: sum(), mean(), abs() e sd(). Claro que, o R te oferece liberdade de escrever suas próprias funções, ou de desenhar o seu próprio caminho até soluções dessas questões. Portanto, não se preocupe se você encontrar uma solução para questões abaixo, que não incluem o uso dessas funções específicas.1.3.) Considerando que variável \\(X\\) segue uma distribuição normal, como você normalizaria (isto é, calcular o índice \\(Z\\) da distribuição) os valores presentes vetor vec abaixo, que contém uma amostra de valores da variável \\(X\\).1.3.B) Utilizando novamente variável vec, calcule o seu desvio médio.","code":"\nconj <- c(290, 34, 512, 54, 89, 10)\nvec <- c(0.5, 1.2, 2.5, 1.3, 2.2, 3.7)\nvec <- c(0.5, 1.2, 2.5, 1.3, 2.2, 3.7)"},{"path":"fundamentos-da-linguagem-r.html","id":"fundamentos-da-linguagem-r","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"Capítulo 2 Fundamentos da Linguagem R","text":"","code":""},{"path":"fundamentos-da-linguagem-r.html","id":"sec:fundamentos_R","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.1 Introdução","text":"Nas próximas seções vou abordar os fundamentos da linguagem: os básicos de sua sintaxe, quais são estruturas e tipos de dados que linguagem oferece, e como suas regras de coercion funcionam.Na maior parte de sua análise, você não vai estar interessado em como o R está estruturando ou interpretando os seus dados em um dado momento. Porém, várias das funções ou ações que você deseja aplicar, exigem que os seus dados estejam estruturados em uma forma específica. Logo, ter familiaridade com os fundamentos R, com suas estruturas e suas propriedades, e principalmente, poder reconhecê-las, vai te salvar muito tempo. Com esse conhecimento, será mais fácil de você evitar erros, e será mais fácil de identificar e transformar estrutura de seus dados para qualquer que seja sua necessidade em um dado momento de sua análise.Tendo isso em mente, além de introduzir linguagem, próximas seções também tem como objetivo, lhe fornecer um base sólida desses fundamentos, para que você possa identificar e transitar entre essas diversas estruturas e tipos de dados, de forma flúida.","code":""},{"path":"fundamentos-da-linguagem-r.html","id":"objetos-uma-revisão","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.2 Objetos (uma revisão)","text":"Uma das principais características R, é que ele é uma linguagem orientada objetos (object oriented). Isto significa, que quando você estiver trabalhando com seus dados R, você estará aplicando operações e transformações sobre os objetos onde seus dados estão guardados.Os objetos R, são como caixas que você utiliza na sua mudança. Você guarda algo dentro dessa caixa, e coloca um adesivo com um nome para essa caixa, para que você se lembre que está dentro dela. dia seguinte à mudança, quando você precisar conteúdo que está guardado naquela caixa, você procura essa caixa pelo nome que você deu ela.exemplo abaixo, eu estou criando um objeto, que dou o nome de data_aniversario, e estou utilizando o símbolo <- para definir o valor deste objeto para data de aniversário de um amigo importante (20 de maio). O símbolo <- é comumente chamado de assignment, e significa que estamos atribuindo um valor um objeto (caso abaixo, data_aniversario). Em outras palavras, os comandos abaixo, podem ser lidos como: eu atribuo ao objeto de nome data_aniversario, o valor de \"20 de maio\". Após isso, sempre que eu chamar por esse nome, o R irá procurar por uma caixa (ou um objeto) que possui um adesivo com um nome de data_aniversario. Quando ele encontrar essa caixa, ele irá retornar console o que tem dentro dessa caixa (ou desse objeto).O conceito de objeto é uma metáfora, ou uma forma útil de enxergarmos este sistema. Pois para o R, o nome data_aniversario se trata apenas uma conexão até o valor (\"20 de maio\"). Para demonstrarmos essa ideia, vamos utilizar os endereços desses objetos. Isto é, todos os valores contidos nos objetos que você cria em sua sessão R, vão obrigatoriamente ocupar um espaço, ou um endereço da memória RAM de seu computador. Enquanto este objeto estiver “vivo,” ou seja, enquanto esta conexão entre o nome x e os seus valores permanecer acessível em sua sessão, esses valores vão estar ocupando um endereço específico de sua memória RAM. Para descobrirmos esse endereço, nós podemos utilizar função ref() pacote lobstr. Vamos supor por exemplo, que nós criamos um vetor chamado x, que contém três números. Perceba abaixo pelo resultado da função ref(), que ao criar este objeto x, os seus valores foram alocados endereço 0x1ca169c03d8 da minha memória RAM.Portanto, um objeto R, nada mais é que uma conexão entre um nome e valores que estão guardados em um endereço da memória RAM de seu computador. Os únicos momentos em que este endereço muda, serão todas vezes em que você reiniciar sua sessão R, ou todas vezes em que você executar novamente os códigos necessários para criar os seus objetos. Tendo isso em mente, em uma representação visual, um objeto R pode ser representado da seguinte maneira:\nFigure 2.1: Representação de um objeto\nPara desenvolvermos essa ideia, pense o que ocorreria, se atribuíssemos os valores objeto x, um novo objeto. Segundo essa perspectiva, nós estaríamos apenas conectando o vetor com os valores 6, 7 e 8, um novo nome, exemplo abaixo, ao nome y. Nós poderíamos utilizar novamente função ref() para conferirmos o endereço onde os valores objeto y, se encontram, e perceba que eles estão mesmo local que os valores objeto x.Logo, se atualizarmos nossa representação visual, temos o seguinte resultado:\nFigure 2.2: Conectando mais nomes um mesmo conjunto de valores\nEm outras palavras, o R em nenhum momento criou uma cópia vetor contendo os valores 6, 7 e 8, e alocou essa cópia objeto y. Ele apenas conectou um novo nome (y) esse vetor de valores. Por isso, quando você possui um objeto, e atribui um novo valor este objeto, você está na verdade eliminando conexão que o nome deste objeto possuía com o valor que estava guardado anteriormente naquele objeto. Ou seja, se você retornar ao vetor x, e definir um novo valor para ele, você estaria eliminando sua conexão com o vetor que contém os números 6, 7 e 8, e atribuindo essa conexão um outro conjunto de valores. Por exemplo, caso eu executasse o comando x <- \"Hello World\", o resultado seria uma nova conexão como você pode ver pela figura 2.3.\nFigure 2.3: Atribuindo novos valores seus objetos\nO R vai jogar fora, qualquer valor que não esteja conectado um nome, ou um objeto em sua sessão. Logo, tendo em mente figura 2.3, caso eu atribuísse um novo valor ao objeto y, uma outra conexão até o vetor que contém os números 6, 7 e 8, seria eliminada. Com isso, este vetor não possuiria mais nenhuma conexão até um nome, e por isso, seria descartado pelo R. Portanto, se você precisa atribuir um novo valor para um objeto, mas deseja manter o valor que você deu ele anteriormente, basta que você crie uma nova conexão até o valor antigo. Em outras palavras, se você quer manter este valor, basta conectá-lo um novo objeto.exemplo abaixo, eu crio um objeto (economista_1) contendo o nome de um economista famoso, e em seguida conecto este nome um novo objeto (economista_anterior). Portanto, o nome de Keynes está agora conectado dois nomes, ou está contido em dois objetos diferentes em sua sessão R. Por último, eu sobreponho o nome de Keynes que guardei primeiro objeto (economista_1), pelo nome de outro economista famoso. Quando faço isso, estou efetivamente eliminando uma das conexões até o nome de Keynes, e atribuindo essa conexão ao nome de Schumpeter. Porém, como o nome de Keynes ainda possui uma conexão existente (economista_anterior), o nome continua “vivo” e presente em nossa sessão, e se quisermos acessar novamente esse nome, basta chamarmos pelo objeto onde o salvamos.","code":"\ndata_aniversario <- \"20 de maio\"\n\n### Quando eu chamo pelo nome deste objeto\n### no console, o R me retorna o que tem dentro dele.\ndata_aniversario## [1] \"20 de maio\"\nlibrary(lobstr)\n\nx <- c(6, 7, 8)\n\nref(x)## [1:0x1ca169c03d8] <dbl> \ny <- x\n\nref(y)## [1:0x1ca169c03d8] <dbl> \n# Primeiro valor\neconomista_1 <- \"John Maynard Keynes\"\n\n# Atribuindo o primeiro valor a um novo\n# objeto\neconomista_anterior <- economista_1\n\n# Sobrepondo o primeiro valor no\n# primeiro objeto com um novo nome\neconomista_1 <- \"Joseph Alois Schumpeter\"\n\neconomista_1## [1] \"Joseph Alois Schumpeter\"\neconomista_anterior## [1] \"John Maynard Keynes\""},{"path":"fundamentos-da-linguagem-r.html","id":"estruturas-e-tipos-de-dados","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.3 Estruturas e tipos de dados","text":"O R possui diferentes formas de estruturar (ou organizar) os dados que você fornece ele. Essas formas são o que estou chamando de estruturas de dados. Quando estamos decidindo em qual estrutura devemos guardar os nossos dados, estamos basicamente fazendo o processo descrito na figura 2.4:\nFigure 2.4: Estruturas de dados\nAlém da forma como os nossos dados estão organizados dentro R, nós podemos estar interessados também na forma em que o R está interpretando os nossos dados, em um dado momento. Neste caso, estamos nos perguntando qual o tipo de dado que o R está associando aqueles valores, e em muitas ocasiões podemos nos surpreender com escolhas da linguagem. Uma supresa, que está representada na figura 2.5. Em resumo, quando eu vejo o valor \"20/05/2020\", eu rapidamente o associo à data 20 de maio de 2020, mas será que o R compreende que este valor se trata de uma data?Pelo fato das datas não estarem entre os tipos de dados básicos R, ele não vai identificar sozinho que aquele valor se trata de uma data, até que gente diga isso ele. Até lá, o R irá interpretar este valor como um simples texto. Isso é um ponto importante, pois várias funções ou ações que queremos executar R, exigem que os seus dados estejam tipo adequado. Por isso, você vai enfrentar diversas situações onde o console lhe retorna um erro confuso, e depois de alguns minutos, você busca conferir estrutura de seus dados, e descobre que o R estava o tempo todo interpretando os seus números como textos!\nFigure 2.5: Tipos de dados\nPortanto, vamos começar descrevendo nas próximas seções estruturas de dados presentes na linguagem, e em seguida, os tipos de dados básicos R. Até onde recordo, tem apenas uma estrutura R em específico, que não vou descrever nas próximas seções, que é o array. Nós veremos mais frente, matrizes, que R são vetores com duas dimensões (uma dimensão para linhas e outra para colunas). O array também é (assim como matriz) um vetor com mais de uma dimensão, porém, ele pode ser um vetor com “n” dimensões. Em outras palavras, com um array você pode criar um objeto tridimensional (3 dimensões), ou se quiser ir longe, um objeto com 4, 5, ou infinitas dimensões.","code":""},{"path":"fundamentos-da-linguagem-r.html","id":"sec:estruturas_dados","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.4 Estruturas de dados","text":"","code":""},{"path":"fundamentos-da-linguagem-r.html","id":"sec:vetores_estrutura","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.4.1 Vetores","text":"Os vetores são estrutura básica da linguagem R, pois todas outras estruturas, são construídas partir desses vetores. Um vetor é simplesmente uma sequência de valores. Valores que podem ser datas, números, textos, índices, ou qualquer outro tipo que você imaginar. Pelo fato de ser uma simples sequência de valores, o vetor é uma estrutura unidimensional. É como se esse vetor fosse composto por apenas uma coluna, que você preenche com quantas linhas você precisar. Ou então, você também pode imaginá-lo como uma corda, que amarra e mantém os seus valores conectados um atrás outro.forma mais simples de se criar um vetor, é através da função c() (abreviação para combine, ou combinar), em que você fornece os valores que quer incluir neste vetor, separando-os por vírgulas. outra forma (indireta) de se criar um vetor, é através de funções que retornam por padrão este tipo de estrutura. Um exemplo simples, é função : que serve para criar sequências numéricas R, exemplo abaixo, uso essa função para criar uma sequência de 1 10. Outro exemplo, seria função rep() que serve para repetir um conjunto de valores, por quantas vezes você quiser.Como o vetor é uma estrutura unidimensional, eu posso acessar um único valor dentro desse vetor, utilizando apenas um índice. Por exemplo, se eu quero extrair o quarto valor dessa sequência, eu utilizo o número 4, se eu quero o terceiro valor, o número 3, e assim por diante. Para acessar “partes,” ou um único valor de uma estrutura R, nós utilizamos função [, e para utilizá-la, basta abrir colchetes após o nome objeto onde você salvou este vetor, ou após função que está gerando este vetor.Para acessar mais de um valor dentro deste vetor, você terá que fornecer um novo vetor de índices à função [. Um jeito prático de criar este novo vetor de índices, é criando uma sequência com função : que vimos anteriormente. Um detalhe, é que o R irá extrair os valores na ordem em que você os dá [. Logo, se eu dentro de [ incluir o vetor c(2,4,6,1), o R irá lhe retornar um novo vetor, que contém o segundo, quarto, sexto e primeiro item vetor anterior, respectivamente. Caso você repita algum índice, o R irá repetir o valor dentro vetor resultante, e não te avisará sobre isso.Os vetores que estamos criando com essas funções são comumente chamados de vetores atômicos (atomic vector). Esses vetores possuem uma propriedade simples e importante: vetores atômicos possuem apenas um único tipo de dado dentro deles. Você não consegue guardar dentro de um mesmo vetor, valores de dois tipos de dados diferentes (por exemplo, textos e números) sem que alguma transformação ocorra. Caso você tente burlar essa regra, o R irá automaticamente converter os valores para um único tipo de dado, e pode ser que parte desses dados não possam ser convertidos de forma lógica para este único tipo, e acabam sendo “perdidos” neste processo. Falaremos mais sobre esse processo de conversão, quando chegarmos em tipos de dados.","code":"\nc(48, 24, 12, 6)## [1] 48 24 12  6\nc(\"a\", \"b\", \"c\", \"d\")## [1] \"a\" \"b\" \"c\" \"d\"\n1:10##  [1]  1  2  3  4  5  6  7  8  9 10\nrep(c(\"Ana\", \"Eduardo\"), times = 5)##  [1] \"Ana\"     \"Eduardo\" \"Ana\"     \"Eduardo\" \"Ana\"     \"Eduardo\" \"Ana\"    \n##  [8] \"Eduardo\" \"Ana\"     \"Eduardo\"\nvetor <- 1:10\n\nvetor[4]## [1] 4\nc(\"a\", \"b\", \"c\")[3]## [1] \"c\"\nvetor <- 1:25\n\nvetor[1:4]## [1] 1 2 3 4\nvetor[8:13]## [1]  8  9 10 11 12 13\nvetor[c(2,4,4,1)]## [1] 2 4 4 1"},{"path":"fundamentos-da-linguagem-r.html","id":"matrizes","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.4.2 Matrizes","text":"Matrizes nada mais são que vetores com duas dimensões. Se você possui dados atualmente alocados em um vetor, e deseja organizá-los em colunas e linhas, você pode rapidamente criar uma matriz com este vetor, ao adicionar dimensões ele, através da função dim(). Você usa função sobre o vetor desejado à esquerda símbolo de assignment (<-), e atribui um valor ao resultado dessa função. caso de matrizes, esse valor será um vetor com dois elementos, o primeiro definindo o número de linhas, e o segundo, o número de colunas.Uma outra forma de criar uma matriz, é através da função matrix(). Você primeiro fornece um vetor à função, e define quantas colunas você deseja em ncol, e quantas linhas em nrow. Um detalhe que fica claro exemplo abaixo, é que ao criar uma matriz, ela por padrão será preenchida por coluna, e não por linha. Caso você queira que ela seja preenchida por linha, você deve adicionar o valor TRUE, ao argumento byrow na função.Os vetores são estruturas unidimensionais, e com apenas um índice poderíamos acessar um valor contido nele. Porém, matrizes possuem duas dimensões, logo, teremos que fornecer dois índices à função [ para acessarmos um único elemento dessa matriz. Basta você separar esses dois índices por uma vírgula, onde o primeiro valor corresponde linha, e o segundo, coluna desejada. exemplo abaixo, estou extraindo o elemento que se encontra na terceira linha da quarta coluna.Eu posso também extrair uma parte dessa matriz, ao fornecer mais valores dentro de um vetor, para cada um dos dois índices. primeiro exemplo abaixo, eu extraio todos os valores da primeira terceira linha da segunda coluna da matriz. Agora, caso eu queira extrair todos os valores de uma dimensão (todas linhas, ou todas colunas), basta que eu deixe em “branco” o lado de cada índice. segundo exemplo abaixo, estou extraindo todos os valores da segunda coluna.Pelo fato de matrizes serem vetores com duas dimensões, elas herdam propriedade vetor, e portanto: matrizes podem conter dados de apenas um único tipo. Por essa característica, você provavelmente utilizará essa estrutura poucas vezes. De qualquer forma é útil conhecê-la.","code":"\nvetor <- 1:6\n\ndim(vetor) <- c(3,2)\n\nvetor##      [,1] [,2]\n## [1,]    1    4\n## [2,]    2    5\n## [3,]    3    6\n# Para preencher a matriz, por linha, adicione\n# byrow = TRUE à função\nmatrix(1:20, nrow = 5, ncol = 4)##      [,1] [,2] [,3] [,4]\n## [1,]    1    6   11   16\n## [2,]    2    7   12   17\n## [3,]    3    8   13   18\n## [4,]    4    9   14   19\n## [5,]    5   10   15   20\nmatriz <- matrix(1:20, nrow = 5, ncol = 4)\n\nmatriz[3,4]## [1] 18\nmatriz[1:3, 2] # É o mesmo que: matriz[c(1,2,3), 2]## [1] 6 7 8\nmatriz[ , 2]## [1]  6  7  8  9 10"},{"path":"fundamentos-da-linguagem-r.html","id":"listas","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.4.3 Listas","text":"lista é uma estrutura especial e muito importante R, pois ela é exceção da propriedade dos vetores (que podem conter apenas um tipo de dado). Portanto, uma lista é um vetor, onde cada elemento deste vetor pode ser não apenas de um tipo de dado diferente, mas também de tamanho e estrutura diferentes. Dito de outra forma, você pode incluir o que você quiser em cada elemento de uma lista.Uma lista é criada pela função list(), e para utilizá-la, basta fornecer os valores que deseja inserir em cada elemento desta lista, separados por vírgulas. exemplo abaixo, estou inserindo primeiro elemento desta lista data que vimos anteriormente (“20/05/2020”), segundo, estou incluindo uma matriz, terceiro, um vetor com nomes, e quarto, um data.frame (falaremos sobre eles após essa seção).Perceba que nós nomeamos cada elemento dessa lista. Isso abre novas possibilidades, pois agora podemos utilizar um sistema diferente da função [ para acessarmos os valores específicos de uma lista, utilizando o operador $. Através deste operador, podemos acessar os elementos dessa lista, através nome que demos para cada um deles. O problema deste sistema, é que ele lhe permite acessar todos os valores contidos em um elemento de sua lista, mas não lhe permite extrair valores específicos contidos em cada um destes elementos da lista.Você não precisa nomear cada um dos elementos dessa lista como fizemos acima. Eu nomeie apenas para dar um exemplo operador $. Porém, neste caso em que você não atribui um nome esses elementos, você não pode acessá-los mais pelo operador $, e terá que retornar à funçaõ [ para tal serviço. Em outras palavras, se você deseja criar uma lista, mas não está muito preocupado em nomear cada um dos elementos que vão estar nessa lista, basta separar esses valores por vírgulas como exemplo abaixo:Antes de prosseguirmos, darei uma nova descrição (desssa vez, uma descrição visual) de uma lista, para que você fixe na sua cabeça o que ela é. Eu espero que eu tenha desejado bem o suficiente, para que você seja capaz de identificar um trem carregando quatro vagões na figura 2.6. Podemos pensar esse trem como uma lista, e os seus vagões como os elementos dessa lista. Tendo isso em mente, temos na figura 2.6 uma representação de uma lista com quatro elementos.Como disse anteriormente, podemos incluir o que quisermos dentro de cada elemento dessa lista, ou dentro de cada vagão desse trem. Pois cada vagão é capaz de comportar elementos de qualquer dimensão e em qualquer estrutura, e como esses vagões estão separados uns dos outros, esses elementos não precisam compartilhar das mesmas características. Dito de outra forma, eu posso carregar 15 toneladas de ouro primeiro vagão, 100 Kg de carvão segundo vagão, e 1 Kg de ferro terceiro vagão.\nFigure 2.6: Representação de uma lista\nPortanto, lista é uma estrutura que lhe permite transportar todos esses diferentes elementos, em um mesmo objeto R (ou todos esses diferentes componentes em um mesmo trem). Quando chegarmos em interação, você verá que essa característica torna lista, uma estrutura extremamente útil.Agora como eu posso extrair valores dessa lista através da função [ ? Bem, lista é exceção da propriedade dos vetores, mas ela continua sendo um vetor em sua essência, ou uma estrutura unidimensional. Por isso, você pode acessar um item de uma lista com apenas um índice dentro de [.Porém, caso você usar apenas um colchete para selecionar o primeiro elemento de sua lista, você percebe que uma pequena descrição (\"[[1]]\"), ou o nome que você deu aquele elemento, aparece em cima dos valores contidos neste elemento da lista. Por isso, se você deseja extrair apenas os valores desse elemento, sem essa descrição, você deve utilizar o índice dentro de dois colchetes.Isso ocorre, porque quando você utiliza apenas um colchete para selecionar o primeiro elemento, o R acaba lhe retornando uma nova lista contendo um elemento, e não apenas o que está dentro deste elemento em si. Dizendo em termos da representação visual que utilizamos na figura 2.6, se eu possuo um trem com quatro vagões, e utilizo um colchete para selecionar o primeiro vagão, o R retorna um novo trem que contém o primeiro vagão. Mas se eu utilizo dois colchetes, o R retorna apenas o primeiro vagão, e nada mais.\nFigure 2.7: Diferença entre um e dois colchetes em listas\nMas como eu faço para extrair um valor específico de um elemento de uma lista? Para isso você deve abrir um novo colchete após os colchetes duplos que você criou para selecionar o elemento da lista. partir daí, basta replicar o que vimos anteriormente com os índices. exemplo abaixo, estou primeiro selecionando o terceiro elemento da nossa lista (que é uma matriz), e selecionando o item da terceira linha da primeira coluna desta matriz.","code":"\n# Lista nomeada\n# nome = valor\nlista <- list(\n  data = \"20/05/2020\",\n  matriz = matrix(1:20, ncol = 4, nrow = 5),\n  vetor = c(\"Belo Horizonte\", \"Londrina\", \"Macapá\"),\n  tabela = data.frame(x = 21:30, y = rnorm(10))\n)\n\nlista## $data\n## [1] \"20/05/2020\"\n## \n## $matriz\n##      [,1] [,2] [,3] [,4]\n## [1,]    1    6   11   16\n## [2,]    2    7   12   17\n## [3,]    3    8   13   18\n## [4,]    4    9   14   19\n## [5,]    5   10   15   20\n## \n## $vetor\n## [1] \"Belo Horizonte\" \"Londrina\"       \"Macapá\"        \n## \n## $tabela\n##     x          y\n## 1  21  1.0630998\n## 2  22 -0.3041839\n## 3  23  0.3700188\n## 4  24  0.2670988\n## 5  25 -0.5425200\n## 6  26  1.2078678\n## 7  27  1.1604026\n## 8  28  0.7002136\n## 9  29  1.5868335\n## 10 30  0.5584864\nlista$matriz##      [,1] [,2] [,3] [,4]\n## [1,]    1    6   11   16\n## [2,]    2    7   12   17\n## [3,]    3    8   13   18\n## [4,]    4    9   14   19\n## [5,]    5   10   15   20\nlista$vetor## [1] \"Belo Horizonte\" \"Londrina\"       \"Macapá\"\nlista <- list(\n  c(6, 7, 8),\n  c(\"a\", \"b\", \"c\"),\n  c(T, F, T)\n)\n\nlista## [[1]]\n## [1] 6 7 8\n## \n## [[2]]\n## [1] \"a\" \"b\" \"c\"\n## \n## [[3]]\n## [1]  TRUE FALSE  TRUE\nlista <- list(\n  1:20,\n  \"O ano tem 365 dias\",\n  matrix(1:20, ncol = 4, nrow = 5)\n)\n\nlista[1]## [[1]]\n##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\nlista[[1]]##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\nlista[[2]]## [1] \"O ano tem 365 dias\"\nlista[[3]]##      [,1] [,2] [,3] [,4]\n## [1,]    1    6   11   16\n## [2,]    2    7   12   17\n## [3,]    3    8   13   18\n## [4,]    4    9   14   19\n## [5,]    5   10   15   20\nlista[[3]][3,1]## [1] 3"},{"path":"fundamentos-da-linguagem-r.html","id":"tabelas-no-r-data.frame","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.4.4 Tabelas no R: data.frame","text":"O data.frame é principal estrutura utilizada para guardar tabelas e bases de dados R. Na grande maioria das vezes que você importar os seus dados para o R, eles serão alocados dentro de um data.frame. Essa estrutura é fundo, uma lista com algumas propriedades mais. Por isso, o data.frame herda uma de suas principais propriedades: cada uma das colunas da tabela formada por um data.frame, pode conter um tipo de dado diferente das demais colunas deste data.frame.Esta é uma das principais características que tornam o data.frame, uma estrutura adequada para guardar grande maioria das bases de dados. Pois é muito comum, que você possua em sua base, diversas colunas contendo dados de diferentes tipos. Por exemplo, você pode ter uma base que possui uma coluna contendo datas, outras duas contendo valores numéricos, e uma última coluna contendo textos, ou rótulos indicando qual indicador ou grupo, os valores numéricos da linha se referem. E ao importar uma base como essa para o R, é de seu desejo que o R interprete essas colunas corretamente e mantenha os tipos desses dados intactos.Os data.frame’s são criados pela função data.frame(). Você deve preencher essa função com os valores que você deseja alocar em cada coluna separados por vírgulas. Você pode escolher não dar um nome cada coluna, neste caso função se ocupará de dar um nome genérico para elas. Caso opte por definir esses nomes, você deve fornecê-los antes dos valores da coluna, seguindo seguinte estrutura:Caso você esteja em dúvida, tudo o que função rnorm() faz é gerar valores aleatórios seguindo uma distribuição normal. Vemos que exemplo acima, geramos uma tabela com 3 colunas e 10 linhas, e aqui chego segunda principal propriedade de um data.frame, que é: todas colunas de um data.frame devem possuir o mesmo número de linhas. O motivo dessa propriedade é um pouco óbvio, pois se estamos tentando formar uma tabela de dados, é natural pensarmos que ela deve formar um retângulo uniforme.Isso significa, que se eu pedisse para função rep() repetir os valores 6 vezes (ao invés de 5), gerando assim um vetor de 12 elementos (ou 12 linhas), função data.frame() retornaria um erro, indicando que o número de linhas criadas pelos diferentes vetores não possuem o mesmo número de linhas.Caso não tivéssemos essa propriedade, estaríamos permitindo que alguma dessas colunas deste data.frame, fosse mais longa que outras. Neste caso, como você lidaria com observações “sobressalentes” da tabela ? Você possui um valor na coluna x que não possui um valor correspondente na coluna y, será que você considera o valor da coluna y como vazio ? Não disponível ? Não existente ? Enfim, uma confusão que é desnecessária.Essa propriedade nos garante que para cada observação (ou linha) da nossa tabela, deve sempre existir um valor na coluna y correspondente ao valor da coluna x, mesmo que o valor da coluna y seja um valor NA (não disponível), ou algo indicando que não foi possível coletar esse valor plano físico de nossa atividade.Ao voltar para o exemplo acima, você pode perceber que na terceira coluna que definimos em data.frame(), demos uma simples constante (25) à função. Como resultado, função acaba preenchendo toda coluna por essa constante. Isso ocorre sempre que você fornece um único valor uma coluna de seu data.frame, seja este valor, uma data, um texto, um número ou qualquer outro tipo que imaginar.partir daqui, é interessante criarmos um modelo visual em nossa cabeça, sobre o que um data.frame representa. Como disse anteriormente, um data.frame, é basicamente uma lista, com algumas propriedades mais, em especial propriedade de que todos os seus elementos devem possuir o mesmo número de linhas. Portanto, se você quer imaginar um data.frame em sua mente, você pode imaginar uma lista, onde cada um de seus elementos, representa uma coluna desse data.frame. Em conjunto, essas colunas (ou os elementos dessa lista) formam uma tabela, sendo essa tabela, comumente referida como um data.frame.\nFigure 2.8: Representação de um data.frame partir de uma lista\nVale destacar um outro comportamento da função data.frame(). Ela transforma por padrão, todos os textos em fatores (factor), ou em outras palavras, valores de uma variável categórica que possui um conjunto limitado de valores possíveis. Vamos aprender mais sobre este tipo de dados nas próximas seções. Inicialmente, isso não tem grandes implicações sobre os seus dados. Eles vão continuar sendo apresentados como textos, e única grande mudança será sobre forma como o R irá ordenar esses valores caso você peça isso ele. Mas é importante saber deste detalhe, pois você vai querer suprimir esse comportamento na maioria das vezes. Para isso, basta adicionar o valor FALSE para o argumento stringsAsFactors.exemplo acima, você também percebe que eu utilizei dentro da função .character(), o operador $ para acessar os valores da coluna cidade da nossa tabela. Em data.frame’s você sempre pode utilizar este mecanismo para acessar os valores de uma das colunas de sua tabela, pois data.frame() irá sempre se preocupar em nomear colunas caso você não o faça. Portanto, mesmo que data.frame() invente um nome completamente esquisito para suas colunas, elas sempre terão um nome para o qual você pode se referir com $.Isso não significa que você deixará de utilizar o sistema [, pois essa função é muito mais flexível que você imagina. Uma de suas principais e mais poderosas ferramentas, é um sistema que é comumente chamado de logical subsetting. Com ele, podemos usar função [ para extrair valores de um objeto, de acordo com o resultado de testes lógicos. Em diversas funções de pacotes que você utilizar, se você visitar o código fonte dessas funções, você irá encontrar este sistema sendo utilizado em algum momento, sendo portanto, uma ferramenta extremamente útil dentro R.Em resumo, se você quer extrair todos os valores de uma coluna de seu data.frame, você pode utilizar o sistema $, ou o mesmo sistema que utilizamos em matrizes, ao deixar o índice das linhas em “branco” dentro de [. Se você quer extrair partes específicas de sua tabela, você terá que usar [ da mesma forma que o utilizamos em matrizes. Como colunas de um data.frame são nomeados, você pode também extrair uma coluna inteira, ao colocar o nome dessa coluna entre aspas dentro dos colchetes. Todos os sistemas utilizados abaixo, nos retorna todos os valores da coluna cidade.Você deve ter percebido acima que utilizei novamente os dois colchetes, ao referir dentro deles pelo nome da coluna desejada. Este sistema funciona exatamente da mesma forma que ele funciona em listas. Se eu utilizar um colchete, o R retorna um data.frame contendo uma única coluna (neste caso, coluna cidade), se eu uso dois colchetes, o R retorna um vetor contendo apenas os valores dessa coluna.Agora, voltando um pouco em nossa descrição, quando eu disse que um data.frame são listas, pois herdava muitas de suas propriedades, eu acabei omitindo uma dessas propriedades para evitar confusões. Você deve ter percebido pelos exemplos anteriores, que cada elemento de um data.frame é uma coluna de sua tabela. Você talvez tenha percebido também que todos esses elementos nos exemplos anteriores, eram vetores. Isso é uma característica marcante de um data.frame, pois na maioria das vezes em que você ver um, ele estará servindo apenas como um laço, que amarra e mantém diferentes vetores unidos em uma mesma estrutura, vetores esses que juntos formam uma tabela.Você deve estar pensando: “Mas é claro que cada coluna é um vetor! Não faria sentido se eu incluísse matrizes ou outras tabelas em uma coluna de uma tabela! Um vetor é estrutura que faz mais sentido para essas colunas!” Bom, eu creio que agora é uma boa hora para “explodir” sua cabeça!…ou pelo menos metaforicamente falando. outra propriedade que data.frame’s herdam de listas, é que cada um de seus elementos também não precisam ser da mesma estrutura. Essa propriedade significa que eu posso incluir sim, uma matriz, ou um outro data.frame, como uma nova coluna de um data.frame que está salvo em algum objeto. Lembre-se que principal diferença entre um data.frame e uma lista, é que os elementos de um data.frame precisam obrigatoriamente ter o mesmo número de linhas. exemplo abaixo, eu estou criando inicialmente um data.frame com 10 linhas e 2 colunas, logo, se eu quiser incluir uma nova tabela como uma nova coluna desse data.frame, essa nova tabela (ou novo data.frame) deve possuir 10 linhas (mas esse novo data.frame pode ter quantas colunas você desejar).Você pode facilmente adicionar uma nova coluna um data.frame, utilizando o operador $. Você escreve primeiro o nome objeto onde o seu data.frame está contido, abre o cifrão ($), e em seguida, coloca um nome de uma coluna que não existe em seu data.frame até aquele momento. Se não há alguma coluna neste data.frame que possui este nome, o R irá adicionar esta coluna ele, e para você preencher essa coluna com algum valor, basta utilizar o símbolo de assignment (<-), como se você estivesse salvando algum valor em um novo objeto. Após criar essa nova coluna, eu chamo por ela, para que o R mostre o que tem nessa coluna, e como esperávamos, ele retorna o novo data.frame que criamos.Na figura 2.5, estou utilizando função str() sobre o objeto tabela. Essa função nos retorna console, uma descrição da estrutura de um objeto. retângulo vermelho, temos estrutura geral objeto, vemos que o objeto tabela é um data.frame com dez linhas e três colunas. Os nomes de suas três colunas estão especificadas retêngulo verde. direita nome da terceira coluna (chamada novo_dataframe), podemos ver uma descrição de sua estrutura marcada por um retângulo azul. Vemos neste retângulo azul, portanto, estrutura desta terceira coluna, e podemos confirmar que se trata também de um data.frame com 10 linhas e 3 colunas, e retângulo roxo, podemos ver o nome das três colunas (caso abaixo, colunas x, y e z) contidas neste segundo data.frame. Os falantes de língua inglesa costumam se referir esta situação onde inserimos uma nova estrutura dentro de uma mesma estrutura, como uma nested structure, ou uma estrutura “aninhada.” Logo, o exemplo que estou dando, se trata de um nested data.frame. Pois estamos inserindo um data.frame, dentro de um outro data.frame.\nFigure 2.9: Estrutura de um data.frame aninhado\nSe você chamar pelo nome tabela console, para ver o que tem dentro deste objeto, o console irá lhe mostrar um data.frame com 10 linhas e 5 colunas. Pois ele lhe apresenta tanto 2 colunas definidas como vetores em tabela, quanto 3 colunas definidas em tabela$novo_dataframe, tudo em uma mesma tabela. Entretanto, como vimos através da função str(), o R está considerando este objeto como um data.frame com 10 linhas e 3 colunas, onde terceira coluna contém um novo data.frame de 10 linhas e com outras 3 colunas, e não como um único data.frame com 10 linhas e 5 colunas.Tendo essas considerações em mente, você pode sim incluir dados que estão em qualquer uma das estruturas anteriormente mencionadas, dentro de uma coluna (ou elemento) de um data.frame. Essa propriedade é mais citada nos manuais originais da linguagem (R Core Team 2020b, 2020a), enquanto é muito pouco mencionada, ou pouco explicada em detalhes em outros livros-texto sobre linguagem. Pois é uma propriedade que faz pouco sentido, considerando-se principais aplicações de um data.frame. Porém, com essa propriedade, você pode pensar facilmente em uma outra estrutura que é muito mais útil e muito mais poderosa, para ser incluída em uma nova coluna de seu data.frame. Essa estrutura, é uma lista!Pense um pouco sobre isso. Uma lista é um vetor em sua essência, e por isso, pode facilmente formar uma nova coluna desse data.frame. vantagem de se incluir uma lista, é que agora em cada célula (ou em cada linha) dessa nova coluna, eu posso guardar um dado de um tipo, tamanho e estrutura diferentes. Se fossemos utilizar representação visual da seção anterior, é como se coluna de seu data.frame tenha se transformado em um trem, e agora cada célula, ou cada linha dessa coluna, tenha se tornado um vagão deste trem. Com essa realidade, você pode por exemplo, facilmente aplicar um modelo de regressão sobre 1.000 bases de dados diferentes, e ainda guardar os resultados em cada linha de uma nova coluna, tudo isso com apenas um comando! Dessa forma, você terá em uma coluna de seu data.frame contendo uma lista, lista essa que está mantendo todos esses 1.000 data.frame’s diferentes juntos.Se você consegue entender língua inglesa, mesmo que sutilmente, eu altamente recomendo que assista palestra de Hadley Wickham, entitulada “Managing many models R”, que está disponível YouTube6. Nesta palestra, ele dá um exemplo prático de como você pode implementar essa ideia, ao aplicar um modelo de regressão sobre várias bases diferentes, utilizando essa propriedade em um data.frame.","code":"\n# Estrutura Básica:\n# data.frame(\n#   <nome_coluna> = <valor_coluna> \n# )\n\ndata.frame(\n  nomes = rep(c(\"Ana\", \"Eduardo\"), times = 5),\n  numeros = rnorm(10),\n  constante = 25\n)##      nomes     numeros constante\n## 1      Ana -1.27659221        25\n## 2  Eduardo -0.57326541        25\n## 3      Ana -1.22461261        25\n## 4  Eduardo -0.47340064        25\n## 5      Ana -0.62036668        25\n## 6  Eduardo  0.04211587        25\n## 7      Ana -0.91092165        25\n## 8  Eduardo  0.15802877        25\n## 9      Ana -0.65458464        25\n## 10 Eduardo  1.76728727        25\ntabela <- data.frame(\n  cidade = rep(c(\"Belo Horizonte\", \"Londrina\", \"Macapá\"), times = 4),\n  valor = rnorm(12),\n  stringsAsFactors = FALSE\n)\n\n# Estou utilizando a função is.character()\n# para confirmar que data.frame() manteve\n# a coluna de cidades como texto (characters)\nis.character(tabela$cidade)## [1] TRUE\ntabela$cidade\n\ntabela[, 1]\n\ntabela[[\"cidade\"]]\ntabela <- data.frame(\n  cidade = rep(c(\"Belo Horizonte\", \"Londrina\"), times = 5),\n  valor = rnorm(10)\n)\n\ntabela$novo_dataframe <- data.frame(\n  x = rep(\"Ana\", times = 10),\n  y = rep(\"Eduardo\", times = 10),\n  z = 25\n)\n\ntabela$novo_dataframe##      x       y  z\n## 1  Ana Eduardo 25\n## 2  Ana Eduardo 25\n## 3  Ana Eduardo 25\n## 4  Ana Eduardo 25\n## 5  Ana Eduardo 25\n## 6  Ana Eduardo 25\n## 7  Ana Eduardo 25\n## 8  Ana Eduardo 25\n## 9  Ana Eduardo 25\n## 10 Ana Eduardo 25"},{"path":"fundamentos-da-linguagem-r.html","id":"sec:fundamentos_tibble","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.4.5 tibble’s como uma alternativa moderna aos data.frame’s","text":"Um tibble nada mais é que uma “versão moderna” de um data.frame. Essa estrutura de dado é originária pacote tibble, logo, se você deseja utilizá-la em algum de seus dados, você terá que chamar obrigatoriamente por esse pacote com o comando library()7. Lembre-se que o pacote deve estar instalado em sua máquina, para que você seja capaz de chamar por ele com o comando library().Portanto, essa estrutura foi criada com o intuito de melhorar alguns comportamentos data.frame, que eram adequados para sua época, mas que hoje, são desnecessários e que podem gerar um pouco de dor de cabeça. Tais estruturas podem ser criadas zero, através da função tibble(), que funciona da mesma maneira que data.frame(). Você dá o nome para cada coluna, e após um igual (=) você define o que irá preencher cada uma dessas colunas.Por outro lado, se você já possui um data.frame e deseja convertê-lo para um tibble, você precisa apenas aplicar função as_tibble() sobre ele.primeira melhoria dessas estruturas, se encontra método de print(), ou em outras palavras, na forma como o R lhe mostra sua tabela console. Quando chamamos por um objeto que é um data.frame, o console acaba lhe retornando muito mais linhas que o necessário (ele pode retornar até 1000 linhas), além de todas colunas da tabela. Se o seu data.frame possui várias colunas, você pode se sentir frustrado com esse comportamento, pois se alguma coluna de sua tabela não couber ao lado das colunas anteriores, o console acaba quebrando o resultado em várias “linhas,” algo que pode tornar leitura confusa com certa facilidade.origens R são antigas (> 50 anos), e aparentemente esse não era um comportamento muito ruim na época, talvez porque dimensões das tabelas dessa época eram muito limitadas. Porém, com capacidades de processamento atuais, essa atitude é desnecessária ou indesejada em quase todas situações. Veja exemplo abaixo, onde eu pego base flights (que possui 19 variáveis diferentes), e transformo-em um data.frame com função .data.frame(). Para que o resultado não consuma muito espaço deste material, eu ainda limito o resultado às 5 primeiras linhas da tabela com head(). Perceba que tabela foi dividida em 3 linhas diferentes de output.Quando suas tabelas são tibble’s, o console lhe retorna por padrão, apenas 10 primeiras linhas da tabela (caso tabela seja muito pequena, ele pode lhe retornar todas linhas), o que já é o suficiente para vermos sua estrutura. Além disso, caso próximas colunas não caibam em uma mesma “linha,” ou ao lado das colunas anteriores, o tibble acaba omitindo essas colunas para não sobrecarregar o seu console de resultados. Lembre-se que você sempre pode ver toda tabela, em uma janela separada através da função View().Veja o exemplo abaixo, onde eu chamo novamente pela base flights. O primeiro detalhe que você percebe, é dimensão da tabela (algo que não é informado, quando chamamos por um data.frame) canto superior esquerdo da tabela (336.776 linhas e 19 colunas). O segundo detalhe, é que o tipo de dado contido em cada coluna, está descrito logo abaixo nome da coluna, de acordo com abreviação deste tipo. Por exemplo, nas três primeiras colunas estão contidos números inteiros (integer’s - int), enquanto na sexta coluna (dep_delay) temos números decimais (double’s - dbl).Mesmo que em um tibble, você fique sem possibilidade de visualizar todas outras colunas da tabela, que não cabem na mesma linha junto com colunas anteriores, um tibble sempre lhe retorna logo abaixo da tabela, uma lista contendo o nome de todas colunas restantes, além tipo de dado contido em cada coluna, através das mesmas abreviações que vimos nas colunas anteriores.Além desses pontos, tibble’s vão sempre criar destaques, ou ênfases em certos dados console, algo que os data.frame’s não fazem em nenhum momento. Por exemplo, tibble’s vão sempre marcar de vermelho, qualquer número que seja negativo, uma funcionalidade que é bem familiar aos usuários de Excel que utilizam formatação condicional. Um outro detalhe, é que essa estrutura também marca casas dos milhares com um pequeno sublinhado, o que facilita muito leitura de números muito grandes.\nFigure 2.10: Ênfase em valores numéricos presentes em um tibble\nPara mais, um comportamento muito comum de um data.frame, é converter os seus dados em textos, para fatores (factor). Este não é um comportamento de todo ruim, e nem sempre ele ocorre. Porém o principal valor dos fatores R, está uso de dummies em regressões e análises estatísticas, além da maneira como ordenação de seus valores é executada. Estas características são importantes, mas também são irrelevantes para uma gama muito grande de situações. Em outras palavras, este é um comportamento desnecessário na maioria de nossas análises.Por isso, uma outra característica que os tibble’s carregam, é que eles nunca transformam os seus dados para um outro tipo. Isso é um ponto muito importante! funções com quais nós trabalhamos R, geralmente funcionam melhor com (ou são especializadas em) uma estrutura ou tipo de dado específico, e quando nós estruturamos nossas análises sobre essas funções, nós desejamos evitar mudanças não autorizadas sobre os tipos e estruturas utilizados.Ou seja, é sempre melhor evitar transformações implícitas de seus dados. Pois essas operações podem muito bem, levantar erros dos quais você não compreende, até que você (depois de muito tempo analisando os resultados) perceba que os seus dados foram convertidos para algo incompatível com o que você deseja realizar.Dessa forma, em um tibble os seus dados em texto são interpretados como textos (character), menos que você peça explicitamente ao R que interprete esses dados de uma outra forma. Veja o exemplo abaixo, onde utilizo função str() para ver um resumo da estrutura de cada tabela. Podemos ver abaixo, que coluna text na tabela tib contém dados tipo character (chr), enquanto essa mesma coluna na tabela df, possui dados tipo factor.Uma última característica de um tibble, é que ele lhe permite criar colunas com nomes que não respeitam regras usuais R. Por exemplo, não é permitido criar variáveis que possuam um nome que se inicia por um número, ou então, que possuam algum tipo de espaço ao longo dele. Mas dentro de um tibble, você não possui tais restrições. exemplo abaixo, eu tento ultrapassar essa regra na função data.frame(), e ela acaba preenchendo o espaço nome, com um ponto (.), e também coloca uma letra qualquer antes número da coluna “10_janeiro,” enquanto em um tibble, isso não ocorre. Entretanto, mesmo que você possua essa liberdade em um tibble, ao se referir essas colunas que não se encaixam nas regras R, você terá de contornar o nome dessas colunas, com acentos graves ().Portanto, os tibble’s foram criados com o intuito de manter funcionalidades importantes de um data.frame, e ao mesmo tempo, eliminar comportamentos que hoje são desnecessários ou ineficientes. Em resumo, um tibble é uma estrutura preguiçosa. Pois ele nunca converte implicitamente os seus dados para algum outro tipo, ele não altera o nome de suas colunas, e ele também não sobrecarrega o seu console com linhas e linhas de resultados, lhe mostrando apenas o necessário.","code":"\nlibrary(tibble)\n\ntab_tibble <- tibble(\n  Datas = seq.Date(as.Date(\"2020-12-01\"), as.Date(\"2020-12-10\"), by = 1),\n  Usuario = sample(c(\"Ana\", \"Eduardo\"), size = 10, replace = T),\n  Valor = sample(c(2000, 3000, 4000, 5000), size = 10, replace = T)\n)\n\ntab_tibble## # A tibble: 10 x 3\n##    Datas      Usuario Valor\n##    <date>     <chr>   <dbl>\n##  1 2020-12-01 Eduardo  2000\n##  2 2020-12-02 Ana      2000\n##  3 2020-12-03 Ana      5000\n##  4 2020-12-04 Eduardo  3000\n##  5 2020-12-05 Eduardo  3000\n##  6 2020-12-06 Ana      3000\n##  7 2020-12-07 Ana      2000\n##  8 2020-12-08 Ana      5000\n##  9 2020-12-09 Ana      2000\n## 10 2020-12-10 Eduardo  2000\ntabela <- as_tibble(tabela)\nlibrary(nycflights13)\n\nas.data.frame(flights) %>% \n  head(n = 5)##   year month day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n## 1 2013     1   1      517            515         2      830            819\n## 2 2013     1   1      533            529         4      850            830\n## 3 2013     1   1      542            540         2      923            850\n## 4 2013     1   1      544            545        -1     1004           1022\n## 5 2013     1   1      554            600        -6      812            837\n##   arr_delay carrier flight tailnum origin dest air_time distance hour\n## 1        11      UA   1545  N14228    EWR  IAH      227     1400    5\n## 2        20      UA   1714  N24211    LGA  IAH      227     1416    5\n## 3        33      AA   1141  N619AA    JFK  MIA      160     1089    5\n## 4       -18      B6    725  N804JB    JFK  BQN      183     1576    5\n## 5       -25      DL    461  N668DN    LGA  ATL      116      762    6\n##   minute           time_hour\n## 1     15 2013-01-01 10:00:00\n## 2     29 2013-01-01 10:00:00\n## 3     40 2013-01-01 10:00:00\n## 4     45 2013-01-01 10:00:00\n## 5      0 2013-01-01 11:00:00\nView(flights)\nflights## # A tibble: 336,776 x 19\n##     year month   day dep_time sched_dep_time dep_delay arr_time\n##    <int> <int> <int>    <dbl>          <dbl>     <dbl>    <dbl>\n##  1  2013     1     1      517            515         2      830\n##  2  2013     1     1      533            529         4      850\n##  3  2013     1     1      542            540         2      923\n##  4  2013     1     1      544            545        -1     1004\n##  5  2013     1     1      554            600        -6      812\n##  6  2013     1     1      554            558        -4      740\n##  7  2013     1     1      555            600        -5      913\n##  8  2013     1     1      557            600        -3      709\n##  9  2013     1     1      557            600        -3      838\n## 10  2013     1     1      558            600        -2      753\n## # ... with 336,766 more rows, and 12 more variables: sched_arr_time <dbl>,\n## #   arr_delay <dbl>, carrier <chr>, flight <dbl>, tailnum <chr>,\n## #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n## #   minute <dbl>, time_hour <dttm>\ntib <- tibble(\n  x = rnorm(10),\n  text = sample(c(\"Ana\", \"Eduardo\"), size = 10, replace = T)\n)\n\ndf <- data.frame(\n  x = rnorm(10),\n  text = sample(c(\"Ana\", \"Eduardo\"), size = 10, replace = T)\n)\n\nstr(tib)tibble [10 x 2] (S3: tbl_df/tbl/data.frame)\n $ x   : num [1:10] 0.172 0.315 0.119 -0.155 -0.165 ...\n $ text: chr [1:10] \"Eduardo\" \"Ana\" \"Eduardo\" \"Eduardo\" ...\nstr(df)'data.frame':   10 obs. of  2 variables:\n $ x   : num  0.0639 -0.4522 0.7528 -1.3353 1.454 ...\n $ text: Factor w/ 2 levels \"Ana\",\"Eduardo\": 2 2 2 1 2 2 1 1 2 1\ndata_frame <- data.frame(\n    \"Nome coluna\" = rnorm(10),\n    \"10_janeiro\" = rnorm(10)\n  )\n\ntibble <- tibble(\n    \"Nome coluna\" = rnorm(10),\n    \"10_janeiro\" = rnorm(10)\n  )\n\nhead(data_frame, 10)##    Nome.coluna X10_janeiro\n## 1  -0.65209478 -1.28630053\n## 2  -0.05689678 -1.64060553\n## 3  -1.91435943  0.45018710\n## 4   1.17658331 -0.01855983\n## 5  -1.66497244 -0.31806837\n## 6  -0.46353040 -0.92936215\n## 7  -1.11592011 -1.48746031\n## 8  -0.75081900 -1.07519230\n## 9   2.08716655  1.00002880\n## 10  0.01739562 -0.62126669\ntibble## # A tibble: 10 x 2\n##    `Nome coluna` `10_janeiro`\n##            <dbl>        <dbl>\n##  1        -1.38       -0.144 \n##  2         1.87        0.208 \n##  3         0.425       2.31  \n##  4        -0.239       0.106 \n##  5         1.06        0.457 \n##  6         0.886      -0.0772\n##  7        -0.619      -0.334 \n##  8         2.21       -0.0347\n##  9        -0.255       0.788 \n## 10        -1.42        2.08\ntibble$`10_janeiro`##  [1] -0.14439960  0.20753834  2.30797840  0.10580237  0.45699881\n##  [6] -0.07715294 -0.33400084 -0.03472603  0.78763961  2.07524501"},{"path":"fundamentos-da-linguagem-r.html","id":"tipos-de-dados","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.5 Tipos de dados","text":"Como foi destacado anteriormente, além das estruturas de dados, o R possui os tipos de dados. Tipos esses que dizem respeito forma como o R está interpretando os seus dados, em um dado momento. Os cinco tipos de dados básicos da linguagem são:character: valores de texto ou caracteres.character: valores de texto ou caracteres.double: valores númericos inclusos conjunto dos números reais.double: valores númericos inclusos conjunto dos números reais.integer: valores númericos inclusos conjunto de números inteiros, ou basicamente, números sem casas decimais.integer: valores númericos inclusos conjunto de números inteiros, ou basicamente, números sem casas decimais.logical: valores TRUE (verdadeiro) e FALSE (falso), resultantes de testes lógicos.logical: valores TRUE (verdadeiro) e FALSE (falso), resultantes de testes lógicos.complex: valores em números complexos.complex: valores em números complexos.Há vários outros tipos de dados mais complexos, como datas (Date) e fatores (factor), que são construídos partir desses tipos básicos da linguagem. Tendo isso em mente, o único tipo básico que não irei abordar nesta seção, será o tipo complex, pois é um tipo muito específico e extremamente raro na linguagem.","code":""},{"path":"fundamentos-da-linguagem-r.html","id":"textos-e-caracteres","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.5.1 Textos e caracteres","text":"Você geralmente utiliza valores em texto em quase todos os instantes de sua análise, seja para criar rótulos de seus valores numéricos, indicando qual indicador, região ou grupo aqueles valores se referem, ou então para criar rótulos, títulos e subtítulos elegantes para o seu gráfico. Todo valor em texto R, deve ser fornecido entre aspas (simples - ', ou duplas - \"), sendo essa uma convenção utilizada em quase todas linguagens de programação, e R não é diferente. caso R, esta convenção se torna ainda mais importante, pois ela também serve para diferenciar valores em texto dos nomes de objetos.Quando queremos acessar os valores que estão dentro de um objeto, nós escrevemos o nome deste objeto console. Mas quando estamos fornecendo um valor de texto ao R, é muito comum que nos esqueçamos de contorná-lo com aspas. Como resultado, o R acaba procurando por um objeto que possua um nome igual este valor, e caso o R não encontre um objeto com esta característica, ele acaba lhe retornando um erro indicando que ele não encontrou um objeto com este nome em sua sessão. Além disso, se este valor que você está dando ao R possuir algum espaço, o R irá lhe retornar um erro um pouco diferente, dizendo que o símbolo o qual você inseriu console, é inválido. Por isso, você deve lembrar de contornar esse valor por aspas, caso você deseje que ele seja interpretado como um texto simples.Isso não quer dizer que você precisa escrever na mão todos os valores contornados por aspas. Na maioria das vezes, quando você importar suas bases de dados, o R irá automaticamente converter os seus textos para character’s. Caso ele converta de forma incorreta esses valores para algum outro tipo de dado, você pode facilmente corrigir isso, obrigando-o converter esses valores para textos com função .character().Todos os outros tipos que citamos anteriormente podem ser convertidos para textos, pois este é o tipo mais flexível de todos. O motivo disto é simples: nós não podemos escrever textos (ou palavras), em números, digo, qual seria o número correspondente à letra “” ? 1 ? 2 ? 3 ? …; mas nós podemos escrever números, datas, nomes, fatores, TRUE e FALSE em textos. Basta contornar todos esses diferentes tipos e valores por aspas, que o R irá interpretá-los como textos (character), ao invés de seus tipos originais.","code":"> O_ano_tem_365_dias\n## Erro: objeto 'O_ano_tem_365_dias' não encontrado\n\n> O ano tem 365 dias\n## Erro: unexpected symbol in \"O ano\"\n\n> \"O ano tem 365 dias\"\n## [1] \"O ano tem 365 dias\"\nvetor_l <- c(TRUE, FALSE, TRUE, FALSE)\n\nvetor_d <- c(2.25, 4.1, 7.8)\n\nas.character(vetor_l)## [1] \"TRUE\"  \"FALSE\" \"TRUE\"  \"FALSE\"\nas.character(vetor_d)## [1] \"2.25\" \"4.1\"  \"7.8\""},{"path":"fundamentos-da-linguagem-r.html","id":"números-reais","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.5.2 Números reais","text":"Quase sempre que estiver trabalhando com dados numéricos, esses dados estarão sendo interpretados como double’s, pois este tipo básico abarca todo o conjunto dos números reais. E como o conjunto de números inteiros (integer) está incluso conjunto dos números reais, quando você insere um número inteiro, ou um número sem casas decimais console, ele será interpretado inicialmente pelo R como um número real (double).Dito de outra forma, se eu ao console, e inserir apenas o número 10, o R estará interpretando este 10 como um double, e não como integer, mesmo que ele esteja lhe mostrando console este número sem casas decimais. É como se este 10, fosse na verdade para o R algo como 10,00000000000… exemplo abaixo, eu utilizo função .integer() para perguntar ao R, se ele está interpretando este valor como um integer, e como esperávamos função nos retorna um FALSE, indicando que não se trata de um número inteiro.Vale destacar, que o R é uma linguagem centralizada nos padrões americanos, e que portanto, utiliza o ponto para definir casas decimais, ao invés da vírgula que nós brasileiros utilizamos. Logo, se você quer criar um vetor de números decimais, por exemplo, você deve definir casas decimais de seus valores, através de pontos, e vírgulas vão servir apenas para separar esses valores vetor.Você pode converter um vetor, ou um conjunto de valores para o tipo double, através da função .double(). Basta fornecer o vetor, ou o conjunto de valores que deseja converter, à função:","code":"\n# O R está basicamente interpretando\n# este 10 como 10.00000000, mesmo\n# que ele te mostre\n10## [1] 10\nis.double(10)## [1] TRUE\nis.integer(10)## [1] FALSE\nc(1.24, 2.25, 3.62381, 7.05)## [1] 1.24000 2.25000 3.62381 7.05000\nvetor_l <- c(TRUE, FALSE, TRUE, FALSE)\n\nas.double(vetor_l)## [1] 1 0 1 0"},{"path":"fundamentos-da-linguagem-r.html","id":"números-inteiros","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.5.3 Números inteiros","text":"O tipo integer abarca o conjunto dos números inteiros, ou basicamente todos os números sem casas decimais. Você utilizará muito este tipo, quando estiver utilizando sequências numéricas, seja para extrair partes de um objeto com função [, ou gerando um índice para linhas de sua tabela. Como vimos na seção anterior, caso você insira um número sem casas decimais console, o R irá interpretar inicialmente este número como um double.Assim sendo, você tem três formas de criar um integer R. primeira é inserindo um L maiúsculo após o número que está criando. segunda, é transformando o seu vetor de números (que se encontra tipo double) para integer, através da função .integer(). terceira, seria através de funções que lhe retornam por padrão este tipo de dado, sendo o principal exemplo, função : que lhe retorna por padrão uma sequência de integer’s. Podemos confirmar se os números criados são de fato integer’s, usando função .integer().","code":"\nc(1L, 2L, 3L, 10L)## [1]  1  2  3 10\nas.integer(c(1, 2, 10, 1.5))## [1]  1  2 10  1\nis.integer(1:10)## [1] TRUE"},{"path":"fundamentos-da-linguagem-r.html","id":"valores-lógicos","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.5.4 Valores lógicos","text":"Este talvez seja o tipo básico que você esteja mais curioso sobre. Você já deve ter percebido que temos apenas dois valores possíveis dentro deste tipo, que são verdadeiro - TRUE, e falso - FALSE. Você irá utilizar muito este tipo para filtrar linhas de seu data.frame, para preencher uma coluna de rótulos, ou para identificar valores “não disponíveis” e outliers de sua base.Você possui duas formas de obter esses valores R. primeira, é escrevê-los na mão, podendo também se referir apenas primeira letra maíuscula de cada um, ao invés de escrever toda palavra. segunda e principal forma, é através de testes lógicos. exemplo abaixo, eu estou criando um vetor com 5 elementos, e em seguida, peço ao R que diga se cada elemento deste vetor é maior que 5. Vemos que apenas o terceiro e o quarto elemento deste vetor, são maiores que 5.O que acabamos de fazer acima, se trata de um teste lógico, pois estamos testando uma hipótese (maior que 5) sobre cada um dos elementos deste vetor. Como resultado, o R lhe retorna um vetor com o mesmo comprimento primeiro, porém agora, este vetor está preenchido com TRUE’s e FALSE’s, lhe indicando quais dos elementos primeiro vetor se encaixam na hipótese que você definiu.Este vetor contendo apenas valores lógicos, não é tão útil em sua singularidade. Porém, ao utilizarmos ele sobre à função [, podemos utilizar o sistema que mencionei anteriormente, chamado de logical subsetting, que é uma forma extremamente útil de extrairmos partes de um objeto. ideia, é extrairmos qualquer elemento deste objeto que possua um valor TRUE correspondente em um teste lógico específico que podemos definir. Consequentemente, poderíamos utilizar o teste anterior que criamos, para extrair todos os elementos vetor, que são maiores que 5, desta forma:","code":"\nvetor <- c(0.5, 2.45, 5.6, 7.2, 1.3)\n\nvetor > 5## [1] FALSE FALSE  TRUE  TRUE FALSE\nvetor[vetor > 5]## [1] 5.6 7.2"},{"path":"fundamentos-da-linguagem-r.html","id":"sec:coercion_R_fundamentos","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.6 Coerção no R","text":"Quando discuti sobre vetores e sua principal propriedade (vetores podem manter apenas um tipo de dado dentro dele), eu mencionei que caso você tentasse burlar essa regra, o R automaticamente converteria todos os valores para um único tipo de dado. Este processo é usualmente chamado por coercion, ou coerção, e iremos explicar como ele funciona nesta seção.Você geralmente não provoca este evento propositalmente, mas ele pode ocorrer ao importar bases onde seus dados não seguem um padrão uniforme, ou quando seus valores vazios são representados por algum caractere especial. Agora, se os números e valores da sua base estão bem formatados, e os valores vazios são realmente vazios, você dificilmente enfrentará este problema. Mas é útil conhecê-lo, pois este evento gera confusão em muitos usuários, em especial ao perceberem que seus números estavam o tempo todo sendo interpretados como texto (character).Este processo de coerção ocorre apenas sobre vetores atômicos. Porém, lembre-se que todas outras estruturas são construídas partir desses vetores, ou todas outras estruturas podem conter esses vetores dentro delas. Logo, uma coluna de seu data.frame, ou toda uma matriz, podem ser convertidos para o tipo de dado errado, independentemente de você ter ou não requisitado por tal transformação.Quando o processo de coerção ocorre, o R irá transformar os dados para o tipo mais flexível, seguindo uma espécie de árvore, que está referenciada na figura 2.10. Você pode ver que o tipo character, está topo da árvore, e portanto, é o tipo mais flexível de todos, enquanto o logical que está na base, é o tipo mais restrito de todos. Isso significa, que se você criar um vetor com valores integer e logical, todos esses valores serão convertidos para integer’s. Se um vetor com valores integer e character, esses valores serão convertidos para character’s. E assim por diante. Ou seja, você sabe para qual tipo esse vetor será convertido, ao olhar para os dois tipos que estão sendo misturados neste vetor, e identificar o tipo mais flexível dos dois.\nFigure 2.11: Árvore de tipos para coerção\nIsto não significa que você não pode criar um vetor de logical partir de qualquer um dos outros tipos básicos. Mas para realizar essa transformação, você terá que pedir explicitamente por ela, através da função .logical(). Se o seu vetor se encontra tipo double ou integer, valores que são iguais 0, serão convertidos para FALSE, e qualquer outro valor diferente de 0 será convertido para TRUE. Mas se o seu vetor se encontra tipo character, apenas textos explícitos dos valores lógicos (FALSE e TRUE), podem ser convertidos.Após toda essa leitura, você deve ter compreendido, que temos funções .* e funções .* para cada um dos quatro tipos básicos. funções .* servem para confirmar se os dados alocados em um objeto, estão ou não em um determinado tipo de dado. Ou seja, se eu quero saber se uma coluna de meu data.frame está tipo double, eu utilizo função .double() sobre esta coluna. Já funções .* servem para converter explicitamente os valores para um tipo de dado específico. Portanto, se eu tenho um vetor com double’s e quero transformá-los em character’s, eu forneço este vetor à função .character(). Quando uma função .* encontrar um elemento deste vetor, que ela não consegue converter para o tipo especificado, função acaba inserindo um NA (valor não disponível) lugar deste elemento.","code":"\nvetor <- c(0, 1, 0.5, -2, 20)\n\nas.character(vetor)## [1] \"0\"   \"1\"   \"0.5\" \"-2\"  \"20\"\nas.logical(vetor)## [1] FALSE  TRUE  TRUE  TRUE  TRUE\nas.integer(vetor)## [1]  0  1  0 -2 20\nvetor <- c(\"a\", \"b\", \"c\")\n\nas.logical(vetor)## [1] NA NA NA"},{"path":"fundamentos-da-linguagem-r.html","id":"subsetting","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.7 Subsetting","text":"operações de subsetting, são extremamente importantes R, e você irá utilizá-las com grande frequência ao longo de seu trabalho. Ao longo das seções de Estruturas de Dados, eu dei exemplos sobre como utilizar o subsetting com cada tipo de estrutura. Tendo isso em mente, essa seção busca explicitar (ou formalizar) algumas características importantes dessas operações. Como o próprio nome dá entender, operações de subsetting servem para extrairmos ou modificarmos subsets (partes) de seus objetos (R Core Team 2020b). Como vimos anteriormente, essas operações são realizadas pelas funções [ e [[.Para utilizar função [, você precisa abrir um par de colchetes ([ ]) após o nome objeto (ou função) com o qual está trabalhando. Já para função [[, você necessita abrir dois pares de colchetes ([[ ]]) após o nome (ou função) com o qual você está trabalhando. Também já vimos ao longo das seções de Estruturas de Dados, que para extrairmos partes de estruturas unidimensionais como vetores e listas, precisamos de apenas um índice, ou de um único conjunto de índices. Mas para extrairmos partes de estruturas bidimensionais, como matrizes e data.frame’s, precisamos de dois índices, ou de dois conjuntos de índices.Além disso, lembre-se que como definimos anteriormente, listas são estruturas especiais, pois podem conter diversas outras estruturas em seus elementos. Portanto, apesar das listas serem estruturas unidimensionais, elas podem conter outras estruturas bidimensionais dentro delas. Por isso, caso você esteja interessado em extrair partes de uma estrutura bidimensional, que está dentro de algum elemento de uma lista, por exemplo, você irá precisar de uma combinação entre um único índice (para acessar o elemento da lista) e outros dois conjuntos de índices (para acessar uma parte específica da estrutura bidimensional).","code":""},{"path":"fundamentos-da-linguagem-r.html","id":"principais-diferenças-entre-as-funções-e","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.7.1 Principais diferenças entre as funções [ e [[:","text":"função [ pode trabalhar com todas dimensões disponíveis de um objeto. dimensões disponíveis dependem da estrutura em que esse objeto se encontra. Enquanto isso, função [[ pode trabalhar com apenas uma dessas dimensões disponíveis.função [ pode trabalhar com todas dimensões disponíveis de um objeto. dimensões disponíveis dependem da estrutura em que esse objeto se encontra. Enquanto isso, função [[ pode trabalhar com apenas uma dessas dimensões disponíveis.função [ permite você extrair um conjunto de elementos (ou seções) de um objeto (Ex: da 1° 100° linha de um data.frame; os elementos 4, 5 e 8 de um vetor; 3° ao 6° elemento de uma lista). Já função [[ lhe permite extrair uma única parte, ou um único elemento de um objeto (Ex: o 5° elemento de uma lista; 2° coluna de um data.frame; o 10° elemento de um vetor).função [ permite você extrair um conjunto de elementos (ou seções) de um objeto (Ex: da 1° 100° linha de um data.frame; os elementos 4, 5 e 8 de um vetor; 3° ao 6° elemento de uma lista). Já função [[ lhe permite extrair uma única parte, ou um único elemento de um objeto (Ex: o 5° elemento de uma lista; 2° coluna de um data.frame; o 10° elemento de um vetor).função [ geralmente lhe retorna um resultado na mesma estrutura de seu objeto original. Em outras palavras, se você utilizar função [ sobre uma lista, ela irá lhe retornar uma lista como resultado. Já função [[, geralmente lhe retorna um resultado em uma estrutura diferente. Dito de outra forma, se você utilizar função [[ sobre um data.frame, por exemplo, ela geralmente vai lhe retornar um vetor como resultado.função [ geralmente lhe retorna um resultado na mesma estrutura de seu objeto original. Em outras palavras, se você utilizar função [ sobre uma lista, ela irá lhe retornar uma lista como resultado. Já função [[, geralmente lhe retorna um resultado em uma estrutura diferente. Dito de outra forma, se você utilizar função [[ sobre um data.frame, por exemplo, ela geralmente vai lhe retornar um vetor como resultado.","code":""},{"path":"fundamentos-da-linguagem-r.html","id":"dimensões-disponíveis-em-subsetting","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.7.2 Dimensões disponíveis em subsetting","text":"estrutura em que um objeto se encontra, define dimensões que estão disponíveis para funções [ e [[ . Logo, se você está trabalhando com um data.frame, por exemplo, você possui duas dimensões (linhas e colunas) com quais você pode trabalhar com função [. Mas se você está trabalhando com uma estrutura unidimensional, como um vetor atômico, você terá apenas uma única dimensão (os elementos desse vetor) para trabalhar em ambas às funções de subsetting ([ e [[).Uma das diferenças básicas entre funções [ e [[, se encontra número de dimensões com quais elas podem trabalhar. função [, seria uma forma mais “geral” de subsetting, pois ela pode trabalhar com todas dimensões disponíveis segundo estrutura que um objeto se encontra. Já função [[, representa uma forma mais restritiva de subsetting, pois ela trabalha em geral com apenas uma única dimensão de seu objeto (independentemente de qual seja sua estrutura).Portanto, se temos uma estrutura bidimensional como um data.frame, função [ pode trabalhar com suas duas dimensões (linhas e colunas). Porém, função [[ pode trabalhar apenas com uma dessas dimensões, sendo caso de data.frame’s, dimensão das colunas. Agora, quando estamos trabalhando com uma estrutura unidimensional, como nós possuímos apenas uma dimensão (elementos) disponível, não há diferença entre funções [ e [[ sentido estabelecido anteriormente. De qualquer maneira, função [ continuará sendo forma mais geral e flexível de subsetting para objetos unidimensionais. Pois função [ lhe permite selecionar um conjunto, ou uma sequência de elementos de uma estrutura unidimensional, enquanto que com função [[, você poderá selecionar apenas um único elemento dessa estrutura. Um resumo das dimensões disponíveis em cada estrutura, se encontra na tabela 2.1.\nFigure 2.12: Resumo das dimensões disponíveis em cada estrutura\n\nFigure 2.13: Notação matemática das dimensões disponíveis em cada estrutura\nNós também podemos ver essas diferenças entre dimensões disponíveis em cada estrutura e para cada função de subsetting, sob uma perspectiva mais matemática, ao formar uma notação matemática de cada estrutura, incluindo subscritos que representem suas respectivas dimensões. Essa visão está exposta na tabela 2.2. Por exemplo, pegando um data.frame chamado \\(DF\\), com \\(\\) linhas e \\(j\\) colunas (\\(DF_{,j}\\)), temos que o comando DF[2,4] busca extrair o valor (ou valores) localizados na 2° linha da 4° coluna da tabela. Por outro lado, considerando-se uma lista chamada \\(L\\), contendo \\(e\\) elementos (\\(L_e\\)), o comando L[[4]], traz como resultado, o 4° elemento dessa lista.","code":""},{"path":"fundamentos-da-linguagem-r.html","id":"tipos-de-índices","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.7.3 Tipos de índices","text":"Os índices que você fornece às funções [ e [[, podem ser de três tipos: 1) índices de texto - character; 2) índices numéricos - integer; 3) índices lógicos - logical. Logo abaixo, temos um exemplo uso de índices numéricos sobre um vetor qualquer. Lembre-se que caso de vetores, nós podemos utilizar um único índice para extrairmos um único valor objeto em questão, e nós utilizamos dois ou mais índices, para extrairmos um conjunto de valores deste mesmo vetor.Para utilizar um índice de texto (character), o objeto sobre o qual você está trabalhando, deve ser uma estrutura nomeada. Todas estruturas (vetor, lista, matriz e data.frame) permitem o uso de nomes, que você pode acessar e definir através de funções como colnames(), row.names() e names(). Sendo que algumas estruturas, mais especificamente os data.frame’s, vão sempre nomear automaticamente os seus elementos. Ou seja, você sempre poderá utilizar um índice de texto em um data.frame, para selecionar alguma de suas colunas. Pois mesmo que você se esqueça de nomear alguma coluna, ao criar o seu data.frame, função que cria essa estrutura irá automaticamente criar um nome qualquer para cada coluna não nomeada.Em outras estruturas como um vetor, nomes não são atribuídos automaticamente cada um de seus elementos, e por isso, você deve nomear os elementos deste vetor, para que você seja capaz de utilizar um índice de texto nele. Para isso, basta igualar esses elementos um valor em texto (valor entre aspas) que representa esse nome, como exemplo abaixo:Por último, os índices lógicos (TRUE ou FALSE) são extremamente úteis em diversas aplicações, especialmente quando desejamos realizar um subsetting mais “complexo.” Porém, pelo fato de que função [[ nos permite extrair apenas uma única parte de um objeto, os índices lógicos são de certa forma inúteis com essa função. Portanto, sempre que utilizar índices tipo lógico para selecionar os seus dados, você muito provavelmente quer utilizá-los com função [. Por padrão, funções [ e [[, vão extrair todas partes de um objeto, que possuírem um valor TRUE correspondente.Portanto, exemplo abaixo, caso eu utilize o vetor lógico vlog, para selecionar valores vetor vec, função [ irá selecionar o 2°, 3° e 5° valor vetor vec. Pois são essas posições vetor vlog que contém TRUE’s. Porém, principal forma de gerarmos esses vetores lógicos serem utilizados na função [, é através de testes lógicos. Por exemplo, podemos testar quais valores vetor vec, são maiores que 3, através operador lógico > (maior que).O R possui vários operadores lógicos diferentes, e o operador > é apenas um deles. Um outro operador muito conhecido, é o de negação \"!\". Este operador é utilizado, quando você deseja inverter um teste lógico, ou de certa forma, inverter o comportamento da função [ quando fornecemos índices lógicos. O que o operador ! faz na verdade, é inverter os valores de um vetor lógico. Logo, se eu aplicar este operador ao vetor vlog, esse será o resultado:Portanto, os valores que antes eram TRUE, passam ser FALSE, e vice-versa. Por isso, ao utilizarmos o operador ! sobre um teste lógico qualquer, nós invertemos o teste em questão. Pois o operador ! inverte os valores vetor lógico resultante desse teste. Com isso, se eu utilizar esse operador sobre o teste anterior, onde testamos quais valores vetor vec são maiores que 3, nós estaremos efetivamente testando hipótese contrária, de que esses valores são menores ou iguais 3. Vale ressaltar, que esse operador deve ser posicionado antes objeto que você deseja inverter, ou antes teste lógico ser realizado.Um uso muito comum deste operador, é em conjunto com função .na(). Essa função, aplica um teste lógico sobre cada valor de um vetor, testando hipótese de que esse valor se trata de um valor não-disponível (NA). Por isso, caso o valor em questão, seja de fato um valor não-disponível, função .na() irá retornar um TRUE correspondente, caso contrário, função vai lhe retornar um FALSE. Logo, caso eu utilize função .na() dentro da função [, estaremos selecionando todos os valores não-disponíveis de um vetor. Porém, é muito mais comum que pessoas queiram fazer justamente o contrário, que é eliminar esses valores não-disponíveis de seus dados. Por essa razão, é muito comum que se utilize o operador ! em conjunto com função .na(), pois dessa forma, estaremos selecionando justamente os valores que se encaixam na hipótese contrária testada por .na().Vamos pensar caso de um data.frame. Como definimos anteriormente, temos duas dimensões com quais podemos trabalhar na função [, com este tipo de estrutura. Podemos por exemplo, utilizar o operador ! e função .na() sobre dimensão das linhas desse data.frame. Dessa forma, podemos eliminar todas linhas dessa tabela, que possuam algum valor não-disponível em uma coluna. Veja o exemplo abaixo, em que uma tabela chamada df, contém três valores não-disponíveis na coluna valor.","code":"\nvec <- c(2.2, 1.3, 4.5, 3.7, 5.2)\n\nvec[4]## [1] 3.7\nvec[1:4]## [1] 2.2 1.3 4.5 3.7\nvec[c(3,5,1)]## [1] 4.5 5.2 2.2\ndf <- data.frame(\n  id = LETTERS[1:10],\n  nome = \"Ana\",\n  valor = rnorm(10),\n  \"Belo Horizonte\"\n)\n\ndf##      id nome      valor X.Belo.Horizonte.\n## 1     a  Ana  1.0273924    Belo Horizonte\n## 2  <NA>  Ana  1.2079084    Belo Horizonte\n## 3  <NA>  Ana -1.2313234    Belo Horizonte\n## 4  <NA>  Ana  0.9838956    Belo Horizonte\n## 5  <NA>  Ana  0.2199248    Belo Horizonte\n## 6  <NA>  Ana -1.4672500    Belo Horizonte\n## 7  <NA>  Ana  0.5210227    Belo Horizonte\n## 8  <NA>  Ana -0.1587546    Belo Horizonte\n## 9  <NA>  Ana  1.4645873    Belo Horizonte\n## 10 <NA>  Ana -0.7660820    Belo Horizonte\ncolnames(df)[4] <- \"cidade\"\n\ndf[[\"cidade\"]]##  [1] \"Belo Horizonte\" \"Belo Horizonte\" \"Belo Horizonte\" \"Belo Horizonte\"\n##  [5] \"Belo Horizonte\" \"Belo Horizonte\" \"Belo Horizonte\" \"Belo Horizonte\"\n##  [9] \"Belo Horizonte\" \"Belo Horizonte\"\ndf[c(\"id\", \"valor\")]##      id      valor\n## 1     a  1.0273924\n## 2  <NA>  1.2079084\n## 3  <NA> -1.2313234\n## 4  <NA>  0.9838956\n## 5  <NA>  0.2199248\n## 6  <NA> -1.4672500\n## 7  <NA>  0.5210227\n## 8  <NA> -0.1587546\n## 9  <NA>  1.4645873\n## 10 <NA> -0.7660820\ndf[[\"valor\"]]##  [1]  1.0273924  1.2079084 -1.2313234  0.9838956  0.2199248 -1.4672500\n##  [7]  0.5210227 -0.1587546  1.4645873 -0.7660820\ndf[[\"nome\"]]##  [1] \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\" \"Ana\"\nvec <- c(\"a\" = 1, \"b\" = 2, \"c\" = 3, \"d\" = 4)\n\nvec[\"c\"]## c \n## 3\nvec[c(\"a\", \"c\", \"b\")]## a c b \n## 1 3 2\nvec[[\"b\"]]## [1] 2\nvec <- c(2.2, 1.5, 3.4, 6.7, 8.9)\n\nvlog <- c(FALSE, TRUE, TRUE, FALSE, TRUE)\n\nvec[vlog]## [1] 1.5 3.4 8.9\nvec[vec > 3]## [1] 3.4 6.7 8.9\n!vlog## [1]  TRUE FALSE FALSE  TRUE FALSE\nvec[!vec > 3]## [1] 2.2 1.5\nvec <- c(2.2, 1.3, NA_real_, NA_real_, 2.5)\n\nvec## [1] 2.2 1.3  NA  NA 2.5\nvec[is.na(vec)]## [1] NA NA\nvec[!is.na(vec)]## [1] 2.2 1.3 2.5\ndf <- data.frame(\n  id = LETTERS[1:8],\n  valor = c(1.2, 2.5, NA_real_, 5.5, NA_real_, NA_real_, 3.5, 1.3),\n  nome = sample(c(\"Ana\", \"Luiza\", \"João\"), size = 8, replace = TRUE)\n)\n\ndf##     id valor  nome\n## 1    a   1.2 Luiza\n## 2 <NA>   2.5   Ana\n## 3 <NA>    NA   Ana\n## 4 <NA>   5.5  João\n## 5 <NA>    NA Luiza\n## 6 <NA>    NA  João\n## 7 <NA>   3.5  João\n## 8 <NA>   1.3  João\nnao_e_NA <- !(is.na(df$valor))\n\ndf[nao_e_NA, ]##     id valor  nome\n## 1    a   1.2 Luiza\n## 2 <NA>   2.5   Ana\n## 4 <NA>   5.5  João\n## 7 <NA>   3.5  João\n## 8 <NA>   1.3  João"},{"path":"fundamentos-da-linguagem-r.html","id":"o-operador-e-a-estrutura-do-resultado","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.7.4 O operador $ e a estrutura do resultado","text":"Você provavelmente se lembra operador $, que se trata de um atalho à função [[. Porém, você talvez tenha percebido também, que utilizamos o operador $ apenas em estruturas nomeadas. Logo, apesar de o operador $ ser um “irmão” da função [[, ele não herda todas características dessa função. Por exemplo, nós não podemos utilizar índices numéricos ou lógicos com este operador, para selecionarmos alguma parte de um objeto. Isto significa, que o operador $ se trata de uma versão ainda mais restrita de subsetting, em relação à função [[. únicas estruturas nomeadas com quais este operador funciona, são listas e data.frame’s. Em outras palavras, mesmo que você nomeie os elementos de um vetor atômico, você não poderá utilizar o operador $ para selecionar um desses elementos.Dentre características da função [[ herdadas pelo operador $, está o fato de que este operador pode trabalhar apenas com uma dimensão de um objeto. Em listas, podemos utilizar o operador $ para selecionarmos algum dos elementos nomeados dessa lista. Já em data.frame’s, o operador $ pode ser utilizado para selecionarmos uma das colunas desse data.frame8.Um outro ponto ser discutido, é que tanto o operador $, quanto função [[, geram um resultado em uma estrutura diferente da estrutura objeto original. Ou seja, quando realizamos um subsetting por meio desses operadores, o resultado geralmente possui uma estrutura com menos componentes que estrutura objeto original, de onde estamos retirando esta parte. Dito de outra forma, se utilizarmos o operador $, ou função [[ para selecionarmos coluna valor data.frame df abaixo, o resultado de ambas funções, serão um vetor atômico contendo os valores dessa coluna, e não um data.frame contendo apenas coluna valor.Logo, o uso da função [[ (ou operador $) sobre data.frame’s, vão lhe trazer coluna (ou o elemento) em si data.frame, e não um novo data.frame contendo essa coluna. Podemos confirmar isso, com o uso da função str(), que nos traz um resumo da estrutura de um objeto. Perceba nos exemplos abaixo, que em ambos os casos, o resultado da função str() está nos dizendo que o objeto resultante uso de $ ou de [[, se trata de um vetor atômico contendo dados tipo numérico (num).Essa característica é definida em detalhes capítulo 4 de Wickham (2015a). Sendo exatamente esta característica, que eu estava querendo destacar na figura 2.7, quando estávamos descrevendo listas. Se você utilizar função [ para selecionar um elemento de uma lista, o resultado será uma nova lista contendo esse elemento. Mas se você utilizar função [[ para fazer este trabalho, o resultado será apenas o elemento em si.Você pode entender essa característica como uma “simplificação resultado,” como se funções [[ e $ gerassem um resultado em uma estrutura mais simples que objeto original. Porém, eu creio que essa é uma forma equivocada de se enxergar esse sistema, pois estruturas não são usualmente comparadas em níveis de complexidade, mas sim por suas propriedades e características. Por isso, uma forma mais útil e fiél de se enxergar essa característica, é através da representação apresentada pela figura 2.7, onde através da função [[, podemos selecionar o elemento em si de uma lista, e não uma lista contendo este elemento. Além disso, uma outra forma útil de exergarmos essa característica resultado das funções [[ e $, é como uma forma de eliminarmos componentes da estrutura objeto original. Em outras palavras, podemos enxergar o operador $ ou função [[, como uma forma de gerarmos um resultado com menos componentes que estrutura objeto original.Por exemplo, se temos um data.frame chamado df, onde temos duas colunas simples (que são vetores atômicos), e em seguida, adicionamos duas novas colunas, uma contendo uma lista, e outra contendo um outro data.frame de duas colunas (y e z), nós temos uma estrutura razoavelmente complexa. Se utilizarmos função str(), para nos fornecer um resumo da estrutura de df, vemos que esse objeto tem pelo menos três componentes: 1) os vetores representados pelas colunas x e nome; 2) os cinco elementos da lista alocada na coluna lista; 3) e duas colunas contidas data.frame da coluna outro_df.Caso eu utilize funções [[ e $ para selecionarmos alguma das colunas de df, podemos aplicar novamente função str() sobre o resultado, para compreendermos sua estrutura. Veja pelo exemplo abaixo, que o resultado da função str() nos descreve uma estrutura com menos componentes que estrutura original. Com isso, eu quero destacar que estrutura desse resultado não necessariamente será menos “complexa” que original, mas sim que essa estrutura terá menos componentes. Portanto, pelo menos um dos componentes da estrutura original, será eliminado com o uso de [[ ou de $.","code":"\nvec <- c(\"a\" = 2.5, \"b\" = 4.3, \"c\" = 1.2)\n\nvec$aError in vec$a : $ operator is invalid for atomic vectors\ndf <- data.frame(\n  id = LETTERS[1:10],\n  valor = rnorm(10),\n  nome = sample(c(\"Ana\", \"Luiza\", \"João\"), size = 10, replace = TRUE)\n)\n\nstr(df$valor)##  num [1:10] -0.7037 0.9608 1.7905 -1.0642 0.0176 ...\nstr(df[[\"valor\"]])##  num [1:10] -0.7037 0.9608 1.7905 -1.0642 0.0176 ...\ndf <- data.frame(\n  x = rnorm(5),\n  nome = \"Ana\"\n)\n\ndf$lista <- list(1, 2, 3, 4, 5)\ndf$outro_df <- data.frame(y = rnorm(5), z = rnorm(5))\n\nstr(df)## 'data.frame':    5 obs. of  4 variables:\n##  $ x       : num  0.9261 0.0369 -1.0662 -0.2385 1.4952\n##  $ nome    : chr  \"Ana\" \"Ana\" \"Ana\" \"Ana\" ...\n##  $ lista   :List of 5\n##   ..$ : num 1\n##   ..$ : num 2\n##   ..$ : num 3\n##   ..$ : num 4\n##   ..$ : num 5\n##  $ outro_df:'data.frame':    5 obs. of  2 variables:\n##   ..$ y: num  1.1722 -1.4577 0.0951 0.8477 -1.6244\n##   ..$ z: num  1.409 -0.542 0.279 -0.194 1.576\nstr(df[[\"lista\"]])## List of 5\n##  $ : num 1\n##  $ : num 2\n##  $ : num 3\n##  $ : num 4\n##  $ : num 5\nstr(df[[\"outro_df\"]])## 'data.frame':    5 obs. of  2 variables:\n##  $ y: num  1.1722 -1.4577 0.0951 0.8477 -1.6244\n##  $ z: num  1.409 -0.542 0.279 -0.194 1.576\nstr(df$outro_df)## 'data.frame':    5 obs. of  2 variables:\n##  $ y: num  1.1722 -1.4577 0.0951 0.8477 -1.6244\n##  $ z: num  1.409 -0.542 0.279 -0.194 1.576"},{"path":"fundamentos-da-linguagem-r.html","id":"valores-especiais-do-r","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"2.8 Valores especiais do R","text":"Na linguagem R, possuímos alguns valores especiais, que não apenas são tratados de maneira diferente em relação outros valores, mas que também efetivamente alteram o comportamento de algumas operações importantes na linguagem. Por exemplo, se você tentar dividir qualquer número por 0 console, ao invés R lhe retornar um erro, lhe indicando que essa divisão é indefinida, o console vai lhe retornar o valor Inf, que se refere infinito (ou infinite). Por outro lado, de forma ainda mais estranha, se você tentar dividir 0 por ele mesmo, o console vai lhe retornar o valor NaN, que significa “number”, ou em outras palavras, que o valor resultante da divisão não é um número.Esses são alguns exemplos de valores especiais que você pode adquirir. Porém, o valor especial mais comum, é o valor NA, que significa avaliable, ou “não-disponível.” Este valor geralmente é resultado de uma dessas duas situações: 1) ao importar sua base de dados para o R, linguagem vai preencher automaticamente todas células em sua base que estiverem vazias, com um valor NA; 2) quando você executa (ou causa de maneira indireta) um processo de coerção, qual o R não consegue realizar. Ou seja, se o R não souber como converter um valor específico, para o tipo de dado ao qual você requisitou, ele vai lhe retornar um valor NA correspondente aquele valor.Portanto, primeira situação ocorre durante o processo de importação de dados, em todas ocasiões em que você possuir alguma observação vazia na base de dados que você está importando. Logo, se em uma planilha Excel, por exemplo, você possuir alguma célula vazia em sua tabela, ao importar essa planilha para o R, essas células vazias serão preenchidas com valores NA R. Lembre-se que um valor NA indica uma observação não-disponível, o que significa que o valor correspondente aquela observação não pôde ser observado, ou não pôde ser registrado momento de coleta dos dados.Já segunda situação, ocorre sempre quando o R não sabe como realizar o processo de coerção, pelo qual requisitamos, de uma forma lógica. Por exemplo, isso ocorre ao tentarmos converter valores de texto para números com .double(). Pois o R não sabe como, ou não sabe qual maneira mais adequada de se converter esses valores em texto para números. Por isso, linguagem vai lhe retornar como resultado, valores NA.Por que estamos falando desses valores especiais? Porque eles alteram o comportamento de certas operações importantes R e, com isso, podem deixar você desorientado! Por exemplo, se você tentar calcular soma de uma coluna (de um data.frame) que contém um valor NA, o resultado dessa operação será um valor NA. Da mesma forma, se coluna possuir um valor NaN, o resultado dessa soma será um valor NaN. Para que isso ocorra, o valor especial pode estar em qualquer linha que seja, basta que ele ocorra uma única vez, que sua soma não vai funcionar.Isso não significa que esses valores especiais serão uma dor de cabeça para você, pois cada um deles tem o seu propósito, e eles o cumprem muito bem. Mas é importante que você saiba quão especiais eles são, e dos efeitos que eles causam em certas operações R. Com isso, se em alguma situação uma função lhe retornar um valor NA, quando ela deveria lhe retornar algum valor definido, ou se essa função se comportar de maneira inesperada, você pode desconfiar que algum valor especial presente em seus dados, possa ser fonte de sua surpresa.Em geral, todas funções que são afetadas por esses valores especiais, como funções sum() e mean(), possuem um argumento na.rm, que define se função deve ignorar esses valores especiais em seus cálculos. Portanto, caso uma coluna de seu data.frame possua esses valores especiais, e você precisa ignorá-los durante o cálculo de uma soma, lembre-se de configurar este argumento para verdadeiro (TRUE).Um outro tipo de operação importante que é afetada por esses valores especiais, são os testes lógicos. Como exemplo, vamos criar um teste lógico sobre os dados apresentados pela tabela compras. Nós temos nessa tabela, o nome da composição química dos principais remédios que estão em falta nos estoques de três grandes hospitais. Os três remédios presentes nessa tabela, são remédios bem comuns, como o valor AA que se refere à composição química da Aspirina (Ácido Acetilsalicílico).Por exemplo, se nós quiséssemos identificar todas linhas na tabela compras, em que composição química da Aspirina (valor AA) aparece em pelo menos um dos hospitais (ou dito de outra forma, em pelo menos uma das colunas), poderíamos aplicar um teste lógico sobre tabela compras. O teste lógico abaixo, serve para esse propósito, mas se olharmos para o resultado desse teste, podemos identificar que algo está errado.Perceba acima, que o teste lógico detectou com sucesso todas linhas da tabela compras, que possuem um valor AA em pelo menos uma de suas colunas. Mais especificamente, linhas de posição 1°, 2°, 4°, 5°, 8° e 10°. Porém, podemos também identificar, que para linhas de posição 6°, 7° e 9° na tabela, o teste lógico teste nos retornou valores NA. Ou seja, ao invés teste lógico nos retornar um valor FALSE, para linhas que não possuem um valor AA ao longo de suas colunas, ele acaba nos retornando um valor NA, pelo simples fato de que temos um valor NA em pelo menos uma das colunas. Isso se torna um grande problema, partir momento em que desejamos filtrar nossa tabela compras, ao fornecer o nosso vetor teste, à função de subsetting.Portanto, o problema gerado pelos valores NA presentes resultado teste lógico, é que eles geram indiretamente um novo problema ser resolvido. O objetivo principal está em identificar linhas da tabela compras, que possuem um valor AA, em pelo menos uma de suas colunas, e filtrá-las da tabela. Porém, ao fornecermos esse vetor teste à função de subsetting, função [ acaba adicionando uma nova linha ao resultado, para cada valor NA presente vetor teste. Logo, o resultado que era para ter 6 linhas, acaba tendo 9. Com isso, teríamos um novo trabalho de eliminar essas novas linhas de NA’s, para chegarmos às linhas que queremos filtrar da nossa tabela compras.","code":"\nsum(c(1, 2, 3, NA, 4))## [1] NA\nsum(c(1, 2, 3, NaN, 4))## [1] NaN\nsum(c(1, 2, 3, NA, 4), na.rm = TRUE)## [1] 10\ncompras <- structure(list(ano = c(2019, 2019, 2019, 2019, 2019, 2019, 2019, \n2019, 2019, 2019), mes = c(2L, 4L, 5L, 6L, 8L, 8L, 10L, 10L, \n10L, 12L), hospital1 = c(\"AA\", NA, \"dexametasona\", \"AA\", NA, \n\"doxiciclina\", NA, \"AA\", \"doxiciclina\", NA), hospital2 = c(\"AA\", \n\"doxiciclina\", \"dexametasona\", \"dexametasona\", \"AA\", NA, \"dexametasona\", \n\"AA\", \"dexametasona\", \"AA\"), hospital3 = c(\"AA\", \"AA\", \"dexametasona\", \nNA, \"dexametasona\", \"doxiciclina\", \"dexametasona\", NA, NA, \"AA\"\n)), row.names = 1:10, class = \"data.frame\")\n\n\ncompras##     ano mes    hospital1    hospital2    hospital3\n## 1  2019   2           AA           AA           AA\n## 2  2019   4         <NA>  doxiciclina           AA\n## 3  2019   5 dexametasona dexametasona dexametasona\n## 4  2019   6           AA dexametasona         <NA>\n## 5  2019   8         <NA>           AA dexametasona\n## 6  2019   8  doxiciclina         <NA>  doxiciclina\n## 7  2019  10         <NA> dexametasona dexametasona\n## 8  2019  10           AA           AA         <NA>\n## 9  2019  10  doxiciclina dexametasona         <NA>\n## 10 2019  12         <NA>           AA           AA\nteste <- compras$hospital1 == \"AA\" |\n  compras$hospital2 == \"AA\" |\n  compras$hospital3 == \"AA\" \n\nteste##  [1]  TRUE  TRUE FALSE  TRUE  TRUE    NA    NA  TRUE    NA  TRUE\ncompras[teste, ]##       ano mes hospital1    hospital2    hospital3\n## 1    2019   2        AA           AA           AA\n## 2    2019   4      <NA>  doxiciclina           AA\n## 4    2019   6        AA dexametasona         <NA>\n## 5    2019   8      <NA>           AA dexametasona\n## NA     NA  NA      <NA>         <NA>         <NA>\n## NA.1   NA  NA      <NA>         <NA>         <NA>\n## 8    2019  10        AA           AA         <NA>\n## NA.2   NA  NA      <NA>         <NA>         <NA>\n## 10   2019  12      <NA>           AA           AA"},{"path":"fundamentos-da-linguagem-r.html","id":"exercícios-1","chapter":"Capítulo 2 Fundamentos da Linguagem R","heading":"Exercícios","text":"Questão 2.1. Em cada item desta questão, temos um simples print() de um objeto qualquer. Com base apenas nessa primeira imagem objeto, tente identificar estrutura (vetor, matriz, lista, data.frame) na qual esse objeto se encontra:2.1.) Objeto 1:2.1.B) Objeto 2:2.1.C) Objeto 3:2.1.D) Objeto 4:2.1.E) Objeto 5:2.1.F) Objeto 6:Questão 2.2. Em cada item abaixo, você deve criar um teste lógico que seja capaz de testar condições postas enunciado. Em alguns itens, será fornecido o código necessário para que você crie certos objetos (como v_seq, v_rep, lst, etc.), pois os testes lógicos se baseiam nesses objetos, ou devem ser aplicados diretamente sobre esses objetos. Portanto, lembre-se de copiar o código fornecido pela questão, colar em seu console, e apertar Enter para recriar esses objetos em sua sessão R.2.2.) Crie um teste lógico que seja capaz de identificar quais dos cinco objetos abaixo, são um vetor atômico.2.2.B) Imagine que você receba em sua sessão R, o objeto lst abaixo. Tente criar um teste lógico que possa confirmar se esse objeto é uma lista. Pelo código abaixo, você já sabe que este objeto é sim uma lista. Entretanto, nem sempre você terá acesso fácil ao código que criou certo objeto, ou, nem sempre você consegue prever que tipos de objetos serão criados partir dos comandos escritos por outras pessoas. Por isso, quando você não conhece o input que você vai receber, é sempre importante se basear em teste lógicos que possam lhe assegurar que os seus objetos estão na estrutura desejada.2.2.C) Utilizando mesma lista lst exercício acima, crie um teste lógico capaz de identificar se essa lista possui um item chamado “estado.” Primeiro, aplique o seu teste lógico sobre lst, e confira se o resultado teste é TRUE. Em seguida, aplique esse mesmo teste lógico sobre lista lst_sem_estado abaixo, e veja se o resultado teste é de fato FALSE.2.2.D) Suponha que você possua tabela tab abaixo. Crie um teste lógico que possa identificar se coluna total é tipo double.2.2.E) Utilizando mesma tabela tab acima, crie um teste lógico que possa identificar se tabela possui exatamente 10 linhas, E, se essa tabela possui uma coluna chamada “vendas,” E, se 3° coluna da tabela é tipo character. Perceba enunciado desta questão, os E’s separando cada condição ser testada. Esses E’s estão indicando que essas condições são dependentes, ou, em outras palavras, elas precisam ser satisfeitas ao mesmo tempo.2.2.F) Se eu te der um número qualquer, referente um ano específico (por exemplo, 2005 ou 1997), crie um teste lógico capaz de atestar se esse ano fornecido é um ano bissexto. Um ano bissexto é definido pelas seguintes condições: 1) cada 4 anos, temos um ano bissexto; 2) cada 100 anos, nós não devemos ter um ano bissexto; 3) cada 400 anos temos um ano bissexto. Um detalhe: últimas regras são mais importantes que primeiras, ou seja, regra 3 prevalece sobre regras 1 e 2, da mesma forma que regra 2, prevalece sobre regra 1. Caso essas definições não estejam muito claras, elas basicamente significam o seguinte: 1) o ano deve ser múltiplo de 4; 2) o ano não deve ser múltiplo de 100 não ser que ele seja múltiplo de 400; 3) se o ano é múltiplo de 400, ele é obrigatoriamente um ano bissexto.Questão 2.3. Em cada item abaixo, fornecemos um vetor formado pela função c(). Perceba que em cada um desses vetores, valores de diferentes tipos são misturados. Como definimos na seção Coerção R, quando dados de diferentes tipos são colocados dentro de um vetor atômico, o R automaticamente realiza um processo de coerção, ao converter todos esses dados para um único tipo. O seu objetivo nessa questão é simplesmente advinhar o tipo (double, integer, logical, ou character) de dado, para o qual esses dados serão convertidos. Caso esteja na dúvida, basta copiar e colar o código em seu console que você terá uma visão resultado.2.3.)2.3.B)2.3.C)2.3.D)2.3.E)Questão 2.4. Os próximos exercícios serão voltados para subsetting. Ao longo desses exercícios, estaremos utilizando o data.frame flights, que provêm pacote nycflights13. Por isso, lembre-se que para ter acesso essa tabela, é necessário que você chame por esse pacote em sua sessão, com o comando library(). Caso você não tenha o pacote instalado em sua máquina, execute o comando install.packages() mostrado abaixo.2.4.) Encontre todas linhas da tabela flights em que carrier seja igual \"B6\", e que month seja igual 5.2.4.B) Todos os voôs descritos na tabela flights, correspondem voôs que ocorreram aeroporto de Nova York, ao longo ano de 2013. coluna dep_delay apresenta o tempo de atraso (em minutos) momento de partida aeroporto, e coluna arr_delay apresenta o tempo de atraso (em minutos) momento de chegada ao aeroporto. Tendo isso em mente, ano de 2013, quantos voôs obtiveram um tempo de atraso total acima tempo médio de atraso?2.4.C) Selecione linhas da tabela flights que se encaixam em pelo menos uma dessas duas condições: 1) possuem um arr_delay abaixo de 2 minutos, e que o aeroporto de destino (dest) seja \"BOS\"; 2) cujo horário de partida programado (sched_dep_time) seja de 6:00 (ou 600), e que o mês de ocorrência voô seja igual 1.","code":"## [[1]]\n##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n## [24] 24 25 26 27 28 29 30##  [1]  1  2  3  4  5  6  7  8  9 10##      [,1] [,2] [,3] [,4] [,5]\n## [1,] \"MG\" \"MG\" \"DF\" \"SP\" \"MG\"\n## [2,] \"MS\" \"DF\" \"DF\" \"SP\" \"DF\"\n## [3,] \"DF\" \"DF\" \"MG\" \"SP\" \"MG\"\n## [4,] \"MG\" \"SP\" \"MG\" \"SP\" \"MG\"\n## [5,] \"SP\" \"SP\" \"MG\" \"DF\" \"MG\"##    id valor\n## 1   1 -0.29\n## 2   2 -0.30\n## 3   3 -0.41\n## 4   4  0.25\n## 5   5 -0.89\n## 6   6  0.44\n## 7   7 -1.24\n## 8   8 -0.22\n## 9   9  0.38\n## 10 10  0.13## $estado\n## [1] \"MG\"\n## \n## $cidade\n## [1] \"Belo Horizonte\"\n## \n## $n_municipios\n## [1] 853\n## \n## $regiao\n## [1] \"Sudeste\"##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [24] NA NA\n      v_seq <- 10:25\n      v_rep <- rep(\"abc\", times = 30)\n      lst <- list(1:10)\n      mt <- matrix(1:20, nrow = 4, ncol = 5)\n      dt <- data.frame(15, \"A\", 1:10)\n      lst <- list(\n        estado = \"MG\",\n        cidade = \"Belo Horizonte\",\n        n_municipios = 853,\n        regiao = \"Sudeste\"\n      )\n      lst_sem_estado <- list(\n        regiao = \"Sudeste\",\n        n_municipios = 853\n      )\n      tab <- data.frame(\n        unidade = c(\"Centro\", \"Gameleira\", \"Santa Efigênia\", \"Centro\",\n                    \"Barro Preto\", \"Centro\", \"Gameleira\", \"Centro\",\n                    \"Barro Preto\", \"Santa Efigênia\"),\n        mes = c(1, 1, 1, 2, 2, 3, 3, 4, 4, 4),\n        vendas = c(1502, 1430, 1100, 1200, 1443, 1621, 1854, 2200,\n                  1129, 1872),\n        total = c(5362.14, 5105.1, 3927, 4284, 5151.51, 5786.97, \n                  6618.78, 7854, 4030.53, 6683.04)\n      )\n      c(1.2, 2.4, \"3.1\", 1.9)\n      integers <- 1:3\n      doubles <- c(2.23, 9.87, 3.2)\n      \n      c(integers, doubles)\n      c(1.56, 3L, 1L, 5L,  2.32, 9.87)\n      c(TRUE, 1.5, FALSE)\n      c(\"p\", \"b\", \"c\", TRUE, 2L, 4.318)\n      ### Caso você não possua o pacote nycflights13\n      ### instalado, execute o comando:\n\n      ### install.packages(\"nycflights13\")\n\n      library(nycflights13)\n\n      ### Após o comando library() você\n      ### terá acesso à tabela flights\n      flights"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"importando-e-exportando-dados-com-o-r","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"Capítulo 3 Importando e exportando dados com o R","text":"","code":""},{"path":"importando-e-exportando-dados-com-o-r.html","id":"sec:importando_dados","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.1 Introdução e pré-requisitos","text":"Em algum ponto, você vai trabalhar com os seus próprios dados R e, para isso, você precisa obrigatoriamente importar esses dados para dentro R. Neste capítulo, vamos aprender como utilizar funções dos pacotes readr, readxl e haven, para ler e importar dados presentes em arquivos de texto (plain text files - .txt ou .csv), em planilhas Excel (.xlsx) e em arquivos produzidos por programas estatísticos como o Stata (.dta), SPSS (.sav; .zsav e .por) e SAS (.sas).Para que você tenha acesso funções e possa acompanhar os exemplos desse capítulo você precisa chamar pelos pacotes readr, readxl e haven, através comando library(). O pacote readr especificamente, está incluso dentro tidyverse e, por isso, você também pode chamar por ele.","code":"\nlibrary(tidyverse)\n\nlibrary(readr)\nlibrary(readxl)\nlibrary(haven)"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"fontes-de-dados","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.2 Fontes de dados","text":"Os seus dados podem vir de diferentes tipos de fontes. Com isso, os métodos necessários para acessar e importar esses dados para o R, mudam. Em resumo, os seus dados podem provir de três tipos de fontes diferentes:Arquivo estático salvo disco rígido de seu computador.Arquivo estático salvo disco rígido de seu computador.Servidor local ou online.Servidor local ou online.Página da internet.Página da internet.Nós normalmente transportamos os nossos dados através de um arquivo estático, que pode ser salvo em nosso computador. Por isso, ao importar os nossos dados para o R, vamos estar preocupados na grande maioria das vezes, em ler um arquivo que se encontra salvo em nosso computador. Por este motivo, os métodos que serão mostrados nesse capítulo, buscam ler e importar diferentes tipos de arquivos estatícos. Em um processo como esse, localização desse arquivo disco rígido é um fator importante. Além disso, diferentes tipos de arquivos são estruturados de maneiras distintas e, por essa razão, você vai precisar de uma função R que seja capaz de ler esse tipo de arquivo, ou em outras palavras, que seja capaz de reconhecer estrutura desse arquivo.Por outro lado, se você está importando os seus dados partir de um servidor, você muito provavelmente estará extraindo dados de um DBMS (database management system). Os sistemas DBMS mais famosos e mais utilizados mundo, são os sistemas que utilizam linguagem SQL (Structured Query Language). Para extrair um conjunto de dados desse tipo de fonte, você em geral necessita de uma chave, ou uma API (Application Programming Interface) que lhe garanta acesso ao servidor e, portanto, acesso aos dados que você deseja importar. Esse processo de importação não será tratado aqui, mas você vai precisar das funções disponíveis em pacotes como jsonlite, odbc e DBI para tal processo.Além dessas alternativas, você pode estar interessado em coletar dados de uma página da internet. Não estou referindo um arquivo estático que esteja disponível para download através dessa página da internet, mas sim, de coletar o conteúdo dessa página, de coletar os dados que formam própria página da internet em si. Esse tipo de coleta, e os métodos envolvidos nesse processo, são comumente chamados de web scraping, e hoje, representam uma área importante em análise de dados. Esse processo de importação também não será mostrado aqui, mas você pode consultar funções dos pacotes httr, xml2 e rvest para executar tal processo.","code":""},{"path":"importando-e-exportando-dados-com-o-r.html","id":"diretório-de-trabalho","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.3 Diretório de trabalho","text":"linguagem R possui uma forte noção de diretórios de trabalho (Wickham Grolemund 2017, p 113). O diretório de trabalho (working directory) é o local de seu computador onde o R vai procurar pelos arquivos que você demanda, e será onde o R vai guardar todos os arquivos que você pede ele que salve.Isso significa que em todas ocasiões em que você estiver R, ele estará trabalhando com alguma pasta específica de seu computador. RStudio, você pode identificar o seu diretório de trabalho atual na parte esquerda e superior console, logo abaixo nome de sua guia (Console), como mostrado na figura 3.1. Repare abaixo, que momento em que foto presente na figura 3.1 foi tirada, eu estava trabalhando com uma pasta de meu computador chamada Curso-R, que por sua vez, se encontrava dentro de uma pasta chamada Projeto curso R.\nFigure 3.1: Diretório de trabalho - Console RStudio\nNós também podemos descobrir o diretório de trabalho atual em nossa sessão R, através da função getwd().Dessa forma, supondo que o meu diretório de trabalho atual seja pasta Curso-R, se eu pedir por algum arquivo chamado frase.txt, o R vai procurar por esse arquivo dentro dessa pasta Curso-R. Isso tem duas implicações muito importantes. Primeiro, o arquivo frase.txt deve estar dentro dessa pasta Curso-R, caso contrário o R não poderá encontrar o arquivo. Segundo, temos uma maneira muito simples e poderosa de acessarmos qualquer arquivo que esteja presente na pasta Curso-R, pois precisamos apenas nome desse arquivo, como exemplo abaixo.Um ponto muito importante é que extensão arquivo (que traduz o seu tipo) também faz parte nome arquivo. exemplo acima, o arquivo se chama frase e possui extensão .txt, logo, o nome arquivo ser fornecido ao R é frase.txt.","code":"\ngetwd()## [1] \"C:/Users/Pedro/Documents/Projeto curso R/Curso-R\"\nread_lines(\"frase.txt\")## [1] \"Aristóteles foi um filósofo da Grécia Antiga\""},{"path":"importando-e-exportando-dados-com-o-r.html","id":"sec:enderecos_disco_rigido","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.4 Definindo endereços do disco rígido no R","text":"Portanto, o mecanismo de diretórios de trabalho apenas limita o escopo de busca R. Dito de outra forma, ele define onde o R irá procurar pelos seus arquivos e, onde esses arquivos serão salvos através R. Entretanto, isso não quer dizer que você não possa acessar arquivos que se encontram em outras áreas seu computador. Porém, para acessarmos qualquer arquivo que esteja fora de seu diretório de trabalho atual, nós precisamos obrigatoriamente fornecer o endereço até esse arquivo para o R.","code":""},{"path":"importando-e-exportando-dados-com-o-r.html","id":"cuidados-ao-definir-endereços","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.4.1 Cuidados ao definir endereços","text":"Alguns cuidados R são necessários ao definir um endereço até um arquivo. Primeiro, endereços de seu disco rígido devem sempre ser fornecidos como textos (strings), por isso, lembre-se de contornar o seu endereço com aspas duplas ou simples R. Segundo, o Windows utiliza por padrão barra inclinada à esquerda (\\) para separar cada diretório presente caminho até um certo arquivo. Todavia, barra inclinada à esquerda possui um significado especial para o R.Abordando especificamente o segundo ponto, você tem duas alternativas para contornar particularidades das barras inclinadas utilizadas nos endereços de seus arquivos: 1) utilizar o estilo dos sistemas Mac e Linux, que utilizam barra inclinada à direita (/) para separar os diretórios; 2) ou contornar o comportamento especial de uma barra inclinada à esquerda, com duas barras inclinadas à esquerda (\\\\). Ou seja, é como se essas duas barras \\\\ significassem apenas uma barra \\ para o R. Eu particularmente prefiro utilizar o estilo dos sistemas Mac e Linux para resolver esse problema, pois ele incorre em um trabalho menor de digitação.Por exemplo, eu possuo um arquivo chamado livros.txt localizado dentro da pasta Lista de compras, que por sua vez, se encontra dentro da minha pasta de Documentos Windows. Segundo o padrão Windows, o endereço até esse arquivo seria: \"C:\\Users\\Pedro\\Documents\\Lista de compras\\livros.txt\". Porém, levando-se em conta os pontos que acabamos de abordar, nós poderíamos fornecer um dos dois endereços abaixo para referir este arquivo R:","code":"\nlivros <- read_csv(\"C:\\\\Users\\\\Pedro\\\\Documents\\\\Lista de compras\\\\livros.txt\")\n\nlivros <- read_csv(\"C:/Users/Pedro/Documents/Lista de compras/livros.txt\")\nlivros## # A tibble: 4 x 3\n##   Título                               Autor                          Preço\n##   <chr>                                <chr>                          <dbl>\n## 1 O Hobbit                             J. R. R. Tolkien                40.7\n## 2 Matemática para Economistas          Carl P. Simon e Lawrence Blume 140. \n## 3 Microeconomia: uma abordagem moderna Hal R. Varian                  142. \n## 4 A Luneta Âmbar                       Philip Pullman                  42.9"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"endereços-relativos-e-absolutos","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.4.2 Endereços relativos e absolutos","text":"depender seu diretório de trabalho atual, e de onde o seu arquivo de interesse se encontra, você pode utilizar dois estilos diferentes de endereços (relativo e absoluto) para se referir um dado arquivo. Vamos utilizar como exemplo, o conjunto de arquivos mostrados na figura 3.2 que se encontram dentro de uma pasta chamada Dados.\nFigure 3.2: Exemplo de arquivos\nCaso o seu diretório de trabalho atual fosse, por exemplo, pasta Projeto curso R, você poderia fornecer um endereço relativo para qualquer um desses arquivos presentes na pasta Dados. Pois pasta Dados se encontra dentro da pasta Projeto curso R. Em outras palavras, pasta Dados é uma subpasta da pasta Projeto curso R.Logo, um endereço relativo possui como ponto inicial, o seu diretório de trabalho atual. Por isso, você pode acessar qualquer arquivo que esteja dentro de seu diretório de trabalho, ou dentro de alguma de suas subpastas, através de um endereço relativo. caso dos arquivos da pasta Dados, nós poderíamos fornecer o endereço \"Curso-R/Dados/\" para chegarmos pasta Dados. Em seguida, precisaríamos apenas acrescentar o nome arquivo de nosso desejo. Por exemplo, se fôssemos ler o arquivo de nome covid.csv, o endereço resultante seria \"Curso-R/Dados/covid.csv\".Por outro lado, se o seu diretório de trabalho atual uma pasta posterior à pasta Dados (ou seja, uma subpasta da pasta Dados), e você quiser acessar um dos arquivos da pasta Dados, você terá que fornecer um endereço absoluto até o arquivo em questão. Um endereço absoluto é um endereço que parte desde o disco rígido de seu computador até o arquivo de interesse. Por isso, um endereço absoluto sempre aponta para o mesmo local de seu computador, independente de qual seja o seu diretório de trabalho atual.Para coletarmos o endereço absoluto de um arquivo Windows, podemos clicar com o botão direito mouse sobre o arquivo de interesse, e selecionar opção Propriedades. Uma caixa vai abrir em sua tela, contendo diversas informações sobre o arquivo em questão. Logo sua frente, temos seção chamada Local na parte inicial dessa caixa, onde podemos encontrar o endereço absoluto até pasta onde o seu arquivo de interesse está localizado.Logo, se eu utilizasse esse recurso sobre um dos arquivos mostrados na figura 3.2, eu encontraria o seguinte endereço nessa seção Local: \"C:\\Users\\Pedro\\Documents\\Projeto curso R\\Curso-R\\Dados\". Com esse endereço, precisamos apenas adicionar o nome arquivo desejado, e ajustar barras inclinadas à esquerda de acordo com alternativas apresentadas na seção anterior. Por exemplo, se o nosso arquivo de interesse fosse o covid.csv, o endereço absoluto ser fornecido ao R seria: \"C:/Users/Pedro/Documents/Projeto curso R/Curso-R/Dados/covid.csv\".Segundo Wickham Grolemund (2017), é recomendável que você evite endereços absolutos, especialmente se você trabalha em conjunto. Pois é muito provável que os computadores de seus parceiros de trabalho não possuem exatamente mesma estrutura de diretórios que o seu computador. Por isso, o ideal é que você sempre organize todos os arquivos referentes um certo projeto ou uma certa análise, dentro de uma pasta específica de seu computador. Dessa forma, você pode tornar essa pasta específica o seu diretório de trabalho R, e partir daí, fornecer endereços relativos até cada arquivo.","code":""},{"path":"importando-e-exportando-dados-com-o-r.html","id":"plataforma-de-projetos-do-rstudio","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.5 Plataforma de Projetos do RStudio","text":"R, você pode configurar o seu diretório de trabalho atual, através da função setwd(). Basta fornecer o endereço absoluto até pasta com qual você deseja trabalhar. Veja o exemplo abaixo, em que eu escolho pasta de Documentos Windows como o meu diretório de trabalho:Porém, esse não é um método recomendado de se configurar o seu diretório de trabalho, especialmente porque nós precisamos realizar essa configuração toda vez em que acessamos o R, sendo algo contraproducente. Por isso, Wickham Grolemund (2017) caracterizam plataforma de Projetos RStudio, como uma forma mais adequada e eficiente de realizarmos essa configuração.\nFigure 3.3: Plataforma de Projetos RStudio - Parte 1\nAo criar um projeto RStudio, você está apenas criando um arquivo com o nome desse projeto e que possui uma extensão .Rproj. Esse arquivo .Rproj funciona como um link até pasta onde você o guardou. Dessa forma, ao acessarmos esse projeto RStudio, o seu console já vai estar trabalhando com pasta onde o arquivo .Rproj foi salvo. Em termos técnicos, toda vez que você acessar esse projeto, o RStudio vai automaticamente configurar essa pasta como o seu diretório de trabalho atual R.Para criarmos um projeto RStudio, você pode acessar um pequeno menu localizado na parte superior e direita de sua tela, mostrado na figura 3.3. Ao selecionar opção New Project..., o seu RStudio vai abrir uma aba que está exposta na figura 3.4. Nessa aba, você vai selecionar como deseja criar o novo arquivo .Rproj. Caso você já tenha organizado todos os arquivos de seu projeto um pasta específica, você pode selecionar opção Existing Directory para salvar o arquivo .Rproj nessa pasta já existente. Por outro lado, caso você esteja iniciando sua análise zero, você pode selecionar opção New Directory para criar um novo diretório em seu computador, onde você vai guardar todos os arquivos referentes ao seu projeto.\nFigure 3.4: Plataforma de Projetos RStudio - Parte 2\nAo selecionar uma dessas opções, o RStudio também vai lhe questionar sobre o tipo desse projeto, ou dito de outra maneira, qual o tipo de produto que você busca gerar com esse projeto, através da aba mostrada na figura 3.5. Ou seja, se você está planejando construir um novo pacote para o R, é interessante que você selecione segunda opção (R Package) dessa aba. Pois assim, o próprio RStudio vai automaticamente criar para você, os principais arquivos que um pacote R precisa ter. Em geral, você vai selecionar primeira opção (New Project) para criar um projeto padrão.\nFigure 3.5: Plataforma de Projetos RStudio - Parte 3\nexemplo apresentado pela figura 3.6, eu estou criando um projeto padrão chamado projeto_mortalidade na pasta Desktop (que corresponde área de trabalho) de meu computador. Com isso, uma nova pasta chamada projeto_mortalidade será criada, e sempre que eu acessar novamente o projeto projeto_mortalidade RStudio, através pequeno menu mostrado na figura 3.3, o RStudio vai automaticamente configurar pasta projeto_mortalidade como o diretório de trabalho atual R.\nFigure 3.6: Plataforma de Projetos RStudio - Parte 4\n","code":"\nsetwd(\"C:/Users/Pedro/Documents\")"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"importando-arquivos-de-texto-com-readr","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.6 Importando arquivos de texto com readr","text":"Arquivos de texto, também conhecidos como plain text files, ou flat files, estão entre os formatos de arquivo mais utilizados em todo o mundo para transportar e armazenar dados. Por isso é muito importante que você conheça esses arquivos e saiba reconhecê-los.Um arquivo de texto, normalmente assume extensão .txt, e contém apenas cadeias de textos ou cadeias de valores numéricos que são organizados em linhas. Apesar de simples, os dados armazenados podem ser organizados de diferentes formas em cada linha arquivo. Por essa razão, um arquivo de texto pode assumir diferentes extensões que identificam o tipo de arquivo de texto ao qual ele pertence.Em outras palavras, nós possuímos diferentes tipos de arquivos de texto, e diferença básica entre eles, está na forma como os valores são organizados em cada linha arquivo. Um dos tipos de arquivo de texto mais famosos é o arquivo CSV (comma separated file), que utiliza vírgulas (ou pontos e vírgulas como é o caso brasileiro) para separar os valores de diferentes colunas em cada linha arquivo. Por isso, não basta que você identifique se o seu arquivo de interesse é um arquivo de texto, pois você também precisa identificar o tipo de arquivo de texto qual ele se encaixa.Para importarmos os dados presentes nesses arquivos, vamos utilizar funções pacote readr, que oferece um conjunto de funções especializadas em arquivos de texto. Logo abaixo, temos uma lista que associa os respectivos tipos de arquivos de texto cada uma das funções desse pacote.read_delim(): essa é uma função geral, que é capaz de ler qualquer tipo de arquivo de texto em que os valores estão delimitados por algum caractere especial.read_delim(): essa é uma função geral, que é capaz de ler qualquer tipo de arquivo de texto em que os valores estão delimitados por algum caractere especial.read_csv2(): lê arquivos CSV (comma separated file) que seguem o padrão adotado por alguns países europeus. Arquivos .txt ou .csv, em que os valores são separados por ponto e vírgula (;).read_csv2(): lê arquivos CSV (comma separated file) que seguem o padrão adotado por alguns países europeus. Arquivos .txt ou .csv, em que os valores são separados por ponto e vírgula (;).read_csv(): lê arquivos CSV (comma separated file) que seguem o padrão americano. Arquivos .txt ou .csv onde os valores são separados por vírgula (,).read_csv(): lê arquivos CSV (comma separated file) que seguem o padrão americano. Arquivos .txt ou .csv onde os valores são separados por vírgula (,).read_tsv(): lê arquivos TSV (tab separated values). Arquivos .txt ou .tsv onde os valores são separados por tabulação (\\t).read_tsv(): lê arquivos TSV (tab separated values). Arquivos .txt ou .tsv onde os valores são separados por tabulação (\\t).read_fwf(): lê arquivos FWF (fixed width file). Arquivos .txt ou .fwf onde cada coluna arquivo possui uma largura fixa de valores.read_fwf(): lê arquivos FWF (fixed width file). Arquivos .txt ou .fwf onde cada coluna arquivo possui uma largura fixa de valores.Perceba que o nome de todas funções acima seguem o padrão read_*, onde palavra presente ponto * corresponde extensão que identifica o tipo de arquivo qual função é especializada. Nós sempre iniciamos qualquer uma das funções acima, pelo endereço até o arquivo que desejamos ler. Como exemplo inicial, eu possuo um arquivo CSV chamado Censo_2010.csv, que se encontra dentro da pasta 6 - Importacao.Perceba também exemplo acima, que eu salvo o resultado da função read_csv2() em um objeto chamado Censo_2010. Isso é muito importante! Lembre-se sempre de salvar o resultado das funções read_* em algum objeto. Pois função read_csv2() busca apenas ler o arquivo Censo_2010.csv e encaixar o seu conteúdo em uma tabela (ou um data.frame) R. Ou seja, em nenhum momento, função read_csv2() se preocupa em salvar os dados que ela coletou arquivo Censo_2010.csv, em algum lugar que podemos acessar futuramente. É por essa razão, que eu salvo tabela gerada pela função read_csv2() em um objeto. Pois dessa forma, eu posso acessar novamente os dados que coletamos arquivo Censo_2010.csv, através objeto Censo_2010.Mesmo que o arquivo Censo_2010.csv seja claramente um arquivo CSV, nós precisamos identificar qual o padrão que ele está adotando. Nos EUA, um arquivo CSV utiliza vírgulas (,) para separar os valores de cada coluna. Porém, pelo fato de nós, brasileiros, usarmos vírgula para delimitar casas decimais em números reais, nós empregamos o padrão de um arquivo CSV adotado por alguns países europeus, que utilizam o ponto e vírgula (;) como separador. Logo abaixo, temos linhas iniciais arquivo Censo_2010.csv e, podemos rapidamente identificar que esse arquivo utiliza o padrão europeu. É por este motivo que eu utilizo função read_csv2(), e não função read_csv() para ler o arquivo.Apesar de ser esse o padrão adotado por nós brasileiros, você enfrentará ocasiões em que o seu arquivo de texto possui separadores diferentes esperado. Por exemplo, talvez os seus dados sejam separados por cifrões ($).Em casos como esse, você será obrigado definir explicitamente o separador utilizado arquivo. Para isso, você pode utilizar função read_delim(), que possui o argumento delim, onde podemos determinar o caractere que delimita colunas arquivo.Como um outro exemplo, arquivos TSV são simplificadamente um arquivo CSV que utiliza um caractere especial de tabulação como separador, representado pelos caracteres \\t. Ou seja, nós podemos recriar função read_tsv() através da função read_delim(), ao configurarmos o argumento delim, como exemplo abaixo.","code":"\nlibrary(readr)\n\nCenso_2010 <- read_csv2(\"Parte 1/6 - Importacao/Censo_2010.csv\")## ‐‐ Column specification ‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐‐\n## cols(\n## `Região metropolitana` = col_character(),\n## `População residente` = col_double(),\n## `População em área urbana` = col_double(),\n## `População em área não urbanizada` = col_double(),\n## `População em área isolada` = col_double(),\n## `Área rural` = col_double(),\n## `Aglomerado urbano` = col_double(),\n## Povoado = col_double(),\n## Núcleo = col_double(),\n## `Outros aglomerados` = col_double(),\n## `Código unidade` = col_double()\n## )\n\nCenso_2010## # A tibble: 2,013 x 11\n##    `Região metropol~ `População resid~ `População em ár~ `População em áre~\n##    <chr>                         <dbl>             <dbl>              <dbl>\n##  1 Manaus  AM                  2106322           1972885               3011\n##  2 Homens                      1036676            964041               2018\n##  3 Mulheres                    1069646           1008844                993\n##  4 Careiro da Várzea             23930              1000                 NA\n##  5 Homens                        12688               481                 NA\n##  6 Mulheres                      11242               519                 NA\n##  7 Iranduba                      40781             28979                 NA\n##  8 Homens                        20996             14662                 NA\n##  9 Mulheres                      19785             14317                 NA\n## 10 Itacoatiara                   86839             57863                294\n## # ... with 2,003 more rows, and 7 more variables:\n## #   População em área isolada <dbl>, Área rural <dbl>,\n## #   Aglomerado urbano <dbl>, Povoado <dbl>, Núcleo <dbl>,\n## #   Outros aglomerados <dbl>, Código unidade <dbl>Manaus  AM;2106322;1972885;3011;;108160;;22266;;;30\nHomens;1036676;964041;2018;;59024;;11593;;;30\nMulheres;1069646;1008844;993;;49136;;10673;;;30\nCareiro da Várzea;23930;1000;;;21089;;1841;;;1301159\nHomens;12688;481;;;11281;;926;;;1301159\nMulheres;11242;519;;;9808;;915;;;1301159\nt <- \"Ano$Código$Dia$Valor\n2020$P.A22$01$4230.45\n2020$B.34$02$1250.28\n2020$S.T4$03$3510.90\"\n\nwriteLines(t)## Ano$Código$Dia$Valor\n## 2020$P.A22$01$4230.45\n## 2020$B.34$02$1250.28\n## 2020$S.T4$03$3510.90\nread_delim(t, delim = \"$\")## # A tibble: 3 x 4\n##     Ano Código Dia   Valor\n##   <dbl> <chr>  <chr> <dbl>\n## 1  2020 P.A22  01    4230.\n## 2  2020 B.34   02    1250.\n## 3  2020 S.T4   03    3511.\nt <- \"Ano\\tCódigo\\tDia\\tValor\n2020\\tP.A22\\t01\\t4.230,45\n2020\\tB.34\\t02\\t1.250,28\n2020\\tS.T4\\t03\\t3.510,90\"\n\nwriteLines(t)## Ano  Código  Dia Valor\n## 2020 P.A22   01  4.230,45\n## 2020 B.34    02  1.250,28\n## 2020 S.T4    03  3.510,90\nread_delim(t, delim = \"\\t\")## # A tibble: 3 x 4\n##     Ano Código Dia   Valor\n##   <dbl> <chr>  <chr> <dbl>\n## 1  2020 P.A22  01     4.23\n## 2  2020 B.34   02     1.25\n## 3  2020 S.T4   03     3.51"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"definindo-os-tipos-de-dados-em-cada-coluna","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.6.1 Definindo os tipos de dados em cada coluna","text":"Caso nós não informarmos em qualquer uma das funções read_*, qual o tipo de dado contido em cada coluna de nosso arquivo de texto, essas funções vão por padrão, ler 1000 primeiras linhas de seu arquivo, e com base nessas 1000 linhas, vão tentar adivinhar qual o tipo de dado contido em cada coluna. Após esse processo, função read_* vai ler linhas restantes arquivo, se baseando nos tipos identificados pela função.Tendo isso em mente, todas funções read_* sempre nos fornecem uma pequena descrição, contendo especificação de cada coluna (Column specification). Essa descrição está nos informando justamente qual foi o “chute” da função, ou qual o tipo de dado que função utilizou em cada coluna. Veja exemplo abaixo, que função read_csv() interpretou que colunas Título e Autor continham dados textuais e, por isso, utilizou colunas tipo character (col_character()) para guardar esses dados. Por outro lado, função percebeu que coluna Preço continha dados numéricos e, por essa razão, preferiu utilizar uma coluna tipo double (col_double()) para alocar esses dados na tabela.Isso é uma característica importante e útil das funções read_*, pois podemos contar com esse sistema para definir os tipos de cada coluna arquivo. Porém, esse é um sistema que se torna cada vez mais frágil medida em que o tamanho de nosso arquivo aumenta. Pois essas 1000 primeiras linhas começam representar uma parte cada vez menor arquivo e, portanto, suas chances de demonstrarem fielmente os tipos de dados presentes em todo arquivo, ficam cada vez menores.Por isso, é provável que em algum momento, você terá de contornar esse comportamento, e definir explicitamente os tipos de dados contidos em cada coluna por meio argumento col_types de qualquer função read_*.Para construirmos essa definição, nós utilizamos função cols() e suas variantes col_*. Dentro da função cols(), precisamos igualar o nome da coluna presente arquivo de texto à função col_* que corresponde ao tipo de dado desejado. exemplo abaixo, ao igualar colunas year, month e day à função col_integer(), eu estou definindo que essas colunas devem ser interpretadas como colunas tipo integer. Enquanto isso, ao igualar colunas carrier e tailnum à função col_character(), eu estou requisitando que essas colunas sejam lidas como colunas tipo character.Por outro lado, função cols() nos oferece um atalho chamado .default. Mediante esse atalho, podemos nos referir todas colunas arquivo de uma vez. Por isso, exemplo abaixo, ao igualar esse atalho à função col_double(), eu estou dizendo à função cols(), que qualquer outra coluna arquivo que não tenha sido definida explicitamente na função cols(), deve ser interpretada como uma coluna tipo double. Por este motivo, colunas dep_time e dep_delay (e várias outras), que não foram configuradas explicitamente na função cols(), acabaram sendo interpretadas como colunas tipo double.","code":"\nlivros <- read_csv(\"C:/Users/Pedro/Documents/Lista de compras/livros.txt\")-- Column specification --------------------------------\ncols(\n  Título = col_character(),\n  Autor = col_character(),\n  Preço = col_double()\n)\ntipos_col <- cols(\n  .default = col_double(),\n  year = col_integer(),\n  month = col_integer(),\n  day = col_integer(),\n  carrier = col_character(),\n  tailnum = col_character(),\n  origin = col_character(),\n  dest = col_character(),\n  time_hour = col_datetime(format = \"\")\n)\n\nflights <- read_csv2(\n  \"flights.csv\",\n  col_types = tipos_col\n)\nflights## # A tibble: 336,776 x 19\n##     year month   day dep_time sched_dep_time dep_delay arr_time\n##    <int> <int> <int>    <dbl>          <dbl>     <dbl>    <dbl>\n##  1  2013     1     1      517            515         2      830\n##  2  2013     1     1      533            529         4      850\n##  3  2013     1     1      542            540         2      923\n##  4  2013     1     1      544            545        -1     1004\n##  5  2013     1     1      554            600        -6      812\n##  6  2013     1     1      554            558        -4      740\n##  7  2013     1     1      555            600        -5      913\n##  8  2013     1     1      557            600        -3      709\n##  9  2013     1     1      557            600        -3      838\n## 10  2013     1     1      558            600        -2      753\n## # ... with 336,766 more rows, and 12 more variables: sched_arr_time <dbl>,\n## #   arr_delay <dbl>, carrier <chr>, flight <dbl>, tailnum <chr>,\n## #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n## #   minute <dbl>, time_hour <dttm>"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"sec:readr_locale","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.6.2 Compreendendo o argumento locale","text":"O argumento locale está presente em todas funções read_*, e é responsável por definir especificações arquivo de texto que mudam de país para país. Brasil, por exemplo, datas são definidas formato “Dia/Mês/Ano,” enquanto nos EUA, datas se encontram formato “Ano-Mês-Dia.” Brasil, utilizamos vírgulas para separar parte decimal de um número, enquanto nos EUA, essa separação é definida por um ponto final. Uma diferença ainda mais importante, se encontra sistema de encoding adotado, que varia de maneira muito violenta ao longo dos países.O R, é uma linguagem centrada nos padrões americanos, por isso, sempre que você estiver tentando ler algum arquivo de texto que não se encaixa de alguma forma neste padrão, você terá que ajustar o locale da função read_* que você está utilizando. Algumas funções já preveêm e adotam essas diferenças, um exemplo disso, é função read_csv2(), que é na verdade um atalho para o padrão adotado por nós brasileiros, e por alguns países europeus.Como exemplo inicial, vamos tentar ler o arquivo pib_per_capita.csv, que novamente se encontra dentro da pasta 6 - Importacao. Dessa vez, vamos utilizar função geral pacote, read_delim(). Lembre-se que nessa função, você deve sempre indicar qual o caractere separador arquivo, através argumento delim.Algo deu errado durante importação, pois colunas PIB e PIB per capita foram importadas como colunas de texto (character), sendo que elas são claramente numéricas. Em momentos como esse, é interessante que você consulte primeiras linhas arquivo, para compreender melhor sua estrutura e identificar o que deu errado. Por isso, temos logo abaixo, três primeiras linhas arquivo pib_per_capita.csv. Perceba que os dois últimos valores em cada linha, representam os dados das colunas PIB e PIB per capita. Ao olharmos, por exemplo, para o número 33.389.769,00 nós podemos identificar qual o problema que está ocorrendo em nossa importação.O motivo para tal conflito, se encontra justamente uso ponto final como separador de milhares, e da vírgula para marcar parte decimal dos números dispostos nas colunas PIB e PIB_per_capita. Ou seja, como não informamos nada sobre particularidades arquivo, função read_delim() está imaginando que o arquivo pib_per_capita.csv se encontra padrão americano. Por isso, nós precisamos fornecer essas informações à função read_delim() para que esse problema seja corrigido, através argumento locale.Na verdade, tais informações são fornecidas através da função locale(), como exemplo abaixo. nosso caso, precisamos ajustar o caractere responsável por separar os milhares, que corresponde ao argumento grouping_mark, e o caractere que defini parte decimal dos nossos números, que corresponde ao argumento decimal_mark da função locale(). Perceba exemplo abaixo, que ao provermos essas informações à função read_delim() através da função locale(), colunas PIB e PIB per capita foram corretamente interpretadas como colunas numéricas (double).Apesar de resolvermos o problema gerado anteriormente nas colunas PIB e PIB per capita, ainda há algo que precisamos corrigir nessa importação. O problema remanescente, se encontra em colunas textuais e título de algumas colunas. Perceba que alguns desses textos (especialmente em letras acentuadas) estão esquisitos. Por exemplo, coluna que deveria se chamar Município está denominada como Munic\\xedpio.Esse é um típico problema de encoding, onde função read_delim() imagina que o arquivo pib_per_capita.csv se encontra em um sistema de encoding específico, quando na verdade, ele se encontra em um outro sistema. Ou seja, tudo o que precisamos fazer, é informar qual o sistema correto de leitura arquivo à função read_delim(). Por padrão, todas funções pacote readr vão pressupor que os seus arquivos se encontram sistema UTF-8 de encoding. Porém, maioria dos computadores brasileiros utilizam um outro sistema, sendo ele, o sistema ISO-8859-1, que também é conhecido por Latin1.Nas funções pacote readr, nós podemos definir o encoding de leitura, através argumento encoding presente na função locale(). Nesse argumento, você pode fornecer tanto o nome oficial sistema (ISO-8859-1) quanto o seu apelido (Latin1). Repare exemplo abaixo, que ao definirmos o encoding correto de leitura, os problemas em elementos textuais foram resolvidos. Para ter uma melhor compreensão desse problema, por favor leia seção Encoding de caracteres.","code":"\npib <- read_delim(\"Parte 1/6 - Importacao/pib_per_capita.csv\", delim = \";\")\npib## # A tibble: 853 x 7\n##    IBGE2   IBGE `Munic\\xedpio`        `Popula\\xe7\\xe3o`   Ano PIB          \n##    <dbl>  <dbl> <chr>                             <dbl> <dbl> <chr>        \n##  1    10 310010 \"Abadia dos Dourados\"              6972  2017 33.389.769,00\n##  2    20 310020 \"Abaet\\xe9\"                       23223  2017 96.201.158,00\n##  3    30 310030 \"Abre Campo\"                      13465  2017 29.149.429,00\n##  4    40 310040 \"Acaiaca\"                          3994  2017 2.521.892,00 \n##  5    50 310050 \"A\\xe7ucena\"                       9575  2017 15.250.077,00\n##  6    60 310060 \"\\xc1gua Boa\"                     13600  2017 29.988.906,00\n##  7    70 310070 \"\\xc1gua Comprida\"                 2005  2017 74.771.408,00\n##  8    80 310080 \"Aguanil\"                          4448  2017 15.444.038,00\n##  9    90 310090 \"\\xc1guas Formosas\"               19166  2017 11.236.696,00\n## 10   100 310100 \"\\xc1guas Vermelhas\"              13477  2017 48.088.397,00\n## # ... with 843 more rows, and 1 more variable: PIB per capita <chr>10;310010;Abadia dos Dourados;6972;2017;33.389.769,00;4.789,12\n20;310020;Abaeté;23223;2017;96.201.158,00;4.142,49\n30;310030;Abre Campo;13465;2017;29.149.429,00;2.164,83\npib <- read_delim(\n  \"Parte 1/6 - Importacao/pib_per_capita.csv\",\n  delim = \";\",\n  locale = locale(decimal_mark = \",\", grouping_mark = \".\")\n)\npib## # A tibble: 853 x 7\n##    IBGE2   IBGE `Munic\\xedpio`        `Popula\\xe7\\xe3o`   Ano      PIB\n##    <dbl>  <dbl> <chr>                             <dbl> <dbl>    <dbl>\n##  1    10 310010 \"Abadia dos Dourados\"              6972  2017 33389769\n##  2    20 310020 \"Abaet\\xe9\"                       23223  2017 96201158\n##  3    30 310030 \"Abre Campo\"                      13465  2017 29149429\n##  4    40 310040 \"Acaiaca\"                          3994  2017  2521892\n##  5    50 310050 \"A\\xe7ucena\"                       9575  2017 15250077\n##  6    60 310060 \"\\xc1gua Boa\"                     13600  2017 29988906\n##  7    70 310070 \"\\xc1gua Comprida\"                 2005  2017 74771408\n##  8    80 310080 \"Aguanil\"                          4448  2017 15444038\n##  9    90 310090 \"\\xc1guas Formosas\"               19166  2017 11236696\n## 10   100 310100 \"\\xc1guas Vermelhas\"              13477  2017 48088397\n## # ... with 843 more rows, and 1 more variable: PIB per capita <dbl>\npib <- read_delim(\n  \"Parte 1/6 - Importacao/pib_per_capita.csv\",\n  delim = \";\",\n  locale = locale(\n    decimal_mark = \",\",\n    grouping_mark = \".\",\n    encoding = \"Latin1\"\n  )\n)\npib## # A tibble: 853 x 7\n##    IBGE2   IBGE Município          População   Ano     PIB `PIB per capita`\n##    <dbl>  <dbl> <chr>                  <dbl> <dbl>   <dbl>            <dbl>\n##  1    10 310010 Abadia dos Dourad~      6972  2017  3.34e7            4789.\n##  2    20 310020 Abaeté                 23223  2017  9.62e7            4142.\n##  3    30 310030 Abre Campo             13465  2017  2.91e7            2165.\n##  4    40 310040 Acaiaca                 3994  2017  2.52e6             631.\n##  5    50 310050 Açucena                 9575  2017  1.53e7            1593.\n##  6    60 310060 Água Boa               13600  2017  3.00e7            2205.\n##  7    70 310070 Água Comprida           2005  2017  7.48e7           37292.\n##  8    80 310080 Aguanil                 4448  2017  1.54e7            3472.\n##  9    90 310090 Águas Formosas         19166  2017  1.12e7             586.\n## 10   100 310100 Águas Vermelhas        13477  2017  4.81e7            3568.\n## # ... with 843 more rows"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"outras-configurações-envolvendo-linhas-e-colunas","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.6.3 Outras configurações envolvendo linhas e colunas","text":"Nessa seção, vamos utilizar como exemplo base, o arquivo CSV que forma o objeto t abaixo. Perceba que esse arquivo utiliza pontos e vírgulas como separador, e que ele não possui cabeçalho aparente. Ou seja, aparentemente os nomes das colunas não estão definidas arquivo.Por padrão, funções read_* utilizam primeira linha arquivo para construir o nome de cada coluna presente. Mas se você deseja evitar esse comportamento, você pode configurar o argumento col_names para FALSE. Dessa forma, função read_* vai gerar nomes genéricos para cada coluna. Uma outra alternativa é fornecer um vetor ao argumento col_names, contendo os nomes de cada coluna na ordem em que elas aparecem arquivo, como exemplo abaixo.Além disso, funções read_* nos permite determinar o número máximo de linhas que desejamos ler de um arquivo, através argumento n_max. Logo, mesmo que um arquivo de texto qualquer possua 500 mil linhas, nós podemos ler apenas 10 primeiras linhas desse arquivo, ao configurarmos esse argumento. exemplo abaixo, eu estou lendo apenas 5 primeiras linhas arquivo t.Para mais, também podemos indiretamente definir linha pela qual função deve iniciar leitura, por meio argumento skip. Nesse argumento, você vai determinar quantas linhas início arquivo devem ser desconsideradas pela função. Portanto, exemplo abaixo, eu estou ignorando 2 primeiras linhas arquivo t.","code":"\nt <- \"2020;P.A22;01;4230.45\n2020;B.34;02;1250.28\n2020;S.T4;03;3510.90\n2020;B.35;04;1200.25\n2020;F.J4;05;1542.20\n2020;A.12;06;9854.09\n2020;B.Q2;07;7654.10\n2020;G.T4;08;4328.36\n2020;E.7A;09;2310.25\"\n\nread_delim(t, delim = \";\")## # A tibble: 8 x 4\n##   `2020` P.A22 `01`  `4230.45`\n##    <dbl> <chr> <chr>     <dbl>\n## 1   2020 B.34  02        1250.\n## 2   2020 S.T4  03        3511.\n## 3   2020 B.35  04        1200.\n## 4   2020 F.J4  05        1542.\n## 5   2020 A.12  06        9854.\n## 6   2020 B.Q2  07        7654.\n## 7   2020 G.T4  08        4328.\n## 8   2020 E.7A  09        2310.\ncol <- c(\"Ano\", \"Código\", \"Dia\", \"Valor\")\n\nread_delim(t, delim = \";\", col_names = col)## # A tibble: 9 x 4\n##     Ano Código Dia   Valor\n##   <dbl> <chr>  <chr> <dbl>\n## 1  2020 P.A22  01    4230.\n## 2  2020 B.34   02    1250.\n## 3  2020 S.T4   03    3511.\n## 4  2020 B.35   04    1200.\n## 5  2020 F.J4   05    1542.\n## 6  2020 A.12   06    9854.\n## 7  2020 B.Q2   07    7654.\n## 8  2020 G.T4   08    4328.\n## 9  2020 E.7A   09    2310.\nread_delim(t, delim = \";\", n_max = 5, col_names = col)## # A tibble: 5 x 4\n##     Ano Código Dia   Valor\n##   <dbl> <chr>  <chr> <dbl>\n## 1  2020 P.A22  01    4230.\n## 2  2020 B.34   02    1250.\n## 3  2020 S.T4   03    3511.\n## 4  2020 B.35   04    1200.\n## 5  2020 F.J4   05    1542.\nread_delim(t, delim = \";\", skip = 2, col_names = col)## # A tibble: 7 x 4\n##     Ano Código Dia   Valor\n##   <dbl> <chr>  <chr> <dbl>\n## 1  2020 S.T4   03    3511.\n## 2  2020 B.35   04    1200.\n## 3  2020 F.J4   05    1542.\n## 4  2020 A.12   06    9854.\n## 5  2020 B.Q2   07    7654.\n## 6  2020 G.T4   08    4328.\n## 7  2020 E.7A   09    2310."},{"path":"importando-e-exportando-dados-com-o-r.html","id":"sec:estudo_pnad_continua","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.7 Um estudo de caso: lendo os microdados da PNAD Contínua com read_fwf()","text":"PNAD Contínua é uma pesquisa amostral, e vem sendo realizada desde janeiro de 2012 pelo Instituto Brasileiro de Geografia e Estatística (Pesquisa Nacional Por Amostra de Domicílios Contínua: Notas técnicas 2019). Os principais indicadores periódicos mercado de trabalho são extraídos dessa pesquisa, e por isso, ela representa uma das principais fontes de informação econômica e demográfica país. Nessa seção, vamos utilizar funções pacote readr para importarmos os microdados da divulgação trimestral dessa pesquisa para o R.PNAD Contínua, é organizada em três pesquisas que possuem periodicidades diferentes, são elas: PNAD Contínua Anual, PNAD Contínua Mensal e PNAD Contínua Trimestral. Em outras palavras, ao longo ano, existem três pesquisas da PNAD Contínua, sendo construídas ao mesmo tempo. Porém, essas três pesquisas são divulgadas em períodos diferentes ano, empregam níveis de agregação diferentes, e buscam medir variáveis demográficas diferentes. Nessa seção, vamos focar nos microdados da divulgação trimestral da PNAD Contínua, sendo essa principal parte da PNAD Contínua, e mais utilizada. Você pode encontrar os microdados da PNAD Contínua Trimestral, na página oficial da pesquisa, ou endereço da página servidor, onde esses microdados estão hospedados.Para que você possa acompanhar os comandos mostrados nessa seção, lembre-se de chamar pelo pacote readr, ou pelo tidyverse (que contém o pacote readr). Como vamos utilizar o operador pipe (%>%) ao longo desse capítulo, é possível que você também tenha que chamar pelo pacote magrittr.","code":"\nlibrary(readr)\nlibrary(magrittr)\nlibrary(tidyverse)"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"conhecendo-a-estrutura-dos-microdados","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.7.1 Conhecendo a estrutura dos microdados","text":"Antes de importarmos esses dados, precisamos conhecer estrutura arquivo que contém esses dados. Ou seja, precisamos saber qual extensão desse arquivo, e de que maneira os dados estão organizados dentro desse arquivo. Como exemplo, eu fui até página oficial da pesquisa, e baixei os microdados primeiro trimestre de 2020. O arquivo veio compactado (.zip), e por isso, eu o descompactei para que tivéssemos acesso ao arquivo bruto que contém os microdados, mostrado na figura 3.7.\nFigure 3.7: Arquivo contendo os microdados da PNAD Contínua - 1° Trimestre de 2020\nComo podemos ver pela figura 3.7, o arquivo é um simples documento de texto (extensão .txt), e todas funções de importação pacote readr são capazes de ler este tipo de arquivo. Porém, ainda temos que identificar o tipo, ou estrutura desse documento de texto. Em outras palavras, precisamos compreender como esses dados estão organizados dentro desse arquivo. Será que os valores de cada coluna são separados por vírgulas (.csv)? por ponto e vírgula (.csv)? por tabulação (.tsv)? Para descobrirmos, precisamos dar uma olhada arquivo.Porém, o tamanho arquivo é considerável (aproximadamente 222 MB). Isso nos dá entender que base de dados contida nesse arquivo, é relativamente grande. Como nós queremos dar apenas uma olhada, talvez seja mais interessante lermos apenas 5 primeiras linhas arquivo. funções de importação pacote readr, geralmente possuem um argumento n_max, onde podemos configurar o número máximo de linhas serem lidas arquivo. Portanto, ao aplicarmos função read_csv() abaixo, podemos ver cinco primeiras linhas arquivo. primeira coisa que podemos abstrair resultado, é que o arquivo de texto parece uma muralha de números, e aparentemente não se encaixa em nenhuma das hipóteses anteriores.Esse é um exemplo de arquivo chamado de fixed width file (.fwf), ou “arquivo de largura fixa.” Provavelmente, o principal motivo pelo qual o IBGE decidiu adotar esse formato de arquivo na divulgação de seus dados, está fato de que arquivos desse tipo, são muito mais rápidos de se ler em programas, que um arquivo CSV tradicional. Pois os valores de cada coluna em um arquivo fixed width file, se encontram sempre nos mesmos lugares ao longo arquivo. Em contrapartida, esse tipo de arquivo, torna sua vida mais difícil, pois você precisa especificar largura, ou o número de caracteres presentes em cada coluna, para função que será responsável por ler esse arquivo.Ou seja, nesse tipo arquivo, não há qualquer tipo de valor ou especificação responsável por delimitar colunas da base de dados. O arquivo simplesmente contém todos os valores, um lado outro. Será sua tarefa, dizer ao programa (nosso caso, o R) quantos caracteres estão presentes em cada coluna, ou em outras palavras, definir em quais caracteres estão “quebras” de colunas.Isso significa, que você irá precisar de um dicionário desses dados, contendo especificações de cada coluna dessa base de dados. caso da PNAD Contínua, são oferecidos: 1) o dicionário das variáveis (geralmente em uma planilha Excel, com extensão .xls), que contém uma descrição completa de cada variável (ou coluna) presente na base; 2) e o arquivo de texto input, que contém especificações para importação da base. Você pode baixar esses arquivos separadamente, na página servidor em que os microdados são hospedados, ou então, você pode baixar um ZIP (Dicionario_input.zip) desses arquivos neste link. Logo abaixo, na figura 3.8, temos uma foto desses arquivos em meu computador.\nFigure 3.8: Arquivos input e dicionário da PNAD Contínua\nEntretanto, para surpresa de muitos, o arquivo de texto input (que geralmente assume o nome de input_PNADC_trimestral.txt), é na verdade, um script de importação utilizado pelo programa estatístico SAS9. O SAS é um programa estatístico pago, parecido com o seu concorrente SPSS10, sendo um programa mais popular mercado americano. Logo, se você estivesse trabalhando com o programa SAS, você já teria um script pronto para importar os microdados da PNAD Contínua. Como não é o nosso caso, temos que extrair, partir desse script de SAS, especificações de cada coluna.","code":"\nread_csv(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  n_max = 5\n)## # A tibble: 5 x 1\n##   `202011111  11000001611100110107511000098.75663631000139.734222300005349~\n##   <chr>                                              \n## 1 202011111  11000001611100110107511000098.75663631000139.7342223000053491~\n## 2 202011111  11000001611100110107511000098.75663631000139.7342223000053491~\n## 3 202011111  11000001611100110107511000098.75663631000139.7342223000053491~\n## 4 202011111  11000001611100110307511000098.75663631000139.7342223000053491~\n## 5 202011111  11000001611100110307511000098.75663631000139.7342223000053491~"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"extraindo-especificações-de-um-script-sas","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.7.2 Extraindo especificações de um script SAS","text":"Como veremos mais frente, extrair especificações desse script é uma tarefa simples, e existem hoje, diversas ferramentas que podemos utilizar para rapidamente extraírmos essas informações script, sem necessidade de um trabalho manual. Porém, antes de partirmos para prática, precisamos primeiro, compreender estrutura script de SAS, presente nesse arquivo input (input_PNADC_trimestral). Na figura 3.9, temos um resumo que descreve essa estrutura.O script, ou mais especificamente, os comandos que definem importação dos dados, se inicia pelo termo input, logo, estamos interessados em todas configurações feitas após esse termo. especificações de cada coluna, são compostas por 3 itens principais: 1) posição inicial dessa coluna (ou posição caractere que inicia essa coluna); 2) o nome dessa coluna; e 3) largura dessa coluna, ou em outras palavras, quantidade de caracteres presentes em cada linha dessa coluna. Para o nosso objetivo, precisamos extrair os dois últimos componentes (o nome e largura da coluna), além de definirmos se essa coluna é numérica ou textual, que é determinado pela presença ou não de um cifrão ($) ao lado da largura da coluna, script.\nFigure 3.9: Resumo da estrutura de um script de importação SAS\nmelhor forma de organizarmos essas especificações, é criarmos uma tabela, onde cada linha corresponde uma coluna dos microdados, e cada coluna dessa tabela contém uma das especificações (nome da coluna, largura da coluna, é numérica ou textual?) de cada coluna dos microdados. Para construir essa tabela, eu costumo utilizar macros de um programa de edição de texto (como o Notepad++11) sobre o arquivo input (input_PNADC_trimestral.txt), de forma eliminar os textos irrelevantes, e arrumar especificações na estrutura de um arquivo CSV (.csv). Dessa forma, eu posso importar esse arquivo CSV resultante para o R, e adquirir tabela que desejo. Como um guia, você pode ter acesso esse arquivo CSV, através da cópia que deixei .Portanto, após extrair especificações de cada coluna arquivo input, eu tenho como resultado, um arquivo CSV chamado widths.txt, que eu posso ler através da função read_csv(). Veja pelo resultado abaixo, que eu defini três colunas nesse arquivo CSV. coluna variavel possui os nomes da colunas, na ordem em que elas aparecem script arquivo input, e portanto, nos microdados. coluna width possui o número de caracteres presentes em cada uma dessas colunas. Já coluna char, possui um valor lógico, indicando se os dados contidos nessa coluna, devem ser interpretados como texto (TRUE), ou como números (FALSE).","code":"\ncol_width <- read_csv(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/widths.txt\", \n  col_names = c(\"variavel\", \"width\", \"char\")\n)## -- Column specification --------------------------------\n## cols(\n##   variavel = col_character(),\n##   width = col_double(),\n##   char = col_logical()\n## )\ncol_width## # A tibble: 217 x 3\n##    variavel  width char \n##    <chr>     <dbl> <lgl>\n##  1 Ano           4 TRUE \n##  2 Trimestre     1 TRUE \n##  3 UF            2 TRUE \n##  4 Capital       2 TRUE \n##  5 RM_RIDE       2 TRUE \n##  6 UPA           9 TRUE \n##  7 Estrato       7 TRUE \n##  8 V1008         2 TRUE \n##  9 V1014         2 TRUE \n## 10 V1016         1 TRUE \n## # ... with 207 more rows"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"o-pacote-sascii-como-um-atalho-útil","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.7.3 O pacote SAScii como um atalho útil","text":"O pacote SAScii nos oferece um conjunto de funções voltadas para importação de arquivos fixed width file. Porém, dentre suas funcionalidades, o pacote também nos oferece uma função capaz de converter scripts de importação programa SAS, e extrair especificações de cada coluna em um data.frame. Ou seja, podemos utilizar função parse.SAScii() para extraírmos especificações de cada coluna script presente arquivo input.Essa função é bem simples, e possui dois argumentos principais: 1) sas_ri, o endereço até o arquivo contendo o script de SAS ser convertido; 2) beginline, linha arquivo em que o script de importação se inicia, ou em outras palavras, linha script onde o termo input aparece. Como podemos ver pela figura 3.10, eu abri o arquivo input em meu Notepad++, que possui na lateral esquerda, númeração de cada linha. Dessa forma, eu posso rapidamente identificar que o termo input aparece na linha 18 arquivo.\nFigure 3.10: Início script de importação\nCom essas informações em mente, eu poderia gerar tabela col_width, através dos seguintes comandos:","code":"\nlibrary(SAScii)\nlibrary(tibble)\ncol_width <- parse.SAScii(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/input_PNADC_trimestral.txt\",\n  beginline = 18\n)\nas_tibble(col_width)## # A tibble: 217 x 4\n##    varname   width char  divisor\n##    <chr>     <dbl> <lgl>   <dbl>\n##  1 ANO           4 TRUE        1\n##  2 TRIMESTRE     1 TRUE        1\n##  3 UF            2 TRUE        1\n##  4 CAPITAL       2 TRUE        1\n##  5 RM_RIDE       2 TRUE        1\n##  6 UPA           9 TRUE        1\n##  7 ESTRATO       7 TRUE        1\n##  8 V1008         2 TRUE        1\n##  9 V1014         2 TRUE        1\n## 10 V1016         1 TRUE        1\n## # ... with 207 more rows"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"importando-os-microdados-da-pnad-contínua","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.7.4 Importando os microdados da PNAD Contínua","text":"Agora que possuímos especificações necessárias de cada coluna, podemos começar o processo de importação dos microdados da PNAD Contínua. Como esses microdados estão estruturados em um arquivo de texto tipo fixed width file (.fwf), podemos utilizar função read_fwf() para ler o arquivo. Pois como o próprio nome dessa função dá entender, ela é especializada nesse tipo de arquivo.O primeiro argumento (file) dessa função, é o caminho até o arquivo ser importado. Já o segundo argumento (col_positions), será o local onde vamos fornecer especificações de cada coluna. Entretanto, nós precisamos utilizar uma função como fwf_widths(), para definirmos essas especificações argumento col_positions. Na função fwf_widths() temos apenas dois argumentos, que são widths e col_names. Basta fornecermos ao argumento widths, larguras de cada coluna, e ao argumento col_names, os nomes de cada coluna, como exemplo abaixo.Como podemos ver acima, pela mensagem de parsing failures, obtivemos alguns problemas durante importação. Isso ocorre, pois função read_fwf() está tendo que adivinhar sozinha, quais são os tipos de dados contidos em cada coluna dos microdados. Lembre-se que por padrão, se não fornecemos uma descrição dos tipos de dados de cada coluna à qualquer função pacote readr, essas funções vão automaticamente ler 1000 primeiras linhas de cada coluna, e se basear nesses 1000 valores para determinar o tipo de dado incluso em cada coluna arquivo.Esse sistema automático, apesar de útil, se torna frágil medida em que o tamanho da nossa base cresce. Pois essas 1000 linhas vão representar uma parte cada vez menor da base, e portanto, podem não ser suficientes para determinar com precisão o tipo de dado contido em cada coluna. nosso exemplo, base da PNAD possui 487 mil linhas, logo, essas 1000 linhas representam apenas 0,2% da base. Se função não está sendo capaz de adivinhar corretamente, os tipos de dados de cada coluna, nós precisamos dizer ela exatamente quais são esses tipos. Para isso, vamos utilizar os dados contidos na coluna char, da nossa tabela col_width.funções de importação pacote readr, possuem o argumento col_types, onde podemos definir os tipos de cada coluna. Essa definição pode ser fornecida, utilizando-se função cols(). Porém, para o nosso caso, creio que será mais prático, utilizarmos um método alternativo que o argumento col_types disponibiliza. Esse método alternativo, conciste em fornecermos um vetor de letras, contendo primeira letra de cada tipo. Essas letras devem estar na ordem em que colunas aparecem em seus dados. Logo, se eu fornecer o vetor \"ccdlcdd\", função irá interpretar primeira e segunda coluna como dados tipo character, enquanto terceira e quarta coluna serão interpretadas como dados dos tipos double e logical, respectivamente.Primeiro, precisamos construir esse vetor de letras, que indicam o tipo de cada coluna. Com os dados da nossa tabela col_width, nós já sabemos que todo valor TRUE na coluna char, indica uma coluna de texto, e portanto, essa coluna deve ser interpretada como uma coluna tipo character. Já os valores FALSE indicam uma coluna numérica, e por isso, essa coluna deve ser interpretada como uma coluna tipo double. Com isso, podemos utilizar função ifelse(), para construírmos um vetor inicial de letras, baseado nos valores da coluna char. Em seguida, podemos juntar todas essas letras em um string só, com função paste().Agora com o vetor tipos, podemos fornecê-lo ao argumento col_types e realizar novamente o processo de importação, com os tipos das colunas sendo corretamente interpretados. Porém, repare que mesmo definindo os tipos das colunas, obtivemos novamente erros durante o processo de importação. Dessa vez, foram mais de 2 milhões de erros. Isso não significa necessariamente que o nosso processo de importação esteja incorretamente especificado. Porém, nós deveríamos pelo menos compreender o porque esses erros ocorrem.","code":"\npnad_continua <- read_fwf(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  col_positions = fwf_widths(col_width$width, col_names = col_width$variavel)\n)## -- Column specification -------------------------------------\n## cols(\n##   .default = col_double(),\n##   RM_RIDE = col_logical(),\n##   V1008 = col_character(),\n##   V1014 = col_character(),\n##   V1027 = col_character(),\n##   V1028 = col_character(),\n##   V1029 = col_character(),\n##   V2001 = col_character(),\n##   V2003 = col_character(),\n##   V2005 = col_character(),\n##   V2008 = col_character(),\n##   V20081 = col_character(),\n##   V2009 = col_character(),\n##   `3003` = col_logical(),\n##   V3003A = col_character(),\n##   V3004 = col_logical(),\n##   V3005 = col_logical(),\n##   V3006 = col_character(),\n##   V3009 = col_logical(),\n##   V3009A = col_character(),\n##   V3011 = col_logical()\n## # ... with 87 more columns\n## )\n## i Use `spec()` for the full column specifications.\n## Warning: 156486 parsing failures.\n## row  col               expected actual   file\n## 1670 V40431  1/0/T/F/TRUE/FALSE 2        'C:/Users/Pedro/Downloads/PNADC~'\n## 2194 V4057   1/0/T/F/TRUE/FALSE 2        'C:/Users/Pedro/Downloads/PNADC_~'\n## 2194 V405811 1/0/T/F/TRUE/FALSE 3        'C:/Users/Pedro/Downloads/PNADC~'\n## 2194 V405812 1/0/T/F/TRUE/FALSE 00001200 'C:/Users/Pedro/Downloads/PNADC~'\n## 2194 V405912 1/0/T/F/TRUE/FALSE 00000000 'C:/Users/Pedro/Downloads/PNADC~'\n## .... ....... .................. ........ .........................\n## See problems(...) for more details.\ntipos <- ifelse(col_width$char == TRUE, \"c\", \"d\")\n\ntipos <- paste(tipos, collapse = \"\")\n\ntipos[1] \"ccccccccccccdddcdccccccdcccccccccccccccccccccccccccccccccccccccccccc\ncccccccccccccccccccccccccccdccdcccccdccdddcdddccccccccccccdccdcccccdccddd\nccccdccdccccccdcddcccccccccccccdddcccccdcccccccccccccccccccddcddccdddddcc\"\npnad_continua <- read_fwf(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  col_positions = fwf_widths(col_width$width, col_names = col_width$variavel), \n  col_types = tipos\n)## Warning: 2032039 parsing failures.\n## row    col expected actual                                              file\n##   1 VD4032 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n##   1 VD4033 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n##   1 VD4034 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n##   2 VD4031 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n##   2 VD4032 a double      . 'C:/Users/Pedro/Downloads/PNADC_012020/PNADC_01~'\n## ... ...... ........ ...... ................................................\n## See problems(...) for more details."},{"path":"importando-e-exportando-dados-com-o-r.html","id":"analisando-erros-de-importação","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.7.5 Analisando erros de importação","text":"Nós podemos obter através da função problems(), uma tabela contendo todos os erros que ocorreram durante esse processo de importação. Precisamos apenas fornecer essa função, os comandos que geraram esses problemas, como exemplo abaixo.Pelo que podemos ver da coluna actual, parece que os erros estão ocorrendo, pela presença de um ponto final (“.”), nos locais em que deveriam estar números (double). Podemos utilizar função unique() sobre coluna actual para identificarmos se há algum outro problema que precisamos analisar. Pelo resultado abaixo, percebemos que todos os mais de 2 milhões de erros gerados, estão sendo causados por essa presença de pontos finais na base. Também podemos utilizar função unique() sobre coluna col, para descobrirmos em quais colunas esse erro ocorre. Vemos abaixo, que esses erros estão concentrados em cinco das últimas colunas de toda base (última coluna da base é VD4037).Seria uma boa ideia, olharmos mais de perto como essas colunas aparecem arquivo de microdaddos. Para determinarmos parte arquivo que diz respeito essas colunas, precisamos descobrir o intervalo de caracteres que cobrem essas colunas, através dos dados da tabela col_width. Para isso, vamos precisar descobrir o número total de caracteres em cada linha (ou em outras palavras, largura total da base), ao somarmos largura de todas colunas na tabela col_width. Ao longo caminho, teremos que subtrair uma faixa desse total, para descobrirmos o caractere que inicia o intervalo de colunas que estamos interessados.Em seguida, podemos aplicar função tail() sobre tabela col_width, para extraírmos últimas linhas dessa tabela, e verificarmos especificações das colunas que cobrem essa faixa. Pois nós sabemos que variáveis que geraram problemas na importação, estão entre útimas colunas dos microdados, logo, especificações dessas colunas vão se encontrar nas últimas linhas da tabela col_width. Vemos abaixo, que duas últimas colunas da base (VD4036 e VD4037), das quais não estamos interessados, possuem juntas, 2 caracteres de largura. Portanto, o intervalo que cobre colunas que geraram os problemas na importação (VD4031-VD4035), termina 462° caractere, como vemos abaixo. Pelo resultado de tail(), vemos que colunas das quais estamos interessados (VD4031-VD4035), somam 15 caracteres de largura. Tendo isso em mente, o intervalo que cobre essas colunas, se inicia 448° caractere.Portanto, nós temos agora posição dos caracteres que iniciam e terminam o intervalo de caracteres que dizem respeito colunas que estamos interessados. Porém, ainda precisamos calcular os caracteres de início e de fim de cada uma das cinco colunas (VD4031-VD4035), que cobrem esse intervalor. Para esse trabalho, podemos aplicar uma simples aritmética, como aplicada pelo código abaixo.Agora que nós temos posições dos caracteres que iniciam e que terminam cada uma das cinco colunas, podemos importar apenas essas cinco colunas ao R. Para isso, podemos usar novamente função read_fwf(), aliada à função fwf_positions(). Ou seja, utilizamos anteriormente função fwf_widths() para determinarmos especificações de todas colunas da base. Porém, como nós queremos importar apenas uma parte dessa base, vamos utilizar função fwf_positions() para determinarmos especificações dessas colunas desejadas.Na função fwf_positions(), temos três argumentos principais: 1) start, um vetor contendo posições dos caracteres que iniciam cada coluna; 2) end, um vetor contendo posições dos caracteres que terminam cada coluna; 3) col_names, um vetor contendo os nomes dessas colunas selecionadas. Tendo esses argumentos em mente, podemos importar cinco colunas da seguinte maneira:Logo abaixo, temos o resultado intervalo que selecionamos arquivo, em que podemos ver o grupo de pontos finais que estão causando o problema. Agora, temos que identificar o motivo desses pontos estarem aí. Se nós retornarmos às especificações dessas colunas apresentadas na tabela col_width, nós sabemos que essas colunas são colunas numéricas. Será que esses pontos estão aí, para marcar casas decimais dos números dessa coluna?Talvez não seja esse o caso. Pois se esses pontos estivessem de fato, marcando casas decimais, porque eles não aparecem na primeira linha das colunas VD4031 e VD4035? Isto é, por que o valor 040 que aparece nessas colunas, não se apresenta como 0.40, ou 04.0, ou 40.0 na tabela conferir? Lembre-se que os valores da tabela conferir, são apresentados exatamente da forma como eles se apresentam arquivo dos microdados, pois todas essas colunas estão sendo interpretadas como character. Ou seja, esses valores que eram meros textos arquivo dos microdados, continuam sendo textos R, de forma que não houve nenhuma conversão desses valores.Pela visão que temos até o momento, parece que colunas VD4032, VD4033 e VD4034, estão vazias, de forma que elas possuem apenas pontos finais em toda sua extensão. Talvez seja o momento de verificarmos essa hipótese. Podemos fazer isso, novamente por meio da função unique(). Pelos resultados abaixo, colunas VD4032, VD4033 e VD4034 estão de fato vazias. Com isso, temos seguinte questão: por que uma coluna numérica está preenchida com pontos? Se esses pontos não estão marcando casas decimais em cada linha, é mais provável que esses pontos estejam ali simplesmente para marcar um valor vazio, ou uma observação que não pôde ser mensurada.Em resumo, nós sabemos pelas especificações das colunas presentes arquivo input, que colunas VD4032, VD4033 e VD4034 devem ser interpretadas como colunas numéricas. Ao que tudo indica, esses pontos não possuem o propósito de delimitar casas decimais. Seria apropriado encontrarmos alguma documentação que nos pudesse guiar sobre esses questionamentos. Porém, até onde pesquisei, não há qualquer menção esses pontos ao longo da documentação IBGE sobre esses microdados. Com informações que possuímos, só podemos inferir que esses valores estão servindo para marcar valores não-disponíveis (em outras palavras, estão cumprindo o papel de um valor NA) nessas colunas.Tendo essas considerações em mente, todos esses pontos presentes nessas colunas, devido ao erro que eles incorrem durante o processo de importação, serão convertidos para valores NA ao importarmos base, e portanto, vão representar observações não-disponíveis na base. Ou seja, se função read_fwf() não consegue interpretar corretamente um valor, ele acaba sendo convertido para um valor NA.","code":"\nproblemas <- problems(\n  read_fwf(\n    \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n    col_positions = fwf_widths(col_width$width, col_names = col_width$variavel), \n    col_types = tipos\n  )\n)\n\nproblemas## # A tibble: 2,032,039 x 5\n##      row col    expected   actual file\n##    <int> <chr>  <chr>      <chr>  <chr>        \n##  1     1 VD4032 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  2     1 VD4033 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  3     1 VD4034 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  4     2 VD4031 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  5     2 VD4032 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  6     2 VD4033 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  7     2 VD4034 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  8     2 VD4035 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n##  9     3 VD4031 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n## 10     3 VD4032 a double   .      'C:/Users/Pedro/Downloads/PNADC_012020/PNAD~\n## # ... with 2,032,029 more rows\nunique(problemas$actual)## [1] \".\"\nunique(problemas$col)## [1] \"VD4032\" \"VD4033\" \"VD4034\" \"VD4031\" \"VD4035\"\n(total_caracteres <- sum(col_width$width))## [1] 464\ntail(col_width, 7)##     varname width  char divisor\n## 211  VD4031     3 FALSE       1\n## 212  VD4032     3 FALSE       1\n## 213  VD4033     3 FALSE       1\n## 214  VD4034     3 FALSE       1\n## 215  VD4035     3 FALSE       1\n## 216  VD4036     1  TRUE       1\n## 217  VD4037     1  TRUE       1\n(fim_intervalo <- total_caracteres - 2)## [1] 462\n(inicio_intervalo <- fim_intervalo - 15 + 1)## [1] 448\n(inicio <- (0:4 * 3) + inicio_intervalo)## [1] 448 451 454 457 460\n(fim <- (1:5 * 3) + inicio_intervalo - 1)## [1] 450 453 456 459 462\ncolunas <- c(\"VD4031\",\"VD4032\",\"VD4033\",\"VD4034\",\"VD4035\")\n\nconferir <- read_fwf(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  col_positions = fwf_positions(\n    start = inicio,\n    end = fim,\n    col_names = colunas\n  )\n)## -- Column specification ------------------------------------\n## cols(\n##   VD4031 = col_character(),\n##   VD4032 = col_character(),\n##   VD4033 = col_character(),\n##   VD4034 = col_character(),\n##   VD4035 = col_character()\n## )\nconferir## # A tibble: 487,937 x 5\n##    VD4031 VD4032 VD4033 VD4034 VD4035\n##    <chr>  <chr>  <chr>  <chr>  <chr> \n##  1 040    .      .      .      040   \n##  2 .      .      .      .      .     \n##  3 .      .      .      .      .     \n##  4 .      .      .      .      .     \n##  5 .      .      .      .      .     \n##  6 040    .      .      .      040   \n##  7 .      .      .      .      .     \n##  8 .      .      .      .      .     \n##  9 .      .      .      .      .     \n## 10 040    .      .      .      040   \n## # ... with 487,927 more rows\nunique(conferir$VD4032)## [1] \".\"\nunique(conferir$VD4033)## [1] \".\"\nunique(conferir$VD4034)## [1] \".\"\npnad_continua <- read_fwf(\n  \"C:/Users/Pedro/Downloads/PNADC_012020/PNADC_012020.txt\",\n  col_positions = fwf_widths(col_width$width, col_names = col_width$variavel), \n  col_types = tipos\n)"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"exportando-os-seus-dados-com-o-pacote-readr","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.8 Exportando os seus dados com o pacote readr","text":"Mais que importar os seus dados para dentro R, haverá um momento em que você deseja exportar os seus resultados para fora R, de forma que você possa enviá-los para os seus colegas de trabalho ou para utilizá-los em outros programas. Em um momento como esse, você deseja escrever um arquivo estático em seu computador, contendo esses resultados. O pacote readr oferece funções que permitem escrita de um conjunto de arquivos de texto. Logo abaixo, temos uma lista relacionando os tipos de arquivos de texto às respectivas funções pacote:write_csv2(): constrói um arquivo CSV, segundo o padrão adotado por alguns países europeus; utilizando pontos e vírgulas (;) como separador.write_csv2(): constrói um arquivo CSV, segundo o padrão adotado por alguns países europeus; utilizando pontos e vírgulas (;) como separador.write_csv(): constrói um arquivo CSV, segundo o padrão americano; utilizando vírgulas (,) como separador.write_csv(): constrói um arquivo CSV, segundo o padrão americano; utilizando vírgulas (,) como separador.write_tsv(): constrói um arquivo TSV.write_tsv(): constrói um arquivo TSV.write_delim(): função geral onde você pode definir o caractere ser utilizado como separador arquivo de texto construído.write_delim(): função geral onde você pode definir o caractere ser utilizado como separador arquivo de texto construído.Um fator muito importante sobre o pacote readr em geral, é que todas suas funções utilizam o encoding UTF-8 o tempo todo. Logo, ao utilizar essas funções para exportar os seus dados, lembre-se sempre que os arquivos construídos por essas funções vão estar utilizando o encoding UTF-8. Isso significa que ao utilizar esses arquivos em outros programas como o Excel, você precisa informar ao programa para utilizar o encoding UTF-8 ao ler o arquivo.Para além disso, você não terá nenhum outro problema com esses arquivos. Porém, caso você se sinta incomodado com esse comportamento, você pode utilizar variantes dessas funções presentes nos pacotes básicos R (write.csv2(), write.csv(), write.table()). Pois essas funções variantes vão escrever o arquivo definido, de acordo com o encoding padrão de seu sistema.O primeiro argumento (x) dessas funções, se trata nome objeto em sua sessão que contém os dados que você deseja exportar. Já segundo argumento (file) dessas funções, você deve definir o nome novo arquivo estatíco que será construído. Por exemplo, se eu possuo uma tabela chamada, e desejo salvá-la em um arquivo chamado transf.csv, eu preciso construir os seguintes comandos:Após executar os comandos acima, você irá encontrar na pasta que representa o seu diretório de trabalho atual R, um novo arquivo chamado transf.csv que contém os seus dados. Vale destacar, que você pode salvar esse novo arquivo em diferentes áreas de seu computador. Basta que você forneça um endereço (absoluto ou relativo) até pasta desejada, em conjunto com o nome novo arquivo. Como exemplo, eu posso salvar tabela Censo_2010 dentro da minha área de trabalho da seguinte forma:","code":"\nwrite_csv2(transf, file = \"transf.csv\")\nwrite_csv2(Censo_2010, file = \"C:/Users/Pedro/Desktop/Censo_2010.csv\")"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"sec:read_excel","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.9 Importando planilhas do Excel com readxl","text":"O Excel continua sendo um dos programas mais populares mundo e, por essa razão, muitas pessoas ainda o utilizam para analisar dados e gerar gráficos. Tendo isso em vista, nessa seção, vamos aprender como podemos importar para o R, dados que se encontram em planilhas Excel (.xlsx), através da função read_excel() que pertence ao pacote readxl.O principal argumento da função read_excel() corresponde novamente ao endereço até o arquivo que você deseja ler, ou apenas o seu nome caso esse arquivo se encontre em seu diretório de trabalho atual.","code":"\nlibrary(readxl)\n\ncodigos <- read_excel(\"codigos.xlsx\")\ncodigos## # A tibble: 853 x 4\n##     IBGE1 IBGE2   SEF Municípios         \n##     <dbl> <dbl> <dbl> <chr>              \n##  1 310010    10     1 ABADIA DOS DOURADOS\n##  2 310020    20     2 ABAETÉ             \n##  3 310030    30     3 ABRE CAMPO         \n##  4 310040    40     4 ACAIACA            \n##  5 310050    50     5 AÇUCENA            \n##  6 310060    60     6 ÁGUA BOA           \n##  7 310070    70     7 ÁGUA COMPRIDA      \n##  8 310080    80     8 AGUANIL            \n##  9 310090    90     9 ÁGUAS FORMOSAS     \n## 10 310100   100    10 ÁGUAS VERMELHAS    \n## # ... with 843 more rows"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"delimitando-a-parte-de-seu-arquivo-.xlsx","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.9.1 Delimitando a parte de seu arquivo .xlsx","text":"Um único arquivo .xlsx pode conter várias planilhas, ou várias abas (sheet’s) diferentes. Por padrão, função read_excel() sempre lê primeira planilha de seu arquivo .xlsx. Porém, você pode ler diferentes planilhas de seu arquivo por meio argumento sheet. Somos capazes de selecionar planilha desejada de acordo com sua ordem (1, 2, 3, …), ou de acordo com o nome dado à aba que contém.Além dessas configurações, conseguimos delimitar o intervalo de células serem lidas pela função, através argumento range. Podemos fornecer esse intervalo em dois estilos diferentes. Nós podemos utilizar o sistema tradicional Excel (CL:CL), como exemplo abaixo, em que estamos lendo da célula A1 à célula C150 através da notação A1:C150.Uma outra possibilidade é utilizarmos funções cell_cols() e cell_rows() que limitam o intervalo para apenas uma das dimensões da planilha. Ou seja, nós empregamos função cell_cols(), quando desejamos ler todas linhas, e, apenas algumas colunas da planilha. Enquanto com função cell_rows(), desejamos ler todas colunas da tabela, porém, queremos extrair apenas uma parte das linhas.colunas de uma planilha Excel, são identificadas por uma letra ou por um conjunto de letras (ex: ; E; F; BC). Por isso, ao utilizar função cell_cols() você pode delimitar colunas serem lidas de duas formas: 1) utilizando notação Excel (C:C), com letras que representam colunas desejadas; 2) ou através de um vetor numérico que representa ordem das colunas, e contém o intervalo desejado.Por outro lado, para delimitarmos o intervalo de linhas em cell_rows() precisamos apenas fornecer um vetor de dois elementos, contendo os limites superior e inferior intervalo, ou então, uma sequência que cobre esses limites.O argumento range é tão flexível que nós podemos utilizá-lo para executar o trabalho argumento sheet. Isto é, além intervalo de células, nós também podemos selecionar aba arquivo .xlsx ser lida pela função, através argumento range. Excel, quando você está utilizando em sua planilha, algum valor que é proveniente de uma outra planilha mesmo arquivo .xlsx, o Excel cria uma referência até esse valor. Essa referência possui o nome da planilha em conjunto com referência da célula onde o valor se encontra, separados por um ponto de exclamação (!). Logo, se eu quisesse ler da célula A1 até célula C150, da planilha denominada mtcars, arquivo datasets.xlsx, eu precisaria criar seguinte referência argumento range:Apesar de sua flexibilidade, o argumento range pressupõe que você conheça exatamente células que compõe os limites de sua tabela, ou então, que você pelo menos tenha uma boa compreensão de onde eles se encontram. Por isso, você também possui na função read_excel() os argumentos skip e n_max, que funcionam exatamente da mesma forma empregada pelas funções pacote readr. Logo, esses argumentos representam uma alternativa menos flexível, mas, talvez sejam mais ideais para suas necessidades, especialmente se você deseja apenas pular algumas linhas de metadados que se encontram início de sua planilha.","code":"\n## Lê a terceira planilha do arquivo\nread_excel(\"datasets.xlsx\", sheet = 3)## # A tibble: 71 x 2\n##    weight feed     \n##     <dbl> <chr>    \n##  1    179 horsebean\n##  2    160 horsebean\n##  3    136 horsebean\n##  4    227 horsebean\n##  5    217 horsebean\n##  6    168 horsebean\n##  7    108 horsebean\n##  8    124 horsebean\n##  9    143 horsebean\n## 10    140 horsebean\n## # ... with 61 more rows\n## Lê a planilha presente na aba denominada mtcars\nread_excel(\"datasets.xlsx\", sheet = \"mtcars\")## # A tibble: 32 x 11\n##      mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n##    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n##  2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n##  3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n##  4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n##  5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n##  6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n##  7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n##  8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2\n##  9  22.8     4  141.    95  3.92  3.15  22.9     1     0     4     2\n## 10  19.2     6  168.   123  3.92  3.44  18.3     1     0     4     4\n## # ... with 22 more rows\nread_excel(\"datasets.xlsx\", range = \"A1:C150\")## # A tibble: 149 x 3\n##    Sepal.Length Sepal.Width Petal.Length\n##           <dbl>       <dbl>        <dbl>\n##  1          5.1         3.5          1.4\n##  2          4.9         3            1.4\n##  3          4.7         3.2          1.3\n##  4          4.6         3.1          1.5\n##  5          5           3.6          1.4\n##  6          5.4         3.9          1.7\n##  7          4.6         3.4          1.4\n##  8          5           3.4          1.5\n##  9          4.4         2.9          1.4\n## 10          4.9         3.1          1.5\n## # ... with 139 more rows\n## Da coluna A até a coluna C\nread_excel(\"datasets.xlsx\", range = cell_cols(\"A:C\"))\n\n## Da 1° até a 3° coluna\nread_excel(\"datasets.xlsx\", range = cell_cols(1:3))\n## Da 1° até a 140° linha\nread_excel(\"datasets.xlsx\", range = cell_rows(1:140))\n\n## Da 10° até a 400° linha\nread_excel(\"datasets.xlsx\", range = cell_rows(c(10, 400)))\nread_excel(\"datasets.xlsx\", range = \"mtcars!A1:C150\") ## # A tibble: 149 x 3\n##      mpg   cyl  disp\n##    <dbl> <dbl> <dbl>\n##  1  21       6  160 \n##  2  21       6  160 \n##  3  22.8     4  108 \n##  4  21.4     6  258 \n##  5  18.7     8  360 \n##  6  18.1     6  225 \n##  7  14.3     8  360 \n##  8  24.4     4  147.\n##  9  22.8     4  141.\n## 10  19.2     6  168.\n## # ... with 139 more rows\nread_excel(\"datasets.xlsx\", sheet = 2, n_max = 50, skip = 10, col_names = FALSE) ## # A tibble: 23 x 11\n##     ...1  ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9 ...10 ...11\n##    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1  19.2     6 168.    123  3.92  3.44  18.3     1     0     4     4\n##  2  17.8     6 168.    123  3.92  3.44  18.9     1     0     4     4\n##  3  16.4     8 276.    180  3.07  4.07  17.4     0     0     3     3\n##  4  17.3     8 276.    180  3.07  3.73  17.6     0     0     3     3\n##  5  15.2     8 276.    180  3.07  3.78  18       0     0     3     3\n##  6  10.4     8 472     205  2.93  5.25  18.0     0     0     3     4\n##  7  10.4     8 460     215  3     5.42  17.8     0     0     3     4\n##  8  14.7     8 440     230  3.23  5.34  17.4     0     0     3     4\n##  9  32.4     4  78.7    66  4.08  2.2   19.5     1     1     4     1\n## 10  30.4     4  75.7    52  4.93  1.62  18.5     1     1     4     2\n## # ... with 13 more rows"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"definindo-os-tipos-de-dados-contidos-em-cada-coluna","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.9.2 Definindo os tipos de dados contidos em cada coluna","text":"Por padrão, função read_excel() vai automaticamente decifrar os tipos de dados contidos em cada coluna. Porém, diferentemente das funções pacote readr, que constroem essa suposição com base nos dados em si arquivo, função read_excel() adivinha os dados contidos em cada coluna, com base nos tipos associados cada célula da planilha. Ou seja, se células de uma coluna estão associadas ao tipo Texto, essa coluna será transformada R em uma coluna tipo character.Pelo fato Excel tratar cada célula de forma individual, você possui uma liberdade muito grande programa. Por exemplo, você pode misturar dados de diferentes tipos em uma mesma coluna, ou em uma mesma linha de uma planilha Excel. Porém, essa liberdade tem o seu preço. Um programa que trata suas células dessa maneira, gera uma estrutura incosistente em seus dados. Esse fato é importante, pois você tem um trabalho muito maior ao replicar cálculos em sua tabela. Com uma estrutura inconsistente, você precisa pensar não apenas em quais tipos estão associados cada coluna de sua tabela, mas também, em quais tipos estão associados cada célula de cada coluna. chances de erros serem gerados durante o processo, são bem maiores.Portanto, o sistema que função read_excel() adota, está de acordo com essa característica. Pois se diversas células em uma mesma coluna possuírem tipos diferentes associados elas, função será capaz de reconhecer essa incosistência, e agir adequadamente. Nós sabemos que o R leva muito sério concistência de seus dados, especialmente se tratando de vetores com suas regras de coerção e, por isso, tal liberdade presente em programas como o Excel, representam um desafio para importação de dados provenientes dessa plataforma.R, há duas maneiras principais de lidarmos com essa possível incosistência de uma planilha Excel. Uma está uso tipo character, pois esse é o tipo de dado mais flexível de todos e, portanto, consegue guardar qualquer outro tipo de dado. Outra está na adoção de listas para qualquer coluna que apresente essa inconstância.Portanto, em toda coluna que possui dados de diferentes tipos em suas células, função read_excel() vai geralmente transformar essa coluna, em uma coluna tipo character. Veja exemplo abaixo, mais especificamente, na coluna value que contém ao menos três tipos de dados diferentes.Como destacamos, uma outra alternativa, seria transformarmos essa coluna em uma lista. Dessa forma, nós podemos incluir qualquer tipo de dado em cada elemento dessa lista (ou em cada “célula” dessa coluna). Porém, teremos que pedir explicitamente função read_excel() que realize esse tipo de transformação, através argumento col_types.Portanto, em todas ocasiões que você precisar evitar que função read_excel() decifre os tipos os tipos de cada coluna, você pode definir de forma explícita esses tipos argumento col_types. Você precisa apenas fornecer um vetor esse argumento, contendo rótulos que representam os tipos de cada coluna na ordem em que elas aparecem na planilha. Os rótulos possíveis nesse argumento são : \"skip\", \"guess\", \"logical\", \"numeric\", \"date\", \"text\" e \"list\".","code":"\nread_excel(readxl_example(\"clippy.xlsx\"))## # A tibble: 4 x 2\n##   name                 value    \n##   <chr>                <chr>    \n## 1 Name                 Clippy   \n## 2 Species              paperclip\n## 3 Approx date of death 39083    \n## 4 Weight in grams      0.9\nread_excel(readxl_example(\"clippy.xlsx\"), col_types = c(\"text\", \"list\"))## # A tibble: 4 x 2\n##   name                 value     \n##   <chr>                <list>    \n## 1 Name                 <chr [1]> \n## 2 Species              <chr [1]> \n## 3 Approx date of death <dttm [1]>\n## 4 Weight in grams      <dbl [1]>"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"importando-arquivos-do-spss-stata-e-sas-com-o-pacote-haven","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.10 Importando arquivos do SPSS, Stata e SAS com o pacote haven","text":"Apesar de serem programas mais populares em mercados específicos, especialmente o mercado americano, algumas pessoas Brasil ainda utilizam programas como o Stata para produzirem suas pesquisas. Por isso, nessa seção, vamos utilizar funções pacote haven, com o objetivo de importarmos dados que estejam presentes em arquivos produzidos por um desses três programas: SPSS (.sav, .zsav, .por), Stata (.dta) e SAS (.sas7bdat, .sas7bcat). Logo abaixo, temos uma lista relacionando funções pacote com os respectivos formatos de arquivo.read_dta() - Stata (.dta).read_dta() - Stata (.dta).read_spss() - SPSS (.sav, .zsav, .por).read_spss() - SPSS (.sav, .zsav, .por).read_sas() - SAS (.sas7bdat, .sas7bcat).read_sas() - SAS (.sas7bdat, .sas7bcat).Assim como funções de importações vistas até o momento, o primeiro argumento das três funções acima, se trata endereço ou nome arquivo (caso ele se encontre em seu diretório de trabalho atual) que você deseja ler.","code":"\nread_spss(\"survey.sav\")\n\nread_sas(\"survey.sas7bdat\")\n\nread_dta(\"pnad_2015.dta\")"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"tratando-variáveis-rotuladas","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.10.1 Tratando variáveis rotuladas","text":"Os programas SPSS, SAS e Stata permitem, e muitas vezes utilizam, um sistema de rótulos sobre seus valores. O uso desses rótulos é especialmente comum em colunas que representam variáveis qualitativas (cor, sexo, faixa etária, etc.). Nessas colunas, os dados são representados por valores numéricos, porém, esses valores são rotulados com um valor textual que corresponde faixa, ou categoria qual aquele valor numérico corresponde.Como exemplo, veja tabela abaixo, ou mais especificamente, colunas sex, marital e child. Perceba que essas três colunas, estão sendo tratadas como colunas tipo double + labelled (dbl + lbl). Ou seja, os dados presentes nessas colunas, são dados numéricos (double). Porém, certos rótulos (labelled) estão associados cada um desses valores. Por exemplo, todo valor igual 1 na coluna child, indica que pessoa entrevistada naquela linha é responsável por alguma criança (YES), enquanto todo valor igual 2, representa uma pessoa que não possui uma criança sobre sua tutela ().Toda coluna que estiver rotulada arquivo, será importada dessa maneira para o R, criando um tipo misto. Porém, após importação dos dados, o ideal é que você sempre transforme essas colunas “mistas” para o tipo factor, pois esse tipo de dado apresenta um suporte muito melhor ao longo da linguagem R. Tal transformação pode ser facilmente gerada através da função as_factor(), que provêm pacote forcats.","code":"\npesquisa <- read_spss(\"survey.sav\")\n\npesquisa## # A tibble: 439 x 9\n##       id      sex   age  marital   child     educ   source   smoke smokenum\n##    <dbl> <dbl+lb> <dbl> <dbl+lb> <dbl+l> <dbl+lb> <dbl+lb> <dbl+l>    <dbl>\n##  1   415 2 [FEMA~    24 4 [MARR~ 1 [YES] 5 [COMP~  7 [LIF~ 2 [NO]        NA\n##  2     9 1 [MALE~    39 3 [LIVI~ 1 [YES] 5 [COMP~  1 [WOR~ 1 [YES]        2\n##  3   425 2 [FEMA~    48 4 [MARR~ 1 [YES] 2 [SOME~  4 [CHI~ 2 [NO]        NA\n##  4   307 1 [MALE~    41 5 [REMA~ 1 [YES] 2 [SOME~  1 [WOR~ 2 [NO]         0\n##  5   440 1 [MALE~    23 1 [SING~ 2 [NO]  5 [COMP~  1 [WOR~ 2 [NO]         0\n##  6   484 2 [FEMA~    31 4 [MARR~ 1 [YES] 5 [COMP~  7 [LIF~ 2 [NO]        NA\n##  7   341 2 [FEMA~    30 6 [SEPA~ 2 [NO]  4 [SOME~  8 [MON~ 2 [NO]         0\n##  8   300 1 [MALE~    23 2 [STEA~ 2 [NO]  5 [COMP~  1 [WOR~ 1 [YES]      100\n##  9    61 2 [FEMA~    18 2 [STEA~ 2 [NO]  2 [SOME~  2 [SPO~ 1 [YES]       40\n## 10    24 1 [MALE~    23 1 [SING~ 2 [NO]  6 [POST~ NA       2 [NO]         0\n## # ... with 429 more rows\nlibrary(forcats)\n\npesquisa <- as_factor(pesquisa)\n\npesquisa## # A tibble: 439 x 9\n##       id sex      age marital     child educ       source    smoke smokenum\n##    <dbl> <fct>  <dbl> <fct>       <fct> <fct>      <fct>     <fct>    <dbl>\n##  1   415 FEMAL~    24 MARRIED FI~ YES   COMPLETED~ LIFE IN ~ NO          NA\n##  2     9 MALES     39 LIVING WIT~ YES   COMPLETED~ WORK      YES          2\n##  3   425 FEMAL~    48 MARRIED FI~ YES   SOME SECO~ CHILDREN  NO          NA\n##  4   307 MALES     41 REMARRIED   YES   SOME SECO~ WORK      NO           0\n##  5   440 MALES     23 SINGLE      NO    COMPLETED~ WORK      NO           0\n##  6   484 FEMAL~    31 MARRIED FI~ YES   COMPLETED~ LIFE IN ~ NO          NA\n##  7   341 FEMAL~    30 SEPARATED   NO    SOME ADDI~ MONEY/FI~ NO           0\n##  8   300 MALES     23 STEADY REL~ NO    COMPLETED~ WORK      YES        100\n##  9    61 FEMAL~    18 STEADY REL~ NO    SOME SECO~ SPOUSE O~ YES         40\n## 10    24 MALES     23 SINGLE      NO    POSTGRADU~ <NA>      NO           0\n## # ... with 429 more rows"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"delimitando-partes-do-arquivo","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.10.2 Delimitando partes do arquivo","text":"Todas três funções pacote haven possuem os argumentos skip e n_max, que novamente, funcionam da mesma forma que é empregado pelas funções pacote readr. Portanto, o argumento skip e n_max definem o número de linhas serem ignoradas início arquivo, e o número máximo de linhas arquivo serem lidas, respectivamente.Além dessas opções, funções também oferecem o argumento col_select, pelo qual você pode definir quais colunas arquivo devem ser importadas. Esse recurso é particularmente interessante quando você possui um arquivo muito grande, como os microdados da PNAD contínua, e você deseja utilizar apenas algumas colunas, ou apenas algumas variáveis da pesquisa. Para selecionar colunas argumento col_select, você pode fornecer um vetor contendo os nomes das colunas desejadas, porém, uma outra alternativa mais útil é utilizar um vetor de índices que representam ordem das colunas desejadas.","code":"\nread_spss(\"survey.sav\", skip = 5)## # A tibble: 434 x 9\n##       id      sex   age  marital   child     educ   source   smoke smokenum\n##    <dbl> <dbl+lb> <dbl> <dbl+lb> <dbl+l> <dbl+lb> <dbl+lb> <dbl+l>    <dbl>\n##  1   484 2 [FEMA~    31 4 [MARR~ 1 [YES] 5 [COMP~  7 [LIF~ 2 [NO]        NA\n##  2   341 2 [FEMA~    30 6 [SEPA~ 2 [NO]  4 [SOME~  8 [MON~ 2 [NO]         0\n##  3   300 1 [MALE~    23 2 [STEA~ 2 [NO]  5 [COMP~  1 [WOR~ 1 [YES]      100\n##  4    61 2 [FEMA~    18 2 [STEA~ 2 [NO]  2 [SOME~  2 [SPO~ 1 [YES]       40\n##  5    24 1 [MALE~    23 1 [SING~ 2 [NO]  6 [POST~ NA       2 [NO]         0\n##  6   138 1 [MALE~    27 1 [SING~ 2 [NO]  3 [COMP~  1 [WOR~ 1 [YES]      100\n##  7   184 2 [FEMA~    34 4 [MARR~ 1 [YES] 5 [COMP~  5 [FAM~ 2 [NO]         0\n##  8   183 1 [MALE~    35 1 [SING~ 2 [NO]  4 [SOME~  7 [LIF~ 2 [NO]         0\n##  9   144 2 [FEMA~    43 4 [MARR~ 1 [YES] 2 [SOME~  2 [SPO~ 2 [NO]        NA\n## 10    57 1 [MALE~    50 4 [MARR~ 1 [YES] 4 [SOME~  1 [WOR~ 2 [NO]         0\n## # ... with 424 more rows\nread_spss(\"survey.sav\", n_max = 10)## # A tibble: 434 x 9\n##       id      sex   age  marital   child     educ   source   smoke smokenum\n##    <dbl> <dbl+lb> <dbl> <dbl+lb> <dbl+l> <dbl+lb> <dbl+lb> <dbl+l>    <dbl>\n##  1   484 2 [FEMA~    31 4 [MARR~ 1 [YES] 5 [COMP~  7 [LIF~ 2 [NO]        NA\n##  2   341 2 [FEMA~    30 6 [SEPA~ 2 [NO]  4 [SOME~  8 [MON~ 2 [NO]         0\n##  3   300 1 [MALE~    23 2 [STEA~ 2 [NO]  5 [COMP~  1 [WOR~ 1 [YES]      100\n##  4    61 2 [FEMA~    18 2 [STEA~ 2 [NO]  2 [SOME~  2 [SPO~ 1 [YES]       40\n##  5    24 1 [MALE~    23 1 [SING~ 2 [NO]  6 [POST~ NA       2 [NO]         0\n##  6   138 1 [MALE~    27 1 [SING~ 2 [NO]  3 [COMP~  1 [WOR~ 1 [YES]      100\n##  7   184 2 [FEMA~    34 4 [MARR~ 1 [YES] 5 [COMP~  5 [FAM~ 2 [NO]         0\n##  8   183 1 [MALE~    35 1 [SING~ 2 [NO]  4 [SOME~  7 [LIF~ 2 [NO]         0\n##  9   144 2 [FEMA~    43 4 [MARR~ 1 [YES] 2 [SOME~  2 [SPO~ 2 [NO]        NA\n## 10    57 1 [MALE~    50 4 [MARR~ 1 [YES] 4 [SOME~  1 [WOR~ 2 [NO]         0\n## # ... with 424 more rows\nread_spss(\"survey_complete.sav\", col_select = 45:52)## # A tibble: 439 x 8\n##    lifsat3 lifsat4 lifsat5  pss1  pss2  pss3  pss4  pss5\n##      <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1       5       4       3     3     3     4     3     4\n##  2       5       7       5     2     2     3     5     4\n##  3       7       6       6     1     2     2     4     4\n##  4       7       7       6     4     3     5     5     4\n##  5       4       3       3     2     2     3     2     3\n##  6       2       2       2     1     1     3     4     3\n##  7       1       1       1     4     4     4     2     2\n##  8       5       4       6     3     3     5     3     2\n##  9       2       1       1     4     4     5     2     1\n## 10       1       1       1     4     5     5     1     1\n## # ... with 429 more rows\nread_dta(\"pnad_2015.dta\", col_select = c(\"uf\", \"v0102\", \"v0103\", \"cor\", \"sexo\"))## # A tibble: 164,204 x 5\n##       uf    v0102 v0103        cor          sexo\n##    <dbl>    <dbl> <dbl>  <dbl+lbl>     <dbl+lbl>\n##  1    31 31001718    14 8 [parda]  1 [masculino]\n##  2    15 15003760     1 8 [parda]  1 [masculino]\n##  3    35 35002425     8 2 [branca] 1 [masculino]\n##  4    43 43000126    15 4 [preta]  0 [feminino] \n##  5    33 33001812    18 8 [parda]  1 [masculino]\n##  6    17 17000440     3 8 [parda]  1 [masculino]\n##  7    15 15002683     3 8 [parda]  1 [masculino]\n##  8    15 15003639     6 2 [branca] 1 [masculino]\n##  9    22 22000194     7 8 [parda]  0 [feminino] \n## 10    26 26005808     4 8 [parda]  1 [masculino]\n## # ... with 164,194 more rows"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"sec:encoding","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.11 Encoding de caracteres","text":"Quando nós estamos trabalhando com dados em um computador, estamos lidando com registros digitalizados de informação, e esses registros quase sempre contêm letras e palavras, ou simplesmente, variáveis textuais (strings ou caracteres). Dados geográficos, por exemplo, usualmente vem acompanhado de certas informações textuais, como partes de um endereço (cidade, região, rua, etc.), que dão suporte à identificação e localização de certa informação. Como um outro exemplo, dados de uma pesquisa amostral comumente possuem variáveis qualitativas que funcionam como rótulos, e que categorizam cada pessoa entrevistada em um certo grupo (homem ou mulher; branco, pardo, preto, amarelo ou indígena; etc.).Em uma escala microscópica, informações presentes em um computador são armazenadas como bytes de informação, que por sua vez são formados por bits de informação, que nada mais são que combinações específicas de 0’s e 1’s. Com esse fato, eu quero destacar que os nossos computadores não são capazes de guardar diretamente letras, palavras e outros valores textuais. Na verdade, o que os nossos computadores são capazes de guardar, são os códigos binários que em conjunto formam os bytes de informação que representam cada uma das letras, ou cada um dos caracteres que formam sua palavra, o seu parágrafo ou o seu capítulo. Como exemplo, o nome “Belo Horizonte,” é representado em meu computador através da seguinte sequência de bytes:Cada um dos bytes acima, representam uma letra, e para que o seu computador seja capaz de relacionar cada um desses bytes às respectivas letras que eles representam, ele utiliza um sistema que nós chamamos de encoding. É possível que o sistema operacional de seu computador utilize um sistema de encoding diferente meu. Com isso, os bytes que representam o nome “Belo Horizonte” em seu computador, podem ser diferentes dos bytes acima.","code":"\ncharToRaw(\"Belo Horizonte\")##  [1] 42 65 6c 6f 20 48 6f 72 69 7a 6f 6e 74 65"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"sec:fontes_encoding_tipografia","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.11.1 Um pouco sobre fontes, encoding e tipografia","text":"Para apresentar visualmente em sua tela, uma palavra ou um texto, o seu computador precisa relacionar caracteres (characters) com os seus respectivos glyphs (Haralambous 2007). Uma fonte que se encontra em seu computador, representa um conjunto de glyphs. Um glyph é uma imagem ou um desenho de cada letra que está definida dentro dessa fonte. Quando você está, por exemplo, escrevendo um novo documento Word, e você aperta tecla “,” um caractere (que corresponde letra ) é enviado para o seu computador. Após o seu computador descobrir o glyph da fonte que você está utilizando, que corresponde ao caractere , o Word vai desenhar palavra em seu documento, através glyph que corresponde esse caractere (Haralambous 2007).Ou seja, quando letras e aparecem em sua tela, elas representam o mesmo caractere, mas utilizam diferentes glyphs para serem desenhadas na tela de seu computador, pois ambos os caracteres utilizam fontes diferentes. Por um outro ângulo, nós podemos escrever uma frase de mesmo significado em diferentes línguas, porém, muito provavelmente vamos utilizar diferentes caracteres em cada língua. Por exemplo, ao escrevermos “Olá,” “Hello,” “Bonjour” ou “你好,” estamos dizendo mesma coisa, porém, estamos utilizando caracteres ou letras bem diferentes para tal ato.Portanto, quando importamos os nossos dados para dentro R, qualquer informação ou variável textual que esteja presente nesses dados, são guardadas em nosso computador como bytes de informação; e o sistema que o nosso computador utiliza, para traduzir esses bytes de informação, em caracteres, que futuramente serão renderizados em nossa tela, através dos glyphs que os representa, é chamado de encoding (Haralambous 2007).Os primeiros sistemas de encoding eram capazes de representar apenas letras de línguas anglo-saxônicas. Porém, medida em que os chineses precisavam escrever um relatório em sua língua, ou partir momento em que o povo nórdico precisava representar em seus computadores os diferentes acentos presentes em seu alfabeto, diversos outros sistemas de encoding foram sendo desenvolvidos ao longo tempo. Por isso, nós temos hoje uma miscelânia muito grande de sistemas em uso mundo. Sendo essa confusão, principal motivação por trás desenvolvimento sistema Unicode, que busca universalizar todos esses sistemas em um só (Haralambous 2007).","code":""},{"path":"importando-e-exportando-dados-com-o-r.html","id":"problemas-que-emergem-do-encoding","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.11.2 Problemas que emergem do encoding","text":"Por que esse assunto é importante dentro da leitura e escrita de arquivos? Porque diferentes arquivos podem utilizar diferentes sistemas de encoding, e se quisermos trabalhar corretamente com os dados textuais presentes nesses arquivos, nós devemos interpretá-los através sistema de encoding correto.Quando você lê um arquivo de acordo com um sistema de encoding diferente sistema que o arquivo de fato utiliza, uma troca de caracteres (ou de letras) ocorre. Com isso, os textos presentes em seu arquivo, ou nosso caso, em nossos dados, podem ficar bem estapafúrdios. Devido essa troca de caracteres, há grandes chances de que uma simples pesquisa por algum caractere específico, fique prejudicada.Como exemplo, eu possuo abaixo um vetor t contendo algumas palavras. Ao utilizar função grep() para pesquisar por qualquer palavra que contenha letra “Á.” Como resultado, função nos retorna o número 1, indicando que o primeiro elemento vetor (palavra “Árabe”) possui essa letra.Agora, se eu pedir ao R, que interprete o vetor t segundo um encoding diferente, perceba que função grep() não é mais capaz de encontrar uma palavra que contenha letra “Á.”Na hipótese de você abrir um arquivo e estar utilizando o encoding incorreto, desde de que você não salve esse arquivo enquanto ele estiver dessa forma, você nãi irá corromper o seu arquivo. Em resumo, se algum caractere de seu texto não estiver da forma como você esperava, não salve o seu arquivo! Antes, você precisa ajustar o encoding de leitura arquivo, até o momento em que leitura dos textos presentes em seu arquivo esteja correta.Apenas para que esse problema fique claro, vamos pegar como exemplo, o arquivo livros.txt, que utiliza o sistema de encoding UTF-8.Agora, veja abaixo o que acontece se utilizarmos o encoding errado na leitura arquivo. Alguns sistemas de encoding são relativamente próximos e, por isso, menos trocas tendem ocorrer em seus textos quando utilizamos o encoding errado. Porém, alguns sistemas são muito divergentes e, portanto, os seus textos podem ficar bem bizarros. Perceba abaixo, que ao utilizarmos o encoding Latin1, apenas letras acentuadas foram trocadas.Portanto, tudo o que precisamos fazer aqui, é voltar para o encoding correto de leitura, ao ajustar o valor utilizado argumento encoding de locale(), como vimos na seção Compreendendo o argumento locale. Em geral, Brasil se utiliza o sistema ISO-8859-1, ou simplesmente Latin1. Já funções pacote readr utilizam por padrão, o sistema UTF-8, por isso, você terá de ajustar o encoding de leitura com certa frequência.","code":"\nt <- c(\"Árabe\", \"Francês\" ,\"Japonês\", \"Chinês\")\n\ngrep(\"Á\", x = t)## [1] 1\nEncoding(t) <- \"UTF-8\"\n\nt## [1] \"<c1>rabe\"   \"Franc<ea>s\" \"Japon<ea>s\" \"Chin<ea>s\"\ngrep(\"Á\", x = t)## integer(0)\nlivros <- read_csv(\"livros.txt\")\n\nlivros# A tibble: 4 x 3\n  Titulo                             Autor                       Preco\n  <chr>                              <chr>                       <dbl>\n1 O Hobbit                           J. R. R. Tolkien             40.7\n2 Matemática para Economistas        Carl P. Simon e Lawrence B~ 140. \n3 Microeconomia: uma Abordagem Mode~ Hal R. Varian               141. \n4 A Luneta Âmbar                     Philip Pullman               42.9\nlivros <- read_csv(\"livros.txt\", locale = locale(encoding = \"Latin1\"))\n\nlivros# A tibble: 4 x 3\n  Titulo                              Autor                      Preco\n  <chr>                               <chr>                      <dbl>\n1 \"O Hobbit\"                          J. R. R. Tolkien            40.7\n2 \"MatemÃ¡tica para Economistas\"      Carl P. Simon e Lawrence ~ 140. \n3 \"Microeconomia: uma Abordagem Mode~ Hal R. Varian              141. \n4 \"A Luneta Ã\\u0082mbar\"              Philip Pullman              42.9"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"a-função-guess_encoding-como-um-possível-guia","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"3.11.3 A função guess_encoding() como um possível guia","text":"Nem sempre temos sorte de sabermos o encoding utilizado por um certo arquivo. Por isso, o pacote readr oferece função guess_encoding(), que pode descobrir o encoding utilizado por certo arquivo. Como foi destacado por Wickham Grolemund (2017, p 133), essa função funciona melhor quando você possui uma quantidade grande de texto qual ela pode se basear. Além disso, ela não é certeira 100% tempo, porém, ela lhe oferece um início razoável caso você esteja perdido.Para utilizar essa função, você precisa fornecer o seu texto como bytes. Ou seja, antes de utilizar essa função, você muito provavelmente terá de converter o seu texto para bytes12. Para isso, você pode utilizar função charToRaw(), entretanto, essa função busca transformar um vetor de comprimento 1, logo, para utilizarmos essa função, temos de inserir todos os nossos valores textuais em um único string.Como exemplo, vamos utilizar coluna Municípios arquivo Cod_IBGE.txt, que possui os nomes dos municípios estado de Minas Gerais. Perceba abaixo, que o arquivo utiliza um encoding diferente padrão utilizado pela função read_csv2(), pois quarta coluna que deveria se chamar Municípios, foi interpretada como Munic<U+653C><U+3E64>pios.Para unir todos os nomes de municípios, presentes na coluna Munic<U+653C><U+3E64>pios, nós podemos utilizar função paste(), de acordo com especificações abaixo. Em seguida, podemos transformar o resultado de paste() em um vetor de bytes, e fornecê-lo para função guess_encoding().Repare que função nos deu 57% de chance arquivo Cod_IBGE.txt estar utilizando o encoding ISO-8859-1, que é de fato o encoding utilizado pelo arquivo.","code":"\ndf <- read_csv2(\"Cod_IBGE.txt\")-- Column specification -----------------------------------\ncols(\n  IBGE = col_double(),\n  IBGE2 = col_double(),\n  SEF = col_double(),\n  `Munic<U+653C><U+3E64>pios` = col_character()\n)\nt <- paste(df[[4]], collapse = \" \")\n\nraw <- charToRaw(t)\n\nguess_encoding(raw)## # A tibble: 2 x 2\n##   encoding   confidence\n##   <chr>           <dbl>\n## 1 ISO-8859-1       0.57\n## 2 ISO-8859-2       0.27"},{"path":"importando-e-exportando-dados-com-o-r.html","id":"exercícios-2","chapter":"Capítulo 3 Importando e exportando dados com o R","heading":"Exercícios","text":"Lembre-se que, um arquivo de texto, nada mais é que um arquivo simples contendo um conjunto de textos. Esses textos são organizados em linhas (onde cada linha representa uma observação diferente), e em cada linha desse arquivo, esses textos são separados em diferentes colunas, através de algum caractere especial, como vírgulas (,), ou pontos e vírgulas (;).Questão 3.1. Como descrevemos ao longo desse capítulo, arquivos de texto são talvez o principal formato de arquivo utilizado hoje para o compartilhamento de dados. Por isso, os próximos exercícios buscam reforçar os conhecimentos respeito desses arquivos.3.1.) Considerando o arquivo de texto contido objeto t abaixo, qual é o caractere especial que define colunas desse arquivo? Dado que você tenha identificado esse caractere especial, quais comandos você utilizaria para ler esse arquivo?3.1.B) Perceba abaixo, que os objetos pac1 e pac2 são praticamente iguais. Perceba também, que estamos utilizando os mesmos comandos de importação para ambos os objetos. Porém, os resultados gerados pela função são diferentes em cada objeto. Tente identificar o que está causando essa diferença. Dado que você tenha identificado fonte de tal diferença, como você ajustaria os comandos aplicados sobre cada objeto, de forma que os seus resultados sejam exatamente iguais?3.1.C) Considerando que você tenha chamado com sucesso pelo pacote readr, com o comando library(), você será capaz de executar os comandos mostrados abaixo sem problemas. Tais comandos buscam importar para o R, um arquivo chamado challenge.csv (função readr_example() nos traz localização desse arquivo challenge.csv em seu computador). Porém, perceba pelo resultado abaixo, que erros de importação ocorreram em 1000 linhas arquivo.Ao navegar por todo o conteúdo desse arquivo challenge.csv, você pode perceber que os dados contidos nesse arquivo foram incorretamente interpretados pela função read_csv(). Com isso, o seu trabalho será descobrir o que deu errado nesse processo, e ajustar os comandos de importação desse arquivo para que esse erro não ocorra.Como uma dica, abra o arquivo readr_example(\"challenge.csv\") e veja o seu conteúdo com cuidado. Com os comandos abaixo, você pode navegar por esse arquivo em uma janela de seu próprio RStudio. Portanto, tente descobrir o que está acontecendo de errado, e crie um comando que possa corrigir esse problema de importação.3.1.D) Considerando o objeto t abaixo, como você faria para importar corretamente esse arquivo? Vale ressaltar, que temos uma coluna contendo datas dentro objeto t, e, até o momento, nós ainda não discutimos como o R interpreta ou lida com esse tipo de varíavel. Tal discussão é feita capítulo 12 (Introdução à variáveis de tempo com lubridate). Portanto, não se preocupe caso você não consiga importar especificamente essa coluna da maneira correta. De qualquer maneira, ao final desse livro, nós fornecemos todo o código necessário para interpretar corretamente essa coluna.Questão 3.2. Copie e cole o endereço URL abaixo em seu navegador de preferência. Com esse link, uma planilha em Excel será baixada. Nessa planilha, temos alguns dados referentes aos municípios de Minas Gerais, ou, mais especificamente, como esses municípios se encaixam critério de Produção de Alimentos âmbito da lei estadual 18.030/2009. Tente criar um comando que possa importar corretamente os dados dessa planilha para o R.(https://github.com/pedropark99/Curso-R/blob/master/Dados/emater_icms_solidario.xlsx?raw=true)","code":"\nt <- \"\nID~Valor/Grupo~Unidade\n1~2,5488/Marketing~Kg\n2~4,0101/Análise~Kg\n3~1097/Vendas~g\n4~12,76/Logísitica~Kg\"\npac1 <- \"Setor;Produção;Receita;Gasto em P&D\nProdutos alimentícios;10828,37;199907,55;3358,36\nBebidas;759,53;28093,21;\nProdutos do fumo;69,99;8863,5;121,35\nProdutos têxteis;4153,97;25804,16;746,83\nProdutos de madeira;5088,78;15320,69;279,54\nCelulose e outras pastas;26,95;4245,19;216,7\nRefino de petróleo;75,48;114316,31;1550,73\nProdutos químicos;3179,52;133582,8;2914,09\nProdutos farmacêuticos;621,82;24972,07;1038,73\"\n\n\npac2 <- \"Setor;Produção;Receita;Gasto em P&D\nProdutos alimentícios;10.828,37;199907,55;3358,36\nBebidas;759,53;28093,21;x\nProdutos do fumo;69,99;8863,5;121,35\nProdutos têxteis;4.153,97;25804,16;746,83\nProdutos de madeira;5.088,78;15320,69;279,54\nCelulose e outras pastas;26,95;4245,19;216,7\nRefino de petróleo;75,48;114316,31;1550,73\nProdutos químicos;3.179,52;133582,8;2914,09\nProdutos farmacêuticos;621,82;24972,07;1038,73\"\n\nreadr::read_delim(pac1, delim = \";\")## # A tibble: 9 x 4\n##   Setor                    Produção  Receita `Gasto em P&D`\n##   <chr>                       <dbl>    <dbl>          <dbl>\n## 1 Produtos alimentícios     1082837 19990755         335836\n## 2 Bebidas                     75953  2809321             NA\n## 3 Produtos do fumo             6999    88635          12135\n## 4 Produtos têxteis           415397  2580416          74683\n## 5 Produtos de madeira        508878  1532069          27954\n## 6 Celulose e outras pastas     2695   424519           2167\n## 7 Refino de petróleo           7548 11431631         155073\n## 8 Produtos químicos          317952  1335828         291409\n## 9 Produtos farmacêuticos      62182  2497207         103873\nreadr::read_delim(pac2, delim = \";\")## # A tibble: 9 x 4\n##   Setor                    Produção  Receita `Gasto em P&D`\n##   <chr>                       <dbl>    <dbl> <chr>         \n## 1 Produtos alimentícios       10.8  19990755 3358,36       \n## 2 Bebidas                  75953     2809321 x             \n## 3 Produtos do fumo          6999       88635 121,35        \n## 4 Produtos têxteis             4.15  2580416 746,83        \n## 5 Produtos de madeira          5.09  1532069 279,54        \n## 6 Celulose e outras pastas  2695      424519 216,7         \n## 7 Refino de petróleo        7548    11431631 1550,73       \n## 8 Produtos químicos            3.18  1335828 2914,09       \n## 9 Produtos farmacêuticos   62182     2497207 1038,73\nimport <- read_csv(readr_example(\"challenge.csv\"))\nfile.edit(readr_example(\"challenge.csv\"))\nt <- \"Data_execução*Unidades*Valor_compra\n20/01/2020*21*R$ 3049,50\n23/01/2020*502*R$ 1289,03\n25/01/2020*90*R$ 678,00\n02/02/2020*123*R$ 5401\n05/02/2020*45*R$ 1450,10\n07/02/2020*67*R$ 2320,97\n09/02/2020*187*R$ 6231,76\""},{"path":"transformando-dados-com-dplyr.html","id":"transformando-dados-com-dplyr","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"Capítulo 4 Transformando dados com dplyr","text":"","code":""},{"path":"transformando-dados-com-dplyr.html","id":"introdução-e-pré-requisitos","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.1 Introdução e pré-requisitos","text":"São raras ocasiões em que os seus dados já se encontram formato exato que você precisa para realizar suas análises, ou para gerar os gráficos que você deseja (Wickham Grolemund 2017). Por essa razão, você irá passar uma parte considerável de seu tempo, aplicando transformações sobre os seus dados, e calculando novas variáveis, e como os seus dados estarão, na maioria das situações, alocados em um data.frame, você precisa de ferramentas que sejam eficientes com tal estrutura (Peng 2015). Esse é o objetivo pacote dplyr com o qual vamos trabalhar neste capítulo.Para que você tenha acesso funções e possa acompanhar os exemplos desse capítulo, você precisa chamar pelo pacote dplyr. Porém, vamos utilizar algumas bases de dados que estão disponíveis através de outros pacotes presentes tidyverse. Por isso, é preferível que você chame pelo tidyverse por meio comando library().","code":"\nlibrary(tidyverse)\nlibrary(dplyr)"},{"path":"transformando-dados-com-dplyr.html","id":"panorama-e-padrões-do-pacote-dplyr","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.2 Panorama e padrões do pacote dplyr","text":"Segundo página oficial, o pacote dplyr busca oferecer um conjunto de “verbos” (.e. funções) voltados para operações mais comumente aplicadas em tabelas. Ou seja, funções desse pacote em geral aceitam um data.frame como input, e retornam um novo data.frame como output.Se você possui alguma experiência com relational database management systems (RDBMS), você vai acabar percebendo ao longo deste capítulo, que o pacote dplyr é profundamente inspirado nos verbos da linguagem SQL. Por esse motivo, muitos usuários tendem chamar funções pacote dplyr de “verbos.” Logo abaixo, temos uma lista das principais funções oferecidas pelo pacote, além de uma descrição rápida da ação realizada por cada um desses verbos.select(): busca selecionar ou extrair colunas de seu data.frame.select(): busca selecionar ou extrair colunas de seu data.frame.filter(): busca filtrar linhas de seu data.frame.filter(): busca filtrar linhas de seu data.frame.arrange(): busca ordenar (ou organizar) linhas de seu data.frame.arrange(): busca ordenar (ou organizar) linhas de seu data.frame.mutate(): busca adicionar ou calcular novas colunas em seu data.frame.mutate(): busca adicionar ou calcular novas colunas em seu data.frame.summarise(): busca sintetizar múltiplos valores de seu data.frame em um único valor.summarise(): busca sintetizar múltiplos valores de seu data.frame em um único valor.group_by(): permite que operações sejam executadas dentro de cada “grupo” de seu data.frame; em outras palavras, função busca definir os grupos existentes em seu data.frame, e deixar essa definição explícita e disponível para os outros verbos, de modo que eles possam respeitar esses grupos em suas operações.group_by(): permite que operações sejam executadas dentro de cada “grupo” de seu data.frame; em outras palavras, função busca definir os grupos existentes em seu data.frame, e deixar essa definição explícita e disponível para os outros verbos, de modo que eles possam respeitar esses grupos em suas operações.Dentre os verbos acima, o group_by() é definitivamente o mais difícil de se explicar de uma maneira clara e, ao mesmo tempo, resumida. De qualquer maneira, vamos discutir ele por extenso na seção Agrupando dados e gerando estatísticas sumárias com group_by() e summarise(). Além disso, também vamos abordar nesse capítulo, o uso operador pipe (%>%) que provêm pacote magrittr, e que hoje, faz parte da identidade pacote dplyr, e tidyverse como um todo.Peng (2015) destacou algumas características compartilhadas pelas funções pacote dplyr:Possuem como primeiro argumento (.data), o data.frame qual você deseja aplicar função que você está utilizando.Possuem como primeiro argumento (.data), o data.frame qual você deseja aplicar função que você está utilizando.Os argumentos subsequentes buscam descrever como e onde aplicar função sobre o data.frame definido primeiro argumento.Os argumentos subsequentes buscam descrever como e onde aplicar função sobre o data.frame definido primeiro argumento.Geram um novo data.frame como resultado.Geram um novo data.frame como resultado.Como você definiu o data.frame ser utilizando primeiro argumento da função, você pode se referir às colunas desse data.frame apenas pelo seus nomes. Ou seja, dentro das funções pacote dplyr, você não precisa mais operador $ para acessar colunas data.frame utilizado.Como você definiu o data.frame ser utilizando primeiro argumento da função, você pode se referir às colunas desse data.frame apenas pelo seus nomes. Ou seja, dentro das funções pacote dplyr, você não precisa mais operador $ para acessar colunas data.frame utilizado.momento, essas características podem parecer difusas. Porém, você irá rapidamente reconhecê-las ao longo deste capítulo.","code":""},{"path":"transformando-dados-com-dplyr.html","id":"operador-pipe","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.3 Operador pipe (%>%)","text":"Hoje, o operador pipe (%>%) faz parte da identidade dos pacotes que compõe o tidyverse e, por isso, você irá encontrar esse operador em praticamente qualquer script que utilize algum desses pacotes. Grande parte dessa identidade foi construída nos últimos anos, em especial, com obra de Wickham Grolemund (2017) que se tornou um importante livro-texto da linguagem R como um todo.O operador pipe provêm pacote magrittr, e o seu único objetivo é tornar o seu código mais claro e compreensível. Ou seja, o pipe em nada altera o resultado ou configurações de seus comandos, ele apenas os organiza em uma estrutura mais limpa e arranjada. Apesar de sua origem ser o pacote magrittr, o pipe é carregado automaticamente quando chamamos pelo tidyverse, através comando library(). Com isso, temos duas opções para termos acesso esse operador: chamar pelo pacote magrittr, ou chamar pelo tidyverse.ATALHO: RStudio, você pode criar um pipe através atalho Ctrl + Shift + M.Mesmo que esse efeito seja simples, ele é extremamente importante. estrutura em “cadeia” construída pelo pipe gera uma grande economia em seu tempo de trabalho, pois você não precisa mais se preocupar em salvar o resultado de vários passos intermediários em algum objeto. Dessa maneira, você pode focar mais tempo nas próprias transformações em si, e resultado que você deseja atingir. Além disso, essa estrutura também vai salvar muito de seu tempo, nos momentos em que você retornar ao seu trabalho dia seguinte. Pois se o seu código nessa estrutura está mais claro e fácil de se ler, você pode recuperar com maior rapidez compreensão ponto em que você parou dia anterior.Isso é muito importante, pois você nunca está trabalhando sozinho! Você sempre está, mínimo, trabalhando com o seu futuro eu (Wickham Grolemund 2017). Por isso, qualquer quantidade de tempo que você emprega para tornar os seus comandos mais legíveis e eficientes, você estará automaticamente economizando o seu tempo dia seguinte, quando você terá de retornar esses comandos, e prosseguir com o seu trabalho. Para mais, os seus possíveis colegas de trabalho, ou outras pessoas que estiverem envolvidas desenvolvimento de seu script, vão compreender de maneira mais eficiente transformações que você está aplicando e, portanto, vão ser capazes de contribuir com o seu trabalho de maneira mais rápida.","code":"\n## Com um desses comandos você\n## pode utilizar o operador %>% \nlibrary(tidyverse)\n## Ou\nlibrary(magrittr)"},{"path":"transformando-dados-com-dplyr.html","id":"o-que-o-pipe-faz","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.3.1 O que o pipe faz ?","text":"Em qualquer análise, temos em geral diversas etapas ou transformações serem executadas, e em sua maioria, essas etapas assumem uma ordem específica. Quando realizamos essas etapas R, nós comumente salvamos os resultados de cada passo em novos objetos, e utilizamos esses objetos “intermediários” em cada operação adicional para chegarmos ao resultado final que desejamos. Perceba exemplo abaixo, o trabalho que temos ao salvarmos os resultados de cada passo em um objeto, e utilizarmos esse objeto na próxima transformação.Aqui se encontra uma vantagem importante operador pipe, pois ele elimina essa necessidade de objetos “intermediários,” ao “carregar” os resultados ao longo de diversas funções. Em outras palavras, esse operador funciona como uma ponte entre cada etapa, ou entre cada função aplicada. Dito de uma maneira mais específica, quando conectamos duas funções por um pipe, o operador carrega o resultado da primeira função, e o insere como o primeiro argumento da segunda função. Com isso, eu posso reescrever os comandos anteriores da seguinte forma:Além das vantagens destacadas até o momento, ao evitar o uso de objetos “intermediários,” o pipe acaba evitando que você use desnecessariamente memória de seu computador. Pois cada objeto criado R, precisa ocupar um espaço de sua memória RAM para permanecer “vivo” e disponível em sua sessão. Como evitamos criação desses objetos “intermediários,” estamos utilizando menos memória para realizar exatamente mesmas etapas e gerar os mesmos resultados.Apenas para que o uso pipe fique claro, se eu possuo funções x(), y() e z(), e desejo calcular expressão z(y(x(10), times = 1), n = 20, replace = TRUE), nós podemos reescrever essa expressão modo exposto abaixo. Dessa maneira, o pipe vai pegar o resultado de x(10), e inserí-lo como o primeiro argumento da função y(); depois de calcular o resultado da função y(), o próximo pipe vai passá-lo para função z(); e como função z() é última função da cadeia, o console vai lhe mostrar o resultado final desse processo.","code":"\ndados <- mpg\nagrupamento <- group_by(.data = dados, class)\nbase_ordenada <- arrange(.data = agrupamento, hwy)\nbase_completa <- mutate(\n  .data = base_ordenada,\n  media = mean(hwy),\n  desvio = hwy - media\n)\nmpg %>% \n  group_by(class) %>% \n  arrange(hwy) %>% \n  mutate(\n    media = mean(hwy),\n    desvio = hwy - media\n  )\n## Expressão original\nz(y(x(10), times = 1), n = 20, replace = TRUE)\n\n## Com o uso do pipe %>% \nx(10) %>% \n  y(times = 1) %>% \n  z(n = 20, replace = TRUE)"},{"path":"transformando-dados-com-dplyr.html","id":"o-que-o-pipe-não-é-capaz-de-fazer","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.3.2 O que o pipe não é capaz de fazer ?","text":"O pipe não é capaz de trabalhar perfeitamente com qualquer função, e principal característica que você precisa observar para identificar se essa afirmação é verdadeira ou não para uma dada função, é o seu primeiro argumento.Como o pipe insere o resultado da expressão anterior primeiro argumento da próxima função, esse primeiro argumento precisa corresponder ao argumento qual você deseja utilizar esse resultado. Na maior parte tempo, desejamos utilizar esse resultado como os dados sobre os quais vamos aplicar nossa próxima função. Este é um dos principais motivos pelos quais praticamente todas funções de todos os pacotes que compõe o tidyverse, trabalham perfeitamente bem com o operador pipe. Pois todas essas funções possuem como primeiro argumento, algo parecido com .data, data ou x, que busca definir o objeto sobre o qual vamos aplicar função.Caso o argumento ser utilizado, esteja em uma posição diferente (se trata segundo, terceiro ou quarto argumento da função), você pode utilizar um ponto final (.) para alterar posição em que o resultado das etapas anteriores será introduzido. Basta posicionar o ponto final argumento em que você deseja inserir esse resultado.Um clássico exemplo que se encaixa nessa hipótese, é função lm(), que é principal função empregada cálculo de uma regressão linear R. Nessa função, o primeiro argumento corresponde fórmula ser utilizada na regressão; já os dados serem usados na regressão, são delimitados segundo argumento da função (data). Veja exemplo abaixo, que eu utilizo um ponto final sobre o argumento data, para dizer ao pipe que ele deve inserir o resultado anterior especificamente nesse argumento.","code":"\nmpg %>% \n  lm(hwy ~ cyl, data = .) %>% \n  summary()## \n## Call:\n## lm(formula = hwy ~ cyl, data = .)\n## \n## Residuals:\n##     Min      1Q  Median      3Q     Max \n## -8.7579 -2.4968  0.2421  2.4379 15.2421 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  40.0190     0.9591   41.72   <2e-16 ***\n## cyl          -2.8153     0.1571  -17.92   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 3.865 on 232 degrees of freedom\n## Multiple R-squared:  0.5805, Adjusted R-squared:  0.5787 \n## F-statistic: 321.1 on 1 and 232 DF,  p-value: < 2.2e-16"},{"path":"transformando-dados-com-dplyr.html","id":"duas-dicas-rápidas-sobre-o-pipe","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.3.3 Duas dicas rápidas sobre o pipe","text":"O pipe cria uma espécie de efeito em cadeia, e muitas vezes nos preocupamos demais com etapas dessa cadeia, e nos esquecemos de definir o local em que o resultado dessa cadeia deve ocupar. Portanto, lembre-se que para salvar o resultado final da cadeia formada pelos seus pipe’s, você necessita salvar esse resultado em algum objeto. Para isso, você deve posicionar o nome objeto, e o símbolo de assignment (<-), logo início dessa cadeia, como exemplo abaixo.Uma outra dica, seria não formar cadeias muito longas. Como um guia, uma cadeia de pipe’s não deveria passar de 7 etapas. Caso você precise aplicar mais que 7 etapas, é melhor que você salve o resultado da 7° etapa em um objeto, e inicie uma nova cadeia partir deste objeto.","code":"\nresultado <- mpg %>% \n  group_by(class) %>% \n  arrange(hwy) %>% \n  mutate(\n    media = mean(hwy),\n    desvio = hwy - media\n  )"},{"path":"transformando-dados-com-dplyr.html","id":"selecionando-colunas-com-select","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.4 Selecionando colunas com select()","text":"Como definimos anteriormente, função select() busca selecionar colunas de seu data.frame. Você já possui uma boa ideia de como realizar essa ação através da função de subsetting ([). Porém, nós podemos usufruir da flexibilidade oferecida pela função select(), que lhe permite realizar essa mesma operação de diversas maneiras intuitivas.geral, temos ao menos 5 métodos diferentes que podemos utilizar na função select():simplesmente listar o nome das colunas que desejamos;simplesmente listar o nome das colunas que desejamos;fornecer um vetor externo, contendo os nomes das colunas serem extraídas;fornecer um vetor externo, contendo os nomes das colunas serem extraídas;selecionar um conjunto de colunas com base em seu tipo (integer, double, character, logical);selecionar um conjunto de colunas com base em seu tipo (integer, double, character, logical);selecionar um conjunto de colunas com base em padrões que aparecem nos nomes dessas colunas (nome começa por y, ou termina em z, ou contém x);selecionar um conjunto de colunas com base em padrões que aparecem nos nomes dessas colunas (nome começa por y, ou termina em z, ou contém x);selecionar um conjunto de colunas com base em seus índices numéricos (1° colunas, 2° coluna, 3° coluna, etc.).selecionar um conjunto de colunas com base em seus índices numéricos (1° colunas, 2° coluna, 3° coluna, etc.).Como exemplo inicial, vamos utilizar tabela billboard, que apresenta posição de diversas músicas na lista Billboard Top 100, ao longo ano de 2000. Se você chamou com sucesso pelo tidyverse, você tem acesso essa tabela. Perceba que posição de cada música descrita na tabela, é apresentada de forma semanal, onde cada semana possui sua coluna própria. Por essa razão, temos uma quantidade exorbitante de colunas na tabela.O método 5 citado acima é um dos métodos mais práticos e eficientes de se utilizar função select(). Por exemplo, se desejássemos extrair todas colunas entre 1° e 4° colunas da tabela, poderíamos fornecer um vetor à função, contendo uma sequência de 1 4, que representa os índices das colunas que desejamos, como exemplo abaixo.Agora, e se você precisasse selecionar todas colunas que representam semanas? Nesse caso, o método 5 ainda seria uma boa alternativa, pois você precisaria apenas fornecer uma sequência que represente posição dessas colunas na tabela (de 4 79 para ser mais preciso).Porém, todas essas colunas possuem um padrão em seus nomes. Elas se iniciam pelos caracteres \"wk\", acrescidos de um número que representa o índice da semana que essa coluna corresponde. Portanto, em todas ocasiões que houver algum padrão presente nos nomes das colunas que você deseja selecionar, o método 4 que citamos configura-se como uma ótima solução. Nesse método, devemos utilizar funções de suporte starts_with(), ends_with(), matches().Como os seus próprios nomes dão entender, funções starts_with() e ends_with() vão selecionar qualquer coluna de sua tabela que comece (start) ou termine (end) por uma determinada cadeia de caracteres, respectivamente. Como exemplo, eu posso selecionar todas colunas que apresentam posições semanais na tabela billboard, ao encontrar todas colunas que começam pelas letras \"wk\", com função starts_with().Já função matches() se trata de um caso muito mais flexível das funções starts_with() e ends_with(), pois ela lhe permite selecionar qualquer coluna cujo o nome se encaixa em uma dada expressão regular. Expressões regulares são uma poderosa ferramenta para processamento de texto, qual vamos discutir capítulo 11 deste livro, especialmente na seção Expressões regulares (ou regex) com str_detect(). Outras duas referências úteis sobre o assunto, se encontram capítulo 14 de Wickham Grolemund (2017), que provê uma visão mais direta, além da obra de Friedl (2006) que oferece uma visão técnica e aprofundada sobre o assunto. Veja alguns exemplos abaixo:Essas são maneiras eficientes de selecionarmos um grande conjunto de colunas, porém, muitas vezes nossas necessidades são pequenas e, portanto, não exigem mecanismos tão poderosos. Nessas situações, o método 1 se torna útil pois ele conciste em simplesmente listarmos o nome das colunas desejadas. Como exemplo, eu posso selecionar colunas artist, track e wk5 da tabela billboard pelo comando abaixo.Vale destacar que ordem dos índices utilizados importa para função select(). Logo, se exemplo acima, eu listasse colunas na ordem track, wk5 e artist, o novo data.frame resultante de select(), iria conter essas colunas precisamente nessa ordem. O mesmo efeito seria produzido, caso eu utilizasse novamente o método 5, e fornecesse o vetor c(3, 2, 4) à função. Dessa forma, select() iria retornar um novo data.frame contendo 3 colunas, que correspondem 3°, 2° e 4° colunas da tabela billboard, exatamente nessa ordem.Por outro lado, não há uma maneira de variarmos ordem dos resultados gerados nos métodos 3 e 4, especificamente. Por isso, caso você utililize um desses dois métodos, colunas selecionadas serão apresentadas novo data.frame, precisamente na ordem em que eles aparecem data.frame inicial.Visto esses pontos, ao invés de selecionar colunas, você também pode utilizar o método 1 para rapidamente eliminar algumas colunas de seu data.frame, ao posicionar um sinal negativo (-) antes nome da coluna que você deseja retirar. Por exemplo, eu posso selecionar todas colunas da tabela mpg, exceto colunas hwy e manufacturer por meio seguinte comando:Em contrapartida, o método 3 busca selecionar um conjunto de colunas com base em seu tipo de dado, através da função () e das funções de teste lógico .*() (.double, .character, .integer, …). Como exemplo, nós podemos selecionar todas colunas da tabela billboard que contém dados textuais, através comando abaixo. Portanto, para utilizar esse método você precisa apenas se referir função .*() que corresponde ao tipo de dado qual você está interessado, dentro da função ().Com isso, você possui não apenas uma boa variedade de métodos disponíveis na função select(), mas você também é capaz de misturá-los livremente dentro da função. Ou seja, se de meu desejo, eu posso utilizar os métodos 2, 4 e 5 ao mesmo tempo, como exemplo abaixo. Tratando especificamente método 2, eu preciso fornecer dentro da função all_of(), um vetor contendo os nomes das colunas desejadas. Como exemplo, eu posso novamente extrair colunas artist, track e wk5 através desse método. O método 2, em particular, se torna um método interessante quando ainda não conhecemos o conjunto de colunas serem extraídas. Talvez você precise aplicar previamente diversos testes sobre o seu data.frame, para identificar essas colunas. Logo, um vetor contendo os nomes das colunas desejadas seria o resultado ideal para tais testes.","code":"\nbillboard## # A tibble: 317 x 79\n##    artist   track    date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7\n##    <chr>    <chr>    <date>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1 2 Pac    Baby Do~ 2000-02-26      87    82    72    77    87    94    99\n##  2 2Ge+her  The Har~ 2000-09-02      91    87    92    NA    NA    NA    NA\n##  3 3 Doors~ Krypton~ 2000-04-08      81    70    68    67    66    57    54\n##  4 3 Doors~ Loser    2000-10-21      76    76    72    69    67    65    55\n##  5 504 Boyz Wobble ~ 2000-04-15      57    34    25    17    17    31    36\n##  6 98^0     Give Me~ 2000-08-19      51    39    34    26    26    19     2\n##  7 A*Teens  Dancing~ 2000-07-08      97    97    96    95   100    NA    NA\n##  8 Aaliyah  I Don't~ 2000-01-29      84    62    51    41    38    35    35\n##  9 Aaliyah  Try Aga~ 2000-03-18      59    53    38    28    21    18    16\n## 10 Adams, ~ Open My~ 2000-08-26      76    76    74    69    68    67    61\n## # ... with 307 more rows, and 69 more variables: wk8 <dbl>, wk9 <dbl>,\n## #   wk10 <dbl>, wk11 <dbl>, wk12 <dbl>, wk13 <dbl>, wk14 <dbl>,\n## #   wk15 <dbl>, wk16 <dbl>, wk17 <dbl>, wk18 <dbl>, wk19 <dbl>,\n## #   wk20 <dbl>, wk21 <dbl>, wk22 <dbl>, wk23 <dbl>, wk24 <dbl>,\n## #   wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>, wk29 <dbl>,\n## #   wk30 <dbl>, wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>,\n## #   wk35 <dbl>, wk36 <dbl>, wk37 <dbl>, wk38 <dbl>, wk39 <dbl>,\n## #   wk40 <dbl>, wk41 <dbl>, wk42 <dbl>, wk43 <dbl>, wk44 <dbl>,\n## #   wk45 <dbl>, wk46 <dbl>, wk47 <dbl>, wk48 <dbl>, wk49 <dbl>,\n## #   wk50 <dbl>, wk51 <dbl>, wk52 <dbl>, wk53 <dbl>, wk54 <dbl>,\n## #   wk55 <dbl>, wk56 <dbl>, wk57 <dbl>, wk58 <dbl>, wk59 <dbl>,\n## #   wk60 <dbl>, wk61 <dbl>, wk62 <dbl>, wk63 <dbl>, wk64 <dbl>,\n## #   wk65 <dbl>, wk66 <lgl>, wk67 <lgl>, wk68 <lgl>, wk69 <lgl>,\n## #   wk70 <lgl>, wk71 <lgl>, wk72 <lgl>, wk73 <lgl>, wk74 <lgl>,\n## #   wk75 <lgl>, wk76 <lgl>\nbillboard_sel <- select(billboard, 1:4)\n\nbillboard_sel## # A tibble: 317 x 4\n##    artist         track                   date.entered   wk1\n##    <chr>          <chr>                   <date>       <dbl>\n##  1 2 Pac          Baby Don't Cry (Keep... 2000-02-26      87\n##  2 2Ge+her        The Hardest Part Of ... 2000-09-02      91\n##  3 3 Doors Down   Kryptonite              2000-04-08      81\n##  4 3 Doors Down   Loser                   2000-10-21      76\n##  5 504 Boyz       Wobble Wobble           2000-04-15      57\n##  6 98^0           Give Me Just One Nig... 2000-08-19      51\n##  7 A*Teens        Dancing Queen           2000-07-08      97\n##  8 Aaliyah        I Don't Wanna           2000-01-29      84\n##  9 Aaliyah        Try Again               2000-03-18      59\n## 10 Adams, Yolanda Open My Heart           2000-08-26      76\n## # ... with 307 more rows\nbillboard_sel <- select(billboard, starts_with(\"wk\"))\n\nbillboard_sel## # A tibble: 317 x 76\n##      wk1   wk2   wk3   wk4   wk5   wk6   wk7   wk8   wk9  wk10  wk11  wk12\n##    <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1    87    82    72    77    87    94    99    NA    NA    NA    NA    NA\n##  2    91    87    92    NA    NA    NA    NA    NA    NA    NA    NA    NA\n##  3    81    70    68    67    66    57    54    53    51    51    51    51\n##  4    76    76    72    69    67    65    55    59    62    61    61    59\n##  5    57    34    25    17    17    31    36    49    53    57    64    70\n##  6    51    39    34    26    26    19     2     2     3     6     7    22\n##  7    97    97    96    95   100    NA    NA    NA    NA    NA    NA    NA\n##  8    84    62    51    41    38    35    35    38    38    36    37    37\n##  9    59    53    38    28    21    18    16    14    12    10     9     8\n## 10    76    76    74    69    68    67    61    58    57    59    66    68\n## # ... with 307 more rows, and 64 more variables: wk13 <dbl>, wk14 <dbl>,\n## #   wk15 <dbl>, wk16 <dbl>, wk17 <dbl>, wk18 <dbl>, wk19 <dbl>,\n## #   wk20 <dbl>, wk21 <dbl>, wk22 <dbl>, wk23 <dbl>, wk24 <dbl>,\n## #   wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>, wk29 <dbl>,\n## #   wk30 <dbl>, wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>,\n## #   wk35 <dbl>, wk36 <dbl>, wk37 <dbl>, wk38 <dbl>, wk39 <dbl>,\n## #   wk40 <dbl>, wk41 <dbl>, wk42 <dbl>, wk43 <dbl>, wk44 <dbl>,\n## #   wk45 <dbl>, wk46 <dbl>, wk47 <dbl>, wk48 <dbl>, wk49 <dbl>,\n## #   wk50 <dbl>, wk51 <dbl>, wk52 <dbl>, wk53 <dbl>, wk54 <dbl>,\n## #   wk55 <dbl>, wk56 <dbl>, wk57 <dbl>, wk58 <dbl>, wk59 <dbl>,\n## #   wk60 <dbl>, wk61 <dbl>, wk62 <dbl>, wk63 <dbl>, wk64 <dbl>,\n## #   wk65 <dbl>, wk66 <lgl>, wk67 <lgl>, wk68 <lgl>, wk69 <lgl>,\n## #   wk70 <lgl>, wk71 <lgl>, wk72 <lgl>, wk73 <lgl>, wk74 <lgl>,\n## #   wk75 <lgl>, wk76 <lgl>\n## Seleciona todas as semanas que são\n## maiores do que 9 e menores do que 100.\n## Ou seja, toda semana com dois dígitos\nbillboard %>% \n  select(matches(\"wk[0-9]{2}\")) %>% print(n = 5)## # A tibble: 317 x 67\n##    wk10  wk11  wk12  wk13  wk14  wk15  wk16  wk17  wk18  wk19  wk20  wk21\n##   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n## 1    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n## 2    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA\n## 3    51    51    51    47    44    38    28    22    18    18    14    12\n## 4    61    61    59    61    66    72    76    75    67    73    70    NA\n## 5    57    64    70    75    76    78    85    92    96    NA    NA    NA\n## # ... with 312 more rows, and 55 more variables: wk22 <dbl>, wk23 <dbl>,\n## #   wk24 <dbl>, wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>,\n## #   wk29 <dbl>, wk30 <dbl>, wk31 <dbl>, wk32 <dbl>, wk33 <dbl>,\n## #   wk34 <dbl>, wk35 <dbl>, wk36 <dbl>, wk37 <dbl>, wk38 <dbl>,\n## #   wk39 <dbl>, wk40 <dbl>, wk41 <dbl>, wk42 <dbl>, wk43 <dbl>,\n## #   wk44 <dbl>, wk45 <dbl>, wk46 <dbl>, wk47 <dbl>, wk48 <dbl>,\n## #   wk49 <dbl>, wk50 <dbl>, wk51 <dbl>, wk52 <dbl>, wk53 <dbl>,\n## #   wk54 <dbl>, wk55 <dbl>, wk56 <dbl>, wk57 <dbl>, wk58 <dbl>,\n## #   wk59 <dbl>, wk60 <dbl>, wk61 <dbl>, wk62 <dbl>, wk63 <dbl>,\n## #   wk64 <dbl>, wk65 <dbl>, wk66 <lgl>, wk67 <lgl>, wk68 <lgl>,\n## #   wk69 <lgl>, wk70 <lgl>, wk71 <lgl>, wk72 <lgl>, wk73 <lgl>,\n## #   wk74 <lgl>, wk75 <lgl>, wk76 <lgl>\n## Seleciona todas as colunas cujo nome\n## possua um ponto final antecedido por\n## 4 letras\nbillboard %>% \n  select(matches(\"[a-z]{4}[.]\")) %>% print(n = 5)## # A tibble: 317 x 1\n##   date.entered\n##   <date>      \n## 1 2000-02-26  \n## 2 2000-09-02  \n## 3 2000-04-08  \n## 4 2000-10-21  \n## 5 2000-04-15  \n## # ... with 312 more rows\nbillboard %>% select(artist, track, wk5)## # A tibble: 317 x 3\n##    artist         track                     wk5\n##    <chr>          <chr>                   <dbl>\n##  1 2 Pac          Baby Don't Cry (Keep...    87\n##  2 2Ge+her        The Hardest Part Of ...    NA\n##  3 3 Doors Down   Kryptonite                 66\n##  4 3 Doors Down   Loser                      67\n##  5 504 Boyz       Wobble Wobble              17\n##  6 98^0           Give Me Just One Nig...    26\n##  7 A*Teens        Dancing Queen             100\n##  8 Aaliyah        I Don't Wanna              38\n##  9 Aaliyah        Try Again                  21\n## 10 Adams, Yolanda Open My Heart              68\n## # ... with 307 more rows\nmpg %>% select(-hwy, -manufacturer)## # A tibble: 234 x 9\n##    model      displ  year   cyl trans      drv     cty fl    class  \n##    <chr>      <dbl> <int> <int> <chr>      <chr> <int> <chr> <chr>  \n##  1 a4           1.8  1999     4 auto(l5)   f        18 p     compact\n##  2 a4           1.8  1999     4 manual(m5) f        21 p     compact\n##  3 a4           2    2008     4 manual(m6) f        20 p     compact\n##  4 a4           2    2008     4 auto(av)   f        21 p     compact\n##  5 a4           2.8  1999     6 auto(l5)   f        16 p     compact\n##  6 a4           2.8  1999     6 manual(m5) f        18 p     compact\n##  7 a4           3.1  2008     6 auto(av)   f        18 p     compact\n##  8 a4 quattro   1.8  1999     4 manual(m5) 4        18 p     compact\n##  9 a4 quattro   1.8  1999     4 auto(l5)   4        16 p     compact\n## 10 a4 quattro   2    2008     4 manual(m6) 4        20 p     compact\n## # ... with 224 more rows\nbillboard %>% select(where(is.character))## # A tibble: 317 x 2\n##    artist         track                  \n##    <chr>          <chr>                  \n##  1 2 Pac          Baby Don't Cry (Keep...\n##  2 2Ge+her        The Hardest Part Of ...\n##  3 3 Doors Down   Kryptonite             \n##  4 3 Doors Down   Loser                  \n##  5 504 Boyz       Wobble Wobble          \n##  6 98^0           Give Me Just One Nig...\n##  7 A*Teens        Dancing Queen          \n##  8 Aaliyah        I Don't Wanna          \n##  9 Aaliyah        Try Again              \n## 10 Adams, Yolanda Open My Heart          \n## # ... with 307 more rows\nvec <- c(\"artist\", \"track\", \"wk5\")\n\nbillboard %>% select(\n  all_of(vec),  ## Método 2\n  3:5,  ## Método 5\n  matches(\"wk[0-9]{2}\")  ## Método 4\n)## # A tibble: 317 x 73\n##    artist   track      wk5 date.entered   wk1   wk2  wk10  wk11  wk12  wk13\n##    <chr>    <chr>    <dbl> <date>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1 2 Pac    Baby Do~    87 2000-02-26      87    82    NA    NA    NA    NA\n##  2 2Ge+her  The Har~    NA 2000-09-02      91    87    NA    NA    NA    NA\n##  3 3 Doors~ Krypton~    66 2000-04-08      81    70    51    51    51    47\n##  4 3 Doors~ Loser       67 2000-10-21      76    76    61    61    59    61\n##  5 504 Boyz Wobble ~    17 2000-04-15      57    34    57    64    70    75\n##  6 98^0     Give Me~    26 2000-08-19      51    39     6     7    22    29\n##  7 A*Teens  Dancing~   100 2000-07-08      97    97    NA    NA    NA    NA\n##  8 Aaliyah  I Don't~    38 2000-01-29      84    62    36    37    37    38\n##  9 Aaliyah  Try Aga~    21 2000-03-18      59    53    10     9     8     6\n## 10 Adams, ~ Open My~    68 2000-08-26      76    76    59    66    68    61\n## # ... with 307 more rows, and 63 more variables: wk14 <dbl>, wk15 <dbl>,\n## #   wk16 <dbl>, wk17 <dbl>, wk18 <dbl>, wk19 <dbl>, wk20 <dbl>,\n## #   wk21 <dbl>, wk22 <dbl>, wk23 <dbl>, wk24 <dbl>, wk25 <dbl>,\n## #   wk26 <dbl>, wk27 <dbl>, wk28 <dbl>, wk29 <dbl>, wk30 <dbl>,\n## #   wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>, wk35 <dbl>,\n## #   wk36 <dbl>, wk37 <dbl>, wk38 <dbl>, wk39 <dbl>, wk40 <dbl>,\n## #   wk41 <dbl>, wk42 <dbl>, wk43 <dbl>, wk44 <dbl>, wk45 <dbl>,\n## #   wk46 <dbl>, wk47 <dbl>, wk48 <dbl>, wk49 <dbl>, wk50 <dbl>,\n## #   wk51 <dbl>, wk52 <dbl>, wk53 <dbl>, wk54 <dbl>, wk55 <dbl>,\n## #   wk56 <dbl>, wk57 <dbl>, wk58 <dbl>, wk59 <dbl>, wk60 <dbl>,\n## #   wk61 <dbl>, wk62 <dbl>, wk63 <dbl>, wk64 <dbl>, wk65 <dbl>,\n## #   wk66 <lgl>, wk67 <lgl>, wk68 <lgl>, wk69 <lgl>, wk70 <lgl>,\n## #   wk71 <lgl>, wk72 <lgl>, wk73 <lgl>, wk74 <lgl>, wk75 <lgl>, wk76 <lgl>"},{"path":"transformando-dados-com-dplyr.html","id":"filtrando-linhas-com-filter","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.5 Filtrando linhas com filter()","text":"Você também já possui conhecimento para realizar essa operação através da função de subsetting ([). Porém, novamente o pacote dplyr nos oferece uma alternativa mais intuitiva. função filter() busca filtrar linhas de uma tabela de acordo com uma condição lógica que nós devemos definir. Ou seja, os operadores lógicos são primordiais para essa função. Por isso, temos abaixo na tabela 4.1, um resumo de cada um deles.\nFigure 4.1: Lista de operadores lógicos\nPortanto, ao utilizar função filter() você deve construir uma condição lógica que seja capaz de identificar linhas que você deseja filtrar. Como exemplo inicial, nós podemos retornar à tabela mpg, que contém dados de consumo de diversos modelos de carro. Por exemplo, nós podemos filtrar todas linhas que dizem respeito modelos da Toyota, através comando abaixo. Como um paralelo, temos mais abaixo mesma operação segundo função de subsetting.Múltiplas condições lógicas podem ser construídas dentro da função filter(). Por exemplo, podemos ser um pouco mais específicos e selecionarmos apenas os modelos da Toyota que possuem um motor de 4 cilindradas com o comando abaixo. Repare abaixo, que ao acrescentarmos novas condições na função filter(), elas acabam se tornando dependentes. Ou seja, ambas condições devem ser atendidas ao mesmo tempo em cada linha retornada pela função filter().Nós tradicionalmente estabelecemos relações de dependência entre condições lógicas, por meio operador &. Mas função filter() busca ser prática e, por isso, ela automaticamente realiza esse trabalho por nós. Porém, isso implica que se suas condições forem independentes, ajustes precisam ser feitos, através operador |.Visto esse ponto, você pode estar interessado em filtrar sua tabela, de acordo com um conjunto de valores. Por exemplo, ao invés de selecionar apenas os modelos pertencentes à Toyota, podemos selecionar um conjunto maior de marcas. Em ocasiões como essa, o operador %% se torna útil, pois você está pesquisando se o valor presente em cada linha de sua tabela, pertence ou não um dado conjunto de valores.","code":"\nmpg %>% filter(manufacturer == \"toyota\")## # A tibble: 34 x 11\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n##  1 toyota       4run~   2.7  1999     4 manu~ 4        15    20 r     suv  \n##  2 toyota       4run~   2.7  1999     4 auto~ 4        16    20 r     suv  \n##  3 toyota       4run~   3.4  1999     6 auto~ 4        15    19 r     suv  \n##  4 toyota       4run~   3.4  1999     6 manu~ 4        15    17 r     suv  \n##  5 toyota       4run~   4    2008     6 auto~ 4        16    20 r     suv  \n##  6 toyota       4run~   4.7  2008     8 auto~ 4        14    17 r     suv  \n##  7 toyota       camry   2.2  1999     4 manu~ f        21    29 r     mids~\n##  8 toyota       camry   2.2  1999     4 auto~ f        21    27 r     mids~\n##  9 toyota       camry   2.4  2008     4 manu~ f        21    31 r     mids~\n## 10 toyota       camry   2.4  2008     4 auto~ f        21    31 r     mids~\n## # ... with 24 more rows\n## -------------------------------------\n## A mesma operação por subsetting:\n##\nclog <- mpg$manufacturer == \"toyota\"\n\nmpg[clog, ]\nmpg %>% filter(manufacturer == \"toyota\", cyl == 4)## # A tibble: 18 x 11\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n##  1 toyota       4run~   2.7  1999     4 manu~ 4        15    20 r     suv  \n##  2 toyota       4run~   2.7  1999     4 auto~ 4        16    20 r     suv  \n##  3 toyota       camry   2.2  1999     4 manu~ f        21    29 r     mids~\n##  4 toyota       camry   2.2  1999     4 auto~ f        21    27 r     mids~\n##  5 toyota       camry   2.4  2008     4 manu~ f        21    31 r     mids~\n##  6 toyota       camry   2.4  2008     4 auto~ f        21    31 r     mids~\n##  7 toyota       camr~   2.2  1999     4 auto~ f        21    27 r     comp~\n##  8 toyota       camr~   2.2  1999     4 manu~ f        21    29 r     comp~\n##  9 toyota       camr~   2.4  2008     4 manu~ f        21    31 r     comp~\n## 10 toyota       camr~   2.4  2008     4 auto~ f        22    31 r     comp~\n## 11 toyota       coro~   1.8  1999     4 auto~ f        24    30 r     comp~\n## 12 toyota       coro~   1.8  1999     4 auto~ f        24    33 r     comp~\n## 13 toyota       coro~   1.8  1999     4 manu~ f        26    35 r     comp~\n## 14 toyota       coro~   1.8  2008     4 manu~ f        28    37 r     comp~\n## 15 toyota       coro~   1.8  2008     4 auto~ f        26    35 r     comp~\n## 16 toyota       toyo~   2.7  1999     4 manu~ 4        15    20 r     pick~\n## 17 toyota       toyo~   2.7  1999     4 auto~ 4        16    20 r     pick~\n## 18 toyota       toyo~   2.7  2008     4 manu~ 4        17    22 r     pick~\n## -------------------------------------\n## A mesma operação por subsetting:\n##\nclog <- mpg$manufacturer == \"toyota\" & mpg$cyl == 4\n\nmpg[clog, ]\nmarcas <- c(\"volkswagen\", \"audi\", \"toyota\", \"honda\")\n\nmpg %>% \n  filter(manufacturer %in% marcas)## # A tibble: 88 x 11\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n##  1 audi         a4      1.8  1999     4 auto~ f        18    29 p     comp~\n##  2 audi         a4      1.8  1999     4 manu~ f        21    29 p     comp~\n##  3 audi         a4      2    2008     4 manu~ f        20    31 p     comp~\n##  4 audi         a4      2    2008     4 auto~ f        21    30 p     comp~\n##  5 audi         a4      2.8  1999     6 auto~ f        16    26 p     comp~\n##  6 audi         a4      2.8  1999     6 manu~ f        18    26 p     comp~\n##  7 audi         a4      3.1  2008     6 auto~ f        18    27 p     comp~\n##  8 audi         a4 q~   1.8  1999     4 manu~ 4        18    26 p     comp~\n##  9 audi         a4 q~   1.8  1999     4 auto~ 4        16    25 p     comp~\n## 10 audi         a4 q~   2    2008     4 manu~ 4        20    28 p     comp~\n## # ... with 78 more rows\n## -------------------------------------\n## A mesma operação por subsetting:\n##\nmarcas <- c(\"volkswagen\", \"audi\", \"toyota\", \"honda\")\nclog <- mpg$manufacturer %in% marcas\n\nmpg[clog, ]"},{"path":"transformando-dados-com-dplyr.html","id":"cuidados-com-o-operador-de-igualdade","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.5.1 Cuidados com o operador de igualdade","text":"Quando você estiver filtrando linhas de sua tabela de acordo com uma condição de igualdade, é importante que você tome alguns cuidados, especialmente se valores textuais estiverem envolvidos nessa condição. O primeiro ponto ser abordado é o uso operador ==, que para além de igualdade, ele busca encontrar valores exatamente iguais.O “exatamente” é importante aqui, pois certos valores numéricos podem ser aparentemente idênticos aos nossos olhos, mas ainda assim, diferentes segundo visão de ==. Isso ocorre especialmente com valores numéricos tipo double. Pois os nossos computadores utilizam precisão aritmética finita para guardar esse tipo de valor (Wickham Grolemund 2017, p 47). Isso significa que os nossos computadores guardam apenas casas decimais significantes de um valor double, e perda de casas decimais que ocorre nesse processo, pode ser fonte de alguma diferença em operações aritméticas. Por exemplo, se testarmos igualdade entre \\((\\sqrt{2})^2 = 2\\), o R vai nos indicar alguma diferença existente entre esses dois valores.Por essa razão, quando você estiver testando igualdade entre valores tipo double, é interessante que você utilize função near() ao invés operador ==. Por padrão, função near() possui uma tolerância próxima de \\(1,49 \\times 10^{-8}\\), mas você pode ajustar esse valor pelo argumento tol da função.Para mais, você também deve estar atento ao uso operador ==, quando estiver testando igualdade entre palavras, ou valores textuais. Pois uma palavra pode ser escrita de múltiplas maneiras sem que ela perca o seu sentido, e mínima diferença presente nos caracteres utilizados pode torná-las valores completamente diferentes aos olhos operador ==. Logo, os valores \"Isabela\" e \"isabela\" são diferentes na visão de ==, mesmo que na prática, esses valores muito provavelmente se referem ao mesmo indivíduo.Se você possui em sua coluna, uma variedade maior de valores textuais, que são diferentes, mas que dizem respeito ao mesmo indivíduo (por exemplo, você possui seis variedades de “Isabela”: Isabela; ISABELA; IsAbElA; Ísabela; ísabela; \\@abela), você muito provavelmente necessita de uma expressão regular. Para acessar esse mecanismo e utilizá-lo dentro da função filter(), você precisa de uma função que utilize essa funcionalidade para pesquisar os textos que se encaixam em sua expressão, e que retorne como resultado, um vetor de valores lógicos que indicam linhas de sua tabela em que esses textos ocorrem. Sendo os principais indivíduos dessa categoria, função grepl(), e função str_detect() que pertence ao pacote stringr.Por outro lado, pode ser que você não precise ir tão longe, caso diferenças presentes em seus textos se apresentem na forma de capitalização das letras (maiúsculo ou minúsculo). Por exemplo, suponha que sua variedade de “Isabela” fosse: Isabela; ISABELA; IsAbElA e isabela. Para tornar esses valores iguais, você precisaria apenas de um método de pesquisa que seja capaz de ignorar capitalização das letras. Para isso, você pode utilizar função grepl() que possui o argumento ignore.case, qual você pode pedir função que ignore essas diferenças na capitalização, como exemplo abaixo.","code":"\n(sqrt(2)^2) == 2## [1] FALSE\nnear(sqrt(2)^2, 2)## [1] TRUE\n\"Isabela\" == \"isabela\"## [1] FALSE\nset.seed(2)\ndf <- data.frame(\n  usuario = c(\"Ana\", \"Isabela\", \"isabela\", \"Julia\"),\n  id = 1:4,\n  valor = round(rnorm(4), 2)\n)\n\ndf %>% \n  filter(grepl(\"Isabela\", usuario, ignore.case = TRUE))##   usuario id valor\n## 1 Isabela  2  0.18\n## 2 isabela  3  1.59"},{"path":"transformando-dados-com-dplyr.html","id":"estabelecendo-intervalos-com-a-função-between","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.5.2 Estabelecendo intervalos com a função between()","text":"Para estabelecermos uma condição de intervalo R, precisamos de duas condições lógicas que definam os limites deste intervalo. Em seguida, nós devemos tornar essas duas condições dependentes. Por exemplo, se desejássemos filtrar todas linhas de mpg que possuem um valor na coluna hwy entre 18 e 24, precisaríamos seguinte teste lógico:Porém, de uma maneira mais prática, podemos utilizar função () que conciste em um atalho para essa metodologia. função possui três argumentos: 1) x, coluna ou o vetor sobre o qual você deseja aplicar o teste de intervalo; 2) left, o limite “inferior” (ou “esquerdo”) intervalo; 3) right, o limite “superior” (ou “direito”) intervalo. Logo, se fôssemos traduzir o teste de intervalo anterior para função (), faríamos da seguinte maneira:","code":"\nmpg %>% \n  filter(hwy >= 18, hwy <= 24)\n\n## -------------------------------------\n## A mesma operação por subsetting:\n##\nclog <- mpg$hwy >= 18 & mpg$hwy <= 24\n\nmpg[clog, ]\nmpg %>% \n  filter(between(hwy, 18, 24))## # A tibble: 63 x 11\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n##  1 audi         a6 q~   2.8  1999     6 auto~ 4        15    24 p     mids~\n##  2 audi         a6 q~   4.2  2008     8 auto~ 4        16    23 p     mids~\n##  3 chevrolet    c150~   5.3  2008     8 auto~ r        14    20 r     suv  \n##  4 chevrolet    c150~   5.3  2008     8 auto~ r        14    20 r     suv  \n##  5 chevrolet    corv~   5.7  1999     8 auto~ r        15    23 p     2sea~\n##  6 chevrolet    corv~   7    2008     8 manu~ r        15    24 p     2sea~\n##  7 chevrolet    k150~   5.3  2008     8 auto~ 4        14    19 r     suv  \n##  8 dodge        cara~   2.4  1999     4 auto~ f        18    24 r     mini~\n##  9 dodge        cara~   3    1999     6 auto~ f        17    24 r     mini~\n## 10 dodge        cara~   3.3  1999     6 auto~ f        16    22 r     mini~\n## # ... with 53 more rows"},{"path":"transformando-dados-com-dplyr.html","id":"sec:ataque_terrorista","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.5.3 Ataque terrorista","text":"Vamos dar um pouco de contexto para nossas operações. Nessa seção, vamos utilizar os dados disponíveis na tabela transf, que podem ser importados para o seu R através dos comandos abaixo. tabela transf contém informações sobre diversas transferências bancárias realizadas por uma instituição bancária. Algumas informações presentes nessa tabela incluem: data e o horário da transferência (Data); O username usuário banco responsável por realizar transferência (Usuario); o país de destino da transferência (Pais); um código de identificação da transferência (TransferID); e o valor transferido (Valor).Vamos supor que dia 24 de dezembro de 2018, tenha ocorrido um ataque terrorista na cidade de Berlim (Alemanha). Suponha também, que você faz parte setor de compliance da instituição financeira responsável pelas transferências descritas na tabela transf. Em geral, um dos principais papéis de um setor de compliance é garantir que sua instituição não esteja contribuindo com práticas ilícitas (dentre elas está o terrorismo).Segundo o relatório da polícia, há fortes indícios de que munição utilizada ato, foi comprada durante os dias 20 e 23. Além disso, polícia também destacou que levando em conta quantidade utilizada ataque, somente munição empregada custou em média mais de $15.000.Logo, o seu papel seria se certificar de que instituição qual você pertence, não realizou alguma transferência que se encaixa nessas características. Pois caso tal transferência exista, vocês teriam de abrir uma investigação em conjunto com polícia, para apurar fontes e os destinatários dos recursos dessa transferência.Portanto, estamos procurando por uma transferência na tabela transf de valor acima de $15.000, que possua Alemanha como país de destino, e que tenha ocorrido durante os dias 20 e 23 de dezembro de 2018. Perceba que todas essas condições, ou características da transferência devem ser atendidas ao mesmo tempo. Ou seja, essas condições lógicas são dependentes uma da outra.Lembre-se que quando temos diversas condições lógicas dependentes, nós podemos separá-las por vírgulas na função filter(). Por outro lado, fora uso da função filter(), nós estabelecemos uma relação de dependência entre várias condições lógicas por meio operador &, e será esse o método tradicional utilizado nessa seção. Logo, quando temos diversas condições R que devem ser atendidas ao mesmo tempo, nós devemos conectar cada uma dessas condições pelo operador &, como exemplo abaixo.total, 132 linhas foram retornadas pela função, e você teria de conferir cada uma dessas transferências. Um baita trabalho! Porém, vamos supor que em um minuto de reflexão sobre regras banco, você se lembre que o remetente da transferência não é obrigado apresentar uma prova de fundos ou um comprovante de endereço, caso transferência possua um valor menor que $200. Em casos como esse, o remetente precisa apresentar apenas identidade (que ele pode ter falsificado).Isso é interessante, pois conseguimos reduzir os nossos resultados para apenas 5 transferências. Ao conferirmos informações da primeira transferência, os recursos estão limpos. Porém, próximas 4 transferências levantam algumas suspeitas. Pois elas foram realizadas por clientes diferentes, mas com poucos minutos de diferença. Ao conversar com os agentes Sandra e Eduardo, que autorizaram essas transferências, você descobre que todos os diferentes clientes apresentaram transferências francesas. Será que esses clientes estavam testando regras da instituição para com identidades desse país?Ao procurar por todas transferências em que identidades francesas foram apresentadas, e que foram realizadas entre os dias 20 e 23 de dezembro de 2018, e que possuíam Alemanha como país de destino, você chega uma estranha transferência de $20.000 efetuada poucos minutos depois das 4 transferências que encontramos anteriormente. Durante análise das informações dessa transferência, você percebe diversas falhas presentes na prova de fundos que sustentou decisão de autorização dessa operação. Há uma grande possibilidade de que os chefes e agentes de sua instituição que autorizaram essa operação, estejam em maus lençóis.","code":"\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo <- \"transf_reform.csv\"\n\nlibrary(readr)\n\ntransf <- read_csv2(paste0(github, pasta, arquivo))\ntransf## # A tibble: 20,006 x 6\n##    Data                Usuario   Valor TransferID Pais     Descricao\n##    <dttm>              <chr>     <dbl>      <dbl> <chr>    <lgl>    \n##  1 2018-12-06 22:19:19 Eduardo    599.  116241629 Alemanha NA       \n##  2 2018-12-06 22:10:34 Júlio     4611.  115586504 Alemanha NA       \n##  3 2018-12-06 21:59:50 Nathália  4418.  115079280 Alemanha NA       \n##  4 2018-12-06 21:54:13 Júlio     2740.  114972398 Alemanha NA       \n##  5 2018-12-06 21:41:27 Ana       1408.  116262934 Alemanha NA       \n##  6 2018-12-06 21:18:40 Nathália  5052.  115710402 Alemanha NA       \n##  7 2018-12-06 20:54:32 Eduardo   5665.  114830203 Alemanha NA       \n##  8 2018-12-06 20:15:46 Sandra    1474.  116323455 Alemanha NA       \n##  9 2018-12-06 20:04:35 Armando   8906.  115304382 Alemanha NA       \n## 10 2018-12-22 20:00:56 Armando  18521.  114513684 Alemanha NA       \n## # ... with 19,996 more rows\ntransf %>% \n  filter(\n    Valor > 15000 & Pais == \"Alemanha\" &\n    between(as.Date(Data), as.Date(\"2018-12-20\"), as.Date(\"2018-12-23\"))\n  )## # A tibble: 132 x 6\n##    Data                Usuario      Valor TransferID Pais     Descricao\n##    <dttm>              <chr>        <dbl>      <dbl> <chr>    <lgl>    \n##  1 2018-12-22 20:00:56 Armando     18521.  114513684 Alemanha NA       \n##  2 2018-12-21 18:46:59 Júlio Cesar 16226.  116279014 Alemanha NA       \n##  3 2018-12-21 17:41:48 Nathália    17583.  115748273 Alemanha NA       \n##  4 2018-12-23 09:46:23 Júlio       15396.  115272184 Alemanha NA       \n##  5 2018-12-21 06:38:20 Júlio Cesar 17555.  114983226 Alemanha NA       \n##  6 2018-12-23 18:11:27 Eduardo     17219.  115904797 Alemanha NA       \n##  7 2018-12-22 13:09:13 Eduardo     16255.  114520578 Alemanha NA       \n##  8 2018-12-23 10:59:50 Júlio Cesar 15093.  115919119 Alemanha NA       \n##  9 2018-12-23 10:29:34 Sandra      19241.  114665132 Alemanha NA       \n## 10 2018-12-21 06:04:49 Júlio Cesar 18938.  116281869 Alemanha NA       \n## # ... with 122 more rows\n## -------------------------------------\n## A mesma operação por subsetting:\n##\nclog <- transf$Valor > 15000 & transf$Pais == \"Alemanha\" &\n  between(as.Date(transf$Data), as.Date(\"2018-12-20\"), as.Date(\"2018-12-23\"))\n\ntransf[clog, ]\ntransf %>%\n  filter(\n    Valor <= 200 & Pais == \"Alemanha\" &\n    between(as.Date(Data), as.Date(\"2018‐12‐20\"), as.Date(\"2018‐12‐23\"))\n  )## # A tibble: 5 x 6\n##   Data                Usuario Valor TransferID Pais     Descricao\n##   <dttm>              <chr>   <dbl>      <dbl> <chr>    <lgl>    \n## 1 2018-12-20 00:31:17 Júlio     193  115555598 Alemanha NA       \n## 2 2018-12-22 06:30:01 Sandra    100  116400001 Alemanha NA       \n## 3 2018-12-22 06:35:00 Sandra    200  116400002 Alemanha NA       \n## 4 2018-12-22 06:42:12 Eduardo   200  116400005 Alemanha NA       \n## 5 2018-12-22 06:55:54 Eduardo   150  116400009 Alemanha NA\ntransf %>%\n  inner_join(\n    identidade,\n    by = \"TransferID\"\n  ) %>%\n  filter(\n    Pais == \"Alemanha\" & Identi_Nacion == \"França\" &\n    between(as.Date(Data), as.Date(\"2018‐12‐20\"), as.Date(\"2018‐12‐23\"))\n  )## # A tibble: 5 x 7\n##   Data                Usuario Valor TransferID Pais     Descricao\n##   <dttm>              <chr>   <dbl>      <dbl> <chr>    <lgl>    \n## 1 2018-12-22 06:30:01 Sandra    100  116400001 Alemanha NA       \n## 2 2018-12-22 06:35:00 Sandra    200  116400002 Alemanha NA       \n## 3 2018-12-22 06:42:12 Eduardo   200  116400005 Alemanha NA       \n## 4 2018-12-22 06:55:54 Eduardo   150  116400009 Alemanha NA       \n## 5 2018-12-22 06:59:07 Eduardo 20000  116400010 Alemanha NA       \n## # ... with 1 more variable: Identi_Nacion <chr>"},{"path":"transformando-dados-com-dplyr.html","id":"condições-dependentes-ou-independentes","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.5.4 Condições dependentes (&) ou independentes (|) ?","text":"Na seção anterior, condições lógicas que guiavam o nosso filtro eram dependentes entre si. Em outras palavras, condições deveriam ser todas atendidas ao mesmo tempo. Por essa razão, nós conectamos condições lógicas com o operador &. Porém, em algumas ocasiões suas condições serão independentes e, por isso, devemos utilizar um outro operador para conectá-las, que é barra vertical (|).Por exemplo, se eu quiser encontrar todas transferências na tabela transf que ocorreram dia 13 de novembro de 2018, ou que possuem um valor menor que $500, ou que foram autorizadas pelo agente Eduardo, eu devo construir o comando abaixo. Logo, toda linha da tabela transf que atenda pelo menos uma das condições que estabelecemos, é filtrada pela função filter().","code":"\ntransf %>% \n  filter(\n    as.Date(Data) == as.Date(\"2018-11-13\") | Valor < 500 |\n    Usuario == \"Eduardo\"\n  )## # A tibble: 5,581 x 6\n##    Data                Usuario      Valor TransferID Pais     Descricao\n##    <dttm>              <chr>        <dbl>      <dbl> <chr>    <lgl>    \n##  1 2018-12-06 22:19:19 Eduardo       599.  116241629 Alemanha NA       \n##  2 2018-12-06 20:54:32 Eduardo      5665.  114830203 Alemanha NA       \n##  3 2018-12-06 19:07:50 Eduardo      9561.  115917812 Alemanha NA       \n##  4 2018-12-06 18:09:15 Júlio Cesar   388.  114894102 Alemanha NA       \n##  5 2018-12-06 16:59:38 Eduardo     11759.  115580064 Alemanha NA       \n##  6 2018-12-06 15:21:36 Eduardo      4436.  114425893 Alemanha NA       \n##  7 2018-12-06 14:47:25 Ana           483.  114387526 Alemanha NA       \n##  8 2018-12-06 12:59:58 Ana           207.  115615456 Alemanha NA       \n##  9 2018-12-06 10:05:21 Eduardo       708.  114746955 Alemanha NA       \n## 10 2018-12-06 09:50:03 Eduardo      1587.  114796170 Alemanha NA       \n## # ... with 5,571 more rows\n## -------------------------------------\n## A mesma operação por subsetting:\n##\nclog <- as.Date(transf$Data) == as.Date(\"2018-11-13\") | \n  transf$Valor < 500 | transf$Usuario == \"Eduardo\"\n\ntransf[clog, ]"},{"path":"transformando-dados-com-dplyr.html","id":"ordenando-linhas-com-arrange","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.6 Ordenando linhas com arrange()","text":"Algumas operações que realizamos dependem diretamente da forma como linhas de nossa tabela estão ordenadas. Em outros momentos, desejamos ordenar nossa tabela, para rapidamente identificarmos observações que possuem os 10 maiores valores de alguma variável ao longo da base. Ou seja, ordenação de linhas é uma operação muito comum, e o pacote dplyr oferece função arrange() para tal ação.O uso da função arrange() é bem simples. Tudo o que você precisa fazer é listar colunas pelas quais você deseja ordenar base. Caso coluna seja numérica, arrange() vai seguir uma ordenação numérica. Mas se essa coluna tipo character, arrange() vai utilizar uma ordenação alfabética para organizar os valores da coluna. Por outro lado, na hipótese dessa coluna ser tipo factor, arrange() vai seguir ordem presente nos “níveis” (levels) desse factor, aos quais você pode acessar pela função levels().Você pode recorrer várias colunas para ordenar sua base. Nessa situação, função arrange() vai ordenar colunas na ordem em que você definiu na função. Ou seja, exemplo abaixo, função arrange() primeiro ordena base de acordo com coluna displ, em seguida, segundo coluna hwy, e por último, coluna trans.Por padrão, função arrange() utiliza uma ordenação em um sentido crescente (menor para o maior valor; primeiro para o último valor), qualquer que seja o tipo de dado contido na coluna que você forneceu função. Caso você deseja utilizar uma ordenação em um sentido decrescente (maior para o menor valor; último para o primeiro valor) em uma dada coluna, você deve encapsular o nome dessa coluna na função desc(). exemplo abaixo, arrange() primeiro ordena coluna manufacturer em uma forma decrescente e, em seguida, ordena coluna hwy de acordo com uma ordem crescente.Como estamos basicamente definindo colunas na função arrange(), é natural que você anseie pelos diversos métodos de seleção que aprendemos em select(). Por isso, em versões mais recentes pacote dplyr tivemos introdução da função across(), pela qual você tem novamente acesso todos esses métodos que vimos em select().Vale destacar que função arrange(), por padrão, não respeita os grupos de sua tabela e, portanto, considera toda sua tabela momento em que ordenação ocorre. Ainda veremos em mais detalhes nas próximas seções, função group_by(), pela qual você pode definir os grupos presentes em sua tabela. Portanto, pode ser de seu desejo que ordenação executada por arrange() ocorra dentro de cada um dos grupos que você delimitou através da função group_by(). Para isso, você precisa configurar o argumento .by_group para TRUE.","code":"\nmpg %>% arrange(displ)## # A tibble: 234 x 11\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n##  1 honda        civic   1.6  1999     4 manu~ f        28    33 r     subc~\n##  2 honda        civic   1.6  1999     4 auto~ f        24    32 r     subc~\n##  3 honda        civic   1.6  1999     4 manu~ f        25    32 r     subc~\n##  4 honda        civic   1.6  1999     4 manu~ f        23    29 p     subc~\n##  5 honda        civic   1.6  1999     4 auto~ f        24    32 r     subc~\n##  6 audi         a4      1.8  1999     4 auto~ f        18    29 p     comp~\n##  7 audi         a4      1.8  1999     4 manu~ f        21    29 p     comp~\n##  8 audi         a4 q~   1.8  1999     4 manu~ 4        18    26 p     comp~\n##  9 audi         a4 q~   1.8  1999     4 auto~ 4        16    25 p     comp~\n## 10 honda        civic   1.8  2008     4 manu~ f        26    34 r     subc~\n## # ... with 224 more rows\nmpg %>% arrange(displ, hwy, trans)## # A tibble: 234 x 11\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n##  1 honda        civic   1.6  1999     4 manu~ f        23    29 p     subc~\n##  2 honda        civic   1.6  1999     4 auto~ f        24    32 r     subc~\n##  3 honda        civic   1.6  1999     4 auto~ f        24    32 r     subc~\n##  4 honda        civic   1.6  1999     4 manu~ f        25    32 r     subc~\n##  5 honda        civic   1.6  1999     4 manu~ f        28    33 r     subc~\n##  6 audi         a4 q~   1.8  1999     4 auto~ 4        16    25 p     comp~\n##  7 audi         a4 q~   1.8  1999     4 manu~ 4        18    26 p     comp~\n##  8 audi         a4      1.8  1999     4 auto~ f        18    29 p     comp~\n##  9 volkswagen   pass~   1.8  1999     4 auto~ f        18    29 p     mids~\n## 10 audi         a4      1.8  1999     4 manu~ f        21    29 p     comp~\n## # ... with 224 more rows\nmpg %>% arrange(desc(manufacturer), hwy)## # A tibble: 234 x 11\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n##  1 volkswagen   jetta   2.8  1999     6 auto~ f        16    23 r     comp~\n##  2 volkswagen   gti     2.8  1999     6 manu~ f        17    24 r     comp~\n##  3 volkswagen   jetta   2.8  1999     6 manu~ f        17    24 r     comp~\n##  4 volkswagen   gti     2    1999     4 auto~ f        19    26 r     comp~\n##  5 volkswagen   jetta   2    1999     4 auto~ f        19    26 r     comp~\n##  6 volkswagen   new ~   2    1999     4 auto~ f        19    26 r     subc~\n##  7 volkswagen   pass~   2.8  1999     6 auto~ f        16    26 p     mids~\n##  8 volkswagen   pass~   2.8  1999     6 manu~ f        18    26 p     mids~\n##  9 volkswagen   pass~   3.6  2008     6 auto~ f        17    26 p     mids~\n## 10 volkswagen   new ~   2.5  2008     5 manu~ f        20    28 r     subc~\n## # ... with 224 more rows\n## Ordenar a base segundo as três primeiras colunas\nmpg %>% arrange(across(1:3))\n\n## Ordenar a base segundo o conjunto de colunas\n## que possuem um nome que se inicia\n## pelos caracteres \"dis\"\nmpg %>% arrange(across(starts_with(\"dis\")))\nmpg %>% \n  group_by(manufacturer) %>% \n  arrange(hwy, .by_group = TRUE)## # A tibble: 234 x 11\n## # Groups:   manufacturer [15]\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <int> <chr> <chr>\n##  1 audi         a6 q~   4.2  2008     8 auto~ 4        16    23 p     mids~\n##  2 audi         a6 q~   2.8  1999     6 auto~ 4        15    24 p     mids~\n##  3 audi         a4 q~   1.8  1999     4 auto~ 4        16    25 p     comp~\n##  4 audi         a4 q~   2.8  1999     6 auto~ 4        15    25 p     comp~\n##  5 audi         a4 q~   2.8  1999     6 manu~ 4        17    25 p     comp~\n##  6 audi         a4 q~   3.1  2008     6 auto~ 4        17    25 p     comp~\n##  7 audi         a4 q~   3.1  2008     6 manu~ 4        15    25 p     comp~\n##  8 audi         a6 q~   3.1  2008     6 auto~ 4        17    25 p     mids~\n##  9 audi         a4      2.8  1999     6 auto~ f        16    26 p     comp~\n## 10 audi         a4      2.8  1999     6 manu~ f        18    26 p     comp~\n## # ... with 224 more rows"},{"path":"transformando-dados-com-dplyr.html","id":"sec:mutate_dplyr","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.7 Adicionando variáveis à sua tabela com mutate()","text":"Frequentemente, você deseja adicionar uma nova variável em sua tabela como uma função de outras variáveis já existentes em sua tabela. Para tal fim, o pacote dplyr disponibiliza função mutate(), que oferta um mecanismo limpo e rápido para executarmos tal ação.Como um exemplo inicial, vamos voltar tabela transf que introduzimos na seção Ataque terrorista. coluna Data retém data e o horário em que cada operação foi registrada sistema banco. Entretanto, o horário pode se tornar irrelevante para certos passos e, por essa razão, seria interessante que possuíssemos uma coluna na tabela transf, contendo apenas data de cada transferência. Com esse objetivo em mente, somos capazes de extrair data da coluna Data através da função .Date(), e empregar função mutate() para armazenarmos o resultado desse procedimento em uma nova coluna chamada Sem_hora, como mostrado abaixo.Portanto, sempre que você recorrer à função mutate(), você deve compor essa estrutura de <nome_coluna> = <expressao> em cada coluna adicionada. Ou seja, como flexibidade e eficiência são valores que funções pacote dplyr carregam, você tem capacidade de criar múltiplas colunas em um mesmo mutate(). Porém, como um aviso, é ideal que você não crie mais de 7 colunas ao mesmo tempo. Na hipótese dessa recomendação ser ignorada, há uma probabilidade significativa de você enfrentar problemas de memória e mensagens de erro bastante nebulosas.Um outro ponto muito importante, é que em um mesmo mutate(), você também pode empregar uma nova coluna que você acaba de criar, cálculo de uma outra coluna ser produzida. Por exemplo, eu posso guardar o desvio de Valor em relação à sua média, na coluna Desvio, e logo em seguida, utilizar os valores dessa coluna para produzir coluna Valor_norm, como exposto abaixo.Com isso, parte fundamental de um mutate() é construírmos expressão que produzirá os valores serem alocados na nova coluna que estamos criando. Logo abaixo, consta uma lista de várias funções que você pode utilizar para formar expressão que você deseja. Ademais, essa é uma lista parcial, logo, há diversas outras funções que você pode utilizar para calcular os valores dos quais você necessita.Somatórios: soma total de uma coluna - sum(); somatório por linha, ao longo de algumas colunas - operador +; somatório por linha, ao longo de várias colunas - rowSums().Somatórios: soma total de uma coluna - sum(); somatório por linha, ao longo de algumas colunas - operador +; somatório por linha, ao longo de várias colunas - rowSums().Operações cumulativas: somatório acumulado de uma coluna - cumsum(); média acumulada de uma coluna - cummean(); mínimo acumulado de uma coluna - cummin(); máximo acumulado de uma coluna - cummax().Operações cumulativas: somatório acumulado de uma coluna - cumsum(); média acumulada de uma coluna - cummean(); mínimo acumulado de uma coluna - cummin(); máximo acumulado de uma coluna - cummax().Medidas de posição: média de uma coluna - mean(); mediana de uma coluna - median(); média por linha, ao longo de várias colunas - rowMeans(); média móvel - roll_mean()13.Medidas de posição: média de uma coluna - mean(); mediana de uma coluna - median(); média por linha, ao longo de várias colunas - rowMeans(); média móvel - roll_mean()13.Medidas de dispersão: desvio padrão de uma coluna - sd(); variância de uma coluna - var(); intervalo interquartil - IQR(); desvio absoluto da mediana - mad().Medidas de dispersão: desvio padrão de uma coluna - sd(); variância de uma coluna - var(); intervalo interquartil - IQR(); desvio absoluto da mediana - mad().Operadores aritméticos: soma (+); subtração (-); divisão (/); multiplicação (*); potência, ou elevar um número x (^); restante da divisão (%%); apenas o número inteiro resultante da divisão (%/%); logaritmo - log().Operadores aritméticos: soma (+); subtração (-); divisão (/); multiplicação (*); potência, ou elevar um número x (^); restante da divisão (%%); apenas o número inteiro resultante da divisão (%/%); logaritmo - log().Operadores lógicos: aplique um teste lógico em cada linha, e preencha essa linha com x caso o teste resulte em TRUE, ou preencha com y caso o teste resulte em FALSE - if_else(); quando você quer aplicar uma operação parecida com if_else(), mas que há vários casos possíveis, um exemplo típico seria criar uma coluna de faixas etárias - case_when(); você também pode utilizar normalmente todos os operadores que vimos na seção de de filter(), para criar um teste lógico sobre cada linha - <, <=, >, >=, ==, !=, !, &, |.Operadores lógicos: aplique um teste lógico em cada linha, e preencha essa linha com x caso o teste resulte em TRUE, ou preencha com y caso o teste resulte em FALSE - if_else(); quando você quer aplicar uma operação parecida com if_else(), mas que há vários casos possíveis, um exemplo típico seria criar uma coluna de faixas etárias - case_when(); você também pode utilizar normalmente todos os operadores que vimos na seção de de filter(), para criar um teste lógico sobre cada linha - <, <=, >, >=, ==, !=, !, &, |.Funções para discretizar variáveis contínuas: calcula intervalos de forma encaixar o mesmo número número de observações em cada intervalo (comumente chamados de quantis) - cut_number(); calcula intervalos com o mesmo alcance - cut_interval(); calcula intervalos de largura definida argumento width - cut_width().Funções para discretizar variáveis contínuas: calcula intervalos de forma encaixar o mesmo número número de observações em cada intervalo (comumente chamados de quantis) - cut_number(); calcula intervalos com o mesmo alcance - cut_interval(); calcula intervalos de largura definida argumento width - cut_width().Funções de defasagem e liderança: quando você precisa em algum cálculo naquela linha, utilizar o valor da linha anterior - lag(); ou ao invés valor da linha anterior, você precisa valor da linha posterior - lead().Funções de defasagem e liderança: quando você precisa em algum cálculo naquela linha, utilizar o valor da linha anterior - lag(); ou ao invés valor da linha anterior, você precisa valor da linha posterior - lead().Porém, é necessário ter cautela. Como função mutate() busca trabalhar com data.frame’s, é de suma importância, que você esteja sempre consciente das propriedades que essa estrutura carrega. Em especial, propriedade de que suas colunas devem possuir o mesmo número de elementos. Portanto, se o seu data.frame possui exatamanete 10 mil linhas, você precisa se certificar de que cada expressão utilizada na função mutate(), vai gerar 10 mil elementos como resultado.Na hipótese de que alguma dessas expressões produzam, por exemplo, 9.999 elementos, um erro será acionado, pois esses 9,999 mil elementos não podem ser guardados em um data.frame que possui 10 mil linhas. Logo, função mutate() lhe provê flexibilidade e eficiência, mas ela não é capaz de quebrar regras fundamentais da linguagem R.Um exemplo prático disso é encontrado quando tentamos calcular uma média móvel de alguma série temporal, ou de algum valor diário utilizando função mutate(), como exemplo abaixo. O erro ocorre devido própria natureza cálculo de uma média móvel, que gera uma “perda” de observações, e como consequência, um número menor de observações é gerado dentro resultado. Perceba abaixo, que ao aplicarmos uma janela de cálculo de 5 observações, função roll_mean() foi capaz de produzir 996 valores, consequentemente, perdemos 4 observações processo.Compreendendo os potenciais problemas fabricados por essa característica cálculo de uma média móvel, função roll_mean() oferece o argumento fill, qual podemos pedir à função que complete observações restantes com zeros, como exemplo abaixo. Dessa forma, função volta produzir 1000 observações em seu resultado e, consequentemente, nenhum erro é acionado.Desse modo, estamos discutindo possibilidades existentes com hipótese de sua expressão fornecida à mutate(), produzir múltiplos valores. Todavia, diversas funções extremamente úteis, e que utilizamos com bastante frequência nessas expressões, resultam apenas em um único valor. Grandes exemplos são funções mean() e sum(), que calculam média e soma de uma coluna, respectivamente.Em todas ocasiões em que sua expressão na função mutate() gerar um único valor, qualquer que ele seja, função mutate() irá automaticamente replicar esse mesmo valor ao longo de toda coluna que você acaba de criar. Vemos uma demonstração disso, ao criarmos abaixo, colunas soma, prop e um_numero. Com essa ideia em mente, se temos diversos valores numéricos em uma dada coluna, nós podemos eficientemente calcular uma proporção desses valores em relação ao total de sua coluna, com o uso da função sum(), como exemplo abaixo. Da mesma forma, nós podemos rapidamente normalizar uma coluna númerica segundo fórmula de uma estatística Z, por meio das funções sd() e mean().","code":"\ntransf %>% \n  select(-Pais, -Descricao) %>% \n  mutate(\n    Sem_hora = as.Date(Data)\n  )## # A tibble: 20,006 x 5\n##    Data                Usuario   Valor TransferID Sem_hora  \n##    <dttm>              <chr>     <dbl>      <dbl> <date>    \n##  1 2018-12-06 22:19:19 Eduardo    599.  116241629 2018-12-06\n##  2 2018-12-06 22:10:34 Júlio     4611.  115586504 2018-12-06\n##  3 2018-12-06 21:59:50 Nathália  4418.  115079280 2018-12-06\n##  4 2018-12-06 21:54:13 Júlio     2740.  114972398 2018-12-06\n##  5 2018-12-06 21:41:27 Ana       1408.  116262934 2018-12-06\n##  6 2018-12-06 21:18:40 Nathália  5052.  115710402 2018-12-06\n##  7 2018-12-06 20:54:32 Eduardo   5665.  114830203 2018-12-06\n##  8 2018-12-06 20:15:46 Sandra    1474.  116323455 2018-12-06\n##  9 2018-12-06 20:04:35 Armando   8906.  115304382 2018-12-06\n## 10 2018-12-22 20:00:56 Armando  18521.  114513684 2018-12-22\n## # ... with 19,996 more rows## Estrutura básica de um mutate():\n<sua_tabela> %>% \n  mutate(\n    nome_coluna1 = expressao1,\n    nome_coluna2 = expressao2,\n    nome_coluna3 = expressao3,\n    ...\n  )\ntransf %>% \n  select(-Pais, -Descricao) %>%\n  mutate(\n    Desvio = Valor - mean(Valor),\n    Valor_norm = Desvio / sd(Valor)\n  )## # A tibble: 20,006 x 6\n##    Data                Usuario   Valor TransferID Desvio Valor_norm\n##    <dttm>              <chr>     <dbl>      <dbl>  <dbl>      <dbl>\n##  1 2018-12-06 22:19:19 Eduardo    599.  116241629 -2920.     -0.772\n##  2 2018-12-06 22:10:34 Júlio     4611.  115586504  1093.      0.289\n##  3 2018-12-06 21:59:50 Nathália  4418.  115079280   900.      0.238\n##  4 2018-12-06 21:54:13 Júlio     2740.  114972398  -778.     -0.206\n##  5 2018-12-06 21:41:27 Ana       1408.  116262934 -2110.     -0.558\n##  6 2018-12-06 21:18:40 Nathália  5052.  115710402  1534.      0.405\n##  7 2018-12-06 20:54:32 Eduardo   5665.  114830203  2147.      0.568\n##  8 2018-12-06 20:15:46 Sandra    1474.  116323455 -2044.     -0.540\n##  9 2018-12-06 20:04:35 Armando   8906.  115304382  5387.      1.42 \n## 10 2018-12-22 20:00:56 Armando  18521.  114513684 15003.      3.97 \n## # ... with 19,996 more rows\nset.seed(1)\ndf <- tibble(\n  dia = 1:1000,\n  valor = rnorm(1000)\n)\n\nlibrary(RcppRoll)\n\ndf %>% \n  mutate(\n    media_movel = roll_mean(df$valor, n = 5)\n  )Erro: Problem with `mutate()` input `media_movel`.\nx Input `media_movel` can't be recycled to size 1000.\ni Input `media_movel` is `roll_mean(df$valor, n = 5)`.\ni Input `media_movel` must be size 1000 or 1, not 996.\nRun `rlang::last_error()` to see where the error occurred.\ndf %>% \n  mutate(\n    media_movel = roll_mean(valor, n = 5, fill = 0, align = \"right\")\n  )## # A tibble: 1,000 x 3\n##      dia  valor media_movel\n##    <int>  <dbl>       <dbl>\n##  1     1 -0.626      0     \n##  2     2  0.184      0     \n##  3     3 -0.836      0     \n##  4     4  1.60       0     \n##  5     5  0.330      0.129 \n##  6     6 -0.820      0.0905\n##  7     7  0.487      0.151 \n##  8     8  0.738      0.466 \n##  9     9  0.576      0.262 \n## 10    10 -0.305      0.135 \n## # ... with 990 more rows\ndf <- tibble(\n  id = 1:5,\n  x = c(2.5, 1.5, 3.2, 5.1, 2.2),\n  y = c(1, 2, 3, 4, 5)\n)\n\ndf <- df %>% \n  mutate(\n    soma = sum(x),\n    prop = y * 100 / sum(y),\n    um_numero = 25,\n    norm = (x - mean(x)) / sd(x)\n  )\n\ndf## # A tibble: 5 x 7\n##      id     x     y  soma  prop um_numero   norm\n##   <int> <dbl> <dbl> <dbl> <dbl>     <dbl>  <dbl>\n## 1     1   2.5     1  14.5  6.67        25 -0.291\n## 2     2   1.5     2  14.5 13.3         25 -1.02 \n## 3     3   3.2     3  14.5 20           25  0.219\n## 4     4   5.1     4  14.5 26.7         25  1.60 \n## 5     5   2.2     5  14.5 33.3         25 -0.510"},{"path":"transformando-dados-com-dplyr.html","id":"sec:group_by_summarise","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.8 Agrupando dados e gerando estatísticas sumárias com group_by() e summarise()","text":"Em diversas áreas, é muito comum que contenhamos variáveis qualitativas em nossa base de dados. Variáveis desse tipo, usualmente definem grupos ou estratos de uma amostra, população ou medida, como faixas etárias ou faixas de valor salarial. Se você está analisando, por exemplo, dados epidemiológicos, você em geral deseja examinar se uma dada doença está ocorrendo com maior ou menor intensidade em um determinado grupo de sua população.Ou seja, será que fatores como raça, idade, o gênero, orientação sexual ou localidade de um indivíduo são capazes de afetar suas chances de ser infectado por essa doença? De outra maneira, será que essas variáveis qualitativas são capazes de gerar, por exemplo, diferenças salário deste indivíduo? Da mesma forma, quando analisamos performance de determinadas firmas, desejamos saber se localidade, o setor, o tamanho, o investimento e receita total, além número de funcionários dessa firma são capazes de prover alguma vantagem em relação aos seus concorrentes.Para esse tipo de estudo, o pacote dplyr nos oferece função group_by() que fundamentalmente altera o comportamento de funções como mutate() e summarise(), e nos permite calcular estatísticas e aplicarmos operações dentro de cada grupo presente em nossos dados. Como um exemplo inicial, vamos utilizar tabela minas_pop, que contém dados de população e PIB (Produto Interno Bruto) dos 853 municípios estado de Minas Gerais.Como demonstramos na seção anterior, função sum() serve para calcularmos o total de uma coluna inteira. Logo, se aplicássemos função sum() sobre coluna Populacao, teríamos população total estado de Minas Gerais. Porém, e se desejássemos calcular população total de cada uma das regiões intermediárias (presentes na coluna Intermediaria) que compõe o estado de Minas Gerais?Para isso, nós podemos utilizar função group_by() para determinar onde em nossa tabela se encontram os grupos de nossos dados. nosso caso, esses grupos estão na coluna Intermediaria. Dessa forma, após utilizarmos o group_by(), perceba abaixo que os totais calculados pela função sum(), e que estão apresentados na coluna Pop_total, variam ao longo da tabela de acordo com o valor presente na coluna Intermediaria. Logo, temos agora população total de cada região intermediária na coluna Pop_total. Da mesma maneira, ao invés de possuírmos uma proporção baseada na população estado, proporções de cada município expostas na coluna Prop_pop_mun possuem como denominador, população total da região intermediária qual o município pertence.Para verificarmos se os grupos em uma dada tabela estão definidos, podemos observar se descrição Groups se encontra logo abaixo às dimensões da tabela (tibble: 853 x 7). Essa descrição Groups, acaba nos informando coluna (ou o conjunto de colunas) envolvidas nessa definição, além número de grupos que estão contidos em nossa tabela. Logo, pelo resultado exemplo acima, temos 13 grupos, ou 13 regiões intermediárias diferentes presentes na coluna Intermediaria.Como um outro exemplo, dessa vez, em um contexto mais atual, podemos utilizar os dados de COVID-19 presentes na tabela abaixo, denominada covid. Nessa tabela, temos o acumulado número de casos confirmados vírus em cada estado brasileiro, durante o período de 25 de Fevereiro 27 de Julho de 2020.Durante o ano de 2020, Fundação João Pinheiro (FJP) tem oferecido parte de seu corpo técnico para Secretaria Estadual de Saúde, com o objetivo de dar suporte técnico à instituição monitoramento das estatísticas de contaminação e\nimpacto vírus estado de Minas Gerais.Portanto, uma atividade muito comum com os dados da COVID-19, seria calcularmos variação diária número de casos acumulados. Tal cálculo pode ser atingido, através dos valores acumulados na coluna casos, ao subtrairmos valor da linha corrente, o valor da linha anterior nessa mesma coluna. Para incluirmos o valor da linha anterior em nosso cálculo, podemos usar função lag(), como código abaixo:Porém, temos um problema nessa operação, que emerge fato de que não delimitamos os grupos da tabela. Por essa razão, função mutate() vai aplicar expressão casos - lag(casos) sobre toda tabela de uma vez só. O correto, seria que nós aplicássemos essa operação separadamente sobre os dados de cada estado.Dito de outra forma, ao não dizermos que cada estado deveria ser tratado de forma separada dos demais, estamos invadindo os limites de cada estado com o cálculo pertencente outros estados. Em outras palavras, o problema que emerge código anterior, em que não definimos os grupos, se encontra nas linhas que definem os limites entre cada estado, ou linhas que marcam transição entre os dados estado para os dados estado B. Logo, caso não definirmos esses grupos, estaremos utilizando cálculo da variação presente na primeira linha referente ao estado de São Paulo, o número acumulado de casos localizado na última linha pertencente ao estado que vem antes de São Paulo na base (o estado de Sergipe).Por isso, ao utilizarmos função group_by() sobre tabela covid, faremos com que função mutate() esteja consciente dos limites entre os dados de cada estado, e que portanto, respeite esses limites durante o cálculo dessa variação.Agora que vimos função group_by(), podemos prosseguir para função summarise(), que busca sumarizar, sintetizar ou reduzir múltiplos valores de seu data.frame em poucas linhas. Logo, se eu aplicar função summarise() sobre tabela minas_pop, um novo data.frame será gerado, e ele irá conter provavelmente uma única linha. O seu trabalho é definir os valores que vão ocupar esse espaço.Por isso, dentro da função summarise(), devemos fornecer expressões, exatamente da mesma forma que fornecemos em mutate(). Essas expressões vão ser responsáveis por calcular os valores que vão preencher linhas presentes novo data.frame criado. Se expressões delineadas por você gerarem um único valor ou uma única estatística sumária, o novo data.frame resultante de summarise() vai possuir uma única linha, e uma coluna para cada expressão definida. Como exemplo, podemos calcular o somatório total e média da coluna Populacao da seguinte forma:Por outro lado, caso sua expressão produza \\(n\\) valores como resultado, o novo data.frame fabricado por summarise() vai possuir \\(n\\) linhas para alocar esses valores. Em outras palavras, o número de linhas presente data.frame resultante, nesse caso, depende diretamente da quantidade de valores produzidos por sua expressão. Como um exemplo disso, podemos utilizar função quantile() para extrairmos os limites intervalo interquartil (percentis de número 25 e 75) da coluna Populacao.Apesar dessas características, função summarise() é normalmente utilizada em conjunto com função group_by(). Pois ao definirmos os grupos de nossa tabela, função summarise() passa produzir uma linha para cada grupo presente em nossa tabela. Logo, o cálculo da população total e da população média anterior, que produzia uma única linha, passa gerar 13 valores diferentes e, portanto, 13 linhas diferentes ao agruparmos os dados de acordo com coluna Intermediaria. Podemos ainda aplicar função n(), com o objetivo de descobrirmos quantas linhas, ou quantos municípios representam cada região intermediária estado.Neste momento, vale pena comentar também, função count(), que se traduz como um atalho para junção das funções group_by(), summarise() e n(). Logo, ao invés de construirmos toda estrutura de group_by() e summarise(), nós poderíamos rapidamente contabilizar o número de municípios em cada região intermediária, através da função count(), como exemplo abaixo. Lembrando que cada coluna fornecida à count(), será repassada group_by() e, portanto, será responsável por definir os grupos nos quais contagem será aplicada. Logo, se definíssemos função como count(minas_pop, Intermediaria, Ano), estaríamos calculando o número de municípios existentes em cada região intermediária, dentro de um dado ano descrito em nossa tabela.Para além desses pontos, vale destacar que certos momentos em que você necessita de várias colunas para identificar um único grupo de sua tabela, não são incomuns. Por isso, você pode incluir mais de uma coluna dentro da função group_by(). Por exemplo, suponha que você possua na tabela covid, uma coluna que apresenta o mês ao qual cada linha se encontra. Suponha ainda, que você deseja calcular média mensal de novos casos diários em cada estado. Para realizar essa ação, você precisa aplicar o cálculo da média não apenas dentro de cada estado, mas também, dentro de cada mês disponível na base. Logo, precisamos fornecer tanto coluna estado quanto coluna mes à função group_by(), como exemplo abaixo.Perceba também acima, que utilizamos função ungroup() sobre tabela covid_novo, antes de aplicarmos função group_by(). O motivo para tal operação, está fato de que tabela covid_novo já se encontrava agrupada desde o momento em que ela foi criada. Por isso, ao aplicarmos novamente função group_by() com o uso das colunas estado e mes, para redefinirmos os grupos da tabela, precisamos remover definição anterior desses grupos. Sendo esta única ação executada pela função ungroup().Portanto, partir momento em que você “terminou” de utilizar operações “por grupo” em sua tabela, e deseja ignorar novamente esses grupos em suas próximas etapas, você deve retirar definição dos grupos de sua tabela, por meio da função ungroup().","code":"\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo <- \"populacao.csv\"\n\nminas_pop <- read_csv2(paste0(github, pasta, arquivo))## # A tibble: 853 x 7\n##    IBGE2   IBGE Munic               Populacao   Ano      PIB Intermediaria\n##    <dbl>  <dbl> <chr>                   <dbl> <dbl>    <dbl> <chr>        \n##  1    10 310010 Abadia dos Dourados      6972  2017 33389769 Uberlândia   \n##  2    20 310020 Abaeté                  23223  2017 96201158 Divinópolis  \n##  3    30 310030 Abre Campo              13465  2017 29149429 Juíz de Fora \n##  4    40 310040 Acaiaca                  3994  2017  2521892 Juíz de Fora \n##  5    50 310050 Açucena                  9575  2017 15250077 Ipatinga     \n##  6    60 310060 Água Boa                13600  2017 29988906 Teófilo Otoni\n##  7    70 310070 Água Comprida            2005  2017 74771408 Uberaba      \n##  8    80 310080 Aguanil                  4448  2017 15444038 Varginha     \n##  9    90 310090 Águas Formosas          19166  2017 11236696 Teófilo Otoni\n## 10   100 310100 Águas Vermelhas         13477  2017 48088397 Teófilo Otoni\n## # ... with 843 more rows\nminas_pop %>% \n  select(-Ano, -PIB) %>% \n  group_by(Intermediaria) %>% \n  mutate(\n    Pop_total = sum(Populacao),\n    Prop_pop_mun = Populacao * 100 / Pop_total\n  )## # A tibble: 853 x 7\n## # Groups:   Intermediaria [13]\n##    IBGE2   IBGE Munic        Populacao Intermediaria Pop_total Prop_pop_mun\n##    <dbl>  <dbl> <chr>            <dbl> <chr>             <dbl>        <dbl>\n##  1    10 310010 Abadia dos ~      6972 Uberlândia      1161513        0.600\n##  2    20 310020 Abaeté           23223 Divinópolis     1300658        1.79 \n##  3    30 310030 Abre Campo       13465 Juíz de Fora    2334530        0.577\n##  4    40 310040 Acaiaca           3994 Juíz de Fora    2334530        0.171\n##  5    50 310050 Açucena           9575 Ipatinga        1022384        0.937\n##  6    60 310060 Água Boa         13600 Teófilo Otoni   1222050        1.11 \n##  7    70 310070 Água Compri~      2005 Uberaba          800412        0.250\n##  8    80 310080 Aguanil           4448 Varginha        1634643        0.272\n##  9    90 310090 Águas Formo~     19166 Teófilo Otoni   1222050        1.57 \n## 10   100 310100 Águas Verme~     13477 Teófilo Otoni   1222050        1.10 \n## # ... with 843 more rows\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo <- \"covid.csv\"\n\ncovid <- read_csv2(paste0(github, pasta, arquivo))## # A tibble: 3,625 x 4\n##    data       estado casos mortes\n##    <date>     <chr>  <dbl>  <dbl>\n##  1 2020-03-17 AC         3      0\n##  2 2020-03-18 AC         3      0\n##  3 2020-03-19 AC         4      0\n##  4 2020-03-20 AC         7      0\n##  5 2020-03-21 AC        11      0\n##  6 2020-03-22 AC        11      0\n##  7 2020-03-23 AC        17      0\n##  8 2020-03-24 AC        21      0\n##  9 2020-03-25 AC        23      0\n## 10 2020-03-26 AC        23      0\n## # ... with 3,615 more rows\ncovid %>%\n  mutate(\n    casos_var = casos - lag(casos),\n    mortes_var = mortes - lag(mortes)\n  )\ncovid_novo <- covid %>%\n  group_by(estado) %>% \n  mutate(\n    casos_var = casos - lag(casos),\n    mortes_var = mortes - lag(mortes)\n  )\n\ncovid_novo ## # A tibble: 3,625 x 6\n## # Groups:   estado [27]\n##    data       estado casos mortes casos_var mortes_var\n##    <date>     <chr>  <dbl>  <dbl>     <dbl>      <dbl>\n##  1 2020-03-17 AC         3      0        NA         NA\n##  2 2020-03-18 AC         3      0         0          0\n##  3 2020-03-19 AC         4      0         1          0\n##  4 2020-03-20 AC         7      0         3          0\n##  5 2020-03-21 AC        11      0         4          0\n##  6 2020-03-22 AC        11      0         0          0\n##  7 2020-03-23 AC        17      0         6          0\n##  8 2020-03-24 AC        21      0         4          0\n##  9 2020-03-25 AC        23      0         2          0\n## 10 2020-03-26 AC        23      0         0          0\n## # ... with 3,615 more rows\nminas_pop %>% \n  summarise(\n    total_pop = sum(Populacao),\n    media_pop = mean(Populacao)\n  )## # A tibble: 1 x 2\n##   total_pop media_pop\n##       <dbl>     <dbl>\n## 1  21040662    24667.\nminas_pop %>% \n  summarise(iqr = quantile(Populacao, probs = c(0.25, 0.75)))## # A tibble: 2 x 1\n##     iqr\n##   <dbl>\n## 1  4844\n## 2 17739\nminas_pop %>% \n  group_by(Intermediaria) %>% \n  summarise(\n    total_pop = sum(Populacao),\n    media_pop = mean(Populacao),\n    numero_municipios = n()\n  )## # A tibble: 13 x 4\n##    Intermediaria        total_pop media_pop numero_municipios\n##    <chr>                    <dbl>     <dbl>             <int>\n##  1 Barbacena               772694    15769.                49\n##  2 Belo Horizonte         6237890    84296.                74\n##  3 Divinópolis            1300658    21322.                61\n##  4 Governador Valadares    771775    13306.                58\n##  5 Ipatinga               1022384    23236                 44\n##  6 Juíz de Fora           2334530    15990.               146\n##  7 Montes Claros          1673263    19457.                86\n##  8 Patos de Minas          819435    24101.                34\n##  9 Pouso Alegre           1289415    16118.                80\n## 10 Teófilo Otoni          1222050    14210.                86\n## 11 Uberaba                 800412    27600.                29\n## 12 Uberlândia             1161513    48396.                24\n## 13 Varginha               1634643    19935.                82\nminas_pop %>% count(Intermediaria)## # A tibble: 13 x 2\n##    Intermediaria            n\n##    <chr>                <int>\n##  1 Barbacena               49\n##  2 Belo Horizonte          74\n##  3 Divinópolis             61\n##  4 Governador Valadares    58\n##  5 Ipatinga                44\n##  6 Juíz de Fora           146\n##  7 Montes Claros           86\n##  8 Patos de Minas          34\n##  9 Pouso Alegre            80\n## 10 Teófilo Otoni           86\n## 11 Uberaba                 29\n## 12 Uberlândia              24\n## 13 Varginha                82\n## ----------------------------------------\n## Sem o uso de pipe ( %>% ) teríamos:\ncount(minas_pop, Intermediaria)\ncovid_novo %>% \n  ungroup() %>% \n  mutate(mes = as.integer(format(data, \"%m\"))) %>% \n  group_by(estado, mes) %>% \n  summarise(\n    media_novos_casos = mean(casos_var, na.rm = T)\n  )## `summarise()` has grouped output by 'estado'. You can override using the `.groups` argument.## # A tibble: 136 x 3\n## # Groups:   estado [27]\n##    estado   mes media_novos_casos\n##    <chr>  <int>             <dbl>\n##  1 AC         3              2.79\n##  2 AC         4             12.1 \n##  3 AC         5            188.  \n##  4 AC         6            234.  \n##  5 AC         7            205.  \n##  6 AL         3              0.85\n##  7 AL         4             34.2 \n##  8 AL         5            298.  \n##  9 AL         6            856.  \n## 10 AL         7            750.  \n## # ... with 126 more rows"},{"path":"transformando-dados-com-dplyr.html","id":"a-função-across-como-a-grande-novidade","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.9 A função across() como a grande novidade","text":"função across() foi uma das grandes novidades introduzidas em uma versão recente pacote dplyr (Wickham 2020). Essa função lhe permite aplicar os métodos de seleção que vimos em select(), dentro dos demais verbos expostos (funções mutate(), summarise() e arrange()). Para mais, o principal objetivo dessa função está em prover uma maneira muito mais prática de empregarmos uma mesma operação ao longo de várias colunas.Por exemplo, suponha que você desejasse logaritmizar todas colunas numéricas da tabela mpg. Temos então, que aplicar mesma operação sobre 5 colunas diferentes, mais especificamente, colunas displ, year, cyl, cty e hwy. Com o que vimos até o momento, você provavelmente faria tal ação da seguinte forma:Porém, além de tedioso, repetição envolvida nesse tipo de solução, incorre em uma grande chance de erro de nossa parte. Pois os nossos olhos tendem prestar atenção que é diferente dos demais, que se destaca ambiente, e não sobre blocos e blocos de comandos que são basicamente idênticos.Com isso, função across() provê um excelente mecanismo para automatizarmos essa aplicação. Nessa função, temos dois argumentos principais serem preenchidos: 1).cols, que representa o conjunto de colunas onde ação desejada será aplicada; 2) .fns, função ou expressão que será empregada em cada coluna (neste argumento, você pode fornecer apenas o nome da função). Com isso, poderíamos reescrever operação anterior como:Portanto, em across() você é capaz de aplicar qualquer um dos 5 métodos que vimos em select(). Como um outro exemplo, podemos aplicar função log() sobre qualquer coluna que se inicie pela letra “h,” com o comando abaixo:Por outro lado, caso você necessite aplicar várias funções em cada coluna, é melhor que você crie uma nova função (partir da palavra-chave function) dentro de across(), contendo operações que você deseja aplicar. Pois dessa maneira, você possui um melhor controle sobre em que partes cálculo, os valores de cada coluna serão posicionados.Por exemplo, podemos normalizar todas colunas numéricas da tabela mpg, por uma estatística Z. Perceba abaixo, que nesse caso, precisamos utilizar o valor da coluna em 3 ocasiões: duas vezes numerador, para calcularmos o desvio de cada valor da coluna em relação sua média; e uma vez denominador, para calcularmos o desvio padrão. Repare também, que ao menos quatro funções são utilizadas dentro desse cálculo: funções mean() e sd(), além dos operadores de subtração (-) e de divisão (/).Com isso, função summarise() também se torna um local extremamente útil para o emprego da função across(). Pois através de across(), nós podemos rapidamente aplicar uma função sobre cada coluna que desejamos sintetizar com summarise(). Por exemplo, somos capazes de extrair o valor total de todas colunas numéricas da tabela mpg, por meio dos seguintes comandos:","code":"\nmpg %>% \n  mutate(\n    displ = log(displ),\n    year = log(year),\n    cyl = log(cyl),\n    cty = log(cty),\n    hwy = log(hwy)\n  )\n## Aplicar log() na terceira, quarta,\n## quinta, oitava e nona coluna da tabela mpg:\nmpg %>% \n  mutate(across(.cols = c(3:5, 8:9), .fns = log))## # A tibble: 234 x 11\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <dbl> <dbl> <chr> <chr> <dbl> <dbl> <chr> <chr>\n##  1 audi         a4    0.588  7.60  1.39 auto~ f      2.89  3.37 p     comp~\n##  2 audi         a4    0.588  7.60  1.39 manu~ f      3.04  3.37 p     comp~\n##  3 audi         a4    0.693  7.60  1.39 manu~ f      3.00  3.43 p     comp~\n##  4 audi         a4    0.693  7.60  1.39 auto~ f      3.04  3.40 p     comp~\n##  5 audi         a4    1.03   7.60  1.79 auto~ f      2.77  3.26 p     comp~\n##  6 audi         a4    1.03   7.60  1.79 manu~ f      2.89  3.26 p     comp~\n##  7 audi         a4    1.13   7.60  1.79 auto~ f      2.89  3.30 p     comp~\n##  8 audi         a4 q~ 0.588  7.60  1.39 manu~ 4      2.89  3.26 p     comp~\n##  9 audi         a4 q~ 0.588  7.60  1.39 auto~ 4      2.77  3.22 p     comp~\n## 10 audi         a4 q~ 0.693  7.60  1.39 manu~ 4      3.00  3.33 p     comp~\n## # ... with 224 more rows\nmpg %>% \n  mutate(across(.cols = starts_with(\"h\"), .fns = log))## # A tibble: 234 x 11\n##    manufacturer model displ  year   cyl trans drv     cty   hwy fl    class\n##    <chr>        <chr> <dbl> <int> <int> <chr> <chr> <int> <dbl> <chr> <chr>\n##  1 audi         a4      1.8  1999     4 auto~ f        18  3.37 p     comp~\n##  2 audi         a4      1.8  1999     4 manu~ f        21  3.37 p     comp~\n##  3 audi         a4      2    2008     4 manu~ f        20  3.43 p     comp~\n##  4 audi         a4      2    2008     4 auto~ f        21  3.40 p     comp~\n##  5 audi         a4      2.8  1999     6 auto~ f        16  3.26 p     comp~\n##  6 audi         a4      2.8  1999     6 manu~ f        18  3.26 p     comp~\n##  7 audi         a4      3.1  2008     6 auto~ f        18  3.30 p     comp~\n##  8 audi         a4 q~   1.8  1999     4 manu~ 4        18  3.26 p     comp~\n##  9 audi         a4 q~   1.8  1999     4 auto~ 4        16  3.22 p     comp~\n## 10 audi         a4 q~   2    2008     4 manu~ 4        20  3.33 p     comp~\n## # ... with 224 more rows\nmpg %>% \n  mutate(across(\n    .cols = where(is.numeric),\n    .fns = function(x) x - mean(x) / sd(x)\n  ))## # A tibble: 234 x 11\n##    manufacturer model     displ  year   cyl trans   drv     cty   hwy fl   \n##    <chr>        <chr>     <dbl> <dbl> <dbl> <chr>   <chr> <dbl> <dbl> <chr>\n##  1 audi         a4       -0.887 1555. 0.346 auto(l~ f      14.0  25.1 p    \n##  2 audi         a4       -0.887 1555. 0.346 manual~ f      17.0  25.1 p    \n##  3 audi         a4       -0.687 1564. 0.346 manual~ f      16.0  27.1 p    \n##  4 audi         a4       -0.687 1564. 0.346 auto(a~ f      17.0  26.1 p    \n##  5 audi         a4        0.113 1555. 2.35  auto(l~ f      12.0  22.1 p    \n##  6 audi         a4        0.113 1555. 2.35  manual~ f      14.0  22.1 p    \n##  7 audi         a4        0.413 1564. 2.35  auto(a~ f      14.0  23.1 p    \n##  8 audi         a4 quat~ -0.887 1555. 0.346 manual~ 4      14.0  22.1 p    \n##  9 audi         a4 quat~ -0.887 1555. 0.346 auto(l~ 4      12.0  21.1 p    \n## 10 audi         a4 quat~ -0.687 1564. 0.346 manual~ 4      16.0  24.1 p    \n## # ... with 224 more rows, and 1 more variable: class <chr>\nmpg %>% \n  group_by(cyl) %>% \n  summarise(across(\n    .cols = where(is.numeric),\n    .fns = sum\n  ))## # A tibble: 4 x 5\n##     cyl displ   year   cty   hwy\n##   <int> <dbl>  <int> <int> <int>\n## 1     4  174. 162243  1702  2333\n## 2     5   10    8032    82   115\n## 3     6  269. 158227  1281  1803\n## 4     8  359. 140317   880  1234"},{"path":"transformando-dados-com-dplyr.html","id":"removendo-duplicatas-com-distinct","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.10 Removendo duplicatas com distinct()","text":"vezes, os nossos dados chegam com algum erro de registro, e usualmente, esse erro se manifesta na forma de registros duplicados. Nessa seção, veremos o uso da função distinct() como um mecanismo útil para eliminarmos observações duplicadas em sua tabela. Como um exemplo inicial, podemos utilizar tabela ponto, criada pelos comandos abaixo:Inicialmente, função distinct() funciona da mesma maneira que função unique(). Porém, função unique() pode ser aplicada em praticamente qualquer tipo de estrutura, além tipo de estrutura adotado em seu resultado, variar em diversas aplicações. Enquanto isso, função distinct() (assim como demais funções pacote dplyr) irá sempre aceitar um data.frame como input e gerar um novo data.frame como output. Logo, se aplicarmos distinct() sobre tabela ponto, temos o seguinte resultado:Repare pelo produto acima, que função distinct() eliminou segunda linha da tabela ponto, pois essa era uma duplicata da primeira linha. Para mais, função distinct() nos permite aplicar função sobre colunas específicas data.frame em questão. exemplo acima, nós omitimos essa funcionalidade, e pedimos para que função distinct() fosse aplicada sobre toda tabela. Isso significa, que ao não definirmos uma coluna ou um conjunto de colunas em particular, distinct() vai utilizar combinação dos valores de todas colunas para determinar os valores únicos presentes em sua tabela e, portanto, eliminar os valores duplicados segundo essa abordagem.Como exemplo, podemos aplicar função sobre colunas usuario e tipo. Dessa forma, distinct() nos retorna um novo data.frame contendo os valores únicos presentes nessas colunas. entanto, perceba que um efeito colateral foi gerado, pois nós perdemos todas demais colunas da tabela ponto durante o processo. Isso ocorre em todas ocasiões em que listamos uma combinação de colunas em distinct(). Para evitar esse comportamento, você pode definir o argumento .keep_all para TRUE, como exemplo abaixo.Com isso, se desejamos eliminar os valores duplicados em nossas tabelas, podemos rapidamente aplicar função distinct() sobre toda tabela. Contudo, haverá momentos em que combinações específicas de colunas devem ser utilizadas para determinarmos observações únicas da tabela, ao invés de todas colunas disponíveis. Para isso, você deve listar os nomes das colunas serem utilizadas pela função distinct() neste processo. Além disso, você geralmente vai desejar utilizar configuração .keep_all = TRUE durante essa situação, com o objetivo de conservar demais colunas da tabela resultado de distinct().Ademais, lembre-se que você pode utilizar função across() para ter acesso aos mecanismos de seleção de select(), para definir o conjunto de colunas ser empregado por distinct(). Por exemplo, eu posso encontrar todos os valores únicos criados pela combinação entre colunas dia e tipo, por meio seguinte comando:","code":"\nponto <- tibble(\n  usuario = \"Ana\",\n  dia = c(1, 1, 1, 2, 2),\n  hora = c(14, 14, 18, 8, 13),\n  minuto = c(30, 30, 50, 0, 30),\n  tipo = c(\"E\", \"E\", \"S\", \"E\", \"E\"),\n  mes = 3,\n  ano = 2020\n)\n\nponto## # A tibble: 5 x 7\n##   usuario   dia  hora minuto tipo    mes   ano\n##   <chr>   <dbl> <dbl>  <dbl> <chr> <dbl> <dbl>\n## 1 Ana         1    14     30 E         3  2020\n## 2 Ana         1    14     30 E         3  2020\n## 3 Ana         1    18     50 S         3  2020\n## 4 Ana         2     8      0 E         3  2020\n## 5 Ana         2    13     30 E         3  2020\nponto_dis <- distinct(ponto)\n\nponto_dis## # A tibble: 4 x 7\n##   usuario   dia  hora minuto tipo    mes   ano\n##   <chr>   <dbl> <dbl>  <dbl> <chr> <dbl> <dbl>\n## 1 Ana         1    14     30 E         3  2020\n## 2 Ana         1    18     50 S         3  2020\n## 3 Ana         2     8      0 E         3  2020\n## 4 Ana         2    13     30 E         3  2020\nponto_dis <- distinct(ponto, usuario, tipo)\n\nponto_dis## # A tibble: 2 x 2\n##   usuario tipo \n##   <chr>   <chr>\n## 1 Ana     E    \n## 2 Ana     S\nponto_dis <- distinct(ponto, usuario, tipo, .keep_all = TRUE)\n\nponto_dis## # A tibble: 2 x 7\n##   usuario   dia  hora minuto tipo    mes   ano\n##   <chr>   <dbl> <dbl>  <dbl> <chr> <dbl> <dbl>\n## 1 Ana         1    14     30 E         3  2020\n## 2 Ana         1    18     50 S         3  2020\ndistinct(ponto, across(c(2, 5)), .keep_all = TRUE)## # A tibble: 3 x 7\n##   usuario   dia  hora minuto tipo    mes   ano\n##   <chr>   <dbl> <dbl>  <dbl> <chr> <dbl> <dbl>\n## 1 Ana         1    14     30 E         3  2020\n## 2 Ana         1    18     50 S         3  2020\n## 3 Ana         2     8      0 E         3  2020"},{"path":"transformando-dados-com-dplyr.html","id":"combinando-tabelas-com-bind_cols-e-bind_rows","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"4.11 Combinando tabelas com bind_cols() e bind_rows()","text":"Os pacotes básicos R oferecem funções rbind() e cbind(), que lhe permite combinar objetos. Porém, o pacote dplyr oferece implementações mais rápidas e completas desse mecanismo, através das funções bind_cols() e bind_rows(). mesmo modo que demais funções pacote, bind_cols() e bind_rows() aceitam um conjunto de data.frame’s como input, e lhe retornam um novo data.frame como output.Como exemplo inicial, suponha que você possua o conjunto de tabelas abaixo. Essas tabelas contém dados das vendas de três lojas diferentes.Supondo que você seja um analista da empresa dona dessas lojas, e que foi delegado você, tarefa de analisar os dados dessas tabelas, você terá mínimo o triplo de trabalho, caso mantenha essas tabelas separadas. Pois cada etapa de sua análise teria de ser replicar em três lugares diferentes. Por isso, melhor opção é reunir essas tabelas em um lugar só. Pois dessa maneira, você precisa aplicar suas operações em um único lugar.Ou seja, motivação para o uso das funções bind_rows() e bind_cols(), surge em geral, partir da dificuldade que temos em aplicar mesma função em diversos pontos de nosso trabalho, além da manutenção e monitoramento dos resultados gerados em cada um desses pontos envolvidos nesse serviço. Portanto, se você possui um grande conjunto de tabelas, que são semelhantes entre si, e você precisa aplicar os mesmos passos sobre cada uma delas, é interessante que você tente juntar essas tabelas em uma só. Dessa maneira, você pode direcionar o seu foco e suas energias para um só local.Como tabelas savassi, prado e centro possuem mesmas colunas, faz mais sentido unirmos linhas de cada tabela para formarmos nossa tabela única. Para isso, basta listarmos essas tabelas dentro da função bind_rows(), como demonstrado abaixo. Uma outra opção, seria provermos uma lista de data.frame’s à função, o que também está demonstrado abaixo:Portanto, ao unir linhas de cada tabela, função bind_rows() está de certa forma “empilhando” uma tabela em cima da outra. Mas para que este tipo de operação ocorra de maneira adequada, é importante que colunas de todas tabelas estejam nomeadas igualmente. Dito de outra forma, tabelas envolvidas nesse cálculo, devem ser formadas pelo mesmo grupo de colunas. Essas colunas podem se encontrar em ordens diferentes ao longo das tabelas, mas elas precisam necessariamente estar nomeadas da mesma maneira. Caso alguma coluna em pelo menos uma das tabelas possua um nome diferente de seus pares, função vai alocar os seus valores em uma coluna separada das demais, e isso geralmente não é o que você deseja.Por outro lado, quando estamos planejando unir tabelas partir de suas colunas, nossa preocupação principal deve ser com o número de linhas de cada tabela. Com isso, quando utilizar função bind_cols(), é essencial que tabelas envolvidas possuam exatamente o mesmo número de linhas. Ou seja, caso da função bind_cols(), é primordial que tabelas fornecidas à função, possuam o mesmo número de linhas, pois caso contrário, um erro será acionado pela função, e você não poderá prosseguir.Tendo esse ponto em mente, você utiliza função bind_cols() mesmo modo que função bind_rows(). Basta listar tabelas serem unidas dentro da função, ou fornecer uma lista contendo os data.frame’s serem fundidos. Veja abaixo, um exemplo com tabelas tab1 e tab2.","code":"\nsavassi <- tibble(\n  dia = as.Date(c(\"2020-03-01\", \"2020-03-02\", \"2020-03-03\",\n                  \"2020-03-04\")),\n  produtoid = c(\"10241\", \"10241\", \"10032\", \"15280\"),\n  loja = \"Savassi\",\n  unidades = c(1, 2, 1, 1),\n  valor = c(15.5, 31, 12.4, 16.7)\n)\n\nprado <- tibble(\n  dia = as.Date(c(\"2020-03-10\", \"2020-03-11\", \"2020-03-12\")),\n  produtoid = c(\"15280\", \"10032\", \"10032\"),\n  loja = \"Prado\",\n  unidades = c(3, 4, 2),\n  valor = c(50.1, 49.6, 24.8)\n)\n\ncentro <- tibble(\n  dia = as.Date(c(\"2020-03-07\", \"2020-03-10\", \"2020-03-12\")),\n  produtoid = c(\"15280\", \"15280\", \"15280\"),\n  loja = \"Centro\",\n  unidades = c(5, 1, 1),\n  valor = c(83.5, 16.7, 16.7)\n)\nbind_rows(savassi, prado, centro)## # A tibble: 10 x 5\n##    dia        produtoid loja    unidades valor\n##    <date>     <chr>     <chr>      <dbl> <dbl>\n##  1 2020-03-01 10241     Savassi        1  15.5\n##  2 2020-03-02 10241     Savassi        2  31  \n##  3 2020-03-03 10032     Savassi        1  12.4\n##  4 2020-03-04 15280     Savassi        1  16.7\n##  5 2020-03-10 15280     Prado          3  50.1\n##  6 2020-03-11 10032     Prado          4  49.6\n##  7 2020-03-12 10032     Prado          2  24.8\n##  8 2020-03-07 15280     Centro         5  83.5\n##  9 2020-03-10 15280     Centro         1  16.7\n## 10 2020-03-12 15280     Centro         1  16.7\n## ------------------------------------------------\n## Uma alternativa seria fornecermos uma lista\n## contendo as tabelas a serem unidas:\n\nlista <- list(savassi, prado, centro)\n\nbind_rows(lista)\ncolnames(centro)[2:3] <- c(\"ProdutoID\", \"Loja\")\n\nbind_rows(savassi, prado, centro)## # A tibble: 10 x 7\n##    dia        produtoid loja    unidades valor ProdutoID Loja  \n##    <date>     <chr>     <chr>      <dbl> <dbl> <chr>     <chr> \n##  1 2020-03-01 10241     Savassi        1  15.5 <NA>      <NA>  \n##  2 2020-03-02 10241     Savassi        2  31   <NA>      <NA>  \n##  3 2020-03-03 10032     Savassi        1  12.4 <NA>      <NA>  \n##  4 2020-03-04 15280     Savassi        1  16.7 <NA>      <NA>  \n##  5 2020-03-10 15280     Prado          3  50.1 <NA>      <NA>  \n##  6 2020-03-11 10032     Prado          4  49.6 <NA>      <NA>  \n##  7 2020-03-12 10032     Prado          2  24.8 <NA>      <NA>  \n##  8 2020-03-07 <NA>      <NA>           5  83.5 15280     Centro\n##  9 2020-03-10 <NA>      <NA>           1  16.7 15280     Centro\n## 10 2020-03-12 <NA>      <NA>           1  16.7 15280     Centro\ntab1 <- tibble(\n  dia = 1:5,\n  valor = round(rnorm(5), 2)\n)\n\ntab2 <- tibble(\n  id = c(\"104\", \"104\", \"105\", \"106\", \"106\"),\n  nome = \"Ana\"\n)\n\nbind_cols(tab1, tab2)## # A tibble: 5 x 4\n##     dia valor id    nome \n##   <int> <dbl> <chr> <chr>\n## 1     1  0.35 104   Ana  \n## 2     2 -0.17 104   Ana  \n## 3     3 -0.59 105   Ana  \n## 4     4 -1.33 106   Ana  \n## 5     5 -1.1  106   Ana\n## ------------------------------------------------\n## Uma alternativa seria fornecermos uma lista\n## contendo as tabelas a serem unidas:\n\nlista <- list(tab1, tab2)\n\nbind_cols(lista)"},{"path":"transformando-dados-com-dplyr.html","id":"exercícios-3","chapter":"Capítulo 4 Transformando dados com dplyr","heading":"Exercícios","text":"Uma excelente forma de exercitar os conhecimentos adquiridos nesse capítulo é simplesmente brincar com bases de dados diferentes! Simplesmente, brinque! Tente encontrar fatos curiosos sobre cada base de dados. Faça perguntas (quantas pessoas se encaixam nessa categoria? Quantas mensagens foram enviadas durante esse dia? Qual é o custo médio de um curso de Medicina nos EUA?) e tente respondê-las com funções que você descobriu nesse capítulo.Por isso, maioria dos exercícios seguir são exercícios práticos, que pedem por uma informação específica respeito dos dados contidos em uma determinada tabela (isto é, um data.frame). Para chegar essa informação, você pode utilizar funções pacote dplyr. O código necessário para ter acesso cada uma dessas tabelas será fornecido em cada questão.O projeto TidyTuesday é um ótimo lugar para encontrarmos diferentes bases de dados. Pois todas essas bases estão hospedadas na pasta projeto GitHub, e grande parte delas estão guardadas em arquivos de texto (.txt, .csv, .fwf, etc.), os quais podemos ler e importar diretamente da página GitHub para o R, sem necessidade de baixar arquivos manualmente. Em resumo, o Tidy Tuesday é um projeto onde os integrantes disponibilizam toda semana, uma base de dados diferente. Qualquer pessoa pode submeter uma base de dados para o projeto, incluindo ou não, artigos e materiais que possam instruir os usuários sobre como analizar e compreender os dados contidos nessa base.Questão 4.1. Antes de partirmos para questões práticas, vamos exercitar o seu conhecimento sobre cada função mostrada nesse capítulo. Em cada item abaixo, eu forneço um conjunto de comandos. Cada conjunto inclui funções pacote dplyr (como filter(), mutate(), group_by(), etc.) e uma tabela específica logo início dessa cadeia de comandos, além operador pipe (%>%) conectando cada uma das funções aplicadas. Seu trabalho é ler esse conjunto de comandos, e descrever mentalmente (ou escrever em algum papel) o que cada uma das funções aplicadas está fazendo nessa cadeia. Em outras palavras, seu objetivo é descrever o papel que cada função desempenha nessa cadeia de comandos.4.1.) Descreva os comandos abaixo:4.1.B) Descreva os comandos abaixo:4.1.C) Descreva os comandos abaixo:Questão 4.2. Vamos começar pela base tuition_income.csv, referente semana 11 TidyTuesday em 2020. Com os comandos abaixo, você pode rapidamente importar essa base de dados para o seu R. Os dados contidos nessa base, descrevem um conjunto de universidades dos Estados Unidos durante o perído de 2010 2018, e oferecendo informações como: nome da faculdade/universidade (name); estado em que ela se encontra (state); preço ou custo total (em dólares) exigido pela graduação na instituição (total_price); ano ao qual os valores se referem (year); fica localizada dentro campus ou fora dele? (campus); custo total líquido (custo total menos bolsas de auxílio e prêmios) pago pela graduação na instituição (net_cost).4.2.) Com esses dados em mão, tente descobrir 10 universidades que sofreram os maiores aumentos de preços durante o período descrito na base.4.2.B) Dado que você descubra universidade que sofreu o maior aumento de preço dentre 10 universidades descritas item anterior, procure pelos dados dessa universidade ao longo da base. Com esses dados, discuta o momento em que houve variação. Não tem resposta certa ou errada, apenas encontre os dados dessa universidade na base, e dê sua opinião sobre tamanha variação preço dessa universidade.Questão 4.3. Caso você tenha chamado pelo pacote dplyr com sucesso em sua sessão, através comando library(), você tem acesso à tabela starwars, que é utilizada nessa questão. Tendo tabela starwars em mãos, da coluna 1 até coluna 11, descubra qual coluna tipo character que possui o maior número de valores únicos (ou o maior número de “grupos”) ao longo da base.Questão 4.4. Vamos agora, voltar rapidamente para base de dados transf que visitamos ao longo deste capítulo. Lembre-se que você pode importar essa base diretamente para o seu R, ao copiar e colar os comandos abaixo.4.4.) Qual é receita média que o atendente Eduardo realiza com transferências destinadas à Alemanha?4.4.B) Qual é o país de destino com o qual atendente Ana mais trabalha?4.4.C) Descubra quais foram últimas transferências executadas por cada um dos 8 atendentes presentes em transf. Lembre-se que coluna Data fornece o ponto tempo em que transferência foi executada.","code":"\nstarwars %>% \n  count(sex, eye_color) %>% \n  filter(sex == \"male\", eye_color == \"red\")\nvec <- c(\"species\", \"homeworld\", \"films\", \"vehicles\", \"starships\")\n\nstarwars %>% \n  select(-all_of(vec)) %>% \n  group_by(sex) %>% \n  summarise(peso_medio = mean(mass, na.rm = TRUE))\nmpg %>% \n  mutate(\n    pais_origem = case_when(\n      manufacturer %in% c(\"audi\", \"volkswagen\") ~ \"Alemanha\",\n      manufacturer %in% c(\"nissan\", \"honda\",\n                          \"subaru\", \"toyota\") ~ \"Japão\",\n      manufacturer == \"hyundai\" ~ \"Coréia do Sul\",\n      manufacturer == \"land rover\" ~ \"Inglaterra\",\n      manufacturer %in% c(\"dodge\", \"jeep\", \n                          \"chevrolet\", \"ford\",\n                          \"lincoln\", \"pontiac\",\n                          \"mercury\") ~ \"EUA\"\n    )\n  ) %>% \n  count(pais_origem) %>% \n  mutate(\n    prop = ( n * 100 ) / sum(n)\n  )\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/rfordatascience/\"\narquivo <- \"tidytuesday/master/data/2020/2020-03-10/tuition_income.csv\"\n\ndados <- read_csv(paste0(github, arquivo))\nstarwars## # A tibble: 87 x 14\n##    name      height  mass hair_color  skin_color eye_color birth_year sex  \n##    <chr>      <int> <dbl> <chr>       <chr>      <chr>          <dbl> <chr>\n##  1 Luke Sky~    172    77 blond       fair       blue            19   male \n##  2 C-3PO        167    75 <NA>        gold       yellow         112   none \n##  3 R2-D2         96    32 <NA>        white, bl~ red             33   none \n##  4 Darth Va~    202   136 none        white      yellow          41.9 male \n##  5 Leia Org~    150    49 brown       light      brown           19   fema~\n##  6 Owen Lars    178   120 brown, grey light      blue            52   male \n##  7 Beru Whi~    165    75 brown       light      blue            47   fema~\n##  8 R5-D4         97    32 <NA>        white, red red             NA   none \n##  9 Biggs Da~    183    84 black       light      brown           24   male \n## 10 Obi-Wan ~    182    77 auburn, wh~ fair       blue-gray       57   male \n## # ... with 77 more rows, and 6 more variables: gender <chr>,\n## #   homeworld <chr>, species <chr>, films <list>, vehicles <list>,\n## #   starships <list>\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo <- \"transf_reform.csv\"\n\ntransf <- read_csv2(paste0(github, pasta, arquivo))"},{"path":"funções-e-loops-no-r.html","id":"funções-e-loops-no-r","chapter":"Capítulo 5 Funções e Loops no R","heading":"Capítulo 5 Funções e Loops no R","text":"","code":""},{"path":"funções-e-loops-no-r.html","id":"introdução","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.1 Introdução","text":"Neste capítulo, veremos apenas uma introdução de como você pode criar suas próprias funções R, e automatizar alguns passos utilizando loop’s. É importante frisar que início pode ser bem difícil de implementar sua função. Isso ocorre principalmente, porque funções quando executadas, rodam em um ambiente diferente seu.Você talvez tenha ficado confuso com essa afirmativa, se perguntando: “O que diabos você quer dizer com um ambiente diferente?” O R não só é uma linguagem que trabalha com objetos, mas ele também é uma linguagem que trabalha com objetos que estão guaradados em ambientes específicos. Os ambientes R são comumente chamados por environments. Vamos descrevê-los em mais detalhes na próxima seção.Tudo o que você precisa entender agora, é que todas operações que uma função realiza, ocorrem de forma implícita, em um local onde você não consegue ver cada uma dessas operações. É essa característica que torna bem difícil início, criação de funções pelo usuário. Ao tentar implementar sua função pela primeira vez, você vai enfrentar quase sempre, algum erro. E pelo fato de você não conseguir acompanhar cálculo por cálculo da função, quando um erro aparece, principal pergunta que você se faz é: “De onde este erro está vindo? Em que lugar da minha função ele ocorre?”Tendo essas considerações em mente, vou mostrar aqui como você pode começar montar suas próprias funções, dando algumas dicas de como enfrentar erros, e quais são formas de organizá-las, para que você não se perca meio processo.","code":""},{"path":"funções-e-loops-no-r.html","id":"sec:environments","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.2 Noções básicas de environments","text":"O R é não apenas uma linguagem que trabalha com objetos, mas também é uma linguagem que trabalha com objetos que estão contidos (ou guardados) em certos environments. Um environment (ou ambiente) R, é parecido com uma lista nomeada, onde cada nome mantido nessa lista é único. Sendo que esses nomes dispostos em uma espécie de lista, nada mais são que os nomes dos objetos que estão guardados e disponíveis nesse respectivo environment.","code":""},{"path":"funções-e-loops-no-r.html","id":"o-environment-global","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.2.1 O environment global","text":"Toda vez que você inicia sua sessão R, você está trabalhando com um environment que chamamos de global environment, ou ambiente global. Logo, todos os seus objetos que você cria em sua sessão, são guardados global environment. Você pode se referir esse environment através da função globalenv(). Por exemplo, eu posso usar função ls() para listar os nomes de todos os objetos que estão disponíveis especificamente global environment, como exemplo abaixo. R, o endereço desse environment é referenciado como R_GlobalEnv.Portanto, um environment é uma espécie de caixa, ou como um espaço reservado para guardar um certo conjunto de objetos. O seu global environment é um desses environments, onde ficam todos os seus objetos que você normalmente cria em sua sessão. Porém, todas vezes que você está trabalhando R, há diversos outros environments ativos. O motivo, ou razão principal para existência dessas estruturas, está na forma como linguagem R procura pelos objetos que você pede ela. Ou seja, como é destacado por Wickham (2015a) os environments são estrutura que sustentam regras de scoping, ou regras de “busca” da linguagem R. Mas pelo fato desse ser um assunto mais avançado da linguagem, isto não será abordado aqui. Você pode consultar Wickham (2015a) para mais detalhes.Tudo o que eu quero destacar nessa seção respeito de environments, é o fato de que todo objeto está ligado um certo environment. Logo toda função (lembre-se que tudo R são objetos) possui o seu environment, e por isso, você terá muitas ocasiões em que você terá de acessar uma função através de seu respectivo environment, ao invés de simplesmente chamar pelo nome dessa função console.Por essas razões, podemos entender que um dos principais papéis desempenhados pelos environments R, é o de adicionar uma nova camada de identificação de objetos. Se antes o R identificava os valores contidos em objetos, através nome desse objeto que está conectado esses valores, com o uso de environments, o R agora pode identificar diferentes valores ou diferentes objetos, através nome desse objeto e environment ao qual ele pertence.Pense por exemplo, objeto LETTERS. Esse objeto está disponível toda vez que você inicia sua sessão R, pois ele se encontra environment base (que faz parte de um dos pacotes básicos da linguagem, que sempre são carregados para sua sessão). Nós podemos identificar o environment ao qual um objeto pertence, através da função () pacote pryr. Perceba que esse objeto, contém apenas letras alfabeto em maiúsculo.Portanto, mesmo que eu crie um objeto em minha sessão, ou em outras palavras, um objeto em meu global environment chamado LETTERS, o R ainda será capaz de diferenciar esses dois objetos denominados LETTERS, através environment ao qual eles pertencem. Após criarmos um novo LETTERS, se eu chamar por este objeto console, o resultado será o valor contido objeto LETTERS meu global environment. Isso ocorre, pois o R irá sempre procurar primeiro por um objeto em seu global environment. Depois ele irá procurar em outros environments pelo objeto ao qual você requisitou. Esse caminho de environments pelo qual o R percorre durante sua procura, é comumente chamado por search path (ou “caminho de busca”). Para acessarmos o valor objeto LETTERS original, podemos utilizar função get(), que possui um argumento (envir) onde podemos definir qual o environment em que o R deve procurar pelo objeto. Podemos ver esse problema, através de uma representação visual como da figura 5.1.\nFigure 5.1: Representação de environments\n","code":"\n# Iniciei uma nova sessão no R\n\na <- 1\nb <- 2\n\nls(envir = globalenv())## [1] \"a\" \"b\"\nLETTERS## [1] \"a\"\npryr::where(\"LETTERS\")## <environment: base>\nenv <- pryr::where(\"LETTERS\")\nLETTERS <- \"a\"\n\nLETTERS## [1] \"a\"\nget(\"LETTERS\", envir = env)## [1] \"a\""},{"path":"funções-e-loops-no-r.html","id":"os-environments-de-pacotes","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.2.2 Os environments de pacotes","text":"Portanto, o trabalho de um environment R, é o de vincular, ou de associar um conjunto de nomes (os nomes dos objetos), seus respectivos conjuntos de valores . Ou seja, um dos principais papéis que um environment desempenha R, é o de organizar um conjunto de objetos, de forma que o R seja capaz de diferenciar dois ou mais objetos com o mesmo nome.Um bom exemplo disso, é função filter() pacote dplyr, que vimos capítulo 4. Pois nós temos dentre os pacotes básicos R, mais especificamente pacote stats, uma outra função também chamada filter(). Por isso, sempre que chamamos pelo pacote dplyr através de library(), seguinte mensagem aparece, nos informando que há um choque entre duas funções.Essa mensagem está nos informando, que o pacote dplyr possui funções com os mesmos nomes das funções filter() e lag() pacote stats, e por isso, ela estaria “escondendo” esses objetos de forma evitar conflitos. Isso significa, que após carregarmos o pacote dplyr, e ele “esconder” essas funções, se nós chamarmos pela função filter() console, estaremos utilizando função pacote dplyr, e não função pacote stats.\nFigure 5.2: Ambientes de pacotes R\nPortanto, essas duas funções filter(), são funções diferentes, que servem para propósitos diferentes. O único fator que permite ao R, diferenciar essas funções uma da outra, é o fato de que elas se encontram em ambientes, ou environments diferentes, como demonstrado na figura 5.2. Isso significa que todas funções, possuem um environment ao qual estão associadas. Por isso, nós podemos diferenciar funções filter() e lag() de ambos os pacotes (dplyr e stats), através nome environment ao qual essas funções pertencem.Pacotes são um caso especial, pois eles contém dois environments diferentes que se relacionam entre si. Um é o environment propriamente dito pacote, que contém os seus respectivos objetos, e um outro comumente chamada de namespace. Essa diferenciação só será útil na prática, quando você estiver desenvolvendo um novo pacote para o R. Logo, não se preocupe em entender agora diferença entre esses dois espaços. Apenas entenda que pacotes R, vão além de simples environments que contém os seus próprios objetos e funções, e que estão separados de seu global environment.Tendo isso em mente, quando desejamos utilizar uma função que está em conflito com uma outra função de um outro pacote, nós devemos definir de alguma forma, o environment pacote qual o R deve procurar pela função que você está chamando. caso de pacotes, podemos acessar funções definidas em seus respectivos environments, ao fornecer o nome pacote que contém essa função, em seguida, abrir duas vezes dois pontos (::), e depois, colocar o nome da função que desejamos, como exemplo abaixo.","code":"\nlibrary(dplyr)Attaching package: ‘dplyr’\n\nThe following objects are masked from ‘package:stats’:\n\n    filter, lag\nx <- ts(rnorm(100), start = c(1, 1990), end = c(4, 1998), frequency = 12)\n\nstats::filter(x, filter = c(0.5, 0.8, 0.2))##             Jan         Feb         Mar         Apr         May\n## 166                                                            \n## 167  1.16442920  0.91500252 -0.23768174 -1.44767486 -0.68237859\n## 168  0.88258623  0.42219144  0.33977808  1.47751346  1.49561963\n## 169  0.84370768  0.50916936  0.49375355  0.23956192  0.17568137\n## 170  1.04628841 -1.13401257 -1.25400780  1.19311175  0.79144899\n##             Jun         Jul         Aug         Sep         Oct\n## 166                                                          NA\n## 167 -0.25496455 -0.63263452 -0.10640841 -0.52051165 -0.82019345\n## 168  0.56135033  0.51422710 -0.17227866 -1.18997169  0.02303573\n## 169 -0.31809494  0.43692344  2.11986556  0.99620987  0.56587068\n## 170          NA                                                \n##             Nov         Dec\n## 166  0.53303165  0.94640945\n## 167 -0.82640133  0.09656562\n## 168  1.79113804  1.46001721\n## 169  0.60644086  0.59635066\n## 170"},{"path":"funções-e-loops-no-r.html","id":"sec:environment_exec","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.2.3 O environment de execução de uma função","text":"Toda função R, possui o que nós chamamos de function environment, que corresponde ao environment qual elas foram criadas. exemplo abaixo, podemos ver esses environments pertencentes às funções filter() pacote dplyr, e seq() pacote base. Como um outro exemplo, caso eu crie uma nova função em minha sessão, perceba que o environment qual ela pertence, se trata justamente global environment (R_GlobalEnv).Porém, funções também possuem o que chamamos de environment de execução, que se trata environment qual os seus cálculos são executados. Ou seja, sempre que você executa uma função, os cálculos realizados por essa função são feitos em um environment separado seu global environment. Como consequência, você não consegue visualizar o resultado de cada cálculo ou passo executado por essa função, pois essas etapas estão sendo realizadas em um local distante environment qual você se encontra. É dessa característica que surge uma das principais dificuldades em se criar sua própria função. Pois já que você não pode visualizar os resultados de cada cálculo aplicado pela função, você terá que prever quais seriam possibilidades para cada cálculo. Isso exige de você muita experiência com linguagem, e nem sempre essa experiência será suficiente para para representar realidade com precisão.exemplo abaixo, estou criando uma função f_env, que nos retorna justamente o endereço environment qual essa função executou soma entre 4 e 5. Perceba que cada momento em que eu executo essa função, ela retorna um endereço diferente. Logo, esses environments de execução são temporários (ou efêmeros se preferir), e utilizados uma única vez pela função.O motivo principal pelo qual esses environments de execução existem, é pelo fato de que nós em geral, não queremos que função mexa ou altere os nossos objetos salvos em nosso global environment. Veja por exemplo, função norm que busca normalizar uma variável numérica qualquer. Nessa função, três objetos são criados. Um contendo média de x (media), outro possuindo o desvio-padrão da mesma variável (desvio_pad), e um último contendo os valores já normalizados (normalizado).Pelo fato de que função norm executa os seus cálculos, e portanto, cria os seus objetos em um ambiente separado, mesmo que eu tenha objetos em meu global environment que se chamam media, ou desvio_pad, ou normalizado, em nenhum momento função norm irá afetá-los. função norm pode até utilizar-se de objetos que estão guardados em meu global environment para realizar os seus cálculos, mas em nenhum momento ela irá alterar o valor dessas variáveis em meu global environment, menos que eu peça explicitamente para que ela realize tal alteração. Isso algo que eu não pretendo mostrar aqui, pois exige de você leitor, um conhecimento e experiência maiores com os environments R.","code":"\nrlang::fn_env(dplyr::filter)## <environment: namespace:dplyr>\nrlang::fn_env(seq)## <environment: namespace:base>\nsoma <- function(x, y){\n  return(x + y)\n}\n\nrlang::fn_env(soma)## <environment: R_GlobalEnv>\nf_env <- function(){\n  \n  soma <- 4 + 5\n  \n  env <- environment()\n  \n  return(env)\n}\n\nf_env()## <environment: 0x0000014909db8c40>\nf_env()## <environment: 0x0000014907b673f0>\nnorm <- function(x){\n  media <- mean(x)\n  desvio_pad <- sd(x)\n  \n  normalizado <- (x - media)/desvio_pad\n  \n  return(normalizado)\n}\n\ny <- rnorm(50)\n\nnorm(y)##  [1] -1.29746780  0.26684044 -0.07699576 -0.35852807 -0.19292098\n##  [6]  1.62576071 -0.90452041  0.14979621 -2.13009149 -0.31372789\n## [11] -0.13906998  1.92566364 -0.60455011 -0.51378355 -1.04466154\n## [16]  0.54906817  1.53341938 -0.84350886 -0.06271653  1.74782820\n## [21] -0.32396058  1.05999917  0.76093273 -0.95147507  1.59686409\n## [26]  1.17079379 -0.12584004 -0.54592611 -0.02704583  1.18987831\n## [31] -0.20267237 -1.52616027  0.22302469  1.14728340 -0.80368602\n## [36]  0.12703241 -0.86741299  0.48541843  0.23353726  0.33337287\n## [41] -0.26134945 -0.34928558  1.24785307  0.47362971  0.17853930\n## [46] -2.87897520 -0.92139025  1.13819276 -0.04361194 -0.85339411"},{"path":"funções-e-loops-no-r.html","id":"uma-introdução-teórica-às-funções-no-r","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.3 Uma introdução teórica às funções no R","text":"funções, lhe permitem automatizar tarefas, em uma forma mais intuitiva e poderosa, que uma simples estratégia de copiar-colar (Wickham Grolemund 2017). Portanto, sempre que houver algum tipo de repetição em seu trabalho, você pode utilizar uma função, em conjunto com um loop, para automatizar esse processo. Em outras palavras, uma função lhe permite com apenas um comando, aplicar várias outras funções e processos diferentes de uma vez só. Dessa forma, fica mais fácil aplicar repetidamente o mesmo conjunto de processos e comandos sobre os seus dados.Vamos supor exemplo, que você seja o dono de 4 lojas de doces caseiros, e que essas lojas estão localizadas na cidade de Belo Horizonte, mais especificamente nos bairros Barro Preto, Savassi, Centro e Padre Eustáquio. Toda semana, o gerente de cada loja, te envia uma planilha contendo vendas diárias de cada produto em sua loja. Você como dono dessas lojas, deseja sempre calcular algumas estatísticas para acompanhar vendas de suas empresas.Porém, são 4 planilhas enviadas toda semana, e se você tem que calcular mesmas estatísticas toda semana, porque não criar uma função que já executa esses cálculos por você? Dessa forma, você consegue calcular todas suas estatísticas com apenas um comando, economizando tempo e esforço na manutenção dessas estatísticas.Vamos supor, que planilhas de cada loja, assumem seguinte estrutura abaixo. Como exemplo, vamos utilizar planilha referente loja localizada bairro Savassi:Portanto, cada planilha, apresenta cada venda que ocorreu durante semana em uma determinada loja, e inclui informações como: o dia em que venda ocorreu, o vendedor que realizou venda, o valor da venda, e o código de identificação produto que foi vendido. Vamos supor, que você esteja interessado em calcular: receita total diária da loja, o número de vendas diárias de cada produto, e o lucro total dessa semana na loja de referência da planilha. Para isso, precisaríamos dos seguintes comandos:É um conjunto considerável de comandos, e você terá que replicá-los para outras 3 planilhas. Você pode criar uma função, ou um conjunto de funções, com o objetivo de facilitar esse processo de aplicação desses comandos sobre cada planilha. Porém, como temos ao menos três estatísticas diferentes (receita total diária; numéro de vendas diárias atingidas em cada produto; lucro total da semana), seria mais adequado, criarmos uma função especializada para cada uma dessas estatísticas, e em seguida, criar uma quarta função que será nossa função principal, que ficará responsável por aplicar essas três funções especializadas que criamos, sobre tabelas de vendas de cada loja.Para iniciarmos uma nova função R, nós precisamos utilizar palavra chave function. Dito de outra forma, essa palavra chave indica ao R, que os próximos comandos, representam os componentes da nossa nova função. Toda função R, possui três partes principais, mostradas na figura abaixo. Primeiro, temos o nome da função, que corresponde ao nome objeto em que você está salvando sua função. Segundo, temos os argumentos, ou os parâmetros dessa função, que são definidos dentro de um par de parênteses posicionados ao lado da palavra chave (function). Terceiro, temos o corpo da função, que é definido dentro de um par chaves ({}). Dentro desse par de chaves, você deve colocar todos os comandos, ou todos os cálculos que você deseja aplicar sobre os input’s da função.\nFigure 5.3: Estrutura de uma função\nOs input’s de uma função, são os objetos, ou os dados que você fornece à função para ela trabalhar. Esses input’s são geralmente fornecidos, ao conectarmos um objeto um dos argumentos da função. Porém, esses input’s não precisam estar conectados algum argumento, nem precisam fazer parte de seu global environment.Toda função R, possui ainda um quarto componente, que se trata environment ao qual ela pertence, que definimos na seção “O environment de execução de uma função”. Esse componente é automaticamente definido momento em que você cria função, e é comumente chamado de function environment. Para relembrarmos, esse item se trata apenas environment qual você está criando essa função. Como na maioria tempo, você estará trabalhando seu global environment, maioria das funções que você criar, teram o global environment como o seu function environment.Como exemplo, eu posso criar através dos comandos abaixo, uma simples função de soma chamada funcao_soma(), que possui dois parâmetros, ou dois argumentos chamados x e y. O objeto soma que está definido dentro corpo da função, é criado sempre que você executa função funcao_soma(). Porém, como todas funções são executadas em um ambiente separado de seu global environment, o objeto soma é criado e salvo em um ambiente diferente seu, e por isso, você não possui acesso direto ao objeto soma partir de seu environment. Mas você possui acesso indireto ao objeto soma, se você pedir função funcao_soma(), que lhe retorne (como resultado da função) o que foi salvo neste objeto, como requisitado exemplo abaixo pela função return().Os argumentos de toda função, funcionam como apelidos que auxiliam função, sobre como e onde ela deve posicionar corpo da função, os valores que fornecermos esses argumentos. Ou seja, você não precisa nomear os seus objetos com o mesmo nome presente nos argumentos de uma função. Pois função utiliza o nome de seus argumentos, apenas como um meio de transportar os seus input’s para o seu corpo.Como exemplo, eu possuo abaixo uma função chamada extrair(). Pelo corpo da função, podemos identificar que essa função irá extrair os valores de uma coluna chamada horario, objeto que conectarmos ao argumento x, e irá salvar esses valores em um objeto chamado extr_x. Por outro lado, também podemos perceber que função extrair() busca aplicar função order() sobre os valores contidos na coluna valor, que está presente objeto que fornecermos ao argumento y. Porém, caso argumento z, função vai apenas somar os valores (através da função sum()) contidos objeto que oferecermos à esse argumento da função extrair().Para acessarmos função que acabamos de criar, precisamos apenas utilizar o nome objeto onde salvamos função e abrirmos um par de parênteses. Logo, se eu quisesse acessar função extrair, eu devo utilizar os comandos abaixo. Lembre-se que ao utilizar uma função, você pode definir um argumento implicitamente, ou explicitamente. Se você não deixa claro que argumento um objeto está conectado, esse objeto é conectado ao argumento correspondente sua ordem. Em outras palavras, exemplo abaixo, o primeiro objeto dentro parênteses (como o objeto funcionarios abaixo), é conectado ao primeiro argumento da função extrair (argumento x), o segundo objeto (vendas), ao segundo argumento (argumento y), e assim por diante. Porém, caso você deseja fornecer algum objeto fora da ordem dos argumentos de uma função, você deve definir explicitamente qual o argumento que aquele objeto deve ser direcionado. Para isso, basta igualar o objeto ao nome argumento desejado da função.","code":"\nsavassi## # A tibble: 785 x 6\n##      dia   mes   ano vendedor produtoid valor\n##    <int> <int> <int> <chr>    <chr>     <dbl>\n##  1     1     4  2020 Márcia   23010      4.1 \n##  2     1     4  2020 Ana      10014      7.89\n##  3     1     4  2020 Ana      10115     15.4 \n##  4     1     4  2020 Márcia   53200     11.2 \n##  5     1     4  2020 Ana      10014      7.89\n##  6     1     4  2020 Nathália 53200     11.2 \n##  7     1     4  2020 Nathália 10014      7.89\n##  8     1     4  2020 Márcia   10014      7.89\n##  9     1     4  2020 Nathália 53200     11.2 \n## 10     1     4  2020 Ana      10115     15.4 \n## # ... with 775 more rows\nlibrary(dplyr)\nlibrary(magrittr)\n\nreceita_por_dia <- as.vector(rowsum(savassi$valor, savassi$dia))\nnames(receita_por_dia) <- paste(\"Dia\", unique(savassi$dia))\n\n\nvendas_produto <- savassi %>%\n  group_by(dia, mes, produtoid) %>% \n  summarise(\n    receita = sum(valor),\n    n_vendas = n()\n  ) %>% \n  ungroup()\n\n\ncusto <- c(\"23010\" = 1.5, \"10014\" = 5.43, \"10115\" = 11, \"53200\" = 8.9)\n\nvendas_produto <- vendas_produto %>% \n  mutate(\n    custo_t = custo[vendas_produto$produtoid] * n_vendas,\n    lucro = receita - custo_t\n  )\n\nlucro_total <- sum(vendas_produto$lucro)\nfuncao_soma <- function(x,y){\n  soma <- x + y\n  return(soma)\n}\n\nfuncao_soma(54, 32)## [1] 86\nextrair <- function(x, y, z){\n  extr_x <- x$horario\n  extr_y <- order(y$valor)\n  calc_z <- sum(z)\n}\nextrair(funcionarios, vendas, vendas)\n\nextrair(funcionarios, z = vendas, y = vendas)"},{"path":"funções-e-loops-no-r.html","id":"construindo-um-conjunto-de-funções","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.4 Construindo um conjunto de funções","text":"Vamos retornar ao nosso exemplo, em que você é dono de 4 lojas de doces localizadas na cidade de Belo Horizonte, e você precisa toda semana manter um conjunto de três estatísticas sobre cada loja. Em mais detalhes, precisamos calcular para cada loja, seguintes estatísticas:Receita total diária (queremos identificar se houve alguma variação importante na receita, ao longo da semana).Receita total diária (queremos identificar se houve alguma variação importante na receita, ao longo da semana).Número de vendas diárias de cada produto (queremos saber quais produtos estão bombando).Número de vendas diárias de cada produto (queremos saber quais produtos estão bombando).Lucro total da semana (nessa semana, entramos azul? ou vermelho?).Lucro total da semana (nessa semana, entramos azul? ou vermelho?).Eu poderia muito bem criar uma única função que é capaz de calcular todas essas estatísticas de uma vez só. Porém, com o objetivo de incentivar melhores práticas, vou criar um conjunto de 4 funções. Dentre esse conjunto, 3 função serão responsáveis por calcular estatísticas, e uma quarta função será responsável por aplicar três funções anteriores sobre alguma tabela que fornecermos como input.","code":""},{"path":"funções-e-loops-no-r.html","id":"calculando-a-receita-total-diária","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.4.1 Calculando a receita total diária","text":"Vamos começar, com uma função para calcular receita total diária de cada loja. Primeiro, precisamos decidir um nome para o nossa função, ou em outras palavras, o nome objeto em que vamos salvar nossa função. O nome desse objeto, se torna o nome dessa função. Dessa forma, podemos acessar função salva objeto receita_diaria, ao abrirmos parênteses após esse nome.Para calcularmos receita total diária, precisamos de duas informações: colunas valor e dia. coluna dia, define os grupos que queremos utilizar para calcular nossa receita total. E coluna valor, informa receita adquirida em cada venda. função rowsum() representa uma solução eficiente para calcularmos essa receita, e possui dois argumentos principais: 1) x, o vetor (ou data.frame) com os valores serem somados; 2) group, o vetor contendo os valores que apresentam o grupo de cada observação em x. Porém, como essa função costuma nos retornar uma matriz como resultado, eu posso aplicar função .vector() sobre ela, para transformar esse resultado em um vetor.Como definimos anteriormente, os nomes dos argumentos (vl e grp) da nossa função, são apenas pronomes, ou apelidos para os input’s da nossa função. Esses apelidos, servem apenas para guiar função, e determinam onde esses input’s devem ser posicionados corpo da função. exemplo acima, o pedaço rowsum(x = vl corpo da função, indica que o input que nós fornecermos ao argumento vl da função receita_diaria(), deve ser conectado ao argumento x da função rowsum().Você talvez tenha percebido, que ao executarmos função receita_diaria() acima, nenhum resultado foi retornado. Isso ocorre, porque nós não utilizamos corpo da função, algum comando para retornar o objeto (receita) onde o resultado foi salvo. Ou seja, função aplicou sim os comandos que definimos em seu corpo. Ela apenas não se preocupou em nos retornar o resultado. Para isso, podemos simplesmente chamar pelo nome objeto, ao final corpo da função. Ou utilizar uma função como print() ou return() para nos retornar esse resultado. Eu prefiro utilizar uma função, pois é uma maneira mais formal e clara de se definir o objeto que contém o resultado de sua função. Veja abaixo, que ao colocarmos função return() corpo, nossa função passa nos retornar receitas totais diárias calculadas.Entretanto, o vetor resultante de receita_diaria(), ainda carece de alguma notação, que seja capaz de nos informar o dia que cada valor presente vetor se refere. Ou seja, o valor 1508,27 se refere que dia mês? Dia 01? 02? 03? … Com isso, eu utilizo função names() sobre o objeto receita, para definir um nome para cada um desses valores, contendo o dia que eles se referem.","code":"\nreceita_diaria <- function(vl, grp){\n  \n  receita <- as.vector(rowsum(x = vl, group = grp))\n}\n\nreceita_diaria(savassi$valor, savassi$dia)\nreceita_diaria <- function(vl, grp){\n  \n  receita <- as.vector(rowsum(x = vl, group = grp))\n  \n  return(receita)\n}\n\nreceita_diaria(savassi$valor, savassi$dia)## [1] 1508.27 1714.14 1336.58 1407.90 1766.22\nreceita_diaria <- function(vl, grp){\n  \n  receita <- as.vector(rowsum(x = vl, group = grp))\n  names(receita) <- paste(\"Dia\", unique(grp))\n  \n  return(receita)\n}\n\nreceita_diaria(savassi$valor, savassi$dia)##   Dia 1   Dia 2   Dia 3   Dia 4   Dia 5 \n## 1508.27 1714.14 1336.58 1407.90 1766.22"},{"path":"funções-e-loops-no-r.html","id":"calculando-o-número-de-vendas-diárias-de-cada-produto","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.4.2 Calculando o número de vendas diárias de cada produto","text":"Agora que temos função receita_diaria(), podemos passar agora, para o cálculo numéro de vendas diárias atingidas em cada produto. Vou chamar essa função de produtos_vendas(), e ela vai possuir apenas um argumento (dados), que representa planilha de cada loja, contendo os dados de cada venda da semana.Para realizarmos o cálculo desejado, precisamos realizar duas etapas: 1) pegar tabela que fornecermos como input e agrupá-la, ou seja, precisamos definir o grupo da tabela, e para isso, podemos utilizar função group_by(); 2) em seguida, podemos calcular estatísticas e guardá-las em uma nova tabela. função summarise() é uma boa alternativa para essa etapa. Uma outra etapa opcional, mas não obrigatória nesse cálculo, é de eliminar definição dos grupos da tabela, com o objetivo de retornar tabela calculada, para o estado de uma tabela tradicional. Como eu disse, essa é uma etapa opcional, e que não afeta em nada nossa tabela em si, estamos apenas “desagrupando” tabela, ou eliminando descrição que definia os grupos dessa tabela. Para essa etapa opcional, podemos utilizar função ùngroup().","code":"\nprodutos_vendas <- function(dados){\n\n  vendas_produto <- dados %>%\n    group_by(dia, produtoid) %>% \n    summarise(\n      receita = sum(valor),\n      n_vendas = n()\n    ) %>% \n    ungroup()\n  \n  return(vendas_produto)\n}\n\nprodutos_vendas(savassi) %>% print(n = 10)## # A tibble: 20 x 4\n##      dia produtoid receita n_vendas\n##    <int> <chr>       <dbl>    <int>\n##  1     1 10014        339.       43\n##  2     1 10115        680.       44\n##  3     1 23010        152.       37\n##  4     1 53200        338.       30\n##  5     2 10014        284.       36\n##  6     2 10115        865.       56\n##  7     2 23010        160.       39\n##  8     2 53200        405        36\n##  9     3 10014        252.       32\n## 10     3 10115        525.       34\n## # ... with 10 more rows"},{"path":"funções-e-loops-no-r.html","id":"calculando-o-lucro-total","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.4.3 Calculando o lucro total","text":"Após criarmos funções produtos_vendas() e receita_diaria(), precisamos de uma função para calcularmos o lucro total. Vou dar o nome de calc_lucro() essa função. Sendo que para o cálculo lucro, precisamos apenas subtrair o custo total da receita total. O cálculo da receita total é simples, precisamos apenas somar os valores dispostos na coluna valor da tabela de cada loja.Já para o custo total, temos uma solução prática através uso de subsetting. Precisamos primeiro criar um vetor contendo os custos de cada produto (vetor custo). Em seguida, nós replicamos esse vetor ao longo da tabela de vendas de cada loja, de acordo com cada produto vendido (custo[x$produtoid]). Por último, nós somamos os custos desse vetor para chegarmos ao custo total.","code":"\ncalc_lucro <- function(x){\n  \n  custo <- c(\"23010\" = 1.5, \"10014\" = 5.43, \"10115\" = 11, \"53200\" = 8.9)\n  \n  custo_total <- sum(custo[x$produtoid])\n  \n  receita_total <- sum(x$valor)\n\n  lucro_total <- receita_total - custo_total\n  \n  return(lucro_total)\n}\n\ncalc_lucro(savassi)## [1] 2367.09"},{"path":"funções-e-loops-no-r.html","id":"agrupando-essas-funções-em-uma-só","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.4.4 Agrupando essas funções em uma só","text":"Após construírmos todas três funções que precisamos aplicar, nós podemos criar uma última função, que irá aplicar todas essas três funções de uma vez só. Agora, como podemos retornar múltiplos resultados em uma função? Pois nós temos agora, três resultados diferentes serem calculados pela função, e nós gostaríamos de ter acesso cada um desses três resultados. resposta para essa pergunta, é uma lista. Pois você pode incluir o que você quiser dentro de uma lista, logo, basta colocarmos todos os resultados em uma lista, e pedir função return() que nos retorne essa lista, como resultado da função calc_stats() abaixo.Com função calc_stats(), fica mais simples replicar os cálculos ao longo das tabelas de cada loja, como exemplo abaixo.","code":"\ncalc_stats <- function(tabela){\n  \n  receita <- receita_diaria(vl = tabela$valor, grp = tabela$dia)\n  \n  lucro_total <- calc_lucro(tabela)\n  \n  produtos_vendas <- produtos_vendas(tabela)\n  \n  lista <- list(\n    receita = receita,\n    lucro = lucro_total,\n    vendas = produtos_vendas\n  )\n  \n  return(lista)\n}\nsavassi_stats <- calc_stats(savassi)\nbarro_preto_stats <- calc_stats(barro_preto)\npadre_eustaquio_stats <- calc_stats(padre_eustaquio)\ncentro_stats <- calc_stats(centro)"},{"path":"funções-e-loops-no-r.html","id":"introduzindo-loops","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.5 Introduzindo loops","text":"Como o próprio nome dá entender, um loop busca criar um ciclo que se repete em torno de uma operação (ou de um conjunto de operações). Em outras palavras, um loop cria uma repetição, e em uma dessas repetições, um mesmo conjunto de operações são aplicadas pelo R. O objetivo de um loop, é que cada repetição, podemos alterar os input’s das funções que estão sendo aplicadas nessas operações, e consequentemente, os seus resultados.Na seção passada, vimos como podemos criar funções, que representam uma forma concisa de aplicar todos os seus passos e cálculos, com apenas um comando. Agora, com o uso de loop’s, podemos aplicar repetidamente uma função ao longo de diversos pontos, ou sobre diversos input’s diferentes. Dito de outra forma, com um loop, podemos automatizar o processo de aplicação de uma função ao longo de diferentes input’s.Na linguagem R, temos dois tipos, ou duas famílias principais de loop’s. Mas aqui vou focar apenas em um desses tipos, que é o loop (). estrutura básica de um () loop, se assemelha muito à estrutura de uma função. Porém, diferente de uma função, você não precisa salvar um () loop em algum objeto. Um () loop é sempre iniciado pela palavra chave . Ao lado dessa palavra chave, devem ser posicionados um par de parênteses, e um par de chaves. Criando assim, estrutura básica abaixo.Um () loop possui dois componentes principais: 1) definição loop, que rege como os índices loop vão variar cada repetição; 2) e o corpo deste loop, que contém todas funções e operações que serão aplicadas em cada repetição. definição loop é sempre definida nos parênteses que estão logo em seguida da palavra chave , e será onde você irá definir quantas vezes o loop irá repetir, e também, sobre qual conjunto de valores ele vai variar.\nFigure 5.4: Estrutura de um loop\nUm () loop possui um índice, que cada repetição, assume um valor diferente. Você deve determinar o conjunto de valores que esse índice vai assumir, na definição loop, ao fornecer um vetor (ou uma função que retorne um vetor) contendo esse conjunto de valores, direita da palavra chave . Sendo que através desse vetor, ou desse conjunto de valores, você está indiretamente determinando quantas vezes o loop vai repetir operações definidas em seu corpo. Ou seja, se o vetor fornecido na definição loop, possui 5 valores diferentes, o loop vai gerar 5 repetições, mas se esse vetor possui 10 valores, o loop vai gerar 10 repetições, e assim por diante.Já o corpo loop, funciona da mesma forma que o corpo de uma função. Dessa maneira, o corpo de um loop, contém todas funções e transformações que o () loop vai aplicar em cada repetição. Com isso, você vai utilizar o índice loop, para variar os input’s utilizados pelas funções presentes corpo desse loop, e consequentemente, variar os seus resultados gerados cada repetição loop.O índice dos loop’s mostrados nessa seção, é representado pela letra . Você pode dar o nome que quiser esse índice, basta substituir o na definição loop pelo nome desejado. nosso caso aqui, nós optamos por utilizar letra para nos referir esse índice, e por isso, em todos os locais corpo loop, em que letra aparece sozinha, temos um local onde o índice será utilizado. Em outras palavras, se o meu índice é chamado pela letra , e eu possuo uma parte corpo de meu loop, como sum(), isso significa que cada repetição loop, função sum() será aplicada sobre o valor que o índice assumir nessa respectiva repetição.O exemplo mais simples de um loop, seria um que mostra cada valor incluso vetor que eu forneci na definição loop. exemplo abaixo, estou criando um loop que vai variar sobre uma sequência de 1 10. Perceba abaixo, que o () loop não está executando nada além de um simples comando de print() sobre o valor assumido pelo índice . Ou seja, cada repetição, tudo o que () loop está fazendo é mostrar qual o valor que o índice assumiu nessa repetição.Portanto, exemplo acima, ao estipularmos na definição de loop, o conjunto de valores sobre os quais o índice loop iria variar, incluímos uma sequência de 1 10, através código 1:10. Entretanto, nós podemos incluir o que quisermos como conjunto de valores, desde que eles estejam em algum vetor (seja esse vetor, um vetor atômico ou uma lista). Por exemplo, nós podemos colocar um vetor de nomes, como exemplo abaixo.Porém, uma forma mais interessante e poderosa de se utilizar o índice de seu loop, é através de um mecanismo de subsetting. Ou seja, você pode utilizar o índice de seu loop, como um índice de subsetting, em cada repetição loop. Dessa forma, cada repetição, você aplica funções definidas corpo loop, em uma parte diferente de seus dados. O índice de seu loop, passa ser o índice que representa uma parte específica de seus objetos, ao ser utilizado pelas funções de subsetting (funções [ e [[). Lembre-se que podemos utilizar diferentes tipos de índice dentro das funções de subsetting, como demonstrado na seção Subsetting, porém, caso de um loop, os índices de tipo numérico (integer) e textual (character) são os mais úteis.Por exemplo, logo abaixo, temos uma lista que contém alguns valores numéricos. Porém, eu dei um nome cada um desses valores numéricos. Perceba abaixo, que corpo loop (mais especificamente código lista[[]]), estamos utilizando função [[ para extrair o elemento objeto lista, que possui o nome igual ao valor que o nosso índice assume em uma dada repetição. Dessa forma, nós estamos multiplicando por 10, apenas os elementos de lista, que estão nomeados de acordo com os valores contidos vetor vec, que representa o conjunto de valores que o índice loop vai assumir. Ou seja, nós podemos utilizar um () loop, para aplicarmos uma função apenas sobre algumas partes específicas de nossos dados (deixando outras partes intactas). Perceba abaixo, que em nenhum momento o loop chega lidar com o valor 40, que está nomeado como Marcos objeto lista.","code":"\nfor(i in vetor){\n  # Corpo do loop\n}\nfor(i in 1:10){\n  print(i)\n}## [1] 1\n## [1] 2\n## [1] 3\n## [1] 4\n## [1] 5\n## [1] 6\n## [1] 7\n## [1] 8\n## [1] 9\n## [1] 10\nvec <- c(\"Ana\", \"Eduardo\", \"Heloísa\")\n\nfor(i in vec){\n  print(i)\n}## [1] \"Ana\"\n## [1] \"Eduardo\"\n## [1] \"Heloísa\"\nvec <- c(\"Ana\", \"Eduardo\", \"Heloísa\")\n\nlista <- list(\n  \"Ana\" = 15,\n  \"Eduardo\" = 30,\n  \"Heloísa\" = 10,\n  \"Marcos\" = 40\n)\n\nfor(i in vec){\n  print(lista[[i]])\n  print(lista[[i]] * 10)\n}## [1] 15\n## [1] 150\n## [1] 30\n## [1] 300\n## [1] 10\n## [1] 100"},{"path":"funções-e-loops-no-r.html","id":"sec:growing_vector","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.5.1 O problema do vetor crescente","text":"Para salvar os resultados gerados em cada repetição () loop, é muito importante que você crie previamente, um objeto que possa guardar esses resultados (Gillespie Lovelace 2017; Wickham Grolemund 2017). Em outras palavras, você precisa reservar o espaço necessário para guardar os resultados, antes mesmo de executar o () loop. Por exemplo, se eu possuo um data.frame contendo 4 colunas numéricas, e desejo calcular média de cada coluna, eu preciso criar algum objeto que possa receber 4 médias que serão geradas pelo loop. exemplo abaixo, eu utilizo função vector() para criar um novo vetor atômico chamado media, que é tipo double e que possui 4 elementos. Logo, dentro corpo loop, eu salvo os resultados da função mean() dentro de cada elemento desse vetor media.Esse problema é conhecido por muitos usuários, como o growing vector problem (ou “problema vetor crescente”). Caso você se esqueça de reservar previamente o espaço para guardar os resultados, o seu loop será bem lento. Pois cada repetição loop, um novo resultado é gerado e, portanto, o computador tem que reservar um tempo para aumentar o vetor onde esse resultado será guardado, de forma que aquele novo resultado “caiba” neste vetor. Ou seja, se o meu loop vai gerar 2 mil repetições, o meu computador vai ter que parar 2 mil vezes durante o processo, para aumentar um elemento mais em meu vetor, com o objetivo de guardar o novo resultado gerado em cada uma dessas 2 mil repetições. Por outro lado, se eu já reservo previamente um vetor com 2 mil elementos, o meu computador não precisa parar durante o processo, pois todo o espaço necessário já está preparado e espera novo resultado gerado em cada repetição.Por isso, você precisa sempre pensar sobre quais tipos de resultados serão gerados em seu loop. Ou seja, será que cada repetição de seu loop, um único número é gerado (por exemplo, uma média)? Ou um vetor (podemos aplicar um teste lógico em cada coluna, e ter um vetor lógico como resultado)? Ou uma tabela (na próxima seção, damos um exemplo desse caso)? partir momento que você sabe qual o tipo de resultado que será gerado pelo seu loop, você pode identificar com mais facilidade, qual melhor estrutura para guardar esses valores. Pergunte-se: será que um vetor atômico consegue guardar esses resultados? Ou uma lista é mais adequada? Lembre-se que vetores atômicos só podem guardar dentro de si, valores que pertencem ao mesmo tipo de dado (double, integer, logical, character, etc.). Além disso, nós não podemos guardar um vetor, ou uma tabela, ou em outras palavras, um conjunto de valores dentro de cada elemento de um vetor atômico. Logo, caso o resultado de cada repetição de seu loop seja, por exemplo, uma tabela, é melhor que você utilize uma lista para guardá-las.","code":"\ndf <- data.frame(\n  a = rnorm(20),\n  b = rnorm(20),\n  c = rnorm(20),\n  d = rnorm(20)\n)\n\nmedia <- vector(mode = \"double\", length = 4)\nfor(i in 1:4){\n  media[i] <- mean(df[[i]])\n}\n\nmedia## [1]  0.31714622 -0.02185939 -0.14591883  0.17135666"},{"path":"funções-e-loops-no-r.html","id":"sec:demanda_dist_ICMS","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.6 Um estudo de caso: uma demanda real sobre a distribuição de ICMS","text":"Nessa seção, vou apresentar um exemplo prático, sobre uma demanda real que chegou até mim em 2020. Na época, eu trabalhava como estagiário na Diretoria de Estatística e Informações da Fundação João Pinheiro (FJP-MG), mais especificamente com uma lei estadual que é tradicionalmente chamada de Lei Robin Hood (Lei 18.030 de 2009 - MG). Essa lei rege distribuição ICMS total de Minas Gerais, ao longo dos municípios estado.Em resumo, o Governo de Minas Gerais, coleta o ICMS (imposto sobre operações relativas à circulação de mercadorias e sobre prestações de serviços de transporte interestadual, intermunicipal e de comunicação) gerado em todo o estado, e ao final de um período, ele redistribui esse valor para os 853 municípios estado. Cada município, possui um índice de participação, que corresponde à porcentagem ICMS total ao qual o respectivo município tem direito. Em outras palavras, se o ICMS total gerado estado em um perído foi de 8,5 bilhões de reais, e o município de Belo Horizonte possui um índice de participação equivalente 0,009, isso significa que ao final período, 0,9% ICMS total, ou 76,5 milhões de reais serão transferidos para prefeitura município de Belo Horizonte.lei possui diversos critérios presentes cálculo índice de participação de cada município, sendo alguns deles: Turismo, Esporte, Patrimônio Cultural, População e Receita Própria. Em suma, o índice de participação de cada município, é calculado partir de uma média ponderada dos índices de cada um desses diversos critérios da lei. Você pode encontrar uma descrição completa desses critérios e cálculo dos índices de participação, texto original da lei14.","code":""},{"path":"funções-e-loops-no-r.html","id":"a-demanda-em-si","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.6.1 A demanda em si","text":"demanda é muito simples, porém, ela é trabalhosa e envolve um volume excessivo de repetição se você optar por utilizar programas como Excel para resolvê-la. Dentre os vários critérios da lei, temos o critério de Meio Ambiente, e o orgão responsável pelo cálculo índice referente esse critério, é SEMAD-MG (Secretaria de Estado de Meio Ambiente e Desenvolvimento Sustentável). Um dia, SEMAD chegou até nós da Fundação João Pinheiro (FJP), pedindo por todos os valores de ICMS transferidos para cada município, ao longo dos anos de 2018 e 2019, de acordo com o critério Meio Ambiente da Lei Robin Hood.Nós da FJP, calculamos todo mês, os valores transferidos de ICMS separados por cada critério da lei, e para cada município. Ou seja, para o ano de 2019, pense por exemplo, em uma lista de arquivos de Excel parecida com lista abaixo, onde cada planilha corresponde aos valores de ICMS transferidos em um mês específico ano.\nFigure 5.5: Lista de arquivos Excel\nDando uma olhada mais de perto, cada uma dessas planilhas Excel, assumem estrutura abaixo. Onde cada linha da tabela, representa um município estado de Minas Gerais, e cada coluna (ou pelo menos, grande parte dessas colunas), representa os valores de ICMS transferidos segundo os índices de um critério específico da lei. Ou seja, coluna Educação, nos apresenta os valores de ICMS transferidos para cada município estado, considerando-se o índice que cada um desses municípios adquiriram critério de Educação, e também, considerando-se parcela que o critério de Educação representa total de ICMS distribuído.Porém, temos dois problemas aqui: 1) SEMAD precisa apenas dos valores de ICMS transferidos de acordo com o critério de Meio Ambiente, e nada mais; 2) SEMAD precisa dos valores de ICMS transferidos ao longo de todos os meses dos anos de 2018 e 2019, e se nós temos 12 planilhas por ano, temos que reunir então 24 planilhas para secretaria. Alguns poderiam argumentar que esses pontos não se configuram como problemas de fato. Em outras palavras, algumas pessoas poderiam dizer algo como: “Ora, você precisa apenas pegar 24 planilhas, depois juntá-las em um arquivo .zip, e simplesmente enviar esse arquivo para SEMAD. SEMAD que se vire para coletar e organizar informações dessas planilhas!”Entretanto, essa não é uma boa política de trabalho. Transportando esse problema para um ambiente mais corporativo, o excesso de informação traz dificuldades para tomada de decisão da empresa, pois ele camufla aquelas pequenas informações que são de fato relevantes. Ou seja, carregar apenas informações que são relevantes para empresa, representa uma boa prática. Além disso, o pedido da SEMAD é simples, e os problemas pontuados acima são de rápida e fácil solução R, através uso de funções e loop’s.Como exemplo prático, vamos mostrar metodologia apenas para essas 12 planilhas referentes ao ano de 2019, e você pode replicar facilmente essa metodologia para outras 12, 24, 36 ou quantas outras planilhas desejar. Em suma, metodologia que vou apresentar envolve duas etapas: 1) juntar todas essas 12 planilhas, em uma planilha só. Ou seja, desejamos guardar em uma planilha única, os valores transferidos aos municípios de MG em cada mês ano de 2019; 2) Selecionar apenas colunas relevantes para SEMAD arquivo final. Tendo essas etapas em mente, isso seria um trabalho muito repetitivo Excel. Uma repetição que é cansativa, e que pode facilmente te levar erros processo. Aqueles com mais experiência Excel, poderiam utilizar plataforma de queries programa para carregar os dados de cada planilha. Porém, apenas pelo tempo que você levaria para configurar sua querie, seria muito mais rápido se você simplesmente adotasse estratégia de Crtl+C e Ctrl+V, para transferir os dados em uma planilha única.Por outro lado, traduzindo essa metodologia para o R, precisaríamos realizar seguintes etapas: 1) construir uma função, que será responsável por importar essas planilhas para o R, além de já inserir uma coluna que define o mês que os dados se referem, e de selecionar apenas colunas relevantes para SEMAD; 2) em seguida, podemos utilizar um loop para replicar função criada ao longo de todas planilhas disponíveis na pasta; 3) por fim, uní-las em uma única tabela com função bind_rows(). Ou seja, o objetivo é ler todas 12 planilhas com apenas um comando, e em seguida, utilizar um segundo comando para unir essas planilhas em uma só.Tendo isso em mente, o primeiro passo é criarmos uma função que será responsável por importar e configurar os dados de cada planilha. Antes disso, vamos coletar os nomes de cada planilha, através da função list.files(). Como o próprio nome dá entender, essa função busca listar os nomes de todos os arquivos contidos em uma pasta. Caso você não defina alguma pasta específica na função (diferente que fizemos abaixo), list.files() vai listar todos os arquivos presentes seu diretório de trabalho atual R.Em resumo, nossa função (chamada ler_excel()) vai receber como input, o nome de cada planilha que acabamos de coletar através da função list.files(), e vai aplicar 3 etapas principais: 1) importar para o R, planilha que contém o nome que fornecemos como input; 2) função vai selecionar apenas colunas relevantes à SEMAD (colunas que contém os códigos de cada município, e coluna Meio Ambiente); 3) em seguida, essa função vai criar três novas colunas nessa planilha, que contém o nome da planilha de onde esses dados vieram, além mês e ano, que estão implícitos nome dessa planilha.Para importarmos planilhas Excel, podemos utilizar função read_excel(), que introduzimos na seção Importando arquivos em Excel com readxl. Porém, para fornecermos os endereços corretos de cada planilha à função read_excel(), nós precisamos criar um mecanismo que possa colar o caminho até pasta onde se encontram esses arquivos, ao nome de cada planilha. Algo que podemos facilmente resolver com o uso da função paste(). Com essa função, podemos unir o nome da pasta onde planilhas se encontram (pasta planilhas), ao nome de cada planilha que função receber como input.Para adicionarmos novas colunas à planilha, nós podemos utilizar função mutate(), que introduzimos na seção Adicionando variáveis à nossa tabela com mutate(). Essas novas colunas são necessárias, pois vão conter informações essenciais como o mês e ano que os dados se referem. Dentre essas novas colunas, teremos coluna Origem, que vai conter apenas o nome da planilha que está sendo lida pela função, e que portanto, guarda origem dos dados selecionados pela função. Dessa forma, nós teremos dentro dos nossos dados, uma coluna que é capaz de nos informar planilha de onde os dados vieram.Em contrapartida, como o mês e o ano que os dados de cada planilha se referem, estam implícitos próprio nome da planilha, precisamos de funções que possam lidar com input’s textuais. Para extrairmos os anos de cada planilha, nós podemos utilizar função parse_number() (que é capaz de extrair números que se encontram em uma cadeia de texto), guardando o resultado dessa função, em uma coluna chamada Ano. Entretanto, para extrairmos o mês nome de cada planilha, teremos um pouco mais de trabalho. Pois os nomes de cada planilha variam em comprimento, e por isso, não posso simplesmente extrair os 5, 6, ou 7 primeiros caracteres de cada nome. melhor alternativa, é utilizarmos função str_length() para calcularmos o número total de caracteres em cada nome, e em seguida, eliminarmos parte que permanece constante em todos os nomes das planilhas (mais especificamente, parte _2019).Com nossa função ler_excel() construída, podemos aplicá-la sobre o primeiro nome contido em nosso objeto nomes_planilhas, como um teste. Pelo resultado abaixo, nós podemos confirmar que função está funcionando exatamente como esperávamos.Agora que temos função construída, nós somos capazes de utilizar um () loop para replicar função ler_excel() sobre cada uma das 12 planilhas presentes na pasta planilhas meu computador. Porém, é muito importante destacar, que toda vez em que você tiver que guardar os resultados de seu () loop, você sempre deve criar antes de executar o loop, alguma estrutura que seja capaz de guardar os resultados deste loop. Caso você não realize esse processo, é muito possível que o seu loop se torne muito lento, pelo fato de que o computador terá de guardar um certo tempo (durante execução loop), para se preocupar em alocar esses resultados na memória de seu computador.Como definimos na seção O problema vetor crescente, você precisa pensar sobre qual estrutura de dado é mais adequada para receber (ou armazenar) os resultados de seu loop. exemplo dessa seção, o nosso loop está gerando cada repetição, uma tabela, ou um data.frame. Nós sabemos que serão 12 data.frame’s gerados, e portanto, precisamos de uma estrutura que seja capaz de guardar essas 12 tabelas. Para o nosso caso, uma lista é melhor opção, pois podemos incluir o que quisermos em cada elemento de uma lista. Por isso eu crio uma lista chamada planilhas, antes de excutar o loop. Essa lista possui 12 elementos (que momento estão vazios), onde serão guardados cada uma das tabelas resultantes da nossa função ler_excel().Perceba também abaixo, que dentro da definição loop, eu utilizo função seq_along() sobre o objeto nomes_planilhas. Essa função é um atalho útil, para criarmos uma sequência que vai de 1 até o número total de elementos presentes objeto nomes_planilhas. Ou seja, função seq_along() gera exatamente o mesmo resultado que o comando 1:length(nomes_planilhas). Porém, função seq_along(x) (ao contrário comando 1:length(x)) se comporta de maneira adequada em situações extremas15, e por isso, representa uma forma mais segura de criarmos uma sequência numérica que irá servir como o conjunto de valores sobre o qual o índice loop vai atuar.Após executarmos o loop, cada uma das 12 planilhas foram guardadas em cada elemento da lista planilhas. Perceba abaixo, que cada uma das planilhas se encontram agora formato que esperávamos, após aplicarmos função ler_excel(), pois temos apenas colunas que SEMAD necessita.Porém, ainda não atingimos o resultado desejado. Lembre-se que cada uma das 12 planilhas, se encontram momento, separadas em cada elemento de uma lista. Nós estabelecemos anteriormente, que o ideal seria reunirmos todas essas 12 tabelas, em uma só. Para executarmos esse passo, nós podemos simplesmente aplicar função bind_rows() sobre lista planilhas. Como o próprio nome da função dá entender, ela busca unir, ou colar linhas de diferentes tabelas. Em uma outra perspectiva, é como se função bind_rows() estivesse “empilhando” tabelas, uma em cima da outra. Portanto, se nós temos 12 tabelas diferentes, onde cada linha de cada uma dessas tabelas representa um dos 853 municípios de Minas Gerais, ao unirmos todas essas tabelas, deveríamos ter como resultado, uma única tabela contendo 10.236 linhas (\\(853 \\times 12 = 10.236\\)).","code":"\nlibrary(readxl)\n\nAbril_2019 <- read_excel(\"planilhas/Abril_2019.xlsx\")\n\nAbril_2019## # A tibble: 853 x 27\n##     IBGE1 IBGE2   SEF Municípios        População `População dos 50 + Popu~\n##     <dbl> <dbl> <dbl> <chr>                 <dbl>                     <dbl>\n##  1 310010    10     1 ABADIA DOS DOURA~     8847.                         0\n##  2 310020    20     2 ABAETÉ               29470.                         0\n##  3 310030    30     3 ABRE CAMPO           17087.                         0\n##  4 310040    40     4 ACAIACA               5068.                         0\n##  5 310050    50     5 AÇUCENA              12151.                         0\n##  6 310060    60     6 ÁGUA BOA             17258.                         0\n##  7 310070    70     7 ÁGUA COMPRIDA         2544.                         0\n##  8 310080    80     8 AGUANIL               5644.                         0\n##  9 310090    90     9 ÁGUAS FORMOSAS       24321.                         0\n## 10 310100   100    10 ÁGUAS VERMELHAS      17102.                         0\n## # ... with 843 more rows, and 21 more variables: Área Geográfica <dbl>,\n## #   Educação <dbl>, Patrimônio Cultural <dbl>, Receita Própria <dbl>,\n## #   Cota Mínima <dbl>, Mineradores <dbl>, Saúde Per Capita <dbl>,\n## #   VAF <dbl>, Esportes <dbl>, Turismo <dbl>, Penitenciárias <dbl>,\n## #   Recursos Hídricos <dbl>, Produção de Alimentos 2º semestre <dbl>,\n## #   Unidades de Conservação (IC i) <dbl>, Saneamento <dbl>,\n## #   Mata Seca <dbl>, Meio Ambiente <dbl>, PSF <dbl>, ICMS Solidário <dbl>,\n## #   Índice Mínimo per capita <dbl>, Total <dbl>\nnomes_planilhas <- list.files(\"planilhas/\")\n\nnomes_planilhas##  [1] \"Abril_2019.xlsx\"     \"Agosto_2019.xlsx\"    \"Dezembro_2019.xlsx\" \n##  [4] \"Fevereiro_2019.xlsx\" \"Janeiro_2019.xlsx\"   \"Julho_2019.xlsx\"    \n##  [7] \"Junho_2019.xlsx\"     \"Maio_2019.xlsx\"      \"Marco_2019.xlsx\"    \n## [10] \"Novembro_2019.xlsx\"  \"Outubro_2019.xlsx\"   \"Setembro_2019.xlsx\"\nlibrary(readxl)\nlibrary(tidyverse)\n\nler_excel <- function(x){\n  \n    caminho <- paste(\"planilhas/\", x, sep = \"\")\n    \n    planilha <- read_excel(caminho) %>% \n      mutate(\n        Origem = x,\n        Ano = parse_number(x),\n        Mês = str_sub(x, start = 1, end = str_length(x) - 10)\n      ) %>% \n      select(IBGE1, `Municípios`, Origem, Ano, `Mês`, `Meio Ambiente`)\n    \n    return(planilha)\n}\nler_excel(nomes_planilhas[1])## # A tibble: 853 x 6\n##     IBGE1 Municípios          Origem            Ano Mês   `Meio Ambiente`\n##     <dbl> <chr>               <chr>           <dbl> <chr>           <dbl>\n##  1 310010 ABADIA DOS DOURADOS Abril_2019.xlsx  2019 Abril              0 \n##  2 310020 ABAETÉ              Abril_2019.xlsx  2019 Abril              0 \n##  3 310030 ABRE CAMPO          Abril_2019.xlsx  2019 Abril          10433.\n##  4 310040 ACAIACA             Abril_2019.xlsx  2019 Abril              0 \n##  5 310050 AÇUCENA             Abril_2019.xlsx  2019 Abril           7727.\n##  6 310060 ÁGUA BOA            Abril_2019.xlsx  2019 Abril          10433.\n##  7 310070 ÁGUA COMPRIDA       Abril_2019.xlsx  2019 Abril          21909.\n##  8 310080 AGUANIL             Abril_2019.xlsx  2019 Abril              0 \n##  9 310090 ÁGUAS FORMOSAS      Abril_2019.xlsx  2019 Abril              0 \n## 10 310100 ÁGUAS VERMELHAS     Abril_2019.xlsx  2019 Abril          14750.\n## # ... with 843 more rows\nplanilhas <- vector(mode = \"list\", length = length(nomes_planilhas))\n\nfor(i in seq_along(nomes_planilhas)){\n  \n  planilhas[[i]] <- ler_excel(nomes_planilhas[i])\n  \n}\nplanilhas[[3]]## # A tibble: 853 x 6\n##     IBGE1 Municípios         Origem             Ano Mês     `Meio Ambiente`\n##     <dbl> <chr>              <chr>            <dbl> <chr>             <dbl>\n##  1 310010 ABADIA DOS DOURAD~ Dezembro_2019.x~  2019 Dezemb~              0 \n##  2 310020 ABAETÉ             Dezembro_2019.x~  2019 Dezemb~              0 \n##  3 310030 ABRE CAMPO         Dezembro_2019.x~  2019 Dezemb~              0 \n##  4 310040 ACAIACA            Dezembro_2019.x~  2019 Dezemb~              0 \n##  5 310050 AÇUCENA            Dezembro_2019.x~  2019 Dezemb~           2617.\n##  6 310060 ÁGUA BOA           Dezembro_2019.x~  2019 Dezemb~              0 \n##  7 310070 ÁGUA COMPRIDA      Dezembro_2019.x~  2019 Dezemb~              0 \n##  8 310080 AGUANIL            Dezembro_2019.x~  2019 Dezemb~          16776.\n##  9 310090 ÁGUAS FORMOSAS     Dezembro_2019.x~  2019 Dezemb~              0 \n## 10 310100 ÁGUAS VERMELHAS    Dezembro_2019.x~  2019 Dezemb~          21705.\n## # ... with 843 more rows\nplanilhas <- bind_rows(planilhas)\n\nplanilhas## # A tibble: 10,236 x 6\n##     IBGE1 Municípios          Origem            Ano Mês   `Meio Ambiente`\n##     <dbl> <chr>               <chr>           <dbl> <chr>           <dbl>\n##  1 310010 ABADIA DOS DOURADOS Abril_2019.xlsx  2019 Abril              0 \n##  2 310020 ABAETÉ              Abril_2019.xlsx  2019 Abril              0 \n##  3 310030 ABRE CAMPO          Abril_2019.xlsx  2019 Abril          10433.\n##  4 310040 ACAIACA             Abril_2019.xlsx  2019 Abril              0 \n##  5 310050 AÇUCENA             Abril_2019.xlsx  2019 Abril           7727.\n##  6 310060 ÁGUA BOA            Abril_2019.xlsx  2019 Abril          10433.\n##  7 310070 ÁGUA COMPRIDA       Abril_2019.xlsx  2019 Abril          21909.\n##  8 310080 AGUANIL             Abril_2019.xlsx  2019 Abril              0 \n##  9 310090 ÁGUAS FORMOSAS      Abril_2019.xlsx  2019 Abril              0 \n## 10 310100 ÁGUAS VERMELHAS     Abril_2019.xlsx  2019 Abril          14750.\n## # ... with 10,226 more rows"},{"path":"funções-e-loops-no-r.html","id":"conclusão","chapter":"Capítulo 5 Funções e Loops no R","heading":"5.6.2 Conclusão","text":"Uma tarefa que inicialmente seria trabalhosa e extremamente repetitiva em muitos programas comuns (como o Excel), pode ser resolvida R de maneira fácil e rápida, através uso de uma função e um loop. Tínhamos como objetivo, reunir os dados presentes em 12 planilhas em uma única tabela, e em seguida, selecionar apenas aquelas colunas que eram de interesse da SEMAD. Se reunirmos todos os comandos que utilizamos R, temos um script com mais ou menos 30 linhas. Ou seja, com apenas 30 linhas, nós economizamos um tempo e esforço enormes em nosso trabalho.partir daqui, com tabela única em nossas mãos, nós precisamos apenas exportar essa tabela para fora R. Algo que pode ser rapidamente realizado através de uma função como write_csv2(), que introduzimos na seção Exportando dados em arquivos de texto com readr.","code":"\nlibrary(readxl)\nlibrary(tidyverse)\n\nnomes_planilhas <- list.files(\"planilhas/\")\n\nler_excel <- function(x){\n  \n    caminho <- paste(\"planilhas/\", x, sep = \"\")\n    \n    planilha <- read_excel(caminho) %>% \n      mutate(\n        Origem = x,\n        Ano = parse_number(x),\n        Mês = str_sub(x, start = 1, end = str_length(x) - 10)\n      ) %>% \n      select(IBGE1, `Municípios`, Origem, Ano, `Mês`, `Meio Ambiente`)\n    \n    return(planilha)\n}\nplanilhas <- vector(mode = \"list\", length = length(nomes_planilhas))\n\nfor(i in seq_along(nomes_planilhas)){\n  \n  planilhas[[i]] <- ler_excel(nomes_planilhas[i])\n  \n}\n\nplanilhas <- bind_rows(planilhas)"},{"path":"introdução-a-base-de-dados-relacionais-no-r.html","id":"introdução-a-base-de-dados-relacionais-no-r","chapter":"Capítulo 6 Introdução a base de dados relacionais no R","heading":"Capítulo 6 Introdução a base de dados relacionais no R","text":"","code":""},{"path":"introdução-a-base-de-dados-relacionais-no-r.html","id":"introdução-e-pré-requisitos-1","chapter":"Capítulo 6 Introdução a base de dados relacionais no R","heading":"6.1 Introdução e pré-requisitos","text":"Segundo Nield (2016, p 53), joins são uma das funcionalidades que definem linguagem SQL (Structured Query Language). Por isso, joins são um tipo de operação muito relacionado à RDBMS (Relational DataBase Management Systems), que em sua maioria, utilizam linguagem SQL. Logo, essa seção será muito familiar para aqueles que possuem experiência com essa linguagem.Para executarmos uma operação de join, os pacotes básicos R oferecem função merge(). Entretanto, vamos abordar o pacote dplyr neste capítulo, que também possui funções especializadas neste tipo de operação. Com isso, para ter acesso às funções que vamos mostrar aqui, você pode chamar tanto pelo pacote dplyr quanto pelo tidyverse.","code":"\nlibrary(tidyverse)\nlibrary(dplyr)"},{"path":"introdução-a-base-de-dados-relacionais-no-r.html","id":"sec:relational_data_keys","chapter":"Capítulo 6 Introdução a base de dados relacionais no R","heading":"6.2 Dados relacionais e o conceito de key","text":"Normalmente, trabalhamos com diversas bases de dados diferentes ao mesmo tempo. Pois é muito incomum, que uma única tabela contenha todas informações das quais necessitamos e, por isso, transportar os dados de uma tabela para outra se torna uma atividade essencial em muitas ocasiões.Logo, de alguma maneira, os dados presentes nessas diversas tabelas se relacionam entre si. Por exemplo, suponha que você possua uma tabela contendo o PIB dos municípios estado de Minas Gerais, e uma outra tabela contendo dados demográficos desses mesmos municípios. Se você deseja unir essas duas tabelas em uma só, você precisa de algum mecanismo que possa conectar um valor município X na tabela com linha da tabela B correspondente ao mesmo município X, e através dessa conexão, conduzir o valor da tabela para esse local específico da tabela B, ou vice-versa. O processo que realiza esse cruzamento entre informações, e que por fim, mescla ou funde duas tabelas de acordo com essas conexões, é chamado de join.Por isso, dizemos que os nossos dados são “relacionais.” Pelo fato de que nós possuímos diversas tabelas que descrevem os mesmos indivíduos, municípios, firmas ou eventos. Mesmo que essas tabelas estejam trazendo variáveis ou informações muito diferentes desses indivíduos, elas possuem essa característica em comum e, com isso, possuem uma relação entre si, e vamos frequentemente nos aproveitar dessa relação para executarmos análises mais completas.Porém, para transportarmos esses dados de uma tabela outra, precisamos de alguma chave, ou de algum mecanismo que seja capaz de identificar relações entre duas tabelas. Em outras palavras, se temos na tabela , um valor pertencente ao indivíduo X, e queremos transportar esse valor para tabela B, nós precisamos de algum meio que possa identificar o local da tabela B que seja referente ao indivíduo X. O mecanismo que permite essa comparação, é o que chamamos de key ou de “chave.”Como exemplo inicial, vamos utilizar tabela info, que descreve características pessoais de um conjunto de músicos famosos. Também temos tabela band_instruments, que apenas indica qual o instrumento musical utilizado por parte dos músicos descritos na tabela info.Portanto, precisamos de uma key para detectarmos relações entre tabelas info e band_instruments. Uma key conciste em uma variável (ou um conjunto de variáveis), que é capaz de identificar unicamente cada indivíduo descrito em uma tabela, sendo que essa variável (ou esse conjunto de variáveis), deve obrigatoriamente estar presente em ambas tabelas em que desejamos aplicar o join. Dessa forma, podemos através dessa variável, discenir quais indivíduos estão presentes nas duas tabelas, e quais se encontram em apenas uma delas.Ao observar tabelas info e band_instruments, você talvez perceba que ambas possuem uma coluna denominada name. nosso caso, essa é coluna que representa key entre tabelas info e band_instruments. Logo, ao identificar o músico que está sendo tratado em cada linha, coluna name nos permite cruzar informações existentes em ambas tabelas. Com isso, podemos observar que os músicos John e Paul, estão disponíveis em ambas tabelas, mas os músicos Mick, George e Ringo estão descritos apenas na tabela info, enquanto o músico Keith se encontra apenas na tabela band_instruments.\nFigure 6.1: Cruzamento entre tabelas de acordo com coluna name\nSegundo Nield (2016), podemos ter dois tipos de keys existentes em uma tabela:Primary key: uma variável capaz de identificar unicamente cada uma das observações presentes em sua tabela.Primary key: uma variável capaz de identificar unicamente cada uma das observações presentes em sua tabela.Foreign key: uma variável capaz de identificar unicamente cada uma das observações presentes em uma outra tabela.Foreign key: uma variável capaz de identificar unicamente cada uma das observações presentes em uma outra tabela.Com essas características em mente, podemos afirmar que coluna name existente nas tabelas info e band_instruments, se trata de uma primary key. Pois em ambas tabelas, mais especificamente em cada linha dessa coluna, temos um músico diferente, ou em outras palavras, não há um músico duplicado.Por outro lado, uma foreign key normalmente contém valores repetidos ao longo da base e, por essa razão, não são capazes de identificar unicamente uma observação na tabela em que se encontram. Porém, os valores de uma foreign key certamente fazem referência uma primary key existente em uma outra tabela. Tendo isso em mente, o objetivo de uma foreign key não é o de identificar cada observação presente em uma tabela, mas sim, de indicar ou explicitar relação que sua tabela possui com primary key presente em uma outra tabela.Por exemplo, suponha que eu tenha tabela children abaixo. Essa tabela descreve os filhos de alguns músicos famosos, e coluna father caracteriza-se como foreign key dessa tabela. Não apenas porque os valores da coluna father se repetem ao longo da base, mas também, porque essa coluna pode ser claramente cruzada com coluna name pertencente às tabelas info e band_instruments.","code":"\nd <- c(\"1943-07-26\", \"1940-09-10\", \"1942-06-18\", \"1943-02-25\", \"1940-07-07\")\n\ninfo <- tibble(\n  name = c(\"Mick\", \"John\", \"Paul\", \"George\", \"Ringo\"),\n  band = c(\"Rolling Stones\", \"Beatles\", \"Beatles\", \"Beatles\", \"Beatles\"),\n  born = as.Date(d),\n  children = c(TRUE)\n)\n\nband_instruments <- tibble(\n  name = c(\"John\", \"Paul\", \"Keith\"),\n  plays = c(\"guitar\", \"bass\", \"guitar\")\n)\ninfo## # A tibble: 5 x 4\n##   name   band           born       children\n##   <chr>  <chr>          <date>     <lgl>   \n## 1 Mick   Rolling Stones 1943-07-26 TRUE    \n## 2 John   Beatles        1940-09-10 TRUE    \n## 3 Paul   Beatles        1942-06-18 TRUE    \n## 4 George Beatles        1943-02-25 TRUE    \n## 5 Ringo  Beatles        1940-07-07 TRUE\nband_instruments## # A tibble: 3 x 2\n##   name  plays \n##   <chr> <chr> \n## 1 John  guitar\n## 2 Paul  bass  \n## 3 Keith guitar\nchildren <- tibble(\n  child = c(\"Stella\", \"Beatrice\", \"James\", \"Mary\",\n            \"Heather\", \"Sean\", \"Julian\", \"Zak\",\n            \"Lee\", \"Jason\", \"Dhani\"),\n  sex = c(\"F\", \"F\", \"M\", \"F\", \"F\", \"M\", \"M\", \"M\", \"F\", \"M\", \"M\"),\n  father = c(rep(\"Paul\", times = 5), \"John\", \"John\",\n             rep(\"Ringo\", times = 3), \"Harrison\")\n)\n\nchildren## # A tibble: 11 x 3\n##    child    sex   father  \n##    <chr>    <chr> <chr>   \n##  1 Stella   F     Paul    \n##  2 Beatrice F     Paul    \n##  3 James    M     Paul    \n##  4 Mary     F     Paul    \n##  5 Heather  F     Paul    \n##  6 Sean     M     John    \n##  7 Julian   M     John    \n##  8 Zak      M     Ringo   \n##  9 Lee      F     Ringo   \n## 10 Jason    M     Ringo   \n## 11 Dhani    M     Harrison"},{"path":"introdução-a-base-de-dados-relacionais-no-r.html","id":"introduzindo-joins","chapter":"Capítulo 6 Introdução a base de dados relacionais no R","heading":"6.3 Introduzindo joins","text":"Tendo esses pontos em mente, o pacote dplyr nos oferece quatro funções voltadas para operações de join. Cada uma dessas funções executam um tipo de join diferente, que vamos comentar na próxima seção. Por agora, vamos focar apenas na função inner_join(), que como o seu próprio nome dá entender, busca aplicar um inner join.Para utilizar essa função, precisamos nos preocupar com três argumentos principais. Os dois primeiros argumentos (x e y), definem os data.frame’s serem fundidos pela função. Já terceiro argumento (), você deve delimitar coluna, ou o conjunto de colunas que representam key entre tabelas fornecidas em x e y.Assim como em qualquer outro tipo de join, duas tabelas envolvidas serão unidas, porém, em um inner join, apenas linhas de indivíduos que se encontram em ambas tabelas serão retornadas na nova tabela gerada. Perceba abaixo, que função inner_join() criou uma nova tabela contendo todas colunas presentes nas tabelas info e band_instruments como esperávamos, e que ela manteve apenas linhas referentes aos músicos John e Paul, que são os únicos indivíduos que aparecem em ambas tabelas.Ao observar esse resultado, você talvez chegue conclusão de que um processo de join se trata mesmo processo executado pela função PROCV() Excel. Essa é uma ótima comparação! Pois função PROCV() realiza justamente um join parcial, ao trazer para tabela , uma coluna pertencente tabela B, de acordo com uma key que conecta duas tabelas.Por outro lado, nós não podemos afirmar que função PROCV() busca construir um join per se. Pois um join conciste em um processo de união, em que estamos literalmente fundindo duas tabelas em uma só. Já função PROCV(), é capaz de transportar apenas uma única coluna por tabela, logo, não é de sua filosofia, fundir tabelas envolvidas. Por isso, se temos cinco colunas em uma tabela , quais desejamos levar até tabela B, nós precisamos de cinco PROCV()’s diferentes Excel, enquanto R, precisamos de apenas um inner_join() para realizarmos tal ação.Por último, vale destacar uma característica muito importante de um join, que é o seu processo de pareamento. Devido essa característica, ordem da linhas presentes em ambas tabelas se torna irrelevante para o resultado. Por exemplo, veja na figura 6.2, um exemplo de join, onde coluna ID representa key entre duas tabelas. Repare que linhas na tabela à esquerda que se referem, por exemplo, aos indivíduos de ID 105, 107 e 108, se encontram em linhas diferentes na tabela à direita. Mesmo que esses indivíduos estejam em locais diferentes, função responsável pelo join, vai realizar um pareamento entre duas tabelas, antes de fundí-las. Dessa maneira, podemos nos certificar que informações de cada indivíduo são corretamente posicionadas na tabela resultante.\nFigure 6.2: Representação de um join entre duas tabelas\n","code":"\ninner_join(info, band_instruments, by = \"name\")## # A tibble: 2 x 5\n##   name  band    born       children plays \n##   <chr> <chr>   <date>     <lgl>    <chr> \n## 1 John  Beatles 1940-09-10 TRUE     guitar\n## 2 Paul  Beatles 1942-06-18 TRUE     bass\n## -----------------------------------------------\n## A mesma operação com o uso do pipe ( %>% ):\ninfo %>% \n  inner_join(band_instruments, by = \"name\")"},{"path":"introdução-a-base-de-dados-relacionais-no-r.html","id":"sec:config_colunas_keys","chapter":"Capítulo 6 Introdução a base de dados relacionais no R","heading":"6.4 Configurações sobre as colunas e keys utilizadas no join","text":"Haverá momentos em que uma única coluna não será o bastante para identificarmos cada observação de nossa base. Por isso, teremos oportunidades em que devemos utilizar combinação entre várias colunas, com o objetivo de formarmos uma primary key em nossa tabela.Por exemplo, suponha que você trabalha diariamente com o registro de entradas estoque de um supermercado. Imagine que você possua tabela registro abaixo, que contém dados da seção de bebidas estoque, e que apresentam o dia e mes em que uma determinada carga chegou ao estoque da empresa, além de uma descrição de seu conteúdo (descricao), seu valor de compra (valor) e unidades inclusas (unidades).Nessa tabela, colunas dia, mes, ano, valor, unidades e descricao, sozinhas, são insuficientes para identificarmos cada carga registrada na tabela. Mesmo que, atualmente, cada valor presente na coluna descricao seja único, essa característica provavelmente não vai resistir por muito tempo. Pois o supermercado pode muito bem receber amanhã, por exemplo, uma outra carga de refrigerantes de 2 litros da Mate Couro.Por outro lado, combinação dos valores presentes nas colunas dia, mes, ano, valor, unidades e descricao, pode ser o suficiente para criarmos um código de identificação único para cada carga. Por exemplo, ao voltarmos à tabela registro, podemos encontrar duas cargas que chegaram mesmo dia 18, mesmo mês 2, mesmo ano de 2020, e trazendo mesmas 325 unidades. Todavia, essas duas cargas, possuem descrições diferentes: uma delas incluía garrafas preenchidas com Coca Cola, enquanto outra, continha Mate Couro. Concluindo, ao aliarmos informações referentes data de entrada (18/02/2020), quantidades inclusas nas cargas (325 unidades), e suas descrições (Coca Cola 2L e Mate Couro 2L), podemos enfim diferenciar essas duas cargas:Uma carga que entrou dia 18/02/2020, incluía 325 unidades de 2 litros de Coca Cola.Uma carga que entrou dia 18/02/2020, incluía 325 unidades de 2 litros de Coca Cola.Uma carga que entrou dia 18/02/2020, incluía 325 unidades de 2 litros de Mate Couro.Uma carga que entrou dia 18/02/2020, incluía 325 unidades de 2 litros de Mate Couro.Como um outro exemplo, podemos utilizar bases flights e weather, provenientes pacote nycflights13. Perceba abaixo, que base flights já possui um número grande colunas. Essa tabela apresenta dados diários, referentes diversos voôs que partiram da cidade de Nova York (EUA) durante o ano de 2013. Já tabela weather, contém dados meteorológicos em uma dada hora, e em diversas datas mesmo ano, e que foram especificamente coletados nos aeroportos da mesma cidade de Nova York.Ao aplicarmos um join entre essas tabelas, poderíamos analisar características meterológicas que um determinado avião enfrentou ao levantar voô. Entretanto, necessitaríamos empregar ao menos cinco colunas diferentes para formarmos uma key adequada entre essas tabelas. Pois cada situação meterológica descrita na tabela weather, ocorre em um uma dada localidade, e em um horário específico de um determinado dia. Com isso, teríamos de utilizar colunas: year, month e day para identificarmos data correspondente cada situação; mais coluna hour para determinarmos o momento dia em que essa situação ocorreu; além da coluna origin, que marca o aeroporto de onde cada voô partiu e, portanto, nos fornece uma localização espaço geográfico para cada situação meteorológica.Portanto, em todos os momentos em que você precisar utilizar um conjunto de colunas para formar uma key, como o caso das tabelas weather e flights acima, você deve fornecer um vetor contendo o nome dessas colunas para o argumento da função de join que está utilizando, assim como exemplo abaixo.Porém, tabela flights já possui um número muito grande colunas e, por essa razão, não conseguimos visualizar resultado join, diversas colunas importadas da tabela weather. Sabemos que um join gera, por padrão, uma nova tabela contendo todas colunas de ambas tabelas utilizadas. Contudo, o exemplo acima demonstra que em certas ocasiões, o uso de muitas colunas pode sobrecarregar sua visão e, com isso, dificultar o seu foco que é de fato importante em sua análise.Tendo isso em mente, haverá instantes em que você deseja trazer apenas algumas colunas de uma das tabelas envolvidas join. Mas não há como alterarmos natureza de um join, logo, todas colunas de ambas colunas serão sempre incluídas em seu resultado. Por isso, o ideal é que você selecione colunas desejadas de uma das tabelas antes de empregá-las em um join.Ou seja, ao invés de fornecer tabela completa à função, você pode utilizar ferramentas como select() ou subsetting, para extrair parte desejada de uma das tabelas, e fornecer o resultado dessa seleção para função inner_join(). Entretanto, . De outra forma, não se esqueça de incluir em sua seleção, colunas que você proveu ao argumento .Por exemplo, supondo que você precisasse em seu resultado apenas das colunas dep_time e dep_delay da tabela flights, você poderia fornecer os comandos seguir:Antes de partirmos para próxima seção, vale pena comentar sobre um outro aspecto importante em um join. colunas que formam sua key devem estar nomeadas da mesma maneira em ambas tabelas. Por exemplo, se nós voltarmos às tabelas info e band_instruments, e renomearmos coluna name para member em uma das tabelas, um erro será levantado ao tentarmos aplicar novamente um join sobre tabelas.Logo, ajustes são necessários sobre o argumento , de forma revelarmos para função reponsável pelo join, existência dessa diferença existente entre os nomes dados às colunas que representam key entre tabelas. Fazendo uso dos argumentos x e y como referências, para realizar esse ajuste, você deve igualar o nome dado à coluna da tabela x ao nome dado à coluna correspondente na tabela y, dentro de um vetor - c(), como está demonstrado abaixo.","code":"\nregistro <- tibble(\n  dia = c(3, 18, 18, 25, 25),\n  mes = c(2, 2, 2, 2, 3),\n  ano = 2020,\n  unidades = c(410, 325, 325, 400, 50),\n  valor = c(450, 1400, 1150, 670, 2490),\n  descricao = c(\"Fanta Laranja 350ml\", \n                \"Coca Cola 2L\", \"Mate Couro 2L\",\n                \"Kapo Uva 200ml\", \"Absolut Vodka 1L\")\n)\n\nregistro## # A tibble: 5 x 6\n##     dia   mes   ano unidades valor descricao          \n##   <dbl> <dbl> <dbl>    <dbl> <dbl> <chr>              \n## 1     3     2  2020      410   450 Fanta Laranja 350ml\n## 2    18     2  2020      325  1400 Coca Cola 2L       \n## 3    18     2  2020      325  1150 Mate Couro 2L      \n## 4    25     2  2020      400   670 Kapo Uva 200ml     \n## 5    25     3  2020       50  2490 Absolut Vodka 1L\nlibrary(nycflights13)\nflights## # A tibble: 336,776 x 19\n##     year month   day dep_time sched_dep_time dep_delay arr_time\n##    <int> <int> <int>    <dbl>          <dbl>     <dbl>    <dbl>\n##  1  2013     1     1      517            515         2      830\n##  2  2013     1     1      533            529         4      850\n##  3  2013     1     1      542            540         2      923\n##  4  2013     1     1      544            545        -1     1004\n##  5  2013     1     1      554            600        -6      812\n##  6  2013     1     1      554            558        -4      740\n##  7  2013     1     1      555            600        -5      913\n##  8  2013     1     1      557            600        -3      709\n##  9  2013     1     1      557            600        -3      838\n## 10  2013     1     1      558            600        -2      753\n## # ... with 336,766 more rows, and 12 more variables: sched_arr_time <dbl>,\n## #   arr_delay <dbl>, carrier <chr>, flight <dbl>, tailnum <chr>,\n## #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n## #   minute <dbl>, time_hour <dttm>\nweather## # A tibble: 26,115 x 15\n##    origin  year month   day  hour  temp  dewp humid wind_dir wind_speed\n##    <chr>  <int> <int> <int> <int> <dbl> <dbl> <dbl>    <dbl>      <dbl>\n##  1 EWR     2013     1     1     1  39.0  26.1  59.4      270      10.4 \n##  2 EWR     2013     1     1     2  39.0  27.0  61.6      250       8.06\n##  3 EWR     2013     1     1     3  39.0  28.0  64.4      240      11.5 \n##  4 EWR     2013     1     1     4  39.9  28.0  62.2      250      12.7 \n##  5 EWR     2013     1     1     5  39.0  28.0  64.4      260      12.7 \n##  6 EWR     2013     1     1     6  37.9  28.0  67.2      240      11.5 \n##  7 EWR     2013     1     1     7  39.0  28.0  64.4      240      15.0 \n##  8 EWR     2013     1     1     8  39.9  28.0  62.2      250      10.4 \n##  9 EWR     2013     1     1     9  39.9  28.0  62.2      260      15.0 \n## 10 EWR     2013     1     1    10  41    28.0  59.6      260      13.8 \n## # ... with 26,105 more rows, and 5 more variables: wind_gust <dbl>,\n## #   precip <dbl>, pressure <dbl>, visib <dbl>, time_hour <dttm>\ninner_join(\n  flights,\n  weather,\n  by = c(\"year\", \"month\", \"day\", \"hour\", \"origin\")\n)## # A tibble: 335,220 x 29\n##     year month   day dep_time sched_dep_time dep_delay arr_time\n##    <int> <int> <int>    <dbl>          <dbl>     <dbl>    <dbl>\n##  1  2013     1     1      517            515         2      830\n##  2  2013     1     1      533            529         4      850\n##  3  2013     1     1      542            540         2      923\n##  4  2013     1     1      544            545        -1     1004\n##  5  2013     1     1      554            600        -6      812\n##  6  2013     1     1      554            558        -4      740\n##  7  2013     1     1      555            600        -5      913\n##  8  2013     1     1      557            600        -3      709\n##  9  2013     1     1      557            600        -3      838\n## 10  2013     1     1      558            600        -2      753\n## # ... with 335,210 more rows, and 22 more variables: sched_arr_time <dbl>,\n## #   arr_delay <dbl>, carrier <chr>, flight <dbl>, tailnum <chr>,\n## #   origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\n## #   minute <dbl>, time_hour.x <dttm>, temp <dbl>, dewp <dbl>, humid <dbl>,\n## #   wind_dir <dbl>, wind_speed <dbl>, wind_gust <dbl>, precip <dbl>,\n## #   pressure <dbl>, visib <dbl>, time_hour.y <dttm>\ncols_para_key <- c(\n  \"year\", # Coluna 1 para key\n  \"month\", # Coluna 2 para key \n  \"day\", # Coluna 3 para key\n  \"hour\", # Coluna 4 para key\n  \"origin\" # Coluna 5 para key\n)\n\ncols_desejadas <- c(\"dep_time\", \"dep_delay\")\n\ncols_c <- c(cols_para_key, cols_desejadas)\n\ninner_join(\n  flights %>% select(all_of(cols_c)),\n  weather,\n  by = cols_para_key\n)## # A tibble: 335,220 x 17\n##     year month   day  hour origin dep_time dep_delay  temp  dewp humid\n##    <int> <int> <int> <dbl> <chr>     <dbl>     <dbl> <dbl> <dbl> <dbl>\n##  1  2013     1     1     5 EWR         517         2  39.0  28.0  64.4\n##  2  2013     1     1     5 LGA         533         4  39.9  25.0  54.8\n##  3  2013     1     1     5 JFK         542         2  39.0  27.0  61.6\n##  4  2013     1     1     5 JFK         544        -1  39.0  27.0  61.6\n##  5  2013     1     1     6 LGA         554        -6  39.9  25.0  54.8\n##  6  2013     1     1     5 EWR         554        -4  39.0  28.0  64.4\n##  7  2013     1     1     6 EWR         555        -5  37.9  28.0  67.2\n##  8  2013     1     1     6 LGA         557        -3  39.9  25.0  54.8\n##  9  2013     1     1     6 JFK         557        -3  37.9  27.0  64.3\n## 10  2013     1     1     6 LGA         558        -2  39.9  25.0  54.8\n## # ... with 335,210 more rows, and 7 more variables: wind_dir <dbl>,\n## #   wind_speed <dbl>, wind_gust <dbl>, precip <dbl>, pressure <dbl>,\n## #   visib <dbl>, time_hour <dttm>\n## ----------------------------------------\n## Ou por subsetting:\ninner_join(\n  flights[ , cols_c],\n  weather,\n  by = cols_para_key\n)\ncolnames(band_instruments)[1] <- \"member\"\n\ninner_join(info, band_instruments, by = \"name\")Erro: Join columns must be present in data.\nx Problem with `name`.\nRun `rlang::last_error()` to see where the error occurred.\ninner_join(info, band_instruments, by = c(\"name\" = \"member\"))## # A tibble: 2 x 5\n##   name  band    born       children plays \n##   <chr> <chr>   <date>     <lgl>    <chr> \n## 1 John  Beatles 1940-09-10 TRUE     guitar\n## 2 Paul  Beatles 1942-06-18 TRUE     bass"},{"path":"introdução-a-base-de-dados-relacionais-no-r.html","id":"diferentes-tipos-de-join","chapter":"Capítulo 6 Introdução a base de dados relacionais no R","heading":"6.5 Diferentes tipos de join","text":"Portanto, um join busca construir uma união entre duas tabelas. Porém, podemos realizar essa união de diferentes formas, e até o momento, apresentei apenas uma de suas formas, o inner join, que é executado pela função inner_join(). Nesse método, o join mantém apenas linhas que puderam ser encontradas em ambas tabelas. Logo, se um indivíduo está presente na tabela , mas não se encontra na tabela B, esse indivíduo será descartado em um inner join entre tabelas e B. Como foi destacado por Wickham Grolemund (2017, p 181), essa característica torna o inner join pouco apropriado para maioria das análises, pois uma importante perda de observações pode ser facilmente gerada neste processo.Com isso, nós podemos empregar tipos diferentes de joins, que são comumente chamados de outer joins, pois esses tipos buscam preservar linhas de pelo menos uma das tabelas envolvidas join em questão. Sendo eles:left_join(): mantém todas linhas da tabela definida argumento x, ou tabela à esquerda join, mesmo que os indivíduos descritos nessa tabela não tenham sido encontrados em ambas tabelas.left_join(): mantém todas linhas da tabela definida argumento x, ou tabela à esquerda join, mesmo que os indivíduos descritos nessa tabela não tenham sido encontrados em ambas tabelas.right_join(): mantém todas linhas da tabela definida argumento y, ou tabela à direita join, mesmo que os indivíduos descritos nessa tabela não tenham sido encontrados em ambas tabelas.right_join(): mantém todas linhas da tabela definida argumento y, ou tabela à direita join, mesmo que os indivíduos descritos nessa tabela não tenham sido encontrados em ambas tabelas.full_join(): mantém todas linhas de ambas tabelas definidas nos argumentos x e y, mesmo que os indivíduos de uma dessas tabelas não tenham sido encontrados em ambas tabelas.full_join(): mantém todas linhas de ambas tabelas definidas nos argumentos x e y, mesmo que os indivíduos de uma dessas tabelas não tenham sido encontrados em ambas tabelas.Em todas funções de join mostradas aqui, o primeiro argumento é chamado de x, e o segundo, de y, sendo esses os argumentos que definem duas tabelas serem utilizadas join. Simplificadamente, diferença entre left_join(), right_join() e full_join() reside apenas em quais linhas das tabelas utilizadas, são conservadas por essas funções produto final join. Como essas diferenças são simples, descrições acima já lhe dão uma boa ideia de quais serão linhas conservadas em cada função. Todavia, darei seguir, uma visão mais formal desses comportamentos, com o objetivo principal de fornecer uma segunda visão que pode, principalmente, facilitar sua memorização que cada função faz.Para seguir esse caminho, é interessante que você tente interpretar um join partir de uma perspectiva mais geral ou menos minuciosa processo. Ao aplicarmos um join entre tabelas e B, estamos resumidamente, extraindo colunas da tabela B e adicionando à tabela (ou vice-versa). Com isso, temos nessa concepção, tabela fonte, ou tabela de onde colunas são retiradas, e tabela destinatária, ou tabela para onde essas colunas são levadas. Portanto, segundo esse ponto de vista, o join possui sentido e direção, assim como um vetor em um espaço tridimensional. Pois o processo sempre parte da tabela fonte em direção tabela destinatária. Dessa forma, em um join, ao construírmos uma nova tabela que representa união entre duas tabelas, estamos basicamente extraindo colunas da tabela fonte e incorporando à tabela destinatária.Com isso, eu quero criar perspectiva, de que tabela fonte e tabela destinatária, ocupam lados join, como na figura 6.3. Ou seja, por esse ângulo, estamos compreendendo o join como uma operação que ocorre sempre da direita para esquerda, ou um processo em que estamos sempre carregando um conjunto de colunas da tabela à direita em direção tabela à esquerda. Se mesclarmos essa visão, com primeiras descrições dos outer joins que fornecemos, temos que o argumento x corresponde tabela destinatária, e o argumento y, tabela fonte. Dessa maneira, tabela destinatária (ou o argumento x) é sempre tabela que ocupa o lado esquerdo join, enquanto tabela fonte (ou o argumento y) sempre se trata da tabela que ocupa o lado direito da operação.\nFigure 6.3: tabelas ocupam lados em um join\nLogo, função left_join() busca manter linhas da tabela destinatária (ou tabela que você definiu argumento x da função) intactas resultado join. Isso significa, que caso função left_join() não encontre na tabela fonte, uma linha que corresponde um certo indivíduo presente na tabela destinatária, essa linha será mantida resultado final join. Porém, como está demonstrado abaixo, em todas situações em que função não pôde encontrar esse indivíduo na tabela fonte, left_join() vai preencher linhas correspondentes nas colunas que ele transferiu dessa tabela, com valores NA, indicando justamente que não há informações daquele respectivo indivíduo na tabela fonte.Em contrapartida, função right_join() realiza justamente o processo contrário, ao manter linhas da tabela fonte (ou tabela que você forneceu ao argumento y). Por isso, para todas linhas da tabela fonte que se referem um indivíduo não encontrado na tabela destinatária, right_join() acaba preenchendo os campos provenientes da tabela destinatária, com valores NA, indicando assim que função não conseguiu encontrar mais dados sobre aquele indivíduo na tabela destinatária. Você pode perceber esse comportamento, pela linha referente ao músico Keith, que está disponível na tabela fonte, mas não na tabela destinatária.Por fim, função full_join() executa o processo inverso da função inner_join(). Ou seja, se por um lado, função inner_join() mantém linhas de todos os indivíduos que puderam ser localizados em ambas tabelas, por outro, função full_join() não depende desses indivíduos aparecem ou não em ambas tabelas, ela sempre traz todos os indivíduos em seu resultado. Logo, full_join() mantém todas linhas de ambas tabelas. De certa forma, função full_join() busca encontrar sempre o maior número possível de combinações entre tabelas, e em todas ocasiões que full_join() não encontra um determinado indivíduo, por exemplo, na tabela B, função vai preecher os campos dessa tabela B com valores NA para linhas desse indivíduo. Veja o exemplo abaixo.Como o primeiro data.frame fornecido à função *_join(), será na maioria das situações, sua principal tabela de trabalho, o ideal é que você adote o left_join() como o seu padrão de join (Wickham Grolemund 2017). Pois dessa maneira, você evita uma possível perda de observações em sua tabela mais importante.","code":"\nleft_join(info, band_instruments, by = \"name\")## # A tibble: 5 x 5\n##   name   band           born       children plays \n##   <chr>  <chr>          <date>     <lgl>    <chr> \n## 1 Mick   Rolling Stones 1943-07-26 TRUE     <NA>  \n## 2 John   Beatles        1940-09-10 TRUE     guitar\n## 3 Paul   Beatles        1942-06-18 TRUE     bass  \n## 4 George Beatles        1943-02-25 TRUE     <NA>  \n## 5 Ringo  Beatles        1940-07-07 TRUE     <NA>\nright_join(info, band_instruments, by = \"name\")## # A tibble: 3 x 5\n##   name  band    born       children plays \n##   <chr> <chr>   <date>     <lgl>    <chr> \n## 1 John  Beatles 1940-09-10 TRUE     guitar\n## 2 Paul  Beatles 1942-06-18 TRUE     bass  \n## 3 Keith <NA>    NA         NA       guitar\nfull_join(info, band_instruments, by = \"name\")## # A tibble: 6 x 5\n##   name   band           born       children plays \n##   <chr>  <chr>          <date>     <lgl>    <chr> \n## 1 Mick   Rolling Stones 1943-07-26 TRUE     <NA>  \n## 2 John   Beatles        1940-09-10 TRUE     guitar\n## 3 Paul   Beatles        1942-06-18 TRUE     bass  \n## 4 George Beatles        1943-02-25 TRUE     <NA>  \n## 5 Ringo  Beatles        1940-07-07 TRUE     <NA>  \n## 6 Keith  <NA>           NA         NA       guitar"},{"path":"introdução-a-base-de-dados-relacionais-no-r.html","id":"relações-entre-keys-primary-keys-são-menos-comuns-do-que-você-pensa","chapter":"Capítulo 6 Introdução a base de dados relacionais no R","heading":"6.6 Relações entre keys: primary keys são menos comuns do que você pensa","text":"Na seção Dados relacionais e o conceito de key, nós estabelecemos que variáveis com capacidade de identificar unicamente cada observação de sua base, podem ser caracterizadas como primary keys. Mas para que essa característica seja verdadeira para uma dada variável, os seus valores não podem se repetir ao longo da base, e isso não acontece com tanta frequência na realidade.Como exemplo, podemos voltar ao join entre tabelas flights e weather que mostramos na seção Configurações sobre colunas e keys utilizadas join. Para realizarmos o join entre essas tabelas, nós utilizamos colunas year, month, day, hour e origin como key. Porém, forma como descrevemos essas colunas na seção passada, ficou subentendido que combinação entre elas foi capaz de formar uma primary key. Bem, porque não conferimos se essas colunas assumem de fato esse atributo:Como podemos ver acima, há diversas combinações entre cinco colunas que se repetem ao longo da base. Com isso, podemos afirmar que combinação entre colunas year, month, day, hour e origin não formam uma primary key. Perceba abaixo, que o mesmo vale para tabela weather:Portanto, circunstâncias em que não há uma primary key definida entre duas tabelas, são comuns, inclusive em momentos que você utiliza combinação de todas colunas disponíveis em uma das tabelas para formar uma key. Com isso, eu quero destacar principalmente, que não há problema algum em utilizarmos foreign keys em joins.Logo, você deve definir key mais apropriada para o seu join, baseado seu conhecimento sobre esses dados, e não de forma procurar por colunas de mesmo nome em ambas colunas (Wickham Grolemund 2017). Durante esse processo, nós não estamos perseguindo primary keys de maneira obsessiva, mas sim, pesquisando por relações verdadeiras e lógicas entre tabelas.Por exemplo, caso das tabelas flights e weather, utilizamos colunas year, month, day, hour e origin como key, pelo fato de que eventos climáticos ocorrem um dado momento (hour) de um dia específico (year, month e day), além de geralmente se restringir uma dada região geográfica (origin). Curiosamente, essas colunas não foram suficientes para produzirmos uma primary key, mas foi o suficiente para representarmos uma conexão lógica entre tabelas flights e weather.Assim sendo, qualquer que seja o tipo de key empregado, o processo de join irá ocorrer exatamente da mesma forma. Porém, o tipo que key assume em cada tabela pode alterar combinações geradas resultado join. Como temos duas tabelas em cada join, temos três possibilidades de relação entre keys de cada tabela: 1) primary key \\(\\rightarrow\\) primary key; 2) primary key \\(\\rightarrow\\) foreign key; 3) foreign key \\(\\rightarrow\\) foreign key. Ou seja, em cada uma das tabelas envolvidas em um join, colunas serem utilizadas como key podem se caracterizar como uma primary key ou como uma foreign key.Como exemplo, o join formado pelas tabelas info e band_instruments, possui uma relação de primary key \\(\\rightarrow\\) primary key. Pois coluna name é uma primary key em ambas tabelas. Por outro lado, o join formado pelas tabelas flights e weather, possui uma relação de foreign key \\(\\rightarrow\\) foreign key, visto que cinco colunas utilizadas como key não são capazes de identificar unicamente cada observação nas duas tabelas, como comprovamos acima.Com isso, temos opção de compreendermos relação entre keys, como uma relação de quantidade de cópias, fazendo referência direta ao fato de que uma primary key não possui valores repetidos ao longo da base, enquanto o mesmo não pode ser dito de uma foreign key. Logo, uma relação primary key \\(\\rightarrow\\) primary key pode ser identificada como uma relação de um para um, pois sempre vamos contar com uma única chave para cada observação em ambas tabelas. Para mais, podemos interpretar uma relação primary key \\(\\rightarrow\\) foreign key, como uma relação de um para muitos, pois para cada chave única presente em uma das tabelas, podemos dispor de múltiplas irmãs gêmeas presentes na outra tabela.Deste modo, se tivermos uma relação foreign key \\(\\rightarrow\\) foreign key, ou uma relação de muitos para muitos, para cada conjunto de keys repetidas em ambas tabelas, todas possibilidades de combinação são geradas. Em outras palavras, nesse tipo de relação, o resultado join será uma produto cartesiano como demonstrado pela figura 6.4.Relações de um para um são raras e, por essa razão, vamos mais comumente possuir uma relação de um para muitos em nossas tabelas, onde nesse caso, primary keys são replicadas resultado join, para cada repetição de sua key correspondente na outra tabela, como pode ser visto na figura 6.4.\nFigure 6.4: Resumo das relações possíveis entre keys, inspirado em Wickham e Grolemund (2017)\n","code":"\nflights %>% \n  count(year, month, day, hour, origin) %>% \n  filter(n > 1)## # A tibble: 18,906 x 6\n##     year month   day  hour origin     n\n##    <int> <int> <int> <dbl> <chr>  <int>\n##  1  2013     1     1     5 EWR        2\n##  2  2013     1     1     5 JFK        3\n##  3  2013     1     1     6 EWR       18\n##  4  2013     1     1     6 JFK       17\n##  5  2013     1     1     6 LGA       17\n##  6  2013     1     1     7 EWR       12\n##  7  2013     1     1     7 JFK       16\n##  8  2013     1     1     7 LGA       21\n##  9  2013     1     1     8 EWR       20\n## 10  2013     1     1     8 JFK       23\n## # ... with 18,896 more rows\nweather %>% \n  count(year, month, day, hour, origin) %>% \n  filter(n > 1)## # A tibble: 3 x 6\n##    year month   day  hour origin     n\n##   <int> <int> <int> <int> <chr>  <int>\n## 1  2013    11     3     1 EWR        2\n## 2  2013    11     3     1 JFK        2\n## 3  2013    11     3     1 LGA        2"},{"path":"introdução-a-base-de-dados-relacionais-no-r.html","id":"exercícios-4","chapter":"Capítulo 6 Introdução a base de dados relacionais no R","heading":"Exercícios","text":"O primeiro exercício desse capítulo, envolve duas tabelas publicadas na semana 11 projeto Tidy Tuesday em 2020. Mais especificamente, tabelas tuition_cost e salary_potential. tabela tuition_cost descreve os custos de um curso de graduação em diferentes universidades dos EUA. Em contrapartida, tabela salary_potential fornece uma estimativa salário pontencial que um diploma de graduação de diversas universidades dos EUA podem fornecer um profissional.Brasil, faculdades privadas geralmente cobram por uma mensalidade fixa que abrange todos os custos mínimos. Já algumas universidades privadas, tendem usar um sistema mais complexo, onde uma mensalidade base é cobrada, além de taxas por aulas práticas (para cobrir gastos com o uso de equipamentos) e taxas por matéria matriculada. Em outras palavras, um aluno de uma universidade privada brasileira que se matricula, por exemplo, em 4 matérias num dado semestre, geralmente paga um valor mensal que segue estrutura: mensalidade base + taxa por aula prática (se houver alguma aula prática) + (4 \\(\\times\\) taxa por matrícula).Por outro lado, universidades americanas possuem um sistema mais complexo de cobrança. Primeiro, maior parte dos estudantes americanos optam por morar e se alimentar nos alojamentos da universidade, ao invés de se manterem na casa dos pais. universidade cobra uma taxa específica para esses estudantes, que busca pagar justamente os custos deste alojamento e de sua alimentação. Tal custo é geralmente denominado de room board fees. Segundo, universidades americanas cobram principalmente pelo seu “ensino” (e alguns outros serviços) e, por isso, maior parte de seus preços envolvem o que chamamos de “tuition fees” (ou “taxa de ensino”). Terceiro, os valores divulgados pelas universidades são geralmente anuais, logo, se o tuition fees (ou room board fees) de uma universidade qualquer é de $25 mil, isso significa que um curso de 4 anos nessa universidade custaria em torno de $100 mil.Portanto, universidades americanas cobram, em geral, dois tipos de custos diferentes (room board fees e tuition fees) e, esses custos são em sua maioria, anuais. Grande parte dos alunos acabam pagando ambos desses custos, logo, esses custos somados representam, para grande parte da população, o custo total por ano de uma universidade nos EUA.Para mais, universidades americanas também cobram taxas de ensino (tuition fees) diferentes de acordo com o estado em que o aluno reside. Ou seja, uma universidade que está sediada estado Texas vai cobrar uma taxa mais barata para os alunos que moram estado Texas. Porém, os alunos que são originalmente de outros estados, e estão vindo para essa universidade vão pagar taxas maiores.Questão 6.1. Suponha que você esteja interessado em realizar um curso de graduação em alguma das universidades descritas na tabela tuition_cost. Como você provavelmente não mora nos Estados Unidos, considere os custos referentes alunos state em seus cálculos. Vale também ressaltar que os salários estimados na tabela salary_potential, assim como os custos na tabela tuition_cost, são anuais. Com base nas estimativas de salário presentes na tabela salary_potential e, com base nos custos descritos na tabela tuition_cost, tente calcular (para cada universidade) o tempo de trabalho necessário (após graduação) para pagar pelo investimento que você aplicou curso de graduação.Questão 6.2. Todos os itens abaixo envolvem tabelas consumidores e vendedores, alguns itens serão teóricos, outros, vão lhe requisitar o cálculo de alguma informação. Como esses cálculos envolvem informações de ambas tabelas, você será obrigado aplicar um join entre elas para realizá-lo:6.2.) Quais colunas representam keys em ambas tabelas?6.2.B) Na tabela consumidores, quais colunas representam uma primary key, e quais representam uma foreign key?6.2.C) Descubra o número de cidades nas quais cada vendedor atendeu os seus clientes.Questão 6.3. Dado que você tenha importado tabelas filmes e filmes_receita abaixo para o seu R, e, tendo em mente o que vimos nesse capítulo, explique porque o comando de join abaixo não funciona sobre essas tabelas. Dado que você encontre e explique o que está errado, como você ajustaria esse comando para que ele funcione normalmente?","code":"\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/rfordatascience/\"\npasta <- \"tidytuesday/master/data/2020/2020-03-10/\"\ncost <- \"tuition_cost.csv\"\nsalary <- \"salary_potential.csv\"\n\ntuition_cost <- read_csv(paste0(github, pasta, cost))\nsalary_potential <- read_csv(paste0(github, pasta, salary))\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo1 <- \"consumidor.csv\"\narquivo2 <- \"vendedores.csv\"\n\nconsumidores <- read_csv2(paste0(github, pasta, arquivo1))\nvendedores <- read_csv2(paste0(github, pasta, arquivo2))\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo1 <- \"filmes_dados.csv\"\narquivo2<- \"filmes_receita.csv\"\n\nfilmes <- read_csv2(paste0(github, pasta, arquivo1))\nfilmes_receita <- read_csv2(paste0(github, pasta, arquivo2))\n\n\n### Porque esse comando de join\n### abaixo não funciona?\nfilmes %>% \n  left_join(\n    filmes_receita\n  )"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"tidy-data-uma-abordagem-para-organizar-os-seus-dados","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","text":"","code":""},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"introdução-e-pré-requisitos-2","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.1 Introdução e pré-requisitos","text":"Em qualquer análise, o formato qual os seus dados se encontram, é muito importante. O que vamos discutir neste capítulo, será como reformatar suas tabelas, corrigir valores não disponíveis, ou “vazios” que se encontram formato incorreto, ou então, como preencher suas colunas que estão incompletas de acordo com um certo padrão.Você rapidamente descobre importância que o formato de sua tabela carrega para o seu trabalho, na medida em que você possui pensamentos como: “Uhmm…se essa coluna estivesse na forma x, eu poderia simplesmente aplicar função y() e todos os meus problemas estariam resolvidos”; ou então: “Se o Arnaldo não tivesse colocado os totais junto dos dados desagregados, eu não teria todo esse trabalho!”; ou talvez: “Qual é o sentido de colocar o nome dos países nas colunas? Assim fica muito mais difícil de acompanhar os meus dados!”Para corrigir o formato das nossas tabelas, vamos utilizar neste capítulo funções pacote tidyr que está incluso tidyverse. Pelo próprio nome pacote (tidy, que significa “arrumar”), já sabemos que ele inclui diversas funções que tem como propósito, organizar os seus dados. Portanto, lembre-se de chamar pelo pacote (seja pelo tidyr diretamente, ou pelo tidyverse) antes de prosseguir:","code":"\nlibrary(tidyverse)\n## Ou\nlibrary(tidyr)"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"o-que-é-tidy-data","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.2 O que é tidy data?","text":"Em geral, nós passamos grande parte tempo, reorganizando os nossos dados, para que eles fiquem em um formato adequado para nossa análise. Logo, aprender técnicas que facilitem o seu trabalho nesta atividade, pode economizar uma grande parte de seu tempo.Isso é muito importante, pois uma base de dados que está bagunçada, é em geral bagunçada em sua própria maneira. Como resultado, cada base irá exigir um conjunto de operações e técnicas diferentes das outras bases, para que ela seja arrumada. Algumas delas, vão enfrentar problemas simples de serem resolvidos, já outras, podem estar desarrumadas em um padrão não muito bem definido, e por isso, vão dar mais trabalho para você. Por essas razões, aprender técnicas voltadas para esses problemas, se torna uma atividade necessária.“Tidy datasets alike, every messy dataset messy way”. (Wickham 2014, p 2)Toda essa problemática, ocorre não apenas pelo erro humano, mas também porque podemos representar os nossos dados de diversas maneiras em uma tabela. Sendo que essas maneiras, podem tanto facilitar muito o seu trabalho, quanto tornar o trabalho de outros, num inferno. Veja por exemplo, tabelas abaixo. Ambas, apresentam os mesmos dados, mas em estruturas diferentes.Antes de partirmos para prática, vou lhe fornecer uma base teórica que irá sustentar suas decisões sobre como padronizar e estruturar os seus dados. Eu expliquei anteriormente, que o tidyverse é um conjunto de pacotes que dividem uma mesma filosofia. Isso significa, que esses pacotes possuem uma conexão forte entre si. Por exemplo, funções desses pacotes, retornam os seus resultados em tibble’s, e todas suas funções foram construídas de forma trabalharem bem com o operador pipe (%>%). Todas essas funções também foram projetadas seguindo melhores práticas e técnicas em análise de dados. Sendo uma dessas práticas, o que é comumente chamado na comunidade de tidy data.O conceito de tidy data foi definido por Wickham (2014), e remete forma como você está guardando os dados em sua tabela. Eu não estou dizendo aqui que todas funções tidyverse que apresentei até aqui, trabalham apenas com tidy data, mas sim, que essas funções são mais eficientes com essa estrutura tidy. Uma base de dados que está formato tidy, compartilha das três seguintes características:Cada variável de sua tabela, deve possuir sua própria coluna.Cada variável de sua tabela, deve possuir sua própria coluna.Cada observação de sua tabela, deve possuir sua própria linha.Cada observação de sua tabela, deve possuir sua própria linha.Cada valor de sua tabela, deve possuir sua própria célula.Cada valor de sua tabela, deve possuir sua própria célula.Eu posso pressupor que essas definições acima, já são claras o suficiente para que você entenda o que são dados tidy. Porém, deixar coisas ar, é com certeza uma prática tão ruim quanto incluir totais junto de seus dados desagregados. Por isso, vou passar os próximos parágrafos definindo com maior precisão cada parte que compõe essas características.Primeiro, vou definir o que quero dizer exatamente com linhas, colunas e células de sua tabela. Abaixo temos uma representação de uma base qualquer. O interesse nessa representação, não se trata dos valores e nomes inclusos nessa tabela, mas sim áreas sombreadas dessa tabela, que estão lhe apresentando cada um dos componentes supracitados.\nFigure 7.1: Definindo colunas, linhas e células de uma tabela\nAgora, vamos definir o que são variáveis, observações e valores. Você já deve ter percebido, que toda base de dados, possui uma unidade básica que está sendo descrita ao longo dela. Ou seja, toda base lhe apresenta dados sobre um grupo específico (ou uma amostra) de algo. Esse algo pode ser um conjunto de municípios, empresas, sequências genéticas, animais, clientes, realizações de um evento estocástico, dentre outros.Logo, se minha base contém dados sobre os municípios estado de Minas Gerais (MG), cada um desses municípios são uma observação de minha base. Ao dizer que cada observação deve possuir sua própria linha, eu estou dizendo que todas informações referentes um município específico, devem estar em uma única linha. Em outras palavras, cada uma das 853 (total de municípios em MG) linhas da minha base, contém os dados de um município diferente estado.Entretanto, se minha base descreve evolução PIB desses mesmos municípios nos anos de 2010 2020, eu não possuo mais um valor para cada município, ao longo da base. Neste momento, eu possuo 10 valores diferentes, para cada município, e mesmo que eu ainda esteja falando dos mesmos municípios, unidade básica da minha base, se alterou. Cada um desses 10 valores, representa uma observação PIB deste município em um ano distinto. Logo, cada um desses 10 valores para cada município, deve possuir sua própria linha. Se o estado de Minas Gerais possui 853 municípios diferentes, isso significa que nossa base deveria ter \\(10 \\times 853 = 8.530\\) linhas. Por isso, é importante que você preste atenção em seus dados, e identifique qual é unidade básica que está sendo tratada.Agora, quando eu referir variáveis de sua base, eu geralmente estou referindo colunas de sua base, porque ambos os termos são sinônimos em análises de dados. Porém, alguns cuidados são necessários, pois variáveis de sua base podem não se encontrar nas colunas de sua tabela. Como eu disse anteriormente, há diversas formas de representar os seus dados, e por isso, há diversas formas de alocar os componentes de seus dados ao longo de sua tabela.Uma variável de sua base de dados, não é apenas um elemento que (como o próprio nome dá entender) varia ao longo de sua base, mas é um elemento que lhe apresenta uma característica das suas observação. Cada variável descreve uma característica (cor de pele, população, receita, …) de cada observação (pessoa, município, empresa, …) da minha base. O que é ou não, uma característica de sua unidade básica, irá depender de qual é essa unidade básica que está sendo descrita na base.população total, é uma característica geralmente associada regiões geográficas (municípios, países, etc.), já cor de pele pode ser uma característica de uma amostra de pessoas entrevistadas em uma pesquisa de campo (como PNAD contínua), enquanto o número total de empresas é uma característica associada setores da atividade econômica (CNAE - Classificação Nacional de Atividades Econômicas).Por último, os valores de sua base, correspondem aos registros das características de cada observação de sua base. Como esse talvez seja o ponto mais claro e óbvio de todos, não vou prolongar mais sobre ele. Pois três características de tidy data que citamos anteriormente são interrelacionadas, de forma que você não pode satisfazer apenas duas delas. Logo, se você está satisfazendo duas primeiras, você não precisa se preocupar com característica que diz respeito aos valores.\nFigure 7.2: Três propriedades que caracterizam o formato tidy data\nPortanto, sempre inicie o seu trabalho, identificando unidade básica de sua base. Em seguida, tente encontrar quais são suas variáveis, ou características dessa unidade básica que estão sendo descritas na base. Após isso, basta alocar cada variável em uma coluna, e reservar uma linha para cada observação diferente de sua base, que você automaticamente estará deixando uma célula para cada valor da base.","code":"\ntable2## # A tibble: 12 x 4\n##    country      year type            count\n##    <chr>       <int> <chr>           <int>\n##  1 Afghanistan  1999 cases             745\n##  2 Afghanistan  1999 population   19987071\n##  3 Afghanistan  2000 cases            2666\n##  4 Afghanistan  2000 population   20595360\n##  5 Brazil       1999 cases           37737\n##  6 Brazil       1999 population  172006362\n##  7 Brazil       2000 cases           80488\n##  8 Brazil       2000 population  174504898\n##  9 China        1999 cases          212258\n## 10 China        1999 population 1272915272\n## 11 China        2000 cases          213766\n## 12 China        2000 population 1280428583\ntable3## # A tibble: 6 x 3\n##   country      year rate             \n## * <chr>       <int> <chr>            \n## 1 Afghanistan  1999 745/19987071     \n## 2 Afghanistan  2000 2666/20595360    \n## 3 Brazil       1999 37737/172006362  \n## 4 Brazil       2000 80488/174504898  \n## 5 China        1999 212258/1272915272\n## 6 China        2000 213766/1280428583"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"será-que-você-entendeu-o-que-é-tidy-data","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.2.1 Será que você entendeu o que é tidy data?","text":"Nessa seção vamos fazer um teste rápido, para saber se você entendeu o que é uma tabela formato tidy. Olhe por algum tempo para os exemplos abaixo, e reflita sobre qual dessas tabelas está formato tidy. Tente também descobrir quais são os problemas que tabelas “não tidy” apresentam, ou em outras palavras, qual das três definições que apresentamos anteriormente, que essas tabelas “não tidy” acabam rompendo.Como eu disse anteriormente, primeira coisa que você deve fazer, é identificar unidade básica que está sendo tratada na tabela. Nos exemplos acima, essas tabelas dizem respeito à dados de três países (Brasil, China e Afeganistão) em dois anos diferentes (1999 e 2000). Logo, nossa tabela possui \\(3 \\times 2 = 6\\) observações diferentes. Se uma das regras, impõe que todas linhas devem possuir informações de uma única observação, nossa tabela deveria possuir 6 linhas. Com isso, nós já sabemos que algo está errado com tabela 2, pois ela possui o dobro de linhas.Na verdade, o problema na tabela 2 é que ela está quebrando regra de que cada variável na tabela deve possuir sua própria coluna. Por causa dessa regra, tabela 2 acaba extrapolando o número de linhas necessárias. Olhe para colunas type e count. coluna count lhe apresenta os principais valores que estamos interessados nessa tabela. Porém, coluna type, está lhe apresentando duas variáveis diferentes.Lembre-se de que variáveis, representam características da unidade básica de sua tabela. nosso caso, essa unidade básica são dados anuais de países, logo, cases e population, são variáveis ou características diferentes desses países. Uma dessas variáveis está lhe apresentando um dado demográfico (população total), já outra, está lhe trazendo um indicador epidemiológico (número de casos de alguma doença). Por isso, ambas variáveis deveriam possuir sua própria coluna.Ok, mas e tabelas 1 e 3? Qual delas é tidy? Talvez, para responder essa pergunta, você deveria primeiro procurar pela tabela “não tidy.” Veja tabela 3, e se pergunte: “onde se encontram os valores de população e de casos de cada país nessa tabela?” Ao se fazer essa pergunta, você provavelmente já irá descobrir qual é o problema nessa tabela.tabela 3, também rompe com regra de que cada variável deve possuir sua própria coluna. Pois o número de casos e população total, estão guardados em uma mesma coluna! Ao separar os valores de população e de número de casos na tabela 3, em duas colunas diferentes, você chega na tabela 1, que é um exemplo de tabela tidy, pois agora todas três definições estão sendo respeitadas.","code":"\ntable1## # A tibble: 6 x 4\n##   country      year  cases population\n##   <chr>       <int>  <int>      <int>\n## 1 Afghanistan  1999    745   19987071\n## 2 Afghanistan  2000   2666   20595360\n## 3 Brazil       1999  37737  172006362\n## 4 Brazil       2000  80488  174504898\n## 5 China        1999 212258 1272915272\n## 6 China        2000 213766 1280428583\ntable2## # A tibble: 12 x 4\n##    country      year type            count\n##    <chr>       <int> <chr>           <int>\n##  1 Afghanistan  1999 cases             745\n##  2 Afghanistan  1999 population   19987071\n##  3 Afghanistan  2000 cases            2666\n##  4 Afghanistan  2000 population   20595360\n##  5 Brazil       1999 cases           37737\n##  6 Brazil       1999 population  172006362\n##  7 Brazil       2000 cases           80488\n##  8 Brazil       2000 population  174504898\n##  9 China        1999 cases          212258\n## 10 China        1999 population 1272915272\n## 11 China        2000 cases          213766\n## 12 China        2000 population 1280428583\ntable3## # A tibble: 6 x 3\n##   country      year rate             \n## * <chr>       <int> <chr>            \n## 1 Afghanistan  1999 745/19987071     \n## 2 Afghanistan  2000 2666/20595360    \n## 3 Brazil       1999 37737/172006362  \n## 4 Brazil       2000 80488/174504898  \n## 5 China        1999 212258/1272915272\n## 6 China        2000 213766/1280428583"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"uma-breve-definição-de-formas","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.2.2 Uma breve definição de formas","text":"Apenas para que os exemplos das próximas seções, fiquem mais claros e fáceis de se visualizar mentalmente, vou definir dois formatos gerais que sua tabela pode assumir, que são: long (longa) e wide (larga)16. Ou seja, qualquer que seja sua tabela, ela vai em geral, estar em algum desses dois formatos, de uma forma ou de outra.Esses termos (long e wide) são bem descritivos por si só. ideia é que se uma tabela qualquer, está formato long, ela adquire um aspecto visual de longa, ou em outras palavras, visualmente ela aparenta ter muitas linhas, e poucas colunas. Já uma tabela que está formato wide, adquire um aspecto visual de larga, como se essa tabela possuísse mais colunas que o necessário, e poucas linhas. Perceba pelos exemplos apresentados na figura 7.3, que estamos apresentando exatamente os mesmos dados, eles apenas estão organizados de formas diferentes ao longo das duas tabelas.\nFigure 7.3: Formas gerais que sua tabela pode adquirir\n","code":""},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"operações-de-pivô","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.3 Operações de pivô","text":"operações de pivô são principais operações que você irá utilizar para reformatar sua tabela. O que essas operações fazem, é basicamente alterar dimensões de sua tabela, ou dito de outra maneira, essas operações buscam transformar colunas em linhas, ou vice-versa. Para exemplificar essas operações, vamos utilizar tabelas que vem próprio pacote tidyr. Logo, se você chamou pelo tidyverse através de library(), você tem acesso tabela abaixo. Basta chamar console pelo objeto relig_income.Essa tabela está nos apresentando o salário médio de pessoas pertencentes diferentes religiões. Veja que em cada coluna dessa tabela, você possui os dados de um nível (ou faixa) salarial específico. Essa é uma estrutura que pode ser fácil e intuitiva em alguns momentos, mas certamente irá trazer limites importantes para você dentro R. Devido especialidade que o R possui sobre operações vetorizadas, o ideal seria transformarmos essa tabela para o formato tidy.unidade básica dessa tabela, são os grupos religiosos, e faixa salarial representa uma característica desses grupos. Há diferentes níveis salariais na tabela, que estão sendo distribuídos ao longo de diferentes colunas. Tendo em vista isso, uma das regras não está sendo respeita, pois todos esses diferentes níveis salarias, representam uma única característica, ou em outras palavras, eles transmitem o mesmo tipo de informação, que é um nível salarial daquele grupo religioso. Por isso, todas essas características da tabela, deve estar em uma única coluna. Em uma representação visual resumida, é isso o que precisamos fazer:\nFigure 7.4: Representação de uma operação de pivô\nPor isso, quando você estiver em um momento como este, em que você deseja reformatar sua tabela, ou em outras palavras, transformar suas linhas em colunas, ou vice-versa, você está na verdade, procurando realizar uma operação de pivô.Nestas situações, você deve primeiro pensar como sua tabela ficará, após operação de pivô que você deseja aplicar. Ou seja, após essa operação, sua tabela ficará com mais linhas/colunas? Ou menos linhas/colunas? Em outras palavras, você precisa identificar se você deseja tornar sua tabela mais longa (aumentar o número de linhas, e reduzir o número de colunas), ou então, se você deseja torná-la mais larga (reduzir o número de linhas, e aumentar o número de colunas).","code":"\nrelig_income## # A tibble: 18 x 11\n##    religion       `<$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k`\n##    <chr>            <dbl>     <dbl>     <dbl>     <dbl>     <dbl>     <dbl>\n##  1 Agnostic            27        34        60        81        76       137\n##  2 Atheist             12        27        37        52        35        70\n##  3 Buddhist            27        21        30        34        33        58\n##  4 Catholic           418       617       732       670       638      1116\n##  5 Don’t know/re~      15        14        15        11        10        35\n##  6 Evangelical P~     575       869      1064       982       881      1486\n##  7 Hindu                1         9         7         9        11        34\n##  8 Historically ~     228       244       236       238       197       223\n##  9 Jehovah's Wit~      20        27        24        24        21        30\n## 10 Jewish              19        19        25        25        30        95\n## 11 Mainline Prot      289       495       619       655       651      1107\n## 12 Mormon              29        40        48        51        56       112\n## 13 Muslim               6         7         9        10         9        23\n## 14 Orthodox            13        17        23        32        32        47\n## 15 Other Christi~       9         7        11        13        13        14\n## 16 Other Faiths        20        33        40        46        49        63\n## 17 Other World R~       5         2         3         4         2         7\n## 18 Unaffiliated       217       299       374       365       341       528\n## # ... with 4 more variables: $75-100k <dbl>, $100-150k <dbl>, >150k <dbl>,\n## #   Don't know/refused <dbl>"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"adicionando-linhas-à-sua-tabela-com-pivot_longer","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.3.1 Adicionando linhas à sua tabela com pivot_longer()","text":"Atualmente, tabela relig_income possui poucas linhas e muitas colunas, e por isso, ela adquire um aspecto visual de “larga.” Como eu disse, seria muito interessante para você, que transformasse essa tabela, de modo agrupar diferentes faixas de níveis salarias em menos colunas. Logo, se estamos falando em reduzir o número de colunas, estamos querendo alongar base, ou dito de outra forma, aumentar o número de linhas da base. Para fazermos isso, devemos utilizar função pivot_longer().Essa função possui três argumentos principais: 1) cols, os nomes das colunas que você deseja transformar em linhas; 2) names_to, o nome da nova coluna onde serão alocados os nomes, ou os rótulos das colunas que você definiu em cols; 3) values_to, o nome da nova coluna onde serão alocados os valores da sua tabela, que se encontram nas colunas que você definiu em cols. Como nós queremos transformar todas colunas da tabela relig_income, que contém faixas salariais, eu posso simplesmente colocar argumento cols, um símbolo de menos antes nome da coluna religion, que é única coluna da tabela, que não possui esse tipo de informação. Ou seja, dessa forma, eu estou dizendo à pivot_longer(), para transformar todas colunas (exceto coluna religion).Vale destacar, que você pode selecionar colunas que você deseja transformar em linhas (argumento cols), através dos mesmos mecanismos que utilizamos na função select(). Ao eliminarmos coluna religion com um sinal de menos (-) estávamos utilizando justamente um desses métodos. Mas podemos também, por exemplo, selecionar todas colunas, que possuem dados de tipo numérico, com função .numeric(), atingindo o mesmo resultado anterior. Ou então, poderíamos selecionar todas colunas que possuem em seu nome, algum dígito numérico, através da expressão regular \"\\\\d\" (digit) na função matches().Portanto, sempre que utilizar função pivot_longer(), duas novas colunas serão criadas. Em uma dessas colunas (values_to), função irá guardar os valores que se encontravam nas colunas que você transformou em linhas. Já na outra coluna (names_to), função irá criar rótulos em cada linha, que lhe informam de qual coluna (que você transformou em linhas) veio o valor disposto na coluna anterior (values_to). Você sempre deve definir o nome dessas duas novas colunas, como texto, isto é, sempre forneça os nomes dessas colunas, entre aspas duplas ou simples.Um outro exemplo, seria tabela billboard, que também está disponível pacote tidyr. Nessa tabela, temos posição que diversas músicas ocuparam na lista da Billboard das 100 músicas mais populares mundo, durante o ano de 2000. Portanto posição que cada uma dessas músicas ocuparam nessa lista, ao longo tempo, é unidade básica que está sendo tratada nessa tabela. Agora, repare que tabela possui muitas colunas (79 total), onde em cada uma delas, temos posição de uma música em uma dada semana desde sua entrada na lista.Repare também, que temos nessa tabela, mais semanas que o total de semanas contidas em um ano corrido (\\(365/7 \\approx 52\\) semanas). Pela descrição das colunas restantes, que se encontra logo abaixo da tabela, vemos que tabela possui dados até 76° semana (wk76). Isso provavelmente ocorre, porque algumas músicas que estão sendo descritas nessa tabela, entraram para lista da Billboard meio ano anterior (1999), e portanto, permaneceram na lista mesmo durante o ano de 2000, ultrapassando o período de 1 ano, e portanto, de 52 semanas.Agora, está claro que forma como essa tabela está organizada, pode lhe trazer um trabalho imenso. Especialmente se você precisar aplicar uma função sobre cada uma dessas 76 colunas separadamente. Por isso, o ideal seria transformarmos todas essas 76 colunas, em novas linhas de sua tabela.Porém, você não vai querer digitar o nome de cada uma dessas 76 colunas, argumento cols de pivot_longer(). Novamente, quando há um conjunto muito grande de colunas que desejamos selecionar, podemos utilizar os métodos alternativos de seleção que vimos em select(). Por exemplo, podemos selecionar todas essas colunas pelo seus índices. primeiro exemplo abaixo, estamos fazendo justamente isso, ao dizer à função em cols, que desejamos tranformar todas colunas entre 4° e 79° coluna. Uma outra alternativa, seria selecionarmos todas colunas que possuem nomes que começam por “wk,” com função starts_with(). Ambas alternativas, geram o mesmo resultado.Tais métodos de seleção são muito eficazes, e trazem grande otimização para o seu trabalho. Entretanto, em muitas ocasiões que utilizar essas funções de pivô, você vai precisar transformar apenas um conjunto pequeno de colunas em sua tabela. Nestes casos, talvez seja mais simples, definir diretamente os nomes das colunas que você deseja transformar, em cols. Veja por exemplo, tabela df que eu crio logo abaixo.Essa tabela contém os salários médios de três indivíduos hipotéticos, ao longo de quatro anos diferentes. Note que esses quatro anos, estão distribuídos ao longo de quatro colunas dessa tabela. Nesse exemplo, podemos utilizar novamente função pivot_longer(), para transformarmos essas colunas em linhas. Dessa forma, temos o seguinte resultado:","code":"\nrelig_income %>% \n  pivot_longer(\n    cols = -religion,\n    names_to = \"income\",\n    values_to = \"values\"\n  )## # A tibble: 180 x 3\n##    religion income             values\n##    <chr>    <chr>               <dbl>\n##  1 Agnostic <$10k                  27\n##  2 Agnostic $10-20k                34\n##  3 Agnostic $20-30k                60\n##  4 Agnostic $30-40k                81\n##  5 Agnostic $40-50k                76\n##  6 Agnostic $50-75k               137\n##  7 Agnostic $75-100k              122\n##  8 Agnostic $100-150k             109\n##  9 Agnostic >150k                  84\n## 10 Agnostic Don't know/refused     96\n## # ... with 170 more rows\nrelig_income %>% \n  pivot_longer(\n    cols = is.numeric,\n    names_to = \"income\",\n    values_to = \"values\"\n  )\n\nrelig_income %>% \n  pivot_longer(\n    cols = matches(\"\\\\d\"),\n    names_to = \"income\",\n    values_to = \"values\"\n  )\nbillboard## # A tibble: 317 x 79\n##    artist   track    date.entered   wk1   wk2   wk3   wk4   wk5   wk6   wk7\n##    <chr>    <chr>    <date>       <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n##  1 2 Pac    Baby Do~ 2000-02-26      87    82    72    77    87    94    99\n##  2 2Ge+her  The Har~ 2000-09-02      91    87    92    NA    NA    NA    NA\n##  3 3 Doors~ Krypton~ 2000-04-08      81    70    68    67    66    57    54\n##  4 3 Doors~ Loser    2000-10-21      76    76    72    69    67    65    55\n##  5 504 Boyz Wobble ~ 2000-04-15      57    34    25    17    17    31    36\n##  6 98^0     Give Me~ 2000-08-19      51    39    34    26    26    19     2\n##  7 A*Teens  Dancing~ 2000-07-08      97    97    96    95   100    NA    NA\n##  8 Aaliyah  I Don't~ 2000-01-29      84    62    51    41    38    35    35\n##  9 Aaliyah  Try Aga~ 2000-03-18      59    53    38    28    21    18    16\n## 10 Adams, ~ Open My~ 2000-08-26      76    76    74    69    68    67    61\n## # ... with 307 more rows, and 69 more variables: wk8 <dbl>, wk9 <dbl>,\n## #   wk10 <dbl>, wk11 <dbl>, wk12 <dbl>, wk13 <dbl>, wk14 <dbl>,\n## #   wk15 <dbl>, wk16 <dbl>, wk17 <dbl>, wk18 <dbl>, wk19 <dbl>,\n## #   wk20 <dbl>, wk21 <dbl>, wk22 <dbl>, wk23 <dbl>, wk24 <dbl>,\n## #   wk25 <dbl>, wk26 <dbl>, wk27 <dbl>, wk28 <dbl>, wk29 <dbl>,\n## #   wk30 <dbl>, wk31 <dbl>, wk32 <dbl>, wk33 <dbl>, wk34 <dbl>,\n## #   wk35 <dbl>, wk36 <dbl>, wk37 <dbl>, wk38 <dbl>, wk39 <dbl>,\n## #   wk40 <dbl>, wk41 <dbl>, wk42 <dbl>, wk43 <dbl>, wk44 <dbl>,\n## #   wk45 <dbl>, wk46 <dbl>, wk47 <dbl>, wk48 <dbl>, wk49 <dbl>,\n## #   wk50 <dbl>, wk51 <dbl>, wk52 <dbl>, wk53 <dbl>, wk54 <dbl>,\n## #   wk55 <dbl>, wk56 <dbl>, wk57 <dbl>, wk58 <dbl>, wk59 <dbl>,\n## #   wk60 <dbl>, wk61 <dbl>, wk62 <dbl>, wk63 <dbl>, wk64 <dbl>,\n## #   wk65 <dbl>, wk66 <lgl>, wk67 <lgl>, wk68 <lgl>, wk69 <lgl>,\n## #   wk70 <lgl>, wk71 <lgl>, wk72 <lgl>, wk73 <lgl>, wk74 <lgl>,\n## #   wk75 <lgl>, wk76 <lgl>\nbillboard_long <- billboard %>% \n  pivot_longer(\n    cols = 4:79,\n    names_to = \"week\",\n    values_to = \"position\"\n  )\n\nbillboard_long <- billboard %>% \n  pivot_longer(\n    cols = starts_with(\"wk\"),\n    names_to = \"week\",\n    values_to = \"position\"\n  )\n\nbillboard_long## # A tibble: 24,092 x 5\n##    artist track                   date.entered week  position\n##    <chr>  <chr>                   <date>       <chr>    <dbl>\n##  1 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk1         87\n##  2 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk2         82\n##  3 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk3         72\n##  4 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk4         77\n##  5 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk5         87\n##  6 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk6         94\n##  7 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk7         99\n##  8 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk8         NA\n##  9 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk9         NA\n## 10 2 Pac  Baby Don't Cry (Keep... 2000-02-26   wk10        NA\n## # ... with 24,082 more rows\ndf <- tibble(\n  nome = c(\"Ana\", \"Eduardo\", \"Paulo\"),\n  `2005` = c(1800, 2100, 1230),\n  `2006` = c(2120, 2100, 1450),\n  `2007` = c(2120, 2100, 1980),\n  `2008` = c(3840, 2100, 2430)\n)\n\ndf## # A tibble: 3 x 5\n##   nome    `2005` `2006` `2007` `2008`\n##   <chr>    <dbl>  <dbl>  <dbl>  <dbl>\n## 1 Ana       1800   2120   2120   3840\n## 2 Eduardo   2100   2100   2100   2100\n## 3 Paulo     1230   1450   1980   2430\ndf %>% \n  pivot_longer(\n    cols = c(\"2005\", \"2006\", \"2007\", \"2008\"),\n    names_to = \"ano\",\n    values_to = \"salario\"\n  )## # A tibble: 12 x 3\n##    nome    ano   salario\n##    <chr>   <chr>   <dbl>\n##  1 Ana     2005     1800\n##  2 Ana     2006     2120\n##  3 Ana     2007     2120\n##  4 Ana     2008     3840\n##  5 Eduardo 2005     2100\n##  6 Eduardo 2006     2100\n##  7 Eduardo 2007     2100\n##  8 Eduardo 2008     2100\n##  9 Paulo   2005     1230\n## 10 Paulo   2006     1450\n## 11 Paulo   2007     1980\n## 12 Paulo   2008     2430"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"adicionando-colunas-à-sua-tabela-com-pivot_wider","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.3.2 Adicionando colunas à sua tabela com pivot_wider()","text":"Por outro lado, você talvez deseje realizar operação contrária. Ou seja, se você deseja transformar linhas de sua tabela, em novas colunas, você deve utilizar função pivot_wider(), que possui argumentos muito parecidos com os de pivot_longer().Vamos começar com um exemplo simples. Veja tabela df que estou criando logo abaixo. Nessa tabela, temos dados como o peso, idade e altura de cinco pessoas diferentes. Porém, perceba que essa tabela, não está formato tidy. Pois temos três informações (peso, idade e altura) que representam características diferentes da unidade básica da tabela (pessoas), que estão em uma mesma coluna (variavel).Portanto, tendo identificado o problema, precisamos agora, separar três variáveis contidas na coluna variavel, em três novas colunas da tabela df. Logo, precisamos alargar nossa base, pois estamos eliminando linhas e adicionando colunas à tabela.Já sabemos que podemos utilizar função pivot_wider() para esse trabalho, mas eu ainda não descrevi os seus argumentos, que são os seguintes: 1) id_cols, sendo colunas que são suficientes para, ou capazes de, identificar uma única observação de sua base; 2) names_from, qual coluna de sua tabela que contém linhas serem dividas, ou transformadas, em várias outras colunas; 3) values_from, qual coluna, que contém os valores serem posicionados nas novas células, que serão criadas durante o processo de “alargamento” da sua tabela.Antes de prosseguirmos para os exemplos práticos, é provavelmente uma boa ideia, refletirmos sobre o que o argumento id_cols significa. Para que você identifique colunas serem estipuladas argumento id_cols, você precisa primeiro identificar unidade básica que está sendo tratada em sua tabela. nosso caso, tabela df, contém dados sobre características físicas ou biológicas, de cinco pessoas diferentes. Logo, unidade básica dessa tabela, são pessoas que estão sendo descritas nela, e por isso, coluna nome é capaz de identificar cada unidade básica, pois ela nos traz justamente um código social de identificação, isto é, o nome dessas pessoas.Porém, repare que cada pessoa descrita na tabela df, não possui sua própria linha na tabela. Veja por exemplo, informações referentes à Ana, que estão definidas ao longo das três primeiras linhas da tabela. Com isso, eu quero apenas destacar que cada unidade básica, ou cada observação de sua tabela, não necessariamente vai se encontrar em um única linha, e que isso não deve ser uma regra (ou um guia) para selecionarmos colunas de id_cols. Até porque, nós estamos utilizando uma operação de pivô sobre nossa tabela, justamente pelo fato dela não estar formato tidy. Ou seja, se uma das características que definem o formato tidy, não estão sendo respeitados, é muito provável, que cada observação de sua base, não se encontre em uma única linha.Pensando em um outro exemplo, se você dispõe de uma base que descreve o PIB de cada município estado de Minas Gerais, você precisa definir em id_cols, coluna (ou o conjunto de colunas) que é capaz de identificar cada um dos 853 municípios de MG, pois esses municípios são unidade básica da tabela. Porém, se sua base está descrevendo o PIB desses mesmos municípios, mas agora ao longo dos anos de 2010 2020, sua unidade básica passa ter um componente temporal, e se torna evolução desses municípios ao longo tempo. Dessa forma, você precisaria não apenas de uma coluna que seja capaz de identificar qual o município que está sendo descrito na base, mas também de uma outra coluna que possa identificar qual o ano que informação desse município se refere.Tendo isso em mente, vamos partir para os próximos dois argumentos. nosso caso, queremos pegar três variáveis que estão ao longo da coluna variavel, e separá-las em três colunas diferentes. Isso é exatamente o que devemos definir em names_from. O que este argumento está pedindo, é o nome da coluna que contém os valores que vão servir de nome para novas colunas que pivot_wider() irá criar. Ou seja, ao fornecermos coluna variavel para names_from, pivot_wider() irá criar uma nova coluna para cada valor único que se encontra na coluna variavel. Como ao longo da coluna variavel, temos três valores diferentes (peso, altura e idade), pivot_wider() irá criar três novas colunas que possuem os nomes de peso, altura e idade.Ao criar novas colunas, você precisa preenchê-las de alguma forma, menos que você deseja deixá-las vazias. Em outras palavras, função pivot_wider() irá lhe perguntar: “Ok, eu criei colunas que você pediu para criar, mas eu devo preenchê-las com que valores?” Você deve responder essa pergunta, através argumento values_from, onde você irá definir qual é coluna que contém os valores que você deseja alocar ao longo dessas novas colunas (que foram criadas de acordo com os valores contidos na coluna que você definiu em names_from). Na nossa tabela df, é coluna valor que contém os registros, ou os valores que cada variável (idade, altura e peso) assume nessa amostra. Logo, é essa coluna que devemos conectar à values_from.Esse foi um exemplo simples de como utilizar função, e que vai lhe servir de base para praticamente qualquer aplicação de pivot_wider(). Porém, em algumas situações que você utilizar pivot_wider(), pode ser que sua tabela não possua colunas o suficiente, que possam identificar unicamente cada observação de sua base, e isso, ficará mais claro com um outro exemplo.Com o código abaixo, você é capaz de recriar tabela vendas, em seu R. Lembre-se de executar função set.seed() antes de criar tabela vendas, pois é essa função que garante que você irá recriar exatamente mesma tabela que minha. Nessa tabela vendas, possuímos vendas hipóteticas de diversos produtos (identificados por produtoid), realizadas por alguns vendedores (identificados por usuario) que arrecadaram em cada venda os valores descritos na coluna valor. Perceba também, que essas vendas são diárias, pois possuímos outras três colunas (ano, mes e dia) que definem o dia em que venda ocorreu.Vou antes de mais nada, identificar os níveis (ou valores únicos) contidos nas duas colunas que vão servir de objeto de estudo, para os próximos exemplos. Caso você queira visualizar todos os valores únicos contidos em uma coluna, você pode realizar tal ação através da função unique(). Perceba pelos resultados abaixo, que nós temos cinco vendedores e cinco produtos diferentes que estão sendo descritos ao longo da tabela vendas.Portanto, vamos para o exemplo. Já adianto, que se você tentar distribuir tanto os vendedores (usuario), quanto os produtos vendidos (produtoid), em novas colunas de nossa tabela, utilizando pivot_wider(), um aviso será levantado, e o resultado dessa operação (apesar de correto) será provavelmente, muito estranho para você. Primeiro, veja com os seus próprios olhos, qual é o resultado dessa aplicação, com coluna usuario:Como podemos ver pelo resultado acima, uma mensagem de aviso apareceu, nos informando que os valores não podem ser unicamente identificados através das colunas que fornecemos em id_cols (Values uniquely identified), e que por isso, função pivot_wider(), acabou transformando novas colunas que criamos, em listas (output contain list-cols.).Ou seja, cada uma das colunas que acabamos de criar com pivot_wider(), estão na estrutura de um vetor recursivo (.e. listas). Isso pode ser estranho para muitos usuários, pois na maioria das vezes, colunas de suas tabelas serão vetores atômicos17. Um outro motivo que provavelmente levantou bastante dúvida em sua cabeça é: “Como assim colunas que forneci não são capazes de identificar unicamente os valores? Em que sentido elas não são capazes de realizar tal ação?” Bem, essa questão ficará mais clara, se nos questionarmos como, ou por que motivo essas colunas foram transformadas para listas.Antes de continuarmos, vale ressaltar que novas colunas criadas por pivot_wider() nunca chegaram ser colunas comuns, formadas por vetores atômicos. Logo, desde sua criação, elas já eram listas. Mas se partirmos pressuposto que inicialmente, essas colunas eram vetores atômicos, tal pensamento se torna útil para identificarmos os motivos para o uso de listas. Estes motivos serão identificados seguir.Primeiro, precisamos transformar novamente essas colunas em vetores atômicos, para tentarmos compreender como essas colunas ficariam como simples vetores atômicos. Para isso, vou pegar um pedaço da tabela vendas, mais especificamente, 10 primeiras linhas da tabela, através da função head(). Em seguida, vou preocupar em transformar essas colunas novamente em vetores, através dos comandos abaixo.Após executarmos transformações acima, possuímos agora, uma tabela comum, como qualquer outra que você encontra normalmente R. Veja o resultado abaixo, quando chamamos pelo nome da tabela console. Dessa vez, nas células que possuíam uma lista nula <NULL>(uma lista vazia) temos um valor de NA (não disponível). Já nas células que possuíam uma lista com algum valor, vemos agora, o valor exato que estava contido nessa lista, ao invés da descrição <dbl [1]>.Portanto, se observarmos primeira linha dessa nova tabela pedaco, vemos que vendedora Ana, vendeu dia 01/01/2010, o produto de ID 10104, valor de 3907 reais (e alguns centavos). Neste mesmo dia, o Henrique vendeu o mesmo produto, por quase 2 mil reais mais que Ana, totalizando 6139 reais de receita. Podemos perceber também pelas outras colunas, que nenhum outro vendedor conseguiu vender uma unidade produto de ID 10104, dia 01/01/2010.Neste ponto, se pergunte: “Ok, Ana vendeu uma unidade produto 10104, dia 01. Mas e se ela tivesse vendido duas unidades desse mesmo produto 10104, dia 01?” Tente imaginar, como os dados dessas duas vendas ficariam na tabela. Isso não é uma questão trivial, pois temos agora dados de duas vendas diferentes…mas apenas uma célula disponível em nossa tabela, para guardar esses dados. É partir deste choque, que podemos identificar qual foi o motivo para o uso de listas nas novas colunas.Dito de outra forma, temos uma única célula na tabela (localizada na primeira linha, e quinta coluna da tabela), que deve conter o valor arrecadado na venda produto 10104, realizada pela vendedora Ana dia 01/01/2010. Você poderia pensar: “Bem, por que não somar os valores dessas duas vendas? Dessa forma, temos apenas um valor para encaixar nessa célula.” Essa é uma alternativa possível, porém, ela gera perda de informação, especialmente se o valor arrecadado nas duas operações forem diferentes. Por exemplo, se receita da primeira venda foi de 3907, e da segunda, de 4530. Com essa alternativa, nós sabemos que soma das duas vendas ocorridas naquele dia, geraram 8437 reais de receita, mas nós não sabemos mais, qual foi o menor valor arrecadado nas duas operações.Isso é particularmente importante, pois podemos gerar o mesmo valor (8437 reais) de múltiplas formas. Pode ser que Ana tenha vendido cinco unidades produto 10104, tendo arrecadado em cada venda, o valor de 1687,4 reais. Mas ela poderia atingir o mesmo valor, ao vender dez unidades produto 10104, dessa vez, arrecandando um valor médio bem menor, de 843,7 reais. Portanto, se utilizarmos soma desses valores, como forma de contornarmos o problema posto anteriormente, os administradores da loja não poderão mais inferir da tabela vendas, se suas vendas tem se reduzido em quantidade, ou se o valor arrecadado em cada venda, tem caído ao longo dos últimos anos.Apesar de ser uma alternativa ruim para muitos casos, pode ser desejável agregar informações dessas vendas em uma só para o seu caso. Nesta situação, versões mais recentes pacote tidyr, oferecem na função pivot_wider() o argumento values_fn, onde você pode fornecer o nome de uma função ser aplicada sobre os valores dispostos em cada célula. Logo, se quiséssemos somar os valores de vendas dispostos em cada célula criadas na tabela vendas_wide, poderíamos realizar os comandos abaixo:Recapitulando, nossa hipótese, é de que tenha ocorrido mais de uma venda de um mesmo produto, por um mesmo vendedor, em um mesmo dia na tabela vendas. Para comprovar se essa hipótese ocorre ou não em nossa tabela, podemos coletar o número de observações contidas em cada célula da coluna Ana, por exemplo, e verificarmos se há algum valor acima de 1. Vale ressaltar que colunas criadas por pivot_wider() em vendas_wide, são agora listas, e principalmente, que desejamos coletar o número de observações contidas em cada um dos elementos da lista que representa coluna Ana. Para isso, precisamos de algo como os comandos abaixo:Podemos ver pelo resultado acima, que sim, possuímos dias em que vendedora Ana, vendeu mais de uma vez, o mesmo produto. É neste sentido que função pivot_wider() gerou aquele aviso para nós. função estava nos informando que ela não possuía meios de identificar cada venda realizada pela vendedora Ana desse mesmo produto, nesses dias que foram provavelmente movimentados na loja. Nós fornecemos ao argumento id_cols, colunas ano, mes, dia e produtoid. Porém, essas colunas em conjunto não são capazes de diferenciar três vendas de Ana produto 10013 que ocorreram dia 29/02/2010, por exemplo, nem duas vendas de Henrique produto 10104 dia 18/01/2010, e muitas outras. Foi por esse motivo, que listas foram utilizadas nas novas colunas de pivot_wider().Você talvez pense: “Por que não fornecemos então todas colunas da tabela para id_cols?” Primeiro, esse questionamento carrega um pressuposto que não necessariamente se confirma, que é o de que os valores das vendas realizadas por um mesmo vendedor, de um mesmo produto, e mesmo dia, são diferentes em todas ocasiões. Algo que é possível, mas não necessariamente ocorre ao longo de toda base. O segundo problema, é que coluna valor não está mais disponível para ser utilizada por id_cols, pois se você se lembrar, nós conectamos essa coluna values_from. Isso significa, que essa coluna já está sendo utilizada para preencher novas células que estão sendo criadas por pivot_wider(), e portanto, ela não pode ocupar dois espaços ao mesmo tempo. Tanto que se você tentar adicionar coluna valor id_cols, você irá perceber que nada se altera, e o mesmo resultado é gerado.Portanto, não há uma resposta fácil para uma situação como essa, onde mesmo fornecendo todas colunas para id_cols em pivot_wider(), função ainda não é capaz de identificar unicamente cada valor da coluna que você forneceu em value_from. Você pode utilizar uma solução que gera perda de informação, ao aplicar uma função sumária, ou seja, uma função para agregar esses valores de forma que eles se tornem únicos, dados os conjuntos de colunas que você forneceu em id_cols. Uma outra possibilidade, é que você esteja utilizando operação de pivô errada. Ou seja, melhor alternativa seria alongar (pivot_longer()) sua base, ao invés de alargá-la.Agora, uma última possibilidade mais promissora, é que você esteja realizando operação correta, e que faz sentido manter essas colunas como listas de acordo com o que você deseja realizar com base. Isso inclui o uso de um ferramental que está um pouco além desse capítulo. Por outro lado, lidar com nested data, é mais uma questão de experiência, de se acostumar com tal estrutura, e saber funções adequadas, que aprender algo muito diferente que mostramos aqui. Um outro conhecimento que é de extrema importância nessas situações, é conhecer muito bem como listas funcionam R. Se você conhecer bem essa estrutura, você não terá dificuldades em navegar por nested data. Para uma visão melhor potencial que nested data pode trazer para sua análise, eu recomendo que você procure por uma excelente palestra de Hadley Wickham, entitulada “Managing many models R”18.","code":"\ndf <- structure(list(nome = c(\"Ana\", \"Ana\", \"Ana\", \"Eduardo\", \"Eduardo\", \n\"Eduardo\", \"Paulo\", \"Paulo\", \"Paulo\", \"Henrique\", \"Henrique\", \n\"Henrique\", \"Letícia\", \"Letícia\", \"Letícia\"), variavel = c(\"idade\", \n\"peso\", \"altura\", \"idade\", \"peso\", \"altura\", \"idade\", \"peso\", \n\"altura\", \"idade\", \"peso\", \"altura\", \"idade\", \"peso\", \"altura\"\n), valor = c(20, 61, 1.67, 18, 90, 1.89, 19, 68, 1.67, 23, 82, \n1.72, 27, 56, 1.58)), row.names = c(NA, -15L), class = c(\"tbl_df\", \n\"tbl\", \"data.frame\"))\n\ndf## # A tibble: 15 x 3\n##    nome     variavel valor\n##    <chr>    <chr>    <dbl>\n##  1 Ana      idade    20   \n##  2 Ana      peso     61   \n##  3 Ana      altura    1.67\n##  4 Eduardo  idade    18   \n##  5 Eduardo  peso     90   \n##  6 Eduardo  altura    1.89\n##  7 Paulo    idade    19   \n##  8 Paulo    peso     68   \n##  9 Paulo    altura    1.67\n## 10 Henrique idade    23   \n## 11 Henrique peso     82   \n## 12 Henrique altura    1.72\n## 13 Letícia  idade    27   \n## 14 Letícia  peso     56   \n## 15 Letícia  altura    1.58\ndf %>% \n  pivot_wider(\n    id_cols = nome,\n    names_from = variavel,\n    values_from = valor\n  )## # A tibble: 5 x 4\n##   nome     idade  peso altura\n##   <chr>    <dbl> <dbl>  <dbl>\n## 1 Ana         20    61   1.67\n## 2 Eduardo     18    90   1.89\n## 3 Paulo       19    68   1.67\n## 4 Henrique    23    82   1.72\n## 5 Letícia     27    56   1.58\nnomes <- c(\"Ana\", \"Eduardo\", \"Paulo\", \"Henrique\", \"Letícia\")\nproduto <- c(\"10032\", \"10013\", \"10104\", \"10555\", \"10901\")\n\nset.seed(1)\nvendas <- tibble(\n    ano = sample(2010:2020, size = 10000, replace = TRUE),\n    mes = sample(1:12, size = 10000, replace = TRUE),\n    dia = sample(1:31, size = 10000, replace = TRUE),\n    usuario = sample(nomes, size = 10000, replace = TRUE),\n    valor = rnorm(10000, mean = 5000, sd = 1600),\n    produtoid = sample(produto, size = 10000, replace = TRUE)\n  ) %>% \n  arrange(ano, mes, dia, usuario)\n\nvendas## # A tibble: 10,000 x 6\n##      ano   mes   dia usuario  valor produtoid\n##    <int> <int> <int> <chr>    <dbl> <chr>    \n##  1  2010     1     1 Ana      3907. 10104    \n##  2  2010     1     1 Henrique 6139. 10104    \n##  3  2010     1     2 Henrique 5510. 10013    \n##  4  2010     1     3 Ana      5296. 10555    \n##  5  2010     1     3 Letícia  3525. 10555    \n##  6  2010     1     4 Ana      5102. 10555    \n##  7  2010     1     4 Eduardo  6051. 10013    \n##  8  2010     1     4 Letícia  4600. 10032    \n##  9  2010     1     5 Paulo    5869. 10104    \n## 10  2010     1     6 Ana      7188. 10013    \n## # ... with 9,990 more rows\nunique(vendas$usuario)## [1] \"Ana\"      \"Henrique\" \"Letícia\"  \"Eduardo\"  \"Paulo\"\nunique(vendas$produtoid)## [1] \"10104\" \"10013\" \"10555\" \"10032\" \"10901\"\nvendas_wide <- vendas %>% \n  pivot_wider(\n    id_cols = c(\"ano\", \"mes\", \"dia\", \"produtoid\"),\n    names_from = usuario,\n    values_from = valor\n  )## Warning: Values are not uniquely identified; output will contain list-cols.\n## * Use `values_fn = list` to suppress this warning.\n## * Use `values_fn = length` to identify where the duplicates arise\n## * Use `values_fn = {summary_fun}` to summarise duplicates\nvendas_wide## # A tibble: 7,845 x 9\n##      ano   mes   dia produtoid Ana      Henrique  Letícia  Eduardo  Paulo  \n##    <int> <int> <int> <chr>     <list>   <list>    <list>   <list>   <list> \n##  1  2010     1     1 10104     <dbl [1~ <dbl [1]> <NULL>   <NULL>   <NULL> \n##  2  2010     1     2 10013     <NULL>   <dbl [1]> <NULL>   <NULL>   <NULL> \n##  3  2010     1     3 10555     <dbl [1~ <NULL>    <dbl [1~ <NULL>   <NULL> \n##  4  2010     1     4 10555     <dbl [1~ <NULL>    <NULL>   <NULL>   <NULL> \n##  5  2010     1     4 10013     <NULL>   <NULL>    <NULL>   <dbl [1~ <NULL> \n##  6  2010     1     4 10032     <NULL>   <NULL>    <dbl [1~ <NULL>   <NULL> \n##  7  2010     1     5 10104     <NULL>   <NULL>    <NULL>   <NULL>   <dbl [~\n##  8  2010     1     6 10013     <dbl [1~ <NULL>    <NULL>   <NULL>   <NULL> \n##  9  2010     1     6 10901     <NULL>   <NULL>    <dbl [1~ <NULL>   <NULL> \n## 10  2010     1     7 10013     <NULL>   <dbl [1]> <NULL>   <NULL>   <dbl [~\n## # ... with 7,835 more rows\npedaco <- head(vendas_wide, 10)\n\nfor(i in 5:9){\n  \n  id <- vapply(pedaco[[i]], FUN = is.null, FUN.VALUE = TRUE)\n  \n  pedaco[[i]][id] <- NA_real_\n}\n\npedaco <- pedaco %>% mutate(across(5:9, unlist))\npedaco## # A tibble: 10 x 9\n##      ano   mes   dia produtoid   Ana Henrique Letícia Eduardo Paulo\n##    <int> <int> <int> <chr>     <dbl>    <dbl>   <dbl>   <dbl> <dbl>\n##  1  2010     1     1 10104     3907.    6139.     NA      NA    NA \n##  2  2010     1     2 10013       NA     5510.     NA      NA    NA \n##  3  2010     1     3 10555     5296.      NA    3525.     NA    NA \n##  4  2010     1     4 10555     5102.      NA      NA      NA    NA \n##  5  2010     1     4 10013       NA       NA      NA    6051.   NA \n##  6  2010     1     4 10032       NA       NA    4600.     NA    NA \n##  7  2010     1     5 10104       NA       NA      NA      NA  5869.\n##  8  2010     1     6 10013     7188.      NA      NA      NA    NA \n##  9  2010     1     6 10901       NA       NA    4491.     NA    NA \n## 10  2010     1     7 10013       NA     4407.     NA      NA  2292.\nvendas %>% \n  pivot_wider(\n    id_cols = c(\"ano\", \"mes\", \"dia\", \"produtoid\"),\n    names_from = usuario,\n    values_from = valor,\n    values_fn = sum\n  )## # A tibble: 7,845 x 9\n##      ano   mes   dia produtoid   Ana Henrique Letícia Eduardo Paulo\n##    <int> <int> <int> <chr>     <dbl>    <dbl>   <dbl>   <dbl> <dbl>\n##  1  2010     1     1 10104     3907.    6139.     NA      NA    NA \n##  2  2010     1     2 10013       NA     5510.     NA      NA    NA \n##  3  2010     1     3 10555     5296.      NA    3525.     NA    NA \n##  4  2010     1     4 10555     5102.      NA      NA      NA    NA \n##  5  2010     1     4 10013       NA       NA      NA    6051.   NA \n##  6  2010     1     4 10032       NA       NA    4600.     NA    NA \n##  7  2010     1     5 10104       NA       NA      NA      NA  5869.\n##  8  2010     1     6 10013     7188.      NA      NA      NA    NA \n##  9  2010     1     6 10901       NA       NA    4491.     NA    NA \n## 10  2010     1     7 10013       NA     4407.     NA      NA  2292.\n## # ... with 7,835 more rows\nvec <- vector(mode = \"double\", length = nrow(vendas_wide))\n\nfor(i in seq_along(vendas_wide$Ana)){\n  \n  vec[i] <- length(vendas_wide$Ana[[i]])\n\n}\n\nvec[vec > 1]##  [1] 3 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n## [36] 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 3 3 2 2 2 2 2 2 2 2 2 2 2 2 3\n## [71] 3 2 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 3 3 2 2 2"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"completando-e-expandindo-a-sua-tabela","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.4 Completando e expandindo a sua tabela","text":"operação que vou mostrar seguir, serve para completar, ou inserir linhas que estão faltando em sua tabela. Em outras palavras, essa operação busca tornar os valores que estão implicitamente faltando em sua tabela, em valores não disponíveis explícitos. Você também pode enxergar esse processo, como uma forma rápida de expandir sua tabela, partir de combinações de valores. Um exemplo lógico uso dessa operação, seriam datas que você gostaria que estivessem em sua tabela, mas que não se encontram nela momento. Vamos supor por exemplo, que você possua tabela abaixo:Portanto, temos nessa tabela vendas, o nome de alguns vendedores e os valores de suas vendas efetuadas em alguns dias diferentes. momento, temos vendas explicítas apenas nos dias 01, 05, 07 e 10 de Setembro de 2020, mas o que ocorreu nos dias que estão entre essas datas (dias 02, 03, 04, 06, 08 e 09 de Setembro de 2020)? Caso você estivesse apresentando esses dados para o seu chefe, por exemplo, essa seria uma questão que ele provavelmente faria você.Bem, vamos supor que não tenham ocorrido vendas durante esses dias, e que por isso eles não estão sendo descritos na tabela vendas. Talvez seja de seu desejo, introduzir esses dias na tabela para que ninguém fique em dúvida respeito desses dias. Com isso, precisamos então completar tabela vendas, com linhas que estão implicitamente faltando nela.","code":"\nlibrary(tidyverse)\n\ndias <- c(\"2020-09-01\", \"2020-09-05\", \"2020-09-07\", \"2020-09-10\")\n\nset.seed(1)\nvendas <- tibble(\n  datas = as.Date(dias),\n  nome = c(\"Ana\", \"Julia\", \"Joao\", \"Julia\"),\n  valor = rnorm(4, mean = 500, sd = 150)\n)\n\nvendas## # A tibble: 4 x 3\n##   datas      nome  valor\n##   <date>     <chr> <dbl>\n## 1 2020-09-01 Ana    406.\n## 2 2020-09-05 Julia  528.\n## 3 2020-09-07 Joao   375.\n## 4 2020-09-10 Julia  739."},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"encontrando-possíveis-combinações-com-a-função-expand","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.4.1 Encontrando possíveis combinações com a função expand()","text":"Apesar não ser exatamente o que desejamos para tabela vendas, o processo em que buscamos encontrar possíveis combinações de dados que não estão presentes em nossa tabela, também envolve procura por todas combinações possíveis dos dados presentes nessa tabela. Nessa seção, vamos introduzir alguns métodos para encontrarmos todas combinações possíveis de seus dados.Para isso, podemos utilizar função expand() pacote tidyr. Essa função busca expandir uma tabela, de forma que ela inclua todas possíveis combinações de certos valores. Em maiores detalhes, essa função irá criar (com base nos dados que você fornecer ela) uma nova tabela, ou um novo tibble, que irá incluir todas combinações únicas e possíveis dos valores que você definiu. Portanto, se eu fornecer tabela vendas à função, e pedir ela que encontre todas combinações possíveis entre os valores contidos nas colunas datas e nomes, esse será o resultado:Portanto, expand() irá criar uma nova tabela, contendo todas possíveis combinações entre os valores das colunas datas e nomes da tabela vendas. Incluindo aquelas combinações que não aparecem na tabela inicial. Por exemplo, combinações (2020-09-01, Julia), ou (2020-09-05, Joao) e (2020-09-10, Joao) não estão presentes na tabela vendas, e mesmo assim foram introduzidas resultado de expand().Porém, expand() não definiu novas combinações com datas que estão faltando na tabela vendas (por exemplo, os dias 02, 03, 04 e 08 de Setembro de 2020). Ou seja, em nenhum momento expand() irá adicionar algum dado à sua tabela, seja antes ou depois de encontrar todas combinações únicas. Em outras palavras, expand() irá sempre encontrar todas combinações possíveis, se baseando nos valores que já se encontram nas variáveis que você forneceu ela. Por isso, mesmo que combinação (2020-09-01, Julia) não esteja definida na tabela vendas, ela é uma combinação possível, pois os valores 2020-09-01 e Julia estão presentes na tabela vendas.Vale destacar, que você pode combinar variáveis de sua tabela, com vetores externos. Por exemplo, eu posso utilizar seq.Date() para gerar todas datas que estão entre o dia 01 e 10 de Setembro de 2020. exemplo abaixo, perceba que expand() pega cada um dos 3 nomes únicos definidos na coluna nome de vendas, e combina eles com cada uma das 10 datas guardadas vetor vec_d, gerando assim, uma nova tabela com 30 linhas (\\(3\\) nomes \\(\\times 10\\) datas \\(= 30\\) combinações).Além disso, função expand() conta com uma função auxiliar útil (nesting()), que restringe quais combinações serão válidas para expand(). Ao incluir variáveis dentro da função nesting(), você está dizendo à expand(), que encontre apenas combinações únicas (entre os valores dessas variáveis) que já estão presentes em sua base. Ou seja, se eu colocar colunas datas e nome dentro de nesting(), função expand() irá basicamente repetir tabela vendas. Pois cada uma das 4 linhas (ou 4 combinações entre datas e nome), aparecem uma única vez nessa tabela.Dessa maneira, o uso de nesting() acima, é análogo ao uso da função unique() que vêm dos pacotes básicos R. Logo, poderíamos atingir exatamente o mesmo resultado, utilizando qualquer uma das duas funções. Podemos por exemplo, adicionarmos uma quinta linha à tabela vendas, que repete os valores contidos na quarta linha da tabela. Perceba abaixo, que ao utilizarmos unique() ou nesting(), em ambos os casos, essa quinta linha repetida desaparece. Pois ambas funções buscam encontrar todas combinações únicas que aparecem ao longo da tabela vendas.Vale destacar que você pode combinar o comportamento restrito e irrestrito de expand(). Ou seja, você pode restringir combinações com o uso de nesting() para algumas variáveis, enquanto outras permanecem de fora dessa função, permitindo uma gama maior de combinações. exemplo abaixo, expand() vai encontrar primeiro, cada combinação única entre nome e valor que está presente na tabela vendas, em seguida, função irá encontrar todas combinações possíveis entre combinações anteriores (entre nome e valor) e todas datas descritas na base.Em outras palavras, nós podemos encontrar resultado abaixo, uma combinação como (2020-09-01, Julia, 528.). Pois combinação (Julia, 528.) existe nas colunas nome e valor da tabela vendas, e como deixamos coluna datas de fora de nesting(), expand() irá combinar (Julia, 528.) com toda e qualquer data disponível na tabela vendas.Porém, nós não podemos encontrar resultado abaixo, uma combinação como (2020-09-01, Ana, 739.). Pois única combinação entre colunas nome e valor, presente na tabela vendas, que possui o valor 739 na coluna valor, é linha que contém combinação (Julia, 739.). Logo, se não há nas colunas nome e valor alguma combinação entre Ana e o valor 739., expand() não irá combinar esses valores com todas datas disponíveis na base. Pois combinações entre colunas nome e valor estão sendo restringidas por nesting().","code":"\nexpand(vendas, datas, nome)## # A tibble: 12 x 2\n##    datas      nome \n##    <date>     <chr>\n##  1 2020-09-01 Ana  \n##  2 2020-09-01 Joao \n##  3 2020-09-01 Julia\n##  4 2020-09-05 Ana  \n##  5 2020-09-05 Joao \n##  6 2020-09-05 Julia\n##  7 2020-09-07 Ana  \n##  8 2020-09-07 Joao \n##  9 2020-09-07 Julia\n## 10 2020-09-10 Ana  \n## 11 2020-09-10 Joao \n## 12 2020-09-10 Julia\nvec_d <- seq.Date(min(vendas$datas), max(vendas$datas), by = \"day\")\n\nexpand(vendas, nome, vec_d)## # A tibble: 30 x 2\n##    nome  vec_d     \n##    <chr> <date>    \n##  1 Ana   2020-09-01\n##  2 Ana   2020-09-02\n##  3 Ana   2020-09-03\n##  4 Ana   2020-09-04\n##  5 Ana   2020-09-05\n##  6 Ana   2020-09-06\n##  7 Ana   2020-09-07\n##  8 Ana   2020-09-08\n##  9 Ana   2020-09-09\n## 10 Ana   2020-09-10\n## # ... with 20 more rows\nexpand(vendas, nesting(datas, nome))## # A tibble: 4 x 2\n##   datas      nome \n##   <date>     <chr>\n## 1 2020-09-01 Ana  \n## 2 2020-09-05 Julia\n## 3 2020-09-07 Joao \n## 4 2020-09-10 Julia\nvendas[5, ] <- data.frame(as.Date(\"2020-09-10\"), \"Julia\", 739.29)\n\nvendas## # A tibble: 5 x 3\n##   datas      nome  valor\n##   <date>     <chr> <dbl>\n## 1 2020-09-01 Ana    406.\n## 2 2020-09-05 Julia  528.\n## 3 2020-09-07 Joao   375.\n## 4 2020-09-10 Julia  739.\n## 5 2020-09-10 Julia  739.\n# Estou aplicando unique() sobre a\n# primeira e segunda coluna de vendas\nunique(vendas[ , 1:2]) ## # A tibble: 4 x 2\n##   datas      nome \n##   <date>     <chr>\n## 1 2020-09-01 Ana  \n## 2 2020-09-05 Julia\n## 3 2020-09-07 Joao \n## 4 2020-09-10 Julia\n# O mesmo resultado pode ser\n# atingido com o uso de nesting() em expand()\nexpand(vendas, nesting(datas, nome))## # A tibble: 4 x 2\n##   datas      nome \n##   <date>     <chr>\n## 1 2020-09-01 Ana  \n## 2 2020-09-05 Julia\n## 3 2020-09-07 Joao \n## 4 2020-09-10 Julia\nvendas %>% \n  expand(datas, nesting(nome, valor))## # A tibble: 16 x 3\n##    datas      nome  valor\n##    <date>     <chr> <dbl>\n##  1 2020-09-01 Ana    406.\n##  2 2020-09-01 Joao   375.\n##  3 2020-09-01 Julia  528.\n##  4 2020-09-01 Julia  739.\n##  5 2020-09-05 Ana    406.\n##  6 2020-09-05 Joao   375.\n##  7 2020-09-05 Julia  528.\n##  8 2020-09-05 Julia  739.\n##  9 2020-09-07 Ana    406.\n## 10 2020-09-07 Joao   375.\n## 11 2020-09-07 Julia  528.\n## 12 2020-09-07 Julia  739.\n## 13 2020-09-10 Ana    406.\n## 14 2020-09-10 Joao   375.\n## 15 2020-09-10 Julia  528.\n## 16 2020-09-10 Julia  739."},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"a-metodologia-por-detrás-do-processo","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.4.2 A metodologia por detrás do processo","text":"Apesar de próximo, função expand() não é suficiente para produzirmos o resultado que desejamos. Lembre-se que nós temos tabela abaixo, e que desejamos completá-la com os dados referentes aos dias 02, 03, 04, 06, 08 e 09 de Setembro de 2020, que estão momento faltando nessa tabela.Primeiro, precisamos encontrar todos valores possíveis da variável que está incompleta na tabela vendas. Ou seja, queremos encontrar todas datas possíveis entre os dias 01 e 10 de Setembro de 2020, pois esses dias são os limites da tabela. Dito de outra forma, tabela vendas descreve dados de vendas que ocorreram dia 01 até o dia 10 de Setembro de 2020. Por isso, queremos encontrar todos os dias possíveis entre esse intervalo de tempo.Para isso, podemos utilizar função seq.Date() em conjunto com tibble(). Dessa forma, nos criamos uma nova tabela, que contém uma sequência de datas que vai dia 01 até o dia 10 de Setembro. O mesmo resultado, poderia ser atingido, caso utilizássemos seq.Date() dentro de expand(), já que expand() cria por padrão uma nova tabela com todas combinações possíveis dos dados que você fornece ela.Em seguida, podemos utilizar função full_join()19 pacote dplyr, para trazermos os dados disponíveis na tabela vendas para essa nova tabela nova_tab. Agora, nós temos uma nova tabela, que contém todos os dados que já estão definidos na tabela vendas, além dos dias que estavam faltando anteriormente, e que agora também estão definidos.O que resta agora, é preenchermos os campos com valores não-disponíveis (NA) com algum outro valor que seja mais claro, ou que indique de um forma melhor, que não houve vendas realizadas naquele dia. Visando esse objetivo, temos função replace_na() pacote tidyr. Nessa função, você irá fornecer uma lista (list()) contendo os valores que vão substituir os valores NA em cada coluna de sua tabela. Essa lista precisa ser nomeada. Basta nomear cada valor substituto com o nome da coluna em que você deseja utilizar esse valor. Logo, se eu quero substituir todos os valores NA na coluna valor, por um zero, basta eu nomear esse zero com o nome dessa coluna, dentro da lista (list()) que eu forneci à replace_na().","code":"\nvendas## # A tibble: 4 x 3\n##   datas      nome  valor\n##   <date>     <chr> <dbl>\n## 1 2020-09-01 Ana    406.\n## 2 2020-09-05 Julia  528.\n## 3 2020-09-07 Joao   375.\n## 4 2020-09-10 Julia  739.\nnova_tab <- tibble(\n  datas = seq.Date(min(vendas$datas), max(vendas$datas), by = \"day\")\n)\n\n\nnova_tab## # A tibble: 10 x 1\n##    datas     \n##    <date>    \n##  1 2020-09-01\n##  2 2020-09-02\n##  3 2020-09-03\n##  4 2020-09-04\n##  5 2020-09-05\n##  6 2020-09-06\n##  7 2020-09-07\n##  8 2020-09-08\n##  9 2020-09-09\n## 10 2020-09-10\n# O mesmo resultado poderia ser atingido com:\nnova_tab <- expand(\n  datas = seq.Date(min(vendas$datas), max(vendas$datas), by = \"day\")\n)\nnova_tab <- nova_tab %>% \n  full_join(vendas, by = \"datas\")\n\nnova_tab## # A tibble: 10 x 3\n##    datas      nome  valor\n##    <date>     <chr> <dbl>\n##  1 2020-09-01 Ana    406.\n##  2 2020-09-02 <NA>    NA \n##  3 2020-09-03 <NA>    NA \n##  4 2020-09-04 <NA>    NA \n##  5 2020-09-05 Julia  528.\n##  6 2020-09-06 <NA>    NA \n##  7 2020-09-07 Joao   375.\n##  8 2020-09-08 <NA>    NA \n##  9 2020-09-09 <NA>    NA \n## 10 2020-09-10 Julia  739.\nnova_tab %>% \n  replace_na(\n    list(nome = \"Não houve vendas\", valor = 0)\n  )## # A tibble: 10 x 3\n##    datas      nome             valor\n##    <date>     <chr>            <dbl>\n##  1 2020-09-01 Ana               406.\n##  2 2020-09-02 Não houve vendas    0 \n##  3 2020-09-03 Não houve vendas    0 \n##  4 2020-09-04 Não houve vendas    0 \n##  5 2020-09-05 Julia             528.\n##  6 2020-09-06 Não houve vendas    0 \n##  7 2020-09-07 Joao              375.\n##  8 2020-09-08 Não houve vendas    0 \n##  9 2020-09-09 Não houve vendas    0 \n## 10 2020-09-10 Julia             739."},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"a-função-complete-como-um-atalho-útil","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.4.3 A função complete() como um atalho útil","text":"função complete() é um wrapper, ou uma função auxiliar pacote tidyr, que engloba funções expand(), full_join(), e replace_na(). Ou seja, função complete() é um atalho para aplicarmos metodologia que acabamos de descrever na seção anterior. função possui três argumentos principais: 1) data, o nome objeto onde sua tabela está salva; 2) ..., especificação das colunas serem completadas, ou “expandidas” por complete(); 3) fill, uma lista nomeada (como que fornecemos em replace_na()), que atribui para cada variável (ou coluna) de sua tabela, um valor ser utilizado (ao invés de NA) para combinações faltantes.Vou explicar o argumento fill mais frente, por isso, vamos nos concentrar nos outros dois. tabela que contém os nossos dados se chama vendas, e por isso, é esse valor que devemos atribuir ao argumento data. Porém, como estamos utilizando o pipe (%>%) exemplo abaixo, ele já está realizando esse serviço para nós. Já o segundo argumento (...), diz respeita lista de especificações que vão definir como função complete() deve completar cada coluna da nossa tabela.Em outras palavras, o segundo argumento (...) é parte da função complete() que diz respeito ao uso de expand(). Você deve portanto, preencher este argumento, da mesma forma que você faria com função expand(). exemplo abaixo, o primeiro argumento (data), já está sendo definido pelo operador pipe (%>%). Perceba que eu preencho função complete(), da mesma forma em que preenchi função expand() na seção anterior. Perceba também, que complete() já retorna como resultado, tabela expandida após o uso de full_join().O último passo que resta agora, seria o uso de replace_na() para preencher os valores não-disponíveis por algum outro valor mais claro. Nós ainda podemos utilizar função complete() para executarmos esse passo. Basta você fornecer à complete() através de seu terceiro argumento (fill), mesma lista que você forneceria à replace_na(). Dessa forma, temos:","code":"\nvendas %>% \n  complete(\n    datas = seq.Date(min(datas), max(datas), by = \"day\")\n  )## # A tibble: 10 x 3\n##    datas      nome  valor\n##    <date>     <chr> <dbl>\n##  1 2020-09-01 Ana    406.\n##  2 2020-09-02 <NA>    NA \n##  3 2020-09-03 <NA>    NA \n##  4 2020-09-04 <NA>    NA \n##  5 2020-09-05 Julia  528.\n##  6 2020-09-06 <NA>    NA \n##  7 2020-09-07 Joao   375.\n##  8 2020-09-08 <NA>    NA \n##  9 2020-09-09 <NA>    NA \n## 10 2020-09-10 Julia  739.\nvendas %>% \n  complete(\n    datas = seq.Date(min(datas), max(datas), by = \"day\"),\n    fill = list(nome = \"Não houve vendas\", valor = 0)\n  )## # A tibble: 10 x 3\n##    datas      nome             valor\n##    <date>     <chr>            <dbl>\n##  1 2020-09-01 Ana               406.\n##  2 2020-09-02 Não houve vendas    0 \n##  3 2020-09-03 Não houve vendas    0 \n##  4 2020-09-04 Não houve vendas    0 \n##  5 2020-09-05 Julia             528.\n##  6 2020-09-06 Não houve vendas    0 \n##  7 2020-09-07 Joao              375.\n##  8 2020-09-08 Não houve vendas    0 \n##  9 2020-09-09 Não houve vendas    0 \n## 10 2020-09-10 Julia             739."},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"preenchendo-valores-não-disponíveis-na","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.5 Preenchendo valores não-disponíveis (NA)","text":"","code":""},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"utilizando-se-de-valores-anteriores-ou-posteriores","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.5.1 Utilizando-se de valores anteriores ou posteriores","text":"operações que vou mostrar seguir, servem para preencher linhas com dados não-disponíveis (NA), com valores anteriores ou posteriores que estão disponíveis em sua tabela. Vamos começar com um exemplo simples através da tabela df, que você pode criar em seu R utilizando os comandos abaixo. Nessa tabela, temos algumas vendas anuais hipotéticas. Agora, perceba que por algum motivo, o ano em que vendas ocorreram, só foram guardadas na primeira linha de cada ID (id). Isso é algo que devemos corrigir nessa tabela.Portanto, o que queremos fazer, é completar linhas de NA’s, com o ano correspondente essas vendas. Pelo fato dos anos estarem separados por um número constante de linhas, ou seja, cada 3 linhas de NA’s, temos um novo ano, podemos pensar em algumas soluções relativamente simples como definida abaixo. Porém, simplicidade problema, depende dos intervalos entre cada valor, serem constantes. partir momento em que esses valores começarem se dispersar em distâncias inconcistentes, uma solução como definida abaixo, não servirá.Apesar de ser um problema simples, podemos alcançar uma solução ainda mais simples, ao utilizarmos funções que são especializadas nesses problemas. Esse é o caso da função fill() pacote tidyr, que foi criada justamente para esse propósito. Portanto, sempre que você possuir em sua tabela, uma coluna onde você deseja substituir uma sequência de NA’s pelo último (ou próximo) valor disponível, você pode utilizar essa função para tal tarefa.função fill() possui três argumentos: 1) data, o objeto onde tabela com que deseja trabalhar, está salva; 2) ..., lista de colunas em que você deseja aplicar função; 3) .direction, define direção que função deve seguir na hora de preencher os valores.função fill() trabalha partir de uma dada direção vertical em sua tabela.\nPor padrão, função fill() irá preencher os valores indo para baixo, ou seja, partindo topo da tabela, até sua base. Logo, função irá substituir qualquer NA com o último valor disponível, ou em outras palavras, com o valor disponível anterior ao NA em questão. função lhe oferece o argumento .direction, caso você deseja alterar esse comportamento. Logo, se você deseja preencher esses valores NA’s com o próximo valor disponível em relação ao NA em questão. Isto é, preencher os valores para cima, partindo da base da tabela, e seguindo para o seu topo. Você precisa definir o argumento da seguinte maneira:Portanto, se tivéssemos que colocar essas operações em uma representação visual, teríamos algo como figura 7.5. Lembrando que função usa por padrão, direção , logo, primeiro caso mostrado na figura, você não precisaria definir explicitamente o argumento .direction.\nFigure 7.5: Representação processo executado pela função fill\nApesar de serem os exemplos mais claros de aplicação, serão raras ocasiões em que você terá esse problema posto claramente já de ínicio em sua tabela. Com isso, eu quero dizer que serão raros os momentos em que você desde o início terá uma tabela, onde por algum motivo, os registros aparecem apenas na primeira (ou na última) linha que diz respeito aquele registro.Usualmente, você irá utilizar função fill() quando você já estiver realizando diversas outras transformações em sua tabela, para se chegar aonde deseja. Um exemplo claro dessa ideia, seria uma tabela onde os valores são registrados primeiro dia de cada semana (basicamente você possui dados semanais), mas você precisa calcular uma média móvel diária. Isso significa que para calcular essa média móvel, você teria que completar os dias faltantes de cada semana, e ainda utilizar o fill() para transportar o valor primeiro dia, para os dias restantes da semana.Vale ressaltar, que você pode utilizar em fill(), todos os mecanismos de seleção que introduzimos em select(), para selecionar colunas em que você deseja aplicar função fill(). Isso também significa, que com fill() você pode preencher várias colunas ao mesmo tempo. Agora, para relembrarmos esses mecanismos, vamos criar uma tabela inicialmente vazia, que contém o total de vendas realizadas nos 6 primeiros meses de 2020, por cada funcionário de uma loja.Em seguida, vamos preencher colunas vazias (nome, salario, mes_ent, …) de forma com que informações de cada vendedor, apareçam apenas na última linha que diz respeito aquele vendedor. Como exemplo, informações vendedor Henrique, aparecem apenas na sexta linha da tabela, que é última linha da tabela que se refere ele.Portanto, o que precisamos é aplicar função fill() usando .direction = \"\", em cada uma dessas colunas vazias, de forma preencher o restante das linhas com informações de cada vendedor. Dada natureza dessa tabela, os dois melhores mecanismos que aprendemos em select(), para selecionarmos essas colunas vazias, são: 1) usar os índices dessas colunas; 2) nos basearmos nos tipos de dados contidos em cada coluna; 3) usar um vetor externo com os nomes das colunas que desejamos.Para utilizar o método 3 que citei acima, podemos utilizar o vetor colunas que criamos agora pouco ao preenchermos tabela, e já contém os nomes das colunas que desejamos. Porém, para o exemplo abaixo método 2, você talvez se pergunte: “Se estamos aplicando função fill() sobre todas colunas que contém ou dados de texto (character), ou dados numéricos (numeric), nós também estamos aplicando função sobre colunas mes e vendas, das quais não necessitam de ajuste. O que acontece?” Nada irá ocorrer com colunas mes e vendas, caso elas já estejam corretamente preenchidas, portanto, podemos aplicar função sobre elas sem medo.","code":"\nlibrary(tidyverse)\n\nv <- 2001:2004\n\nset.seed(1)\ndf <- tibble(\n  id = rep(1:4, each = 3),\n  ano = NA_real_,\n  valor = rnorm(12, mean = 1000, sd = 560)\n)\n\ndf[seq(1, 12, by = 3), \"ano\"] <- v\n\ndf## # A tibble: 12 x 3\n##       id   ano valor\n##    <int> <dbl> <dbl>\n##  1     1  2001  649.\n##  2     1    NA 1103.\n##  3     1    NA  532.\n##  4     2  2002 1893.\n##  5     2    NA 1185.\n##  6     2    NA  541.\n##  7     3  2003 1273.\n##  8     3    NA 1413.\n##  9     3    NA 1322.\n## 10     4  2004  829.\n## 11     4    NA 1847.\n## 12     4    NA 1218.\nniveis <- unique(df$ano)\nniveis <- niveis[!is.na(niveis)]\nrepair_vec <- df$ano\nrepair_vec[is.na(repair_vec)] <- rep(niveis, each = 2)\n\ndf$ano <- repair_vec\n\ndf## # A tibble: 12 x 3\n##       id   ano valor\n##    <int> <dbl> <dbl>\n##  1     1  2001  649.\n##  2     1  2001 1103.\n##  3     1  2001  532.\n##  4     2  2002 1893.\n##  5     2  2002 1185.\n##  6     2  2002  541.\n##  7     3  2003 1273.\n##  8     3  2003 1413.\n##  9     3  2003 1322.\n## 10     4  2004  829.\n## 11     4  2004 1847.\n## 12     4  2004 1218.\nlibrary(tidyverse)\n\ndf %>% fill(ano)## # A tibble: 12 x 3\n##       id   ano valor\n##    <int> <dbl> <dbl>\n##  1     1  2001  649.\n##  2     1  2001 1103.\n##  3     1  2001  532.\n##  4     2  2002 1893.\n##  5     2  2002 1185.\n##  6     2  2002  541.\n##  7     3  2003 1273.\n##  8     3  2003 1413.\n##  9     3  2003 1322.\n## 10     4  2004  829.\n## 11     4  2004 1847.\n## 12     4  2004 1218.\ndf %>% fill(ano, .direction = \"up\")## # A tibble: 12 x 3\n##       id   ano valor\n##    <int> <dbl> <dbl>\n##  1     1  2001  649.\n##  2     1  2002 1103.\n##  3     1  2002  532.\n##  4     2  2002 1893.\n##  5     2  2003 1185.\n##  6     2  2003  541.\n##  7     3  2003 1273.\n##  8     3  2004 1413.\n##  9     3  2004 1322.\n## 10     4  2004  829.\n## 11     4    NA 1847.\n## 12     4    NA 1218.\n# Caso prefira não utilizar o pipe ( %>% ),\n# ficaria dessa forma:\n\n# fill(df, ano, .direction = \"up\")\nset.seed(2)\nfuncionarios <- tibble(\n  mes = rep(1:6, times = 4),\n  vendas = floor(rnorm(24, mean = 60, sd = 24)),\n  nome = NA_character_,\n  salario = NA_real_,\n  mes_ent = NA_real_,\n  ano_ent = NA_real_,\n  unidade = NA_character_\n)\n\nfuncionarios## # A tibble: 24 x 7\n##      mes vendas nome  salario mes_ent ano_ent unidade\n##    <int>  <dbl> <chr>   <dbl>   <dbl>   <dbl> <chr>  \n##  1     1     38 <NA>       NA      NA      NA <NA>   \n##  2     2     64 <NA>       NA      NA      NA <NA>   \n##  3     3     98 <NA>       NA      NA      NA <NA>   \n##  4     4     32 <NA>       NA      NA      NA <NA>   \n##  5     5     58 <NA>       NA      NA      NA <NA>   \n##  6     6     63 <NA>       NA      NA      NA <NA>   \n##  7     1     76 <NA>       NA      NA      NA <NA>   \n##  8     2     54 <NA>       NA      NA      NA <NA>   \n##  9     3    107 <NA>       NA      NA      NA <NA>   \n## 10     4     56 <NA>       NA      NA      NA <NA>   \n## # ... with 14 more rows\nvalores <- list(\n  salario = c(1560, 2120, 1745, 1890),\n  nome = c(\"Henrique\", \"Ana\", \"João\", \"Milena\"),\n  ano_ent = c(2000, 2001, 2010, 2015),\n  mes_ent = c(2, 10, 5, 8),\n  unidade = c(\"Afonso Pena\", \"Savassi\", \"São Paulo\", \"Amazonas\")\n)\n\ncolunas <- colnames(funcionarios)[3:7]\n\nfor(i in colunas){\n  \n  funcionarios[1:4 * 6, i] <- valores[[i]]\n  \n}\n\n\n# Com isso, temos o seguinte resultado:\nfuncionarios %>% print(n = 12)## # A tibble: 24 x 7\n##      mes vendas nome     salario mes_ent ano_ent unidade    \n##    <int>  <dbl> <chr>      <dbl>   <dbl>   <dbl> <chr>      \n##  1     1     38 <NA>          NA      NA      NA <NA>       \n##  2     2     64 <NA>          NA      NA      NA <NA>       \n##  3     3     98 <NA>          NA      NA      NA <NA>       \n##  4     4     32 <NA>          NA      NA      NA <NA>       \n##  5     5     58 <NA>          NA      NA      NA <NA>       \n##  6     6     63 Henrique    1560       2    2000 Afonso Pena\n##  7     1     76 <NA>          NA      NA      NA <NA>       \n##  8     2     54 <NA>          NA      NA      NA <NA>       \n##  9     3    107 <NA>          NA      NA      NA <NA>       \n## 10     4     56 <NA>          NA      NA      NA <NA>       \n## 11     5     70 <NA>          NA      NA      NA <NA>       \n## 12     6     83 Ana         2120      10    2001 Savassi    \n## # ... with 12 more rows\n# Todas as três alternativas abaixo\n# geram o mesmo resultado:\n\nfuncionarios %>% \n  fill(\n    3:7,\n    .direction = \"up\"\n  )\n\nfuncionarios %>% \n  fill(\n    all_of(colunas),\n    .direction = \"up\"\n  )\nfuncionarios %>% \n  fill(\n    where(is.character),\n    where(is.numeric),\n    .direction = \"up\"\n  )## # A tibble: 24 x 7\n##      mes vendas nome     salario mes_ent ano_ent unidade    \n##    <int>  <dbl> <chr>      <dbl>   <dbl>   <dbl> <chr>      \n##  1     1     38 Henrique    1560       2    2000 Afonso Pena\n##  2     2     64 Henrique    1560       2    2000 Afonso Pena\n##  3     3     98 Henrique    1560       2    2000 Afonso Pena\n##  4     4     32 Henrique    1560       2    2000 Afonso Pena\n##  5     5     58 Henrique    1560       2    2000 Afonso Pena\n##  6     6     63 Henrique    1560       2    2000 Afonso Pena\n##  7     1     76 Ana         2120      10    2001 Savassi    \n##  8     2     54 Ana         2120      10    2001 Savassi    \n##  9     3    107 Ana         2120      10    2001 Savassi    \n## 10     4     56 Ana         2120      10    2001 Savassi    \n## # ... with 14 more rows"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"um-estudo-de-caso-sobre-médias-móveis-com-complete-e-fill","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.6 Um estudo de caso sobre médias móveis com complete() e fill()","text":"","code":""},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"a-metodologia-de-uma-média-móvel-no-r","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.6.1 A metodologia de uma média móvel no R","text":"Uma média móvel é calculada ao aplicarmos o cálculo da média aritmética, sobre uma sequência de partes (ou subsets) de seus dados. De certa forma, esse processo se parece com uma rolagem, como se estivéssemos “rolando” o cálculo da média ao longo dos nossos dados. Veja por exemplo, o cálculo abaixo, onde utilizamos função roll_mean() pacote RcppRoll para calcularmos uma média móvel que possui uma janela de 3 valores.janela (ou window) de uma média móvel, representa o número de observações que serão utilizadas cálculo da média cada “transição,” ou cada “rolagem.” exemplo acima, aplicamos uma média móvel com uma janela de 3 valores. Isso significa que cada “rolagem,” são utilizados 3 valores cálculo da média. Na primeiro rolagem, temos média vetor (2.7, 3.0, 1.5). Já na segunda rolagem, temos média vetor (3.0, 2.5, 3.2). E assim por diante. Portanto, em uma representação visual, o cálculo da média móvel aplicada por roll_mean(), é apresentado na figura 7.6.Perceba também que o cálculo de uma média móvel implica em perda de observações. Pois exemplo anterior, o vetor vec possui 6 valores, já o resultado de roll_mean() possui apenas 4 valores. Diversas operações estatísticas como essa, possuem o mesmo efeito. Um outro exemplo, seriam operações de diferenciação, que são muito utilizadas em análises de séries temporais, e produzem essa mesma perda de informação. Por outro lado, caso exposto aqui, essa perda de observações, ocorre devido ao tamanho da janela para o cálculo da média móvel.Ou seja, pelo fato de que definimos uma janela de 3 observações para o cálculo da média móvel acima, duas primeiras observações vetor vec, não podem gerar sua própria média móvel. Dito de outra forma, função roll_mean() não pode calcular uma média nas duas primeiras rolagens sobre o vetor vec. Pois na primeira rolagem sobre o vetor, roll_mean() possui apenas uma observação (2.7). Já na segunda rolagem, roll_mean() acumula ainda duas observações (2.7, 3.0). Apenas partir da terceira rolagem, que roll_mean() poderá calcular uma média segundo o tamanho da janela que definimos para ela, pois ela agora possui três observações (2.7, 3.0, 1.5) disponíveis para o cálculo. partir daí, roll_mean() vai continuar rolando e calculando médias móveis, até atingir o conjunto final de três observações vetor vec (3.2, 1.6, 2.5).Logo, sendo \\(j\\) o número de observações presentes em cada janela de cálculo de sua média móvel, e \\(lvec\\) sendo o número de valores presentes em seu vetor inicial, sobre o qual você irá calcular sua média móvel. O número de médias móveis resultantes de roll_mean() (\\(obs\\)), será equivalente : \\(obs = lvec - (j - 1)\\). Em outras palavras, o número de observações que você irá perder (\\(perda\\)), cálculo de sua média móvel será equivalente : \\(perda = j - 1\\).\nFigure 7.6: Representação cálculo de uma média móvel\nAgora, pode ser de seu desejo, contornar essa perda de observações de alguma maneira. Especialmente se você está calculando essa média móvel com base em uma coluna de sua tabela, pois sendo este o caso, provavelmente será de seu interesse, guardar essas médias calculadas em uma nova coluna dessa tabela. Entretanto, se você criar uma tabela, alocando por exemplo o vetor vec em uma coluna, e tentasse adicionar uma nova coluna contendo médias móveis de cada ponto vetor, o R lhe retornaria o erro abaixo. Caso você se lembre das propriedades dos data.frame’s R, você irá entender o porquê que está motivando esse erro. Pois todas colunas de um data.frame devem possuir obrigatoriamente o mesmo número de observações. Como nós perdemos duas das seis observações de vec, cálculo da média móvel, o R não permite alocarmos diretamente essas médias em nossa tabela df.função roll_mean() oferece duas formas de contornar esse problema: 1) definir o alinhamento da função, para preencher observações faltantes com valores não-disponíveis (NA); 2) ou preencher essas observações faltantes com um valor pré-definido, através de seu argumento fill. Ambas formas são válidas e possivelmente são o que você deseja.O primeiro método que citei, envolve o alinhamento da função, que você irá definir através sufixos r e l nome da função. diferença entre os dois tipos de alinhamento, decide em que parte (início, ou final) vetor resultante de roll_mean(), os valores não-disponíveis (NA) serão posicionados. Se você deseja utilizar o alinhamento à direita (right - r), você deve utilizar função roll_meanr(). Mas se você quer utilizar o alinhamento à esquerda (left - l), você deve utilizar função roll_meanl().Quanto ao segundo método que citei, que envolve o argumento fill, você pode utilizar o argumento align, para definir em que partes vetor resultante, o valor que você definiu em fill será posicionado. Por exemplo, caso eu use o valor center em align, o valor definido em fill vai aparecer tanto início quanto ao fim vetor que resulta da função roll_mean(). Mas se eu utilizar o valor right em align, esse valor irá aparecer ao início vetor resultante.","code":"\nlibrary(RcppRoll)\nvec <- c(2.7, 3.0, 1.5, 3.2, 1.6, 2.5)\n\nroll_mean(vec, n = 3)## [1] 2.400000 2.566667 2.100000 2.433333\ndf <- data.frame(x = vec)\n\ndf$media_movel <- roll_mean(df$x, n = 3)Error in `$<-.data.frame`(`*tmp*`, media_movel, value = c(2.4, \n2.56666666666667, : replacement has 4 rows, data has 6.\nroll_meanr(vec, n = 3)## [1]       NA       NA 2.400000 2.566667 2.100000 2.433333\nroll_meanl(vec, n = 3)## [1] 2.400000 2.566667 2.100000 2.433333       NA       NA\nroll_mean(vec, n = 3, fill = 0, align = \"center\")## [1] 0.000000 2.400000 2.566667 2.100000 2.433333 0.000000\nroll_mean(vec, n = 3, fill = 0, align = \"right\")## [1] 0.000000 0.000000 2.400000 2.566667 2.100000 2.433333\nroll_mean(vec, n = 3, fill = 0, align = \"left\")## [1] 2.400000 2.566667 2.100000 2.433333 0.000000 0.000000"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"sec:dados_covid","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.6.2 Os dados da Covid-19","text":"Na próxima seção, busco dar um exemplo prático de como funções complete() e fill() que vimos nas seções anteriores, podem ser utilizadas em conjunto em um problema real. Para isso, vamos utilizar parte dos dados sobre Covid-19 (SARS-COV-2) Brasil. Ao utilizar o código abaixo, lembre-se de renomear primeira coluna da tabela para dia. Dessa forma, nós evitamos confusões com qualquer função que possua um argumento chamado data (funções como mutate(), select(), complete(), lm() e muitas outras possuem tal argumento).Fundação João Pinheiro (FJP-MG) tem dado apoio técnico ao governo de Minas Gerais, acompanhamento da pandemia de COVID-19, ao gerar estatísticas e estimações epidemiológicas para o estado. Eu fiz parte desse esforço por algum tempo, e uma demanda real que havia chegado para mim na época, concistia cálculo de uma média móvel dos novos casos diários da doença para cada estado Brasil. Pois era de desejo da Secretaria Estadual de Saúde, comparar curva dessa média móvel estado de Minas Gerais, com de outros estados brasileiros.Na época em que trabalhei com base covid, ela possuía algumas barreiras, que superei com o uso de complete() e fill(). São essas barreiras, e suas resoluções que busco mostrar nessa seção, como um exemplo real de uso dessas funções. Porém, base covid que está disponível hoje, e que você acaba de importar através dos comandos acima, é base já corrigida e reformatada e, por isso, ela já se encontra em um formato ideal para o cálculo de uma média móvel. Portanto, antes de partirmos para prática, vou aplicar algumas transformações, com o objetivo de “corromper” base covid até o seu ponto inicial. Pois o foco nessa seção, se encontra na demonstração dos problemas de formatação da base, e em suas possíveis soluções.O primeiro ponto ser discutido, são datas iniciais da pandemia em cada estado brasileiro. Brasil, pandemia de Covid-19 atingiu primeiramente o estado de São Paulo, e chegou posteriormente aos demais estados. Como podemos ver pelo resultado abaixo, data inicial de cada estado, ao longo da base covid é difusa. Em alguns estados, os registros se iniciam partir da data primeiro registro de casos da doença (como os estados Acre, Alagoas, Bahia, Amazonas e Espírito Santo). Alguns estados, registraram mais de um caso já primeiro dia (como o Acre, que registrou três casos dia 17 de Março, e o Ceará, que reportou nove casos dia 16 de Março). Porém, outros estados (como Paraíba) não seguem esse padrão, pois seu primeiro dia de registro, o número de casos reportados foi igual zero. Ou seja, pandemia estado da Paraíba não se iniciou oficialmente dia 12 de Março, pois não havia casos reportados até este dia.Isso não representa um grande problema, mas antes das próximas transformações, devemos iniciar os dados de cada estado, dia de primeiro registro de casos da doença. Isto é, os dados da Paraíba, por exemplo, devem se iniciar dia em que houve pela primeira vez, um registro de casos maior que zero. Como coluna casos, representa o número acumulado de casos da doença, nós podemos realizar esse “nivelamento” entre os estados, ao eliminarmos da base, todas linhas que possuem um número acumulado de casos igual zero. Porém, vale pena olharmos mais atentamente sobre essas linhas antes de eliminá-las, para termos certeza de que não estamos causando mais danos ao processo.Perceba pelo resultado abaixo, que todos linhas em que o número acumulado de casos se iguala zero, pertencem ao estado da Paraíba. Todas essas seis datas, são “inúteis” para o propósito da base covid, pois apresentam um cenário anterior à pandemia estado da Paraíba. Portanto, antes de prosseguirmos, vamos eliminar essas linhas, com o uso de filter().base covid atualmente possui os números de casos diários acumulados de cada estado brasileiro. Mas vamos supor, que base covid registrasse o número de casos acumulados, somente nos dias em que esse número se alterasse. Ou seja, se o número de casos acumulados da doença em uma segunda-feira qualquer ano, era de 300, e esse número se manteve constante ao longo da semana, até que na sexta-feira, esse número subiu para 301 casos, base covid irá registrar os números de casos acumulados apenas para datas da segunda e da sexta dessa semana. Tal resultado pode ser atingido com os comandos abaixo. Como nós filtramos anteriormente base, de forma retirar linhas com valores iguais zero na coluna casos, temos que reconstruir o objeto data_inicial, como exposto abaixo.Portanto, temos agora tabela abaixo, onde podemos perceber que dia 21 de Março de 2020 não houve alteração número de casos acumulados estado Acre. Pois esse dia (2020-03-21) não está mais presente na tabela covid. Dito de outra forma, o número de novos casos de Covid-19 que surgiram dia 21 de Março, foi igual zero. O mesmo ocorre com os dias 25 e 27 de Março estado, que também não estão mais presentes na base.Quando trabalhei anteriormente com base covid anteriormente, ela se encontrava inicialmente em um formato muito próximo deste. Por isso, base necessitava de ajustes para o cálculo da média móvel. O intuito da próxima seção, é demonstrar como eu fiz esses ajustes necessários, através das funções complete() e fill().","code":"\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\narquivo <- \"Curso-R/master/Dados/covid.csv\"\n\ncovid <- read_csv2(paste0(github, arquivo))\n\ncolnames(covid)[1] <- \"dia\"\ndata_inicial <- covid %>% \n  group_by(estado) %>% \n  summarise(\n    data_inicial = min(dia),\n    casos_inicial = min(casos)\n  )\n\ndata_inicial %>% print(n = 15)## # A tibble: 27 x 3\n##    estado data_inicial casos_inicial\n##    <chr>  <date>               <dbl>\n##  1 AC     2020-03-17               3\n##  2 AL     2020-03-08               1\n##  3 AM     2020-03-13               2\n##  4 AP     2020-03-20               1\n##  5 BA     2020-03-06               1\n##  6 CE     2020-03-16               9\n##  7 DF     2020-03-07               1\n##  8 ES     2020-03-05               1\n##  9 GO     2020-03-12               3\n## 10 MA     2020-03-20               1\n## 11 MG     2020-03-08               1\n## 12 MS     2020-03-14               2\n## 13 MT     2020-03-20               1\n## 14 PA     2020-03-18               1\n## 15 PB     2020-03-12               0\n## # ... with 12 more rows\ncovid %>% filter(casos == 0)## # A tibble: 6 x 4\n##   dia        estado casos mortes\n##   <date>     <chr>  <dbl>  <dbl>\n## 1 2020-03-12 PB         0      0\n## 2 2020-03-13 PB         0      0\n## 3 2020-03-14 PB         0      0\n## 4 2020-03-15 PB         0      0\n## 5 2020-03-16 PB         0      0\n## 6 2020-03-17 PB         0      0\ncovid <- filter(covid, casos != 0)\ndata_inicial <- covid %>% \n  group_by(estado) %>% \n  summarise(\n    data_inicial = min(dia),\n    casos_inicial = min(casos)\n  ) %>% \n  mutate(\n    dia = as.Date(data_inicial - 1),\n    casos = NA_real_,\n    mortes = NA_real_\n  )\n\ncovid <- covid %>% \n  bind_rows(\n    data_inicial %>% select(dia, estado, casos, mortes)\n  ) %>% \n  group_by(estado) %>% \n  arrange(\n    dia,\n    estado,\n    .by_group = TRUE\n  ) %>% \n  mutate(\n    teste = lead(casos) == casos\n  ) %>% \n  filter(teste == FALSE) %>% \n  ungroup() %>% \n  select(-teste)\ncovid## # A tibble: 3,456 x 4\n##    dia        estado casos mortes\n##    <date>     <chr>  <dbl>  <dbl>\n##  1 2020-03-18 AC         3      0\n##  2 2020-03-19 AC         4      0\n##  3 2020-03-20 AC         7      0\n##  4 2020-03-22 AC        11      0\n##  5 2020-03-23 AC        17      0\n##  6 2020-03-24 AC        21      0\n##  7 2020-03-26 AC        23      0\n##  8 2020-03-28 AC        25      0\n##  9 2020-03-29 AC        34      0\n## 10 2020-03-30 AC        41      0\n## # ... with 3,446 more rows"},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"buscando-soluções-com-complete-e-fill","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"7.6.3 Buscando soluções com complete() e fill()","text":"Considerando que você aplicou transformações expostas na seção anterior (Os dados da Covid-19), você está apto aplicar os comandos apresentados nessa seção. Agora, em que sentido essa nova tabela que temos, é inapropriada para o cálculo da média móvel diária de novos casos? Porque agora faltam os registros dos dias em que não houve alteração número acumulado de casos em cada estado. Ou seja, nós retiramos na seção anterior, justamente aquilo que queremos recuperar nessa seção. Como eu disse, o intuito dessas seções, está nos exemplos de uso das funções complete() e fill(), e não caminho que temos que percorrer para estarmos aptos para aplicação desses exemplos.Portanto, o problema que possuímos agora cálculo da média móvel sobre base covid, é que faltam os dias onde o número de casos acumulados permaneceu constante. Isso significa que agora temos uma quebra cálculo da média móvel. Caso o vetor vec abaixo, representasse uma parte da coluna casos da nossa base covid, se aplicássemos uma média móvel, com uma janela de 3 valores, médias dos dias 03 e 04 não poderiam ser calculadas (ou mínimo, estariam incorretas), tendo em vista transformações que aplicamos na seção anterior.Ou seja, considerando que nós eliminamos na seção anterior, todas linhas de covid, onde o número acumulado de casos permaneceu constante em relação ao seu valor anterior; se aplicarmos mesma transformação ao vetor vec abaixo, o valor referente ao dia 02 seria eliminado, e por isso, uma quebra ocorreria sobre o cálculo das médias móveis dos dias 03 e 04. Pois, dentre os valores dos 3 dias anteriores aos dias 03 e 04, estaria faltando o valor referente ao dia 02.São por essas razões, que devemos recuperar os dias perdidos na tabela covid, mesmo que o número de casos nesses dias tenham permanecido constantes. nosso caso, não podemos utilizar diretamente colunas da base covid, para expandirmos tabela, e recuperarmos datas que foram perdidas. Pois essas datas não se encontram mais na tabela covid. Lembre-se que função complete() irá sempre trabalhar com observações que estão presentes em sua base, caso você não forneça algo mais, com qual ela possa trabalhar. Por isso, teremos que gerar na função complete(), um vetor externo à base covid, de forma incluirmos todas datas que faltam.\nFigure 7.7: Representação das séries temporais da base covid pré e pós-transformações\nAntes de prosseguir, vamos compreender exatamente qual é o estado atual da base covid. Nós eliminamos (na seção anterior) parte dos dias da base. Mais especificamente aqueles dias em que o número acumulado de casos da doença, permaneceu constante em relação seu valor anterior. Portanto, neste momento, séries temporais número de casos de cada estado apresentam quebras. Em uma representação visual, essas séries se assemelham momento às linhas em cor preta, apresentadas gráfico da figura 7.7. São essas quebras que nos impedem de calcularmos uma média móvel desses casos.O primeiro passo, será expandir essas séries com função complete(). Utilizando-se de um vetor (construído pela função seq.Date()), contendo desde o dia 1 da pandemia país (dia dos primeiros casos estado de São Paulo, onde pandemia se iniciou) até o último dia da base. Com isso, função complete() irá combinar cada uma dessas datas, com cada um dos 27 estados. Após essa expansão da tabela covid, séries de cada estado vão incluir todas datas possíveis, incluindo aquelas que originalmente não pertenciam aquele estado. Dessa forma, séries de cada estado, vão ser equivalentes à junção das linhas pretas, azuis e vermelhas gráfico da figura 7.7. Formando assim novamente uma série “sólida,” ou completa.O segundo passo, será “nivelar” séries de acordo com o período inicial de cada estado. Pois, como resultado passo anterior, séries de todos os estados serão iguais em comprimento (ou em número de observações). Pois séries de todos os estados, estarão incluindo desde o dia 1 da pandemia, até o último dia da pandemia. Portanto, seguindo o gráfico da figura 7.7, segundo passo estaremos eliminando área vermelha de cada série, de forma que séries de cada estado vão se equivaler à junção das linhas em preto e azul. Para isso, podemos aplicar os comandos abaixo:O terceiro passo, envolve o uso de fill() para completarmos o número de casos em cada data recuperada. Lembre-se que ao expandirmos tabela com complete(), função preecheu os campos das colunas casos e mortes com valores não-disponíveis (NA), na linha de cada data que não estava presente anteriormente na base covid (ou seja, datas que foram perdidas anteriormente). Portanto, todas linhas que possuem um valor NA nessas colunas, são linhas que correspondem aos dias em que o número acumulado de casos se manteve constante. Como esse número se manteve constante, tudo o que precisamos fazer, é utilizar fill() para puxar os valores disponíveis anteriores para esses campos.Dessa forma, temos novamente, tabela corretamente formatada, e pronta para o cálculo de uma média móvel. O número acumulado de casos certamente tende aumentar com o tempo, mas será que variação desse número, segue o mesmo padrão? Para calcularmos essa variação, podemos utilizar função lag() para utilizarmos o valor da linha anterior de uma coluna. Com isso, podemos subtrair o valor da linha anterior, sobre o valor da linha atual, tirando assim, diferença ou variação entre elas. Em seguida, basta aplicarmos função roll_meanr() sobre esta variação, para adquirirmos uma média móvel número de novos casos diários.","code":"\nvec <- c(\"Dia 01\" = 1, \"Dia 02\" = 1, \"Dia 03\" = 3, \n         \"Dia 04\" = 5, \"Dia 05\" = 7)\n\nvec## Dia 01 Dia 02 Dia 03 Dia 04 Dia 05 \n##      1      1      3      5      7\nmenor_data <- min(data_inicial$data_inicial)\nmaior_data <- max(covid$dia)\n\nnovo_covid <- covid %>% \n  complete(\n    dia = seq.Date(menor_data, maior_data, by = \"day\"),\n    estado\n  ) %>% \n  group_by(estado) %>% \n  arrange(dia, estado, .by_group = T) %>% \n  ungroup()\n\nnovo_covid## # A tibble: 4,131 x 4\n##    dia        estado casos mortes\n##    <date>     <chr>  <dbl>  <dbl>\n##  1 2020-02-25 AC        NA     NA\n##  2 2020-02-26 AC        NA     NA\n##  3 2020-02-27 AC        NA     NA\n##  4 2020-02-28 AC        NA     NA\n##  5 2020-02-29 AC        NA     NA\n##  6 2020-03-01 AC        NA     NA\n##  7 2020-03-02 AC        NA     NA\n##  8 2020-03-03 AC        NA     NA\n##  9 2020-03-04 AC        NA     NA\n## 10 2020-03-05 AC        NA     NA\n## # ... with 4,121 more rows\nnovo_covid <- novo_covid %>% \n  right_join(\n    data_inicial[c(\"estado\", \"data_inicial\")],\n    by = \"estado\"\n  )\n\nteste <- novo_covid$dia >= novo_covid$data_inicial\n\nnovo_covid <- novo_covid[teste, ]\n\nnovo_covid## # A tibble: 3,670 x 5\n##    dia        estado casos mortes data_inicial\n##    <date>     <chr>  <dbl>  <dbl> <date>      \n##  1 2020-03-17 AC        NA     NA 2020-03-17  \n##  2 2020-03-18 AC         3      0 2020-03-17  \n##  3 2020-03-19 AC         4      0 2020-03-17  \n##  4 2020-03-20 AC         7      0 2020-03-17  \n##  5 2020-03-21 AC        NA     NA 2020-03-17  \n##  6 2020-03-22 AC        11      0 2020-03-17  \n##  7 2020-03-23 AC        17      0 2020-03-17  \n##  8 2020-03-24 AC        21      0 2020-03-17  \n##  9 2020-03-25 AC        NA     NA 2020-03-17  \n## 10 2020-03-26 AC        23      0 2020-03-17  \n## # ... with 3,660 more rows\nnovo_covid <- novo_covid %>% \n  fill(casos, mortes, .direction = \"up\")\n\nnovo_covid## # A tibble: 3,670 x 5\n##    dia        estado casos mortes data_inicial\n##    <date>     <chr>  <dbl>  <dbl> <date>      \n##  1 2020-03-17 AC         3      0 2020-03-17  \n##  2 2020-03-18 AC         3      0 2020-03-17  \n##  3 2020-03-19 AC         4      0 2020-03-17  \n##  4 2020-03-20 AC         7      0 2020-03-17  \n##  5 2020-03-21 AC        11      0 2020-03-17  \n##  6 2020-03-22 AC        11      0 2020-03-17  \n##  7 2020-03-23 AC        17      0 2020-03-17  \n##  8 2020-03-24 AC        21      0 2020-03-17  \n##  9 2020-03-25 AC        23      0 2020-03-17  \n## 10 2020-03-26 AC        23      0 2020-03-17  \n## # ... with 3,660 more rows\nlibrary(RcppRoll)\n\nnovo_covid <- novo_covid %>% \n  group_by(estado) %>% \n  mutate(\n    novos_casos = casos - lag(casos),\n    media_casos = roll_meanr(novos_casos, n = 5)\n  )\n\nnovo_covid## # A tibble: 3,670 x 7\n## # Groups:   estado [27]\n##    dia        estado casos mortes data_inicial novos_casos media_casos\n##    <date>     <chr>  <dbl>  <dbl> <date>             <dbl>       <dbl>\n##  1 2020-03-17 AC         3      0 2020-03-17            NA        NA  \n##  2 2020-03-18 AC         3      0 2020-03-17             0        NA  \n##  3 2020-03-19 AC         4      0 2020-03-17             1        NA  \n##  4 2020-03-20 AC         7      0 2020-03-17             3        NA  \n##  5 2020-03-21 AC        11      0 2020-03-17             4        NA  \n##  6 2020-03-22 AC        11      0 2020-03-17             0         1.6\n##  7 2020-03-23 AC        17      0 2020-03-17             6         2.8\n##  8 2020-03-24 AC        21      0 2020-03-17             4         3.4\n##  9 2020-03-25 AC        23      0 2020-03-17             2         3.2\n## 10 2020-03-26 AC        23      0 2020-03-17             0         2.4\n## # ... with 3,660 more rows\nt <- \"Média móvel de 5 dias para os novos casos de Covid-19 nos estados\nda região Sudeste\"\n\nnovo_covid %>% \n  filter(estado %in% c(\"SP\", \"MG\", \"RJ\", \"ES\")) %>% \n  ggplot() +\n  geom_line(\n    aes(x = dia, y = log(media_casos), color = estado),\n    size = 1\n  ) +\n  theme(\n    legend.position = \"bottom\",\n    axis.title.y = element_blank(),\n    plot.title = element_text(face = \"bold\")\n  ) +\n  labs(\n    title = t,\n    subtitle = \"Escala logarítmica\",\n    x = \"Tempo\",\n    color = \"Unidade da Federação\"\n  )## Warning: Removed 20 row(s) containing missing values (geom_path)."},{"path":"tidy-data-uma-abordagem-para-organizar-os-seus-dados.html","id":"exercícios-5","chapter":"Capítulo 7 Tidy Data: Uma abordagem para organizar os seus dados","heading":"Exercícios","text":"Questão 7.1. Os itens desta questão vão utilizar tabela world_bank_pop. Essa tabela advém pacote tidyr, logo, caso você tenha chamado com sucesso por esse pacote através comando library() você já possui acesso essa tabela. tabela world_bank_pop contém uma série histórica de vários dados populacionais para cada país descrito na base.7.1.) tabela world_bank_pop não se encontra em um formato tidy. Indique qual (ou quais) dos pressupostos que definem o formato tidy data é (ou são) violado por essa tabela e, explique o porquê disso.7.1.B) Repare que para além das colunas country e indicator, temos os dados populacionais espalhados ao longo de diversas colunas, onde cada coluna representa o valor dessa série histórica para um determinado ano. Utilize os conhecimentos desse capítulo para reunir essas várias colunas (que se referem anos específicos da série) de modo que base fique mais próxima de um formato tidy data.7.1.C) Filtre todas linhas da tabela que descrevem população total de cada país (isto é, linhas em que o valor na coluna indicator é igual ao código \"SP.POP.TOTL\"), em seguida, tente calcular variação da população total entre cada ano da série, para todos os países.","code":"\nworld_bank_pop## # A tibble: 1,056 x 20\n##    country indicator   `2000` `2001` `2002` `2003`  `2004`  `2005`   `2006`\n##    <chr>   <chr>        <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl>    <dbl>\n##  1 ABW     SP.URB.TO~  4.24e4 4.30e4 4.37e4 4.42e4 4.47e+4 4.49e+4  4.49e+4\n##  2 ABW     SP.URB.GR~  1.18e0 1.41e0 1.43e0 1.31e0 9.51e-1 4.91e-1 -1.78e-2\n##  3 ABW     SP.POP.TO~  9.09e4 9.29e4 9.50e4 9.70e4 9.87e+4 1.00e+5  1.01e+5\n##  4 ABW     SP.POP.GR~  2.06e0 2.23e0 2.23e0 2.11e0 1.76e+0 1.30e+0  7.98e-1\n##  5 AFG     SP.URB.TO~  4.44e6 4.65e6 4.89e6 5.16e6 5.43e+6 5.69e+6  5.93e+6\n##  6 AFG     SP.URB.GR~  3.91e0 4.66e0 5.13e0 5.23e0 5.12e+0 4.77e+0  4.12e+0\n##  7 AFG     SP.POP.TO~  2.01e7 2.10e7 2.20e7 2.31e7 2.41e+7 2.51e+7  2.59e+7\n##  8 AFG     SP.POP.GR~  3.49e0 4.25e0 4.72e0 4.82e0 4.47e+0 3.87e+0  3.23e+0\n##  9 AGO     SP.URB.TO~  8.23e6 8.71e6 9.22e6 9.77e6 1.03e+7 1.09e+7  1.15e+7\n## 10 AGO     SP.URB.GR~  5.44e0 5.59e0 5.70e0 5.76e0 5.75e+0 5.69e+0  4.92e+0\n## # ... with 1,046 more rows, and 11 more variables: 2007 <dbl>, 2008 <dbl>,\n## #   2009 <dbl>, 2010 <dbl>, 2011 <dbl>, 2012 <dbl>, 2013 <dbl>,\n## #   2014 <dbl>, 2015 <dbl>, 2016 <dbl>, 2017 <dbl>"},{"path":"visualização-de-dados-com-ggplot2.html","id":"visualização-de-dados-com-ggplot2","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"Capítulo 8 Visualização de dados com ggplot2","text":"","code":""},{"path":"visualização-de-dados-com-ggplot2.html","id":"introdução-e-pré-requisitos-3","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.1 Introdução e pré-requisitos","text":"Esse é o primeiro capítulo em que vamos introduzir o pacote ggplot2, ou simplesmente ggplot. O ggplot é um pacote voltado para visualização de dados, ou em outras palavras, para construção de gráficos. Para que você possa acompanhar os exemplos dessa seção, você precisa ter o pacote instalado em sua máquina. Após instalá-lo, você pode tanto chamar diretamente pelo pacote ggplot2, quanto pelo tidyverse, que também o inclui, através da função library().","code":"\nlibrary(ggplot2)\nlibrary(tidyverse)"},{"path":"visualização-de-dados-com-ggplot2.html","id":"o-que-é-o-ggplot-e-a-sua-gramática","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.2 O que é o ggplot e a sua gramática","text":"linguagem R é conhecida por sua capacidade gráfica, e Murrell (2006) oferece ótimos exemplos que atestam essa afirmação. Mesmo que linguagem R ofereça “já de fábrica,” o pacote lattice, que já é capaz de muita coisa, o ggplot é sem dúvidas, o pacote mais popular da linguagem que tange criação de gráficos, pois ele oferece algo que os outros pacotes não tem, que é sua flexibilidade20.\nFigure 8.1: phases9032 por Thomas Lin Pedersen\nFlexibilidade é uma das principais características (e principal vantagem) ggplot, e é o que amplia sua utilização para além dos gráficos sérios e frios de um jornal científico, permitindo ao usuário criar gráficos vistosos, e um tanto peculiares. Veja por exemplo, arte criada por Thomas Lin Pedersen, mostrada na figura 8.1. O que lhe dá essa liberdade dentro ggplot, é sua gramática.O pacote ggplot (ou seu nome oficial - ggplot2) foi inicialmente desenvolvido por Wickham (2016), e lançado pela primeira vez ano de 2005. O pacote representa uma implementação da teoria desenvolvida por Wilkinson (2005), chamada de Grammar Graphics (ou “gramática dos gráficos”). Portanto, o ggplot busca abstrair os principais conceitos da teoria de Wilkinson (2005), e implementá-los dentro da linguagem R.Segundo teoria de Wilkinson (2005), todo e qualquer gráfico estatístico, pode ser descrito por um conjunto de camadas, ou componentes, que estão apresentados na figura 8.2. Dessa forma, segundo visão de Wilkinson (2005) todos os tipos de gráfico que conhecemos (pizza, barras, dispersão, boxplot, etc.) fazem parte de um mesmo grupo, e característica que os tornam diferentes entre si, se encontra na forma como camadas abaixo estão definidas em cada gráfico.\nFigure 8.2: Camadas de um gráfico ggplot, baseado em Wickham (2016)\nTendo isso em mente, um gráfico ggplot é composto por várias camadas, que em conjunto formam o gráfico desejado. ideia por trás pacote, portanto, é utilizar uma gramática para descrever de forma concisa, cada uma das camadas apresentadas na figura 8.2. Após definirmos essas camadas, nós podemos somá-las para construírmos o nosso gráfico final. Em outras palavras, você vai adicionando aos poucos, novas camadas ao gráfico, onde cada uma dessas camadas fica responsável por definir um componente específico gráfico (escalas, formas geométricas, legendas, facetas, anotações, …). Caso seja de seu desejo, você pode deixar o próprio ggplot responsável por definir várias das camadas apresentadas na figura 8.2. Porém, em todo gráfico ggplot, você deve obrigatoriamente definir três camadas (em negrito na figura 8.2) apresentadas seguir, sendo portanto, camadas essenciais que formam base de todo gráfico ggplot.Dados: os dados que o gráfico deve expor.Dados: os dados que o gráfico deve expor.Mapeamento estético (aesthetic mapping): uma descrição de como variáveis dispostas em seus dados devem ser mapeadas para elementos visuais (ou estéticos) de seu gráfico.Mapeamento estético (aesthetic mapping): uma descrição de como variáveis dispostas em seus dados devem ser mapeadas para elementos visuais (ou estéticos) de seu gráfico.Geometrias: são formas geométricas gráfico que representam os seus dados, ou seja, em um gráfico de dispersão, seus dados são representados gráfico por pontos, enquanto em um gráfico de barras, seus dados são representados por retângulos.Geometrias: são formas geométricas gráfico que representam os seus dados, ou seja, em um gráfico de dispersão, seus dados são representados gráfico por pontos, enquanto em um gráfico de barras, seus dados são representados por retângulos.gramática ggplot, representa portanto, regras que definem o emprego das funções necessárias, e de seus possíveis parâmetros para acessarmos e controlarmos cada uma das camadas mostradas na figura 8.2. Logo, cada uma dessas camadas, são controladas por uma função (ou por um conjunto de funções) diferente, que lhe permite o uso de diferentes mecanismos e valores em sua definição.","code":""},{"path":"visualização-de-dados-com-ggplot2.html","id":"iniciando-um-gráfico-do-ggplot","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.3 Iniciando um gráfico do ggplot","text":"","code":""},{"path":"visualização-de-dados-com-ggplot2.html","id":"dados","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.3.1 Dados","text":"Primeiro, vamos definir os dados que vamos utilizar em nossos gráficos. tabela datasus, contém contagem de mortes por homicídios dolosos em 2018 Brasil, coletados partir dos microdados SIM/DATASUS. Nessa mesma tabela, temos distribuição dessas mortes, por sexo, por faixa etária, pelo estado (Unidade da Federação - UF) em que mortes ocorreram, e pela cor de pele indivíduos.Vamos começar montar o nosso gráfico. Você sempre inicia um gráfico de ggplot, pela função base pacote - ggplot(). Essa função é responsável por criar o objeto base para o gráfico, e nela, possuímos dois argumentos que compõe duas das três camadas essenciais (que definimos na seção 8.2) desse gráfico, e que podem ou não ser fornecidos nessa função. Esses dois argumentos são: data, que é o nome da tabela onde estão os dados que serão utilizados gráfico; e mapping, que é o aesthetic mapping, ou o mapeamento de variáveis de sua tabela, para componentes estéticos gráfico. Ou seja, você não precisa necessariamente fornecer esses argumentos já na função ggplot(), pois você pode definí-los dentro das funções que formam figuras geométricas (funções geom). O importante, é que você sempre deve começar um gráfico ggplot, com função ggplot().Mas então, qual é diferença entre eu fornecer esses argumentos na função ggplot() ou dentro das funções geom? Pense em um exemplo, qual você busca mostrar em um mesmo gráfico, duas informações diferentes. Você pode utilizar dois geom’s (ou formas geométricas) diferentes para mostrar e diferenciar essas duas informações gráfico. Por exemplo, podemos ter um gráfico que contenha barras mostrando evolução da dívida pública, e linhas mostrando evolução salário médio país.Caso você forneça os dois argumentos (data e mapping) na função ggplot(), você está dizendo ao programa, que ele deve utilizar mesma base de dados, e o mesmo aesthetic mapping, em todos os formatos geométricos (geom) gráfico. Enquanto, ao fornecer esses argumentos dentro de cada função geom, você estaria dizendo ao programa que utilize essa base de dados, e esse aesthetic mapping, apenas naquele formato geométrico (ou geom) especificamente. Tendo isso em mente, não conseguiríamos montar o gráfico descrito parágrafo anterior, ao dar os argumentos já na função ggplot(). Pois o gráfico mostra duas informações diferentes (salário médio e dívida pública), ao longo dos geom’s gráfico. Ou seja, os dois formatos geométricos dispostos gráfico, utilizam dois aesthetic mapping diferentes. Quando chegarmos à seção 8.4 vou explicar isso em mais detalhes.nosso caso, os dados que vamos utilizar, estão na tabela datasus, por isso forneço ao argumento data o nome dessa tabela. Ao rodar o código logo abaixo, você vai perceber que ele gera apenas um quadro cinza vazio. Isso ocorre porque definimos apenas uma das camadas essenciais para compor o gráfico, que são os dados utilizados. Temos que definir outras duas, para completarmos base de um gráfico, por isso, vamos passar agora para o aesthetic mapping.","code":"\nlibrary(readr)\n\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo <- \"datasus.csv\"\n\ndatasus <- read_csv2(paste0(github, pasta, arquivo))## i Using '\\',\\'' as decimal and '\\'.\\'' as grouping mark. Use `read_delim()` for more control.## \n## -- Column specification ---------------------------------------------------\n## cols(\n##   `Faixa etaria` = col_character(),\n##   Genero = col_character(),\n##   Cor = col_character(),\n##   `Nome UF` = col_character(),\n##   UF = col_character(),\n##   Contagem = col_double()\n## )\ndatasus## # A tibble: 1,836 x 6\n##    `Faixa etaria` Genero    Cor      `Nome UF` UF    Contagem\n##    <chr>          <chr>     <chr>    <chr>     <chr>    <dbl>\n##  1 10 a 14        Feminino  Parda    Acre      AC           4\n##  2 10 a 14        Masculino Parda    Acre      AC           4\n##  3 15 a 19        Feminino  Branca   Acre      AC           2\n##  4 15 a 19        Feminino  Parda    Acre      AC           4\n##  5 15 a 19        Masculino Branca   Acre      AC           6\n##  6 15 a 19        Masculino Parda    Acre      AC          65\n##  7 15 a 19        Masculino Preta    Acre      AC           1\n##  8 20 a 24        Feminino  Indígena Acre      AC           1\n##  9 20 a 24        Feminino  Parda    Acre      AC           4\n## 10 20 a 24        Masculino Branca   Acre      AC           7\n## # ... with 1,826 more rows\nggplot(data = datasus)"},{"path":"visualização-de-dados-com-ggplot2.html","id":"mapeamento-de-variáveis-aesthetic-mapping","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.3.2 Mapeamento de variáveis (Aesthetic Mapping)","text":"O aesthetic mapping representa o mapeamento, ou conexão de variáveis em sua tabela (ou sua base de dados), com os componentes estéticos e visuais gráfico. Nós controlamos esse mapeamento através da função aes(). Há diversos desses componentes visuais que compõe um gráfico, e os primeiros que vêm sua mente, são provavelmente cores e formas geométricas. Mas também os próprios eixos, ou melhor dizendo, escalas utilizadas nos eixos, são componentes visuais gráfico. Pois essas escalas definem como formas geométricas vão se posicionar dentro espaço gráfico.Pense por exemplo, globo terrestre. Você pode representar esse globo dentro ggplot, mas para que os formatos sejam corretamente posicionados em um “globo,” você precisa usar uma escala e um sistema de coordenadas diferentes plano cartesiano. Um outro exemplo, seria o gráfico de pizza. Ao pesquisar sobre, você irá perceber que um gráfico de pizza ggplot, é feito partir formato geométrico de barras (geom_bar()). Ou seja, um gráfico de barras, é o ponto de partida para gerar um gráfico de pizza ggplot, e o que diferencia esses dois gráficos, é escala usada. Em um gráfico de pizza, utilizamos uma coordenada circular, chamada de coordenada polar, ao invés plano cartesiano.Agora, vamos continuar montando nosso gráfico. Primeiro, vamos tentar montar um gráfico de barras, que mostre distribuição total de mortes ao longo das faixas etárias país, baseado nos dados apresentados na tabela datasus. Tendo isso em mente, o número de mortes, deve ficar eixo y de nosso gráfico, enquanto os grupos (faixas etárias), devem ficar eixo x.Essa é base nosso mapeamento de variáveis. Estamos definindo que o número de mortes deve ficar eixo y, e faixas etárias eixo x, e nós concedemos essa descrição ao ggplot, dentro da função aes() (abreviação para aesthetic mapping). Dessa vez, ao rodar o código abaixo você vai perceber que um plano cartesiano foi montado, onde temos uma escala para faixa etária eixo x, e outra escala para o total de mortes eixo y. Porém, esse plano cartesiano continua vazio, pois ainda não definimos última camada essencial gráfico, que é forma geométrica que deve representar os nossos dados.Portanto, vamos adicionar ao nosso código, nossa primeira função geom. Cada função geom, se refere um formato geométrico diferente. nosso caso, queremos um gráfico de barras, que é formado pela função geom_bar(). O padrão dessa função (ou formato geométrico) ggplot, é calcular uma contagem dos dados. Em outras palavras, o gráfico de barras ggplot, se comporta inicialmente (por padrão) como um histograma. Ao invés de calcular soma total de certa variável, ele irá contar, quantas vezes cada valor ocorre naquela variável dentro da base de dados.Entretanto, não queremos uma contagem dos dados, pois coluna Contagem já representa uma contagem em si. O que queremos é soma total dessa contagem em cada faixa etária. Por isso, ao invés de fornecer Contagem ao argumento y, eu defino essa coluna para o argumento weight. Todas funções que adicionarmos às várias camadas nosso gráfico, devem ser conectadas por um sinal de +, por isso lembre-se de colocar esse sinal sempre que adicionar uma nova função ao seu gráfico.Agora que definimos três camadas essenciais (dados, aesthethic mapping e geom), temos enfim o nosso primeiro gráfico montado. Há várias coisas que poderíamos fazer partir daqui. Podemos por exemplo, colorir barras de acordo com participação sexo número de mortes. Ou seja, essas cores irão representar em cada barra, o número de mortes que correspondem ao sexo masculino e ao sexo feminino. Por padrão, o geom_bar() empilha esses agrupamentos um em cima outro. Dessa forma, essas cores não apenas nos apresenta o número de mortes em cada sexo, mas indiretamente, elas também nos mostra o quanto que aquele grupo representa (qual sua porcentagem) total de mortes naquela faixa etária.Desta maneira, estamos definindo um outro componente visual gráfico (cores das barras) à uma outra variável de nossos dados (coluna Genero). Logo, estamos falando novamente aesthethic mapping gráfico, e por isso, devemos definir essa ligação dentro da função aes(). Há duas formas de você colorir formas geométricas ggplot, que dependem da forma geométrica e resultado que você quer atingir. Uma barra (ou retângulo), é tratada como uma forma geométrica de área, enquanto outras formas (como pontos e linhas) são tratadas de uma maneira diferente. Nesses formatos de área, você deve utilizar o argumento fill, para preencher o interior deste formato de uma cor.Conseguimos colorir barras, e podemos ver que uma parte muito pequena das mortes correspondem ao sexo feminino, em todas faixas etárias. Agora, e se mudássemos variável de grupos (faixas etárias) nosso gráfico? Vamos conectar uma variável diferente ao eixo x, por exemplo, cor de pele. Perceba, que o restante aesthetic mapping continua o mesmo, e portanto, o gráfico mantém essas outras “conexões” enquanto modifica variável ligada ao eixo x.Como disse anteriormente, há outros componentes visuais que você pode ligar às variáveis de sua tabela de dados. Você pode por exemplo, em alguns geom’s, conectar o formato desse geom uma variável. Eu sei, sua cabeça provavelmente deu uma volta com esse exemplo: “Como assim? Eu posso variar o formato de uma forma geométrica ao longo gráfico?” Na seção 8.4 dou um exemplo dessa estratégia.","code":"\nggplot(\n  data = datasus,\n  mapping = aes(x = `Faixa etaria`, y = Contagem)\n)\nggplot(\n    data = datasus,\n    mapping = aes(x = `Faixa etaria`, weight = Contagem)\n  ) +\n  geom_bar()\nggplot(\n    data = datasus,\n    mapping = aes(\n      x = `Faixa etaria`,\n      weight = Contagem,\n      fill = Genero\n    )\n  ) +\n  geom_bar()\nggplot(\n    data = datasus,\n    mapping = aes(\n      x = Cor,\n      weight = Contagem,\n      fill = Genero\n    )\n  ) +\n  geom_bar()"},{"path":"visualização-de-dados-com-ggplot2.html","id":"formatos-geométricos---funções-geom","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.3.3 Formatos geométricos - funções geom","text":"Cada função geom utiliza um formato geométrico e uma forma de desenho diferentes, para desenhar e representar os seus dados. ggplot há vários geom’s distintos que você pode utilizar. Abaixo estou listando os geom’s mais comuns, mas basta consultar o painel de dicas RStudio21, ou o site oficial de referências pacote22, que você ficará um pouco perdido com tantas opções. Um excelente repositório, com ótimos exemplos de gráficos dos quais você pode tirar inspirações de como e onde utilizar cada geom, é o R Graph Gallery23.geom_bar(): desenha um gráfico de barras.geom_bar(): desenha um gráfico de barras.geom_point(): desenha um gráfico de pontos (ou um gráfico de dispersão).geom_point(): desenha um gráfico de pontos (ou um gráfico de dispersão).geom_line(): desenha um gráfico de linha.geom_line(): desenha um gráfico de linha.geom_boxplot(): desenha um gráfico de boxplot.geom_boxplot(): desenha um gráfico de boxplot.geom_histogram(): desenha um histograma.geom_histogram(): desenha um histograma.geom_sf(): desenha um mapa (geom para dados espaciais).geom_sf(): desenha um mapa (geom para dados espaciais).geom_smooth(): desenha uma linha de média condicional (muito utilizado para desenhar linhas que representam modelos de regressão linear e de outros modelos econométricos).geom_smooth(): desenha uma linha de média condicional (muito utilizado para desenhar linhas que representam modelos de regressão linear e de outros modelos econométricos).geom_text(): utilizado para inserir texto.geom_text(): utilizado para inserir texto.geom_label(): utilizado para inserir rótulos, ou basicamente, textos envoltos por uma caixa.geom_label(): utilizado para inserir rótulos, ou basicamente, textos envoltos por uma caixa.Por exemplo, um gráfico de barras, é geralmente utilizado para apresentar estatísticas descritivas dos nossos dados. Ou seja, esse tipo de gráfico (por padrão) tenta resumir características dos seus dados em poucos números (médias, totais, contagens). Já um gráfico de dispersão (por padrão) nos apresenta diretamente os dados, de forma crua plano cartesiano. Isto é, diferentes geom’s vão tratar (e principalmente, representar) os seus dados de formas distintas. Vamos por exemplo, adicionar pontos ao nosso gráfico anterior, com o geom_point().Para facilitar visualização, eu limitei os valores eixo y gráfico (para o intervalo de 0 1500) por meio da função lims(). Dessa forma, estamos dando um zoom em uma área específica gráfico. Repare que cada ponto representa uma das observações encontradas na nossa base, e que vários deles estão se sobrepondo.Ao substituírmos barras por boxplot’s produzimos um gráfico que além de mostrar todas observações da base com o geom_point(), ele também mostra como distribuição de ambos os sexos se encaixam ao longo alcance (ou range) desses dados. Podemos perceber que nos indivíduos de cor parda, maior contagem para o sexo feminino em toda base, atinge em torno de 175 mortes, enquanto para o sexo masculino, esses valores podem atingir mais de 1000 mortes, apesar de que ambos os valores são outliers em suas respectivas distribuições.Uma outra forma de visualizarmos diferença entre homens e mulheres nesses dados, seria utilizando geom’s de erro, como linhas de alcance. Os geom’s de erro são muito úteis para visualizar medidas de variação ao longo dos grupos. O geom_ribbon() por exemplo, é utilizado em gráficos de séries temporais, para desenhar os intervalos de confiança ou desvios padrão ao redor da linha que representa série. nosso caso, iremos utilizar o geom_linerange(), para desenharmos diferença média entre o número de mortes entre os dois gêneros.O que o geom_linerange() faz é desenhar uma reta de um ponto um ponto B. ideia por traz desse geom é desenharmos um linha que representa (pelo seu comprimento), por exemplo, o desvio padrão de uma variável, ou nosso caso, diferença na média de vítimas de homicídios dolosos entre dois gêneros. Isto significa que temos dois novos componentes visuais que podemos controlar gráfico através aesthetic mapping, que são coordenadas ponto e ponto B. Esses componentes (pontos e B) representam os “limites” (máximo e mínimo) dessa linha, por isso, são controlados pelos argumentos ymax e ymin dentro da função aes(). Há outros geom’s que podem ser controlados por esses argumentos, porém os que vimos anteriormente (geom_point() e geom_bar()) não possuem esses argumentos.Primeiro, precisamos calcular o número médio de mortes de cada gênero e em cada cor de pele, e em seguida, modificar estrutura da tabela, para que possamos mapear os limites (ymin e ymax) linerange de acordo com o sexo. Para isso utilizo funções pacote dplyr, portanto lembre-se de chamar por esse pacote com library(), para ter acesso essas funções. Perceba também que eu inverti o plano cartesiano, utilizando função coord_flip().Agora, muitas coisas estão ocorrendo neste gráfico. Primeiro, o geom_linerange() constrói uma linha para cada cor de pele, que vai da média de mortes sexo feminino até média sexo masculino. Segundo, dois geom_point() são utilizados, onde cada um deles fica responsável por um dos sexos, e desenha um único ponto para cada cor de pele que indica média de mortes para o sexo correspondente. Em seguida, eu uso coord_flip() para inverter o plano cartesiano. Ou seja, variável que estava eixo y (média de mortes) vai para o eixo x, e variável que estava eixo x (cor de pele) vai para o eixo y.Certamente, esse gráfico dá um pouco mais de trabalho de construir. Porém, é uma forma mais simples de se mostrar essa diferença, e com isso, você consegue atingir um público maior. Pode ser que o seu leitor não saiba o que é um boxplot, e há razões razoáveis para se acreditar nisso. Brasil, o boxplot não é comumente tratado ensino básico, e sim ensino superior, e mais especificamente, em cursos que sejam da área de exatas, ou que possuam matérias de estatística na grade curricular. Nós sabemos também que o acesso da população brasileira ao ensino superior é restrito, sendo considerado um local de “elitismo.”Por outro lado, os alunos em geral veêm principais medidas estatísticas de posição central (média, mediana e moda) já ensino básico, e alguns chegam revê-las ensino superior. Logo, chances de seu leitor compreender mensagem que você quer passar: “em média, os homens são principais vítimas de homicídios dolosos, entretanto, nas populações indígenas e de cor de pele amarela, esse padrão não parece ser significativo” são maiores. Essa consideração pode ter menor peso depender de qual seja o público que você busca atingir. Se você está publicando um artigo científico em sua área, é bem provável que os potenciais leitores deste material conheçam um boxplot, e portanto, saibam interpretá-lo corretamente.","code":"\nggplot(\n    data = datasus,\n    mapping = aes(\n      x = Cor,\n      weight = Contagem,\n      fill = Genero\n    )\n  ) +\n  geom_bar() +\n  geom_point(aes(y = Contagem)) +\n  lims(y = c(0,1500))## Warning: Removed 6 rows containing missing values (geom_bar).\nggplot(\n    data = datasus,\n    mapping = aes(\n      x = Cor,\n      y = Contagem,\n      fill = Genero\n    )\n  ) +\n  geom_boxplot() +\n  geom_point()\ndatasus_agrup <- datasus %>% \n  group_by(Cor, Genero) %>% \n  summarise(Media = mean(Contagem)) %>% \n  pivot_wider(\n    id_cols = c(\"Cor\", \"Genero\"),\n    names_from = \"Genero\",\n    values_from = \"Media\"\n  )## `summarise()` has grouped output by 'Cor'. You can override using the `.groups` argument.\nggplot(\n    data = datasus_agrup,\n    aes(x = Cor)\n  ) +\n  geom_linerange(aes(ymax = Masculino, ymin = Feminino)) +\n  geom_point(aes(y = Feminino, color = \"Feminino\")) +\n  geom_point(aes(y = Masculino, color = \"Masculino\")) +\n  coord_flip()"},{"path":"visualização-de-dados-com-ggplot2.html","id":"uma-outra-forma-de-se-compreender-o-aesthetic-mapping","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.4 Uma outra forma de se compreender o aesthetic mapping","text":"Nas seções anteriores, eu defini o aesthetic mapping, como conexão entre variáveis de sua tabela, com os componentes visuais de seu gráfico. Porém, temos uma outra forma útil de enxergarmos esse sistema. Podemos entender o aesthetic mapping, como um mecanismo para determinarmos quais componentes visuais vão variar, e quais vão permanecer constantes ao longo gráfico. Ou seja, se você está definindo, por exemplo, cores da forma geométrica (geom) que representa os seus dados, você pode utilizar o aesthetic mapping para definir se e como essas cores vão variar ao longo gráfico.Por exemplo, vamos voltar ao gráfico de barras que montamos na seção 8.3, que mostra o número total de mortes ao longo das diferentes cores de pele e genêro da base. Perceba, que cor está variando dentro de cada barra (e não entre cada uma delas), de acordo com variável Genero.Nós podemos modificar forma como essas cores variam dentro de cada barra, ao mudarmos variável que define essa variação. Em outras palavras, podemos alterar o comportamento das cores, ao conectar esse componente em aes(), uma outra variável de nossa tabela. Como exemplo, podemos atribuir às UF’s da base. Perceba que temos agora, uma variação muito maior de cores dentro de cada barra.Nós podemos ainda, atribuir mesma variável alocada eixo x para definir variação dessas cores ao longo gráfico. Dessa forma, temos um gráfico onde cada uma das barras terá sua própria cor. Isso não é particularmente útil, mas talvez você deseja ter uma cor separada para cada barra, e caso você esteja com preguiça de pensar e definir quais cores serão essas, deixar essa tarefa nas mãos próprio ggplot é uma solução e um atalho simples para atingir um bom resultado.Portanto, ao conectarmos diferentes variáveis com o argumento (fill) em aes(), que define como cores de cada barra são compostas, podemos modificar forma como essas cores variam ao longo gráfico. Mas e se nós quisermos manter uma única cor para essas barras, ou seja, e se é de seu desejo manter cores constantes ao longo de todo o gráfico? Para isso, basta que você defina essas cores, fora de aes().Em outras palavras, função aes() trabalha com variáveis, ou atributos de suas observações que tendem variar ao longo de sua base. Quando você estiver trabalhando com valores constantes, ou com atributos que possuem um único valor possível ao longo de toda sua base, função aes() provavelmente não será o lugar ideal para trabalharmos com tais valores.Por exemplo, o R possui diversas cores pré-programadas em seu sistema, e sempre que você quiser acessar essas cores ao longo ggplot, você pode se referir elas, através de seus nomes registrados. Caso queira uma lista com os nomes dessas cores pré-programadas, você pode utilizar função colors(). Dentre essas diversas cores, temos uma chamada de steelblue. Logo, caso eu queira que todas barras meu gráfico estejam coloridas de acordo com essa cor, eu preciso fornecer o nome dessa cor ao argumento fill, de fora da função aes().Portanto, você pode aplicar essa metodologia para qualquer outro componente visual de seu gráfico que pode ser definido. Ou seja, se você deseja manter algum dos componentes visuais, definidos por um dos argumentos de aes() (fill, color, size, fontface, linetype, shape, etc.), constantes, você precisa apenas definir esses argumentos fora de aes(). Por outro lado, caso você queira controlar forma como algum desses componentes visuais variam ao longo gráfico, você precisa definir esses argumentos dentro de aes().Porém, você talvez se pergunte: o que ocorre se eu fornecer cor steelblue dentro de aes()? Será que o ggplot reconhece que queremos aplicar essa cor sobre formas geométricas gráfico? resposta curta é não, mas o resultado em geral é um pouco estranho, ou mínimo algo inesperado. Pois em um caso como esse, função aes() irá entender que você deseja colorir barras gráfico, de acordo com uma nova variável em sua tabela, chamada fill, e que possui um único valor possível ao longo da base, mais especificamente, o texto steelblue.Esse comportamento ocorre sempre que você fornece um valor em texto (um string) à algum argumento de aes(). Em uma situação como essa, o ggplot() parece criar uma nova variável em sua tabela chamada fill, e que contém o valor em texto que você forneceu esse argumento. Isso não necessariamente é um comportamento inadequado, mas ele certamente surpreende alguns usuários, e como ele tem se mantido ao longo das últimas versões ggplot, é possível que ele continue funcionar dessa forma, por um bom tempo.","code":"\ndatasus %>% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem, fill = Genero)\n  )\ndatasus %>% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem, fill = UF)\n  )\ndatasus %>% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem, fill = Cor)\n  )\ndatasus %>% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem),\n    fill = \"steelblue\"\n  )\ndatasus %>% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor, weight = Contagem, fill = \"steelblue\")\n  )"},{"path":"visualização-de-dados-com-ggplot2.html","id":"sobrepondo-o-aesthetic-mapping-inicial-em-diversas-camadas","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.5 Sobrepondo o aesthetic mapping inicial em diversas camadas","text":"Agora, vou explicar em maiores detalhes qual é diferença entre: preenchermos os argumentos de data e mapping já na função inicial gráfico (ggplot()), e de preenchê-los nas funções geom.Para isso, vamos usar outros dados. Na tabela PIB eu possuo uma série histórica mensal índice de faturamento real da indústria (Faturamento_indus), da porcentagem PIB que representa dívida pública líquida (Divida_liq_perc), e média mensal da taxa de investimento produtivo (taxa de formação bruta de capital fixo - FBCF) na economia brasileira, além de dados de PIB, coletados IPEAData24.Na seção 8.3, expliquei que ao preencher os argumentos já ggplot() você estaria pedindo ao programa, que utilize mesma base de dados e/ou o mesmo aesthetic mapping ao longo de todas camadas gráfico. Como exemplo, veja o que acontece gráfico abaixo.Como o geom_bar() busca resumir os nossos dados em poucas estatísticas, eu coloquei dessa vez o valor “identity” argumento stat. Isso impede que ele agrupe os dados em alguma medida estatística, fazendo com que o geom apenas identifique os valores que aparecem na base, da mesma forma que um geom_point() faria. Perceba também, que eu estou utilizando três geom’s diferentes gráfico. Mas como eu não defini um aesthetic mapping específico em cada um deles, todos esses geom’s estão mostrando exatamente mesma informação. Dito de outra forma, estes geom’s estão utilizando o mesmo aesthetic mapping, o qual definimos na função ggplot().Você deve estar pensando: “Ok, mas isso não faz sentido! Por que eu usaria três geom’s diferentes para uma mesma informação?” Bem, pode ser que você queira utilizar mais de um geom que mostre mesma informação, por questões estéticas gráfico. Um exemplo simples, seria marcar borda de uma linha criada por geom_line(). Ou seja, não há uma forma direta e simples em geom_line() (algo que já é possível de ser feito geom_point()), de pintar essas bordas de uma cor mais escura (ou clara) que o interior da linha, dando assim uma maior ênfase para aquela linha. Portanto, ideia seria criarmos duas camadas de geom_line(): uma interna, com uma linha mais estreita e de cor mais clara (ou mais escura); e uma externa, com uma linha mais larga (de forma que ela “transborde” para fora da linha interna) e de cor mais escura (ou mais clara).De qualquer maneira, esses geom’s não fazem muito sentido da forma como estão dispostos momento, portanto, vamos mudar de estratégia. Por que não utilizamos um só geom para nos apresentar três informações diferentes?! Para isso, temos que modificar nossa base levemente. O objetivo é pegar três colunas com variáveis que vamos plotar (Faturamento_indus, FBCF e Divida_liq_perc), e agrupá-las em duas colunas: uma com os valores dessas variáveis, e outra coluna com os nomes dessas variáveis, para identificar qual variável o valor na primeira coluna se refere. Realizamos esse trabalho pela função pivot_longer().Novamente, como não incluímos uma função aes(), ou definimos o argumento data dentro geom_line(), ele irá utilizar o data e o aesthetic mapping (aes()) que definimos em ggplot(). Lembra de quando eu disse que você poderia controlar o formato de um geom de acordo com uma variável? O gráfico acima é um exemplo prático disso. Estamos utilizando apenas um geom para mostrar três informações diferentes, e o componente estético que utilizamos para diferenciar essas informações gráfico, é o formato dessas linhas. Portanto, ao definirmos o componente linetype para Nome_variavel, estamos modificando o formato da linha (tracejada ou sólida), de acordo com os valores dessa variavel. Poderíamos usar mesma estratégia em geom_point(), ao definirmos o argumento shape para Nome_variavel. O resultado, seria um gráfico com pontos de três formatos diferentes (triângulos, quadrados e pontos comuns).Entretanto, para utilizarmos essa estratégia, nós tivemos que reestruturar nossa base de dados pela função pivot_longer(). E se você não quisesse modificar essa base? Infelizmente, sem essa modificação, não poderíamos mostrar três variáveis utilizando apenas uma função geom, mas poderíamos realizar o mesmo trabalho com uma função geom para cada variável. Neste caso, teremos que utilizar um aesthetic mapping diferente para cada geom, pois cada um deles, ficará responsável por mostrar os valores de uma variável diferente.primeiro gráfico dessa seção, utilizamos três geom’s diferentes para mostrar uma mesma informação. Se você comparar o código desse primeiro gráfico, ao código gráfico abaixo, você perceberá que eles são quase idênticos, o que mudou, é presença da função aes() nos dois últimos geom’s.O único geom que não possui uma função aes() definida, é o geom_bar(), logo, esse geom vai seguir o aesthetic mapping que definimos em ggplot(). Já os outros dois geom’s, vão seguir o aesthetic mapping que definimos em seus respectivos aes(). Porém, repare que em ambos geom’s, eu apenas defini variável mapeada para o eixo y, não cheguei definir uma nova variável para o eixo x. Quando isso ocorre, função irá novamente recorrer ao aesthetic mapping que você definiu em ggplot(). Ou seja, como não definimos uma nova variável para o eixo x, todos os geom’s gráfico acabam utilizando variável eixo x definida em ggplot().Portanto, você pode sobrepor por completo, ou parcialmente, o aesthetic mapping definido em ggplot() em cada geom, basta omitir os termos dos quais você não deseja sobrepor na nova função aes(). Um outro detalhe, é que não chegamos definir em nenhum momento, um novo valor para o argumento data em algum geom. Logo, apesar de estarmos utilizando diferentes aesthetic mappings, todos os geom’s estão utilizando mesma base de dados.","code":"\nPIB## # A tibble: 184 x 6\n##    Data           PIB PIB_acumulado Divida_liq_perc  FBCF Faturamento_indus\n##    <date>       <dbl>         <dbl>           <dbl> <dbl>             <dbl>\n##  1 2005-01-01 163540.         100              42.3 103.              102. \n##  2 2005-02-01 160702.          98.3            42.7  99.1              98.9\n##  3 2005-03-01 175469.         107.             43.1 112.               98.3\n##  4 2005-04-01 177179          108.             42.5 108.              107. \n##  5 2005-05-01 177497.         109.             42.4 113.              100. \n##  6 2005-06-01 180882.         111.             42.8 115.              104. \n##  7 2005-07-01 184074.         113.             43.2 111.               99.8\n##  8 2005-08-01 187247.         114.             43.2 120.               97  \n##  9 2005-09-01 181539.         111.             43.2 115.               96.1\n## 10 2005-10-01 189183          116.             43.6 110.               95.8\n## # ... with 174 more rows\nggplot(\n  data = PIB,\n  aes(x = Data, y = Faturamento_indus)\n  ) +\n  geom_bar(stat = \"identity\", fill = \"darkgray\") +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"red\")\nPIB_remodelado <- PIB %>% \n  select(Data, Faturamento_indus, FBCF, Divida_liq_perc) %>% \n  pivot_longer(\n    cols = c(\"Faturamento_indus\", \"FBCF\", \"Divida_liq_perc\"),\n    names_to = \"Nome_variavel\",\n    values_to = \"Valor\"\n  )\n\nggplot(\n  data = PIB_remodelado,\n  aes(x = Data, y = Valor, linetype = Nome_variavel)\n  ) +\n  geom_line() \nggplot(\n  data = PIB,\n  aes(x = Data, y = Faturamento_indus)\n  ) +\n  geom_bar(stat = \"identity\", fill = \"darkgray\") +\n  geom_line(aes(y = FBCF), color = \"blue\") +\n  geom_line(aes(y = Divida_liq_perc), color = \"red\")"},{"path":"visualização-de-dados-com-ggplot2.html","id":"resumo-da-estrutura-básica-de-um-gráfico-ggplot","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.5.1 Resumo da estrutura básica de um gráfico ggplot()","text":"Em resumo, todo gráfico ggplot() possui três camadas essenciais, que formam base gráfico: 1) data, base (ou bases) de dados utilizada gráfico em questão; 2) aesthetic mapping, o mapeamento, ou ligação de variáveis presentes na base de dados, para componentes estéticos e visuais gráfico; 3) geom, forma geométrica (retângulos, pontos, polígonos, linhas, etc) que irá representar os seus dados gráfico.Para construir um gráfico ggplot(), você deve sempre definir esses componentes. Os dois primeiros (data e aesthetic mapping), podem ser definidas dentro da função ggplot(), já o terceiro (geom), você define ao utilizar uma (ou várias) das funções geom, em uma (ou em várias) das camadas gráfico. Com isso, temos uma estrutura básica como definida abaixo, para construirmos um gráfico ggplot:Lembre-se que essa é apenas uma estrutura básica. Como mostramos na seção 8.4, podemos sobrepor de diversas formas essa estrutura. E podemos definir diversos outros parâmetros sobre essa estrutura como foi mostrado ao longo capítulo.","code":"ggplot(\n  data = <sua base de dados>,\n  aes(<aesthetic mapping>)\n  ) +\n  <geom_...> #uma função geom a seu gosto"},{"path":"visualização-de-dados-com-ggplot2.html","id":"uma-discussão-sobre-os-principais-geoms","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.6 Uma discussão sobre os principais geom’s","text":"Nas próximas seções vamos descrever rapidamente como grande parte dos principais geom’s se comportam, e quais são os argumentos (ou os componentes estéticos) que podemos controlar através da função aes(). Dessa forma, você pode rapidamente se familiarizar com esses geom’s, adquirindo um vocabulário das funções que os representam, e que cobrem maior parte dos gráficos realizados dia--dia.Lembre-se que há várias funções geom diferentes, das quais muitas não serão descritas aqui. Muitas deles utilizam o mesmo formato geométrico (linhas, retângulos, …), mas desenham esse formato de uma maneira diferente, além de possuírem outros componentes estéticos que podem ser controlados pelo aesthetic mapping gráfico.Caso você não encontre aqui, o formato geométrico que está procurando, ou função geom que realiza o desenho da forma como você deseja, você pode consultar página oficial pacote25. página não possui uma versão em português, porém, você deve se virar razoavelmente bem com ferramentas de tradução (como o Google Tradutor) nessas situações. Se isso não suficiente, você talvez encontre suas dúvidas em outros materiais construídos por brasileiros, como o blog Curso R26, o material departamento de Estatística da UFPR27, ou dentro de alguma pergunta postada na página em português StackOverflow28. O R Graph Gallery29 é um repositório (em inglês) que possui exemplos dos mais diversos geom’s, e que serve como referência perfeita para os momentos em que você não lembra qual o geom que desenha o tipo de gráfico que procura.","code":""},{"path":"visualização-de-dados-com-ggplot2.html","id":"gráficos-de-dispersão-e-gráficos-de-bolha","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.6.1 Gráficos de dispersão e gráficos de bolha","text":"Gráficos de dispersão são formados por geom_point(). Esse geom (por padrão) não transforma os seus dados, ou em outras palavras, ele não busca resumí-los de alguma maneira. Cada ponto desenhado plano cartesiano representa cada uma das linhas presentes em sua base de dados. Os geoms que possuem este comportamento, são comumente chamados de geom’s individuais. Por este padrão, você deve obrigatoriamente definir variáveis de ambos os eixos (x e y), neste geom.Nos exemplos abaixo, estou utilizando tabela mpg que vêm junto ggplot, e nos apresenta dados de consumo de combustível de diversos modelos de carro, para mais detalhes desses dados, execute ?mpg console. Os gráficos nos mostram uma relação aparentemente negativa entre volume ocupado pelos pistões motor (displ), e quilometragem por litro de gasolina (hwy).Após definir os eixos, você pode pintar os pontos de acordo com uma terceira variável, por exemplo, classe carro (compacto, SUV, minivan, …), através argumento color. classe carro é uma variável categórica, e por isso, o ggplot() irá buscar cores contranstantes para pintar os pontos. Mas você também pode definir uma variável contínua este argumento, onde neste caso, o ggplot() irá criar um gradiente de cores para pintar os pontos. Uma outra posibilidade deste geom, é variar o formato dos pontos através argumento shape.partir de geom_point() você também pode construir um gráfico de bolha, através argumento size. Este tipo de gráfico em geral, piora o overplotting, ou sobreposição dos pontos, já que alguns ficam muito grandes. Nestas situações, o argumento alpha é bem útil, sendo ele definido por um número de 0 1, indicando uma porcentagem de opacidade geom. Por padrão, ele é setado para 1 (100%), já exemplo, eu reduzo essa opacidade para 40%.Você pode se aproveitar componente shape para diferenciar, ou destacar bordas dos pontos, ao escolher o shape 21. Este método é esteticamente atraente, e fica muito bom em conjunto com linhas. Dessa forma, você pode pintar o interior dos pontos de uma cor, utilizando fill, e borda desse ponto de outra cor, utilizando color. Lembre-se que isso só é possível, pelo shape que escolhemos para estes pontos, em outras situações, você poderá colorir pontos apenas com uma cor, utilizando o color. exemplo abaixo, eu deixo todos os três argumentos de fora de aes(), dessa forma, o ggplot mantém os valores que dei cada um deles, constantes ao longo de todo o gráfico.","code":"\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy))\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy, color = class))\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy, color = class, shape = drv))\nggplot(data = mpg) +\n  geom_point(aes(x = displ, y = hwy, size = cyl), alpha = 0.4)\nggplot(data = mpg) +\n  geom_point(\n    aes(x = displ, y = hwy),\n    shape = 21,\n    color = \"black\",\n    fill = \"steelblue\"\n  )"},{"path":"visualização-de-dados-com-ggplot2.html","id":"gráficos-de-barra","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.6.2 Gráficos de barra","text":"Como descrevi anteriormente, os gráficos de barras ggplot() são formados pelo geom_bar(), e em geral, são utilizados para apresentar estatísticas que resumem os dados em poucos números (como totais, médias, medianas). Em outras palavras, os geom’s que tem este comportamento, buscam representar várias observações de sua base, com um único formato geométrico, e são comumente chamados de geom’s coletivos. Por essa razão, o argumento stat é importante neste geom, pois nele você pode conceder o valor identity, que evita este comportamento, e faz com que o geom apenas identifique os valores que você fornece ele.ggplot, este geom foi criado com o intuito de permitir que o usuário construa rapidamente gráficos de contagens e somatórios. Portanto, este geom possui mecanismos para calcular essas estatísticas, você não precisa calculá-las por conta própria antes de gerar o ggplot. Por padrão, este geom calcula inicialmente uma contagem dos seus dados. Logo, caso você não defina qual estatística que deseja mostrar, ele irá contar quantidade que cada valor aparece na base. Por exemplo, o gráfico abaixo nos mostra que dentro da tabela mpg, temos em torno de 80 modelos com motores de 4 ou 6 cilindradas, e menos de 10 modelos com 5 cilindradas.Tendo essas considerações em mente, você tem duas opções básicas ao lidar com este geom: 1) fornecer diretamente os dados, e pedir ao geom que calcule estatísticas que você deseja mostrar (contagem ou somatório); ou 2) você primeiro calcula estatísticas que deseja, e pede ao geom que apenas identifique, sem realizar nenhuma transformação desses dados. Caso opte pela opção 2, você deve tomar muito cuidado com o argumento stat = \"identity\", por razões que vou explicar abaixo.Este geom não possui um mecanismo próprio para calcular médias (e muitas outras estatísticas), e portanto, se você quiser mostrá-las utilizando este geom, você terá de calcular separadamente essas médias, e pedir ao geom que apenas identifique com stat = \"identity\".Porém, caso você queira calcular o total, ou o somatório em cada grupo, você pode apenas definir coluna com os valores serem somados, para o argumento weight dentro de aes().Agora, lembra quando eu disse que você pode pedir ao geom que apenas “identifique” os valores de sua base (com stat = \"identity\") ? Com este argumento, o geom_bar() irá ter um comportamento diferente, caso os valores em cada grupo não sejam únicos. exemplo anterior, em que calculei médias de cada cyl em mpg, o geom apenas identificou médias de cada cyl, pois há apenas uma única média para cada cyl. exemplo abaixo, estou criando rapidamente uma tabela, e nela você pode perceber que há dois valores para o grupo \"c\". Agora, repare o que acontece gráfico, o geom_bar() acaba somando estes valores.Em outras palavras, se os seus dados estiverem agrupados, o geom_bar() com stat = \"identity\" irá de fato apenas identificar estes valores. Mas caso os seus dados estiverem desagregados, com mais de um valor por grupo, o geom_bar() irá somar estes valores. Isso significa, que stat = \"identity\" representa uma outra alternativa (além de weight), para criar gráficos de somatório. Bastaria fornecer coluna com os valores serem somados para o eixo y em aes(), e adicionar stat = \"identity\" à geom_bar().Um outro ponto importante neste geom, é o posicionamento das barras. Por padrão, o geom empilha barras que ocupam o mesmo valor eixo x gráfico. Isso nos permite visualizarmos participação dos grupos de uma outra variável categórica (cor de pele, faixa etaria, …), em cada valor presente eixo x. Por outro lado, você talvez esteja interessado na diferença entre os grupos, e não sua participação. Logo, você talvez queira jogar essas barras uma lado da outra, e para isso você deve utilizar o argumento position, dando o valor “dodge”. exemplo abaixo, retorno base de dados datasus, com o objetivo de mostrar diferença em cada cor de pele, da média de vítimas para cada sexo.Portanto, caso você não definisse position para dodge, o ggplot iria empilhar essas barras (azul e vermelho) uma em cima da outra. Em um gráfico de médias como o acima, não faria muito sentido empilhar essas barras, porém, este posicionamento faz muito sentido em gráficos de somatório, como os que fizemos na seção 8.3. Pois dessa forma você consegue visualizar o quanto que cada grupo representa total.Você talvez queira ir um pouco além, e observar diferenças na participação de cada cor de pele, ao longo dos totais de vários grupos. Para isso, você pode dar o valor fill ao argumento position. Dessa forma, o ggplot calcula qual é proporção de cada grupo para cada valor eixo x, em uma escala de 0 1. Nesta situação, você deve definir variável eixo y, para o argumento weight em aes().","code":"\n  ggplot(\n    data = mpg,\n    aes(x = cyl)\n  ) +\n  geom_bar()\nmedias <- mpg %>% \n  group_by(cyl) %>% \n  summarise(media = mean(hwy))\n\n  ggplot(\n    data = medias,\n    aes(x = cyl, y = media)\n  ) +\n  geom_bar(stat = \"identity\")\n  ggplot(\n    data = mpg,\n    aes(x = cyl, weight = hwy)\n  ) +\n  geom_bar()\ntab <- data.frame(\n  grupo = c(\"a\",\"b\",\"c\",\"c\",\"d\"),\n  valor = c(1,2,3,2,2)\n)\n\nggplot(tab, aes(x = grupo, y = valor)) +\n  geom_bar(stat = \"identity\")\nmedias <- datasus %>% \n  group_by(Cor, Genero) %>% \n  summarise(media = mean(Contagem))## `summarise()` has grouped output by 'Cor'. You can override using the `.groups` argument.\n  ggplot(\n    data = medias,\n    aes(x = Cor, y = media, fill = Genero)\n  ) +\n  geom_bar(stat = \"identity\", position = \"dodge\") \n  ggplot(\n    data = datasus,\n    aes(x = `Faixa etaria`, weight = Contagem, fill = Cor)\n  ) +\n  geom_bar(position = \"fill\") "},{"path":"visualização-de-dados-com-ggplot2.html","id":"gráficos-de-linha","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.6.3 Gráficos de linha","text":"Gráficos de linha são muito utilizados em séries temporais, para mostrar evolução de algum índice ao longo tempo. Este tipo de gráfico é criado pelo geom_line(), que possui um comportamento de “conector.”O geom_line() (diferentemente de seu irmão geom_path()) sempre ordena os valores da base (antes de conectá-los), segundo variável alocada eixo x, na ordem que seja mais lógica para essa variável. Veja o exemplo abaixo, onde dou um vetor de datas (fora de ordem) para o eixo x. Independente da ordem em que os valores estiverem em sua base, função irá reordenar base antes de conectar os pontos.Isso significa, que este geom funciona com qualquer variável eixo x que possua uma ordem lógica, seja ela contínua ou categórica. Veja exemplo abaixo, onde eu substituo coluna dia, por um simples vetor de texto. Ao detectar o tipo de dado presente na coluna, função reordena os valores de acordo com ordem lógica para este tipo de dado (exemplo abaixo, ordem alfabética).Conhecer essa funcionalidade é importante, ao fornecer para o geom dados dos quais ele não consegue reconhecer o formato e ordem correta. Pense por exemplo, se você fornecesse uma vetor de datas, mas formato “Abril/2020.” Como os valores começam por um nome, ele reconhece estes valores como texto, e portanto, ordena-os em ordem alfabética, ao invés de ordená-los como meses ano. Nessas situações, transformar esses valores para fatores, e definir sua ordem em seu atributo levels, é melhor alternativa.Eu costumo aumentar grossura dessas linhas através argumento size, que por padrão está setado para 0.5. Geralmente 1 já é um bom nível para mim, mas você pode aumentar o quanto quiser. Como eu quero que grossura, permaneça constante ao longo de toda linha, eu mantenho o argumento size de fora aes(). Isso significa que você poderia variar essa grossura ao longo da linha, apesar de que o resultado seria um tanto esquisito. Tente por exemplo, adicionar ao aes() exemplo anterior, o valor size = valor, e veja o resultado.Neste geom, o argumento group em aes() é muito importante. Este argumento controla como o geom considera os grupos da base, na hora de desenhar o formato geométrico em questão. primeiro exemplo dessa seção, nós não utilizamos este argumento, pois variável ligado ao eixo x (dia) era uma variável contínua. Entretanto, instante em que mudamos os valores dessa coluna para texto, tivemos que adicionar um group = 1 ao aes(). Logo, quando você ligar uma variável contínua ao eixo x, muito provavelmente você não precisará mexer com o group. Caso variável seja categórica, é certo que algum valor deve ser dado ao argumento group.Isso é apenas uma simplificação, que serve como um guia inicial, mas que nem sempre se aplica. Pois o group não diz respeito ao tipo de variável (contínua ou categórica), e sim se você quer separar ou não linhas por algum agrupamento. Se você está apenas querendo mostrar uma única linha gráfico, essa simplificação será útil. Mas com o tempo você vai se pegar utilizando o group, para mostrar em um mesmo gráfico evolução de vários índices diferentes ao longo tempo, mesmo que variável eixo x (datas) seja uma variável contínua. Basta relembrar o exemplo da seção 8.4, em que utilizamos linetype para diferenciar curvas de três indicadores diferentes em um mesmo geom_line(). Você poderia replicar o mesmo gráfico utilizando group, ao invés linetype.Essa questão fica mais clara, ao utilizarmos uma base que possui mais de uma valor por grupo. Veja por exemplo base Oxboys, que vem pacote mlmRev. Essa base é resultado de uma pesquisa, onde os pesquisadores acompanharam durante vários anos, o crescimento de alguns indivíduos.Portanto, coluna Subject identifica qual o indivíduo os valores da linha se referem. Repare que várias linhas dizem respeito ao mesmo indivíduo. Agora, pense como o geom_line() trataria esses diversos valores que se encaixam mesmo grupo (nosso caso, mesmo Subject). Neste caso, o geom_line() irá conectar (incorretamente) todos os valores em conjunto da base, pois ele não sabe que cada um desses valores pertencem sujeitos diferentes, o geom pensa que todos esses valores pertencem um único sujeito. O resultado seria um gráfico com um aspecto de “serra.”Para que isso fique claro, eu adicionei um geom_point() para que você veja cada um dos valores presentes na base. Primeiro, preste atenção nas variáveis que conectamos aos eixos gráfico (idade e altura indivíduo). Ambas variáveis são contínuas, mas neste momento, não há qualquer variável gráfico que possa identificar qual dos indivíduos, cada um desses valores se refere. Logo, o geom_line() acaba conectando todos esses pontos juntos.Ao invés geom_line() conectar todos esses pontos em conjunto, o geom deveria conectar todos os pontos que dizem respeito ao mesmo indivíduo, e é para isso que o argumento group serve. Você define neste argumento, qual coluna que identifica qual é o grupo (ou nosso caso, o indivíduo) que está sendo tratado em cada observação de sua base de dados.Uma outra forma de definirmos esses grupos para o geom, é colorindo linhas com o argumento color, ou então variando o formato dessas linhas com o argumento linetype. Basta você fornecer estes argumentos, uma coluna que seja capaz de identificar cada um dos grupos ou indivíduos (nosso caso, Subject) que estão sendo tratados gráfico.Portanto, toda vez em que utilizar este geom em uma base que possui mais de um valor por grupo, você muito provavelmente terá de utilizar group, especialmente se você precisa diferenciar curvas de cada grupo gráfico.Se você quiser mostrar uma única linha gráfico, você vai mexer obrigatoriamente com o group caso variável eixo x seja categórica, onde neste caso, você deve dar uma constante qualquer ao argumento (eu geralmente defino para 1: aes(group = 1)). Isso é necessário, porque geom_line() entende que cada um dos valores dessa variável categórica, representa um grupo diferente. Dessa forma, cada um desses grupos irá possuir apenas um valor em toda base. Caso você se esqueça de definir este valor para group nesta situção, o seguinte erro irá aparecer:","code":"\ntab <- data.frame(\n  dia = as.Date(c(\"2020-01-01\",\"2020-01-04\",\"2020-01-02\",\"2020-01-03\")),\n  valor = c(10,27,14,23)\n)\n\nggplot(tab, aes(dia, valor)) + geom_line()\ntab$dia <- c(\"a\",\"c\",\"d\",\"b\")\n\nggplot(tab, aes(dia, valor, group = 1)) + geom_line()\ntab$dia <- c(\"Janeiro/2020\", \"Abril/2020\", \"Fevereiro/2020\", \"Março/2020\")\n\nordem <- c(\"Janeiro/2020\", \"Fevereiro/2020\", \"Março/2020\", \"Abril/2020\")\n\nggplot(\n    tab,\n    aes(factor(dia, levels = ordem), valor, group = 1)\n  ) +\n  geom_line()\nhead(mlmRev::Oxboys, n = 10)##    Subject     age height Occasion\n## 1        1 -1.0000  140.5        1\n## 2        1 -0.7479  143.4        2\n## 3        1 -0.4630  144.8        3\n## 4        1 -0.1643  147.1        4\n## 5        1 -0.0027  147.7        5\n## 6        1  0.2466  150.2        6\n## 7        1  0.5562  151.7        7\n## 8        1  0.7781  153.3        8\n## 9        1  0.9945  155.8        9\n## 10       2 -1.0000  136.9        1\nggplot(\n  Oxboys,\n  aes(x = age, y = height)\n) +\n  geom_line()\nggplot(\n  Oxboys,\n  aes(x = age, y = height)\n) +\n  geom_line() +\n  geom_point()\nggplot(\n  Oxboys,\n  aes(x = age, y = height, group = Subject)\n) +\n  geom_line() +\n  geom_point()\nggplot(\n  Oxboys,\n  aes(x = age, y = height, color = Subject)\n) +\n  geom_line()# Each group consists of only one observation. Do you need to adjust the group\n# aesthetic?"},{"path":"visualização-de-dados-com-ggplot2.html","id":"histogramas-e-outros-gráficos-de-frequência","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.6.4 Histogramas e outros gráficos de frequência","text":"Histogramas e polígonos de frequência são gráficos “unidimensionais,” ou dito de outra forma, apresentam informações sobre apenas uma variável, mais especificamente uma variável contínua. Por essa razão, você precisa definir apenas um dos eixos gráfico, geralmente, o eixo x. Estes gráficos são criados por geom_histogram() e geom_freqpoly().Ambos os gráficos funcionam da mesma forma, apenas forma geométrica utilizada é diferente. Eles pegam distribuição da variável ligada ao eixo x, e dividem essa distribuição em vários intervalos (chamados de bin’s), e contam quantos valores se encaixam em cada um destes intervalos. Neste geom, é importante que você teste diferentes larguras para estes intervalos, através argumento binwidth. Por padrão, o geom tenta dividir distribuição em 30 intervalos diferentes.Você pode separar distribuições por alguma variável categórica, dando essa variável ao argumento group. Porém, essas distribuições estarão sobrepostas gráfico, sendo impossível diferenciá-las. Logo, é necessário que você mostre essas distribuições separadas em diferentes facetas gráfico (através da função facet_wrap()).O geom_freqpoly() não sofre seriamente deste problema, pois sua forma geométrica é “oca.” Mas é interessante de qualquer forma, que você ou separe essas distribuições em diferentes facetas gráfico, ou então, que colora distribuições de acordo com variável categórica utilizada.Uma alternativa à estes geom’s, é o geom_density() que calcula uma função de densidade para variável escolhida. Caso esteja interessado em separar essa distribuição de acordo com uma variável categórica, eu recomendo que dê uma olhada pacote ggridges. Este pacote fornece novos geom’s, que posicionam essas distribuições separadas de uma forma esteticamente atraente, sem necessidade de construir diferentes facetas mesmo gráfico, além de fornecer mecanismos para marcar os percentis da distribuição gráfico. É mais fácil ver com seus próprios olhos,30 que eu explicar.Caso você prefira permanecer com o geom padrão ggplot e ainda separar distribuição por uma variável categórica, você pode utilizar o argumento alpha para reduzir opacidade dessas distribuições, como um meio de combater sobreposição. Mas o ideal, é que você separe em diferentes facetas, utilizando facet_wrap() da mesma forma que fizemos para os histogramas.","code":"\nggplot(mpg, aes(hwy)) + geom_histogram()## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nggplot(mpg, aes(hwy)) + geom_freqpoly()## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nggplot(mpg, aes(hwy, group = cyl)) +\n  geom_histogram() +\n  facet_wrap(~class)## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nggplot(mpg, aes(hwy, color = class)) +\n  geom_freqpoly() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nggplot(mpg, aes(hwy, fill = class)) +\n  geom_histogram() +\n  facet_wrap(~class)## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\nggplot(mpg, aes(hwy, fill = class)) + geom_density(alpha = 0.4)"},{"path":"visualização-de-dados-com-ggplot2.html","id":"adicionando-textos-ao-gráfico","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.6.5 Adicionando textos ao gráfico","text":"Você pode adicionar rótulos ao seu gráfico com geom_label(), ou adicionar textos simples com geom_text(). Estes geom’s funcionam exatamente como o geom_point(), porém, ao invés de desenharem pontos, eles desenham textos. Em outras palavras, eles são geom’s individuais, em que desenham um texto, ou um rótulo, para cada uma das observação de sua base de dados.Dessa vez, você deve definir coluna que contém os rótulos/textos que deseja mostrar gráfico, argumento label em aes(). Os rótulos serão posicionados plano cartesiano de acordo com os valores definidos pelas variáveis ligadas aos eixos x e y.Ao colocar textos em um gráfico, você dificilmente não enfrentará algum nível de sobreposição. O ggplot oferece algumas ferramentas que em muitas ocasiões não resolvem o problema, mas que em outras podem ser suficientes. Ambos os geom’s descritos aqui, possuem o argumento check_overlap. Caso ele seja configurado para TRUE, o ggplot irá criar os rótulos na ordem em que eles aparecem na sua base, e eliminar todos os rótulos consecutivos que sobreporem os anteriores. O código ficaria dessa forma:Apesar de uma solução, ela pode muito bem eliminar justamente os rótulos que queremos destacar gráfico, e por isso é pouco desejada. Você poderia também reduzir o tamanho da fonte através de size. Um detalhe é que este argumento trabalha por padrão com valores em milímetros (mm), mas como é um pouco confuso trabalhar com tamanho de fontes nesta unidade, eu geralmente transformo os valores para pontos (pt). exemplo abaixo, estou reduzindo o tamanho das fontes para 7 pt. O problema dessa opção, é que ela representa um trade-entre sobreposição de pontos, e legibilidade dos rótulos, cabe você definir o equilíbrio entre essas opções.melhor solução possível, seria ajustarmos posição de cada um dos pontos individualmente. Entretanto, se você tem vários textos que exigem desvios diferentes, essa solução facilmente se torna muito trabalhosa. ideia, seria criarmos duas novas colunas em nosso data.frame, onde em cada uma você define um valor de desvio vertical (y_desvio), e na outra o valor de desvio horizontal (x_desvio) para o rótulo definido naquela linha. Em seguida, você conecta essas colunas aos argumentos de posição responsáveis por realizar estes deslocamentos de textos (nudge_y e nudge_x) em seu aesthetic mapping (aes()). Veja o código abaixo.Vamos separar uma seção para descrevermos outras soluções mais eficazes para esse problema. Também vamos separar, uma seção para descrevermos quais são estratégias possíveis para você trocar fonte dos textos mostrados gráfico, algo que ainda é dificíl de ser realizado, especialmente se você trabalha Windows. Agora vou explicar o que os argumentos de posição (nudge_x e nudge_y), e os de justificação (hjust e vjust) fazem.Durante muito tempo, eu sofri de uma leve confusão entre esses argumentos. Como você muito provavelmente vai querer ajustar o posicionamento desses textos, vou tentar explicar diferença entre os dois da forma mais clara possível, para que você não sofra mesmo efeito.Vamos começar pelos argumentos de justificação, que são hjust (justificação horizontal) e vjust (justificação vertical). Estes argumentos, servem para alterar justificação, ou o alinhamento da cadeia de texto em relação ao seu ponto de referência (ou de coordenadas).Por padrão, hjust é setado para center, e vjust para middle. Logo, todos os rótulos são centralizados (tanto verticalmente, quanto horizontalmente) ponto que define sua localização. Para mudar o alinhamento de todos os rótulos de uma vez, você pode setar estes argumentos, por fora aes(), fornecendo um dos valores pré-definidos.caso de hjust, há outros quatro valores pré-definidos possíveis (left, right, inward, outward). Caso você coloque left ou right neste argumento, todos os rótulos serão alinhados à esquerda, ou à direita dos pontos. Porém, caso você coloque inward ou outward, os textos serão alinhados (horizontalmente em relação aos pontos de sua localização) em um sentido para o para o centro gráfico, ou se afastando centro gráfico. Dito de outra forma, os textos serão alinhados à esquerda, ou à direita ponto de referência, depender da sua localização em relação ao centro plano cartesiano e sentido escolhido (inward ou outward).Para vjust, há também quatro outros valores pré-definidos (bottom, top, inward, outward). Os valores bottom e top alinham os textos na base ou topo ponto de referência texto. Enquanto os valores inward e outward funcionam mesmo sentido que em hjust, porém eles controlam o alinhamento vertical dos textos.Para deixar claro o que estes argumentos fazem, trago um novo exemplo abaixo que contém cadeias de texto de duas linhas. Caso você queira variar justificação destes textos, ao longo gráfico, significa que você deve conectar uma coluna de seu data.frame estes argumentos em aes(). Porém, estes argumentos não aceitam os valores pré-definidos ao estarem dentro de aes(). Nestas situações, você deve fornecer um número: 0 (justificado à esquerda); 0.5 (centralizado); ou 1 (justificado à direita).Eu acredito que é justamente essa opção numérica, que gera toda confusão sobre função verdadeira destes argumentos. Pois o ggplot não gera nenhum erro caso você dê valores diferentes, e se você aumentar progressivamente estes valores, você irá perceber que o deslocamento dos textos também aumenta. Muitos que se deparam com este comportamento, podem acreditar que estes argumentos servem para deslocar os textos, e não para alinhá-los em relação ao ponto de suas coordenadas. Por isso eu recomendo nestes argumentos, que você utilize um dos valores pré-definidos que citei anteriormente, e utilize essa escala numérica, apenas em situações em que você precisa dessa variação utilizando aes().Uma outra razão pela qual estes argumentos não são apropriados, caso você queira deslocar os textos em um sentido, é que eles não trabalham em sintonia com escalas dos eixos. exemplo abaixo, eu seto o valor de vjust para -4. Porém, o ggplot não deslocou verticalmente os textos em 4 unidades. O texto de valor center, por exemplo, não foi deslocado para coordenadas (x = 1.5, y = 5.5), e se você quiser que ele chegue nessa coordenada? O que você faz? Triplica? Quadruplica o valor anterior? Tudo isso, significa que não há como você prever o quanto o texto irá deslocar, e por isso, você pode perder muito tempo testando diversos valores em um argumento inadequado para o resultado que deseja.Agora, vou explicar como os argumentos de posição funcionam. Como o próprio sufixo deles dá entender, o nudge_y irá deslocar verticalmente os textos, e nudge_x, vai deslocá-los horizontalmente. O verbo nudge em inglês se refere ao ato de “cutucar,” ou empurrar gentilmente alguém, logo, estes argumentos servem para “empurrar” os textos de suas posições originais plano cartesiano. Para demonstrarmos sua aplicação, vamos tentar rotular um gráfico de barras, que apresente um somatório da quilomentragem em cada cilindro.Como descrevi anteriormente, o geom_bar() é um geom coletivo, enquanto os geom’s de texto são geom’s individuais. Por isso, caso você adicionar diretamente um geom_text() ao geom_bar(), sem levar em conta essa diferença, ele irá rotular cada uma das observações da base resumidas em cada barra, e não o total que ela representa.Para rotular corretamente essas barras, você tem duas opções: 1) calcular o somatório em um objeto separado, e em seguida fornecer este objeto ao argumento data, e ajustar o aesthetic mapping de acordo com este objeto, em geom_text(); ou 2) usar transformações estatísticas que o ggplot já disponibiliza para esse trabalho. exemplo abaixo, estou demonstrando opção 1, mas darei um exemplo da opção 2 quando chegarmos à seção de transformações estatísticas ggplot.Portanto, neste exemplo duas camadas de geom utilizam não apenas aesthetic mapping’s, mas também fontes de dados, diferentes. Como você pode reparar acima, os rótulos estão sobre o topo da barra. Por isso, eu posso utilizar o nudge_y para adicionar um pequeno desvio vertical nestes rótulos, dando assim um maior espaço entre ele e barra.Diferentemente dos argumentos de alinhamento, os argumentos de posição (nudge_y e nudge_x) funcionam em sintonia com escala dos eixos. Como escala eixo y termina em aproxidamente 2500, um desvio de 100 é provavelmente suficiente. Isso significa que caso o limite dessa escala fosse 1 décimo disso (250), por exemplo, um desvio de 100 em nudge_y iria gerar um deslocamento considerável nestes rótulos.Além dessas opções, caso você insira textos de 2 ou mais linhas gráfico, você pode se interessar em reduzir ou aumentar o espaço entre-linhas destes textos. Neste caso, você pode controlar este espaço pelo argumento lineheight que define proporção em relação à altura das letras. Um outro ponto possível de customização, é o ângulo dos textos, que é definido pelo argumento angle. Neste argumento, basta fornecer um número (de 0 360) que represente o ângulo desejado.","code":"\nggplot(mpg, aes(x = displ, y = hwy, label = model)) +\n  geom_text()\nggplot(mpg, aes(x = displ, y = hwy, label = model)) +\n  geom_label()\nggplot(mpg, aes(x = displ, y = hwy, label = model)) +\n  geom_text(check_overlap = TRUE)\nggplot(mpg, aes(x = displ, y = hwy, label = model)) +\n  geom_text(size = 7/.pt)\nggplot(\n  mpg,\n  aes(\n    x = displ,\n    y = hwy,\n    label = model,\n    nudge_x = x_desvio,\n    nudge_y = y_desvio\n  )) +\n  geom_text()\ndf <- data.frame(\n  x = c(1, 1, 2, 2, 1.5),\n  y = c(1, 2, 1, 2, 1.5),\n  text = c(\n    \"bottom-left\", \"bottom-right\",\n    \"top-left\", \"top-right\", \"center\"\n  )\n)\n\nggplot(df, aes(x, y)) +\n  geom_point(color = \"darkgray\", size = 7) +\n  geom_text(aes(label = text))\nggplot(df, aes(x, y)) +\n  geom_point(color = \"gray\", size = 7) +\n  geom_text(aes(label = text), vjust = \"inward\", hjust = \"inward\")\ntab <- data.frame(\n  y = rep(1:3, times = 3),\n  x = rep(1:3, each = 3),\n  texto = rep(c(\"Um texto alinhado\\nà esquerda\",\n            \"Um texto\\ncentralizado\",\n            \"Um texto alinhado\\nà direita\"),\n            each = 3\n          ),\n  hjust = rep(c(0, 0.5, 1), each = 3),\n  vjust = rep(c(0, 0.5, 1), times = 3)\n)\n\nggplot(tab, aes(x, y)) +\n  geom_point(size = 7, color = \"darkgray\") +\n  geom_text(aes(\n    label = texto,\n    hjust = hjust,\n    vjust = vjust\n  ))\nggplot(df, aes(x, y)) +\n  geom_point(color = \"gray\", size = 7) +\n  geom_text(aes(label = text), vjust = -4)\nsomatorios <- mpg %>% \n  group_by(cyl) %>% \n  summarise(soma = sum(hwy))\n\nggplot() +\n  geom_bar(\n    mapping = aes(x = cyl, weight = hwy),\n    data = mpg\n  ) +\n  geom_text(\n    mapping = aes(x = cyl, y = soma, label = soma),\n    data = somatorios\n  )\nggplot() +\n  geom_bar(\n    mapping = aes(x = cyl, weight = hwy),\n    data = mpg\n  ) +\n  geom_text(\n    mapping = aes(x = cyl, y = soma, label = soma),\n    data = somatorios, \n    nudge_y = 100\n  )\nggplot() +\n  geom_bar(\n    mapping = aes(x = cyl, weight = hwy),\n    data = mpg\n  ) +\n  geom_text(\n    mapping = aes(x = cyl, y = soma, label = soma),\n    data = somatorios, \n    nudge_y = 100,\n    angle = 45\n  )"},{"path":"visualização-de-dados-com-ggplot2.html","id":"sec:devices_graficos","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.7 Exportando os seus gráficos do ggplot","text":"Após gerar os seus gráficos com o ggplot, você provavelmente vai querer exportá-los para algum arquivo de imagem. Dessa forma, você possa inserí-los em seu artigo em Word (.docx), ou dashboard que você deve apresentar ao seu chefe dia seguinte. Para realizarmos essa tarefa, precisamos utilizar funções que possam construir esses arquivos de imagem, qual podemos guardar os nossos gráficos. Com isso, temos duas alternativas mais comuns, que são:Uma forma mais “moderna” de exportação, através uso da função ggsave(), que é exposta por .Uma forma mais “moderna” de exportação, através uso da função ggsave(), que é exposta por .forma tradicional de se exportar gráficos R, descrita por .forma tradicional de se exportar gráficos R, descrita por .Uma outra referência que também descreve ambas alternativas, se encontra em . primeira alternativa, seria uma forma mais “moderna” de exportar os seus gráficos R, através da função ggsave() (uma função próprio pacote ggplot), que tem se popularizado bastante nos últimos tempos. Entretanto, essa função nada mais é, que um wrapper sobre funções pacote grDevices, que são utilizadas na segunda alternativa apresentada acima. Ou seja, função ggsave() é apenas um atalho para o método descrito por Murrell (2006), que utiliza funções disponíveis pacote grDevices.Em mais detalhes, o pacote grDevices (que está incluso nos pacotes básicos da linguagem) oferece um conjunto de funções capazes de acessar diversos devices gráficos. Cada device gráfico, representa uma engine diferente que vai ser responsável por construir o arquivo onde o seu gráfico será guardado. Portanto, cada uma dessas engines, vão gerar um tipo arquivo diferente, ou em outras palavras, arquivos de extensões diferentes. Você já utiliza muitos desses devices gráficos, praticamente o tempo todo em sua rotina. Você apenas não sabia, que esse era o nome técnico dado às engines, que normalmente constroem esses tipos de arquivos. Sendo os exemplos mais famosos, os arquivos: JPEG/JPG (.jpeg, .jpg), PNG (.png), SVG (.svg) e PDF (.pdf).","code":""},{"path":"visualização-de-dados-com-ggplot2.html","id":"tipos-de-representação-geométrica-em-devices-gráficos","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.7.1 Tipos de representação geométrica em devices gráficos","text":"Ao longo das décadas passadas mais recentes, área da computação gráfica desenvolveu diversos modelos computacionais que fossem capazes de representar visualmente e virtualmente, o nosso mundo real (Hughes et al. 2014). Com isso, eu quero destacar que nós possuímos hoje, formas diferentes de se representar uma mesma imagem em nosso computador.Isso significa, que cada um dos devices gráficos disponíveis, que podemos utilizar para guardar os nossos gráficos R, em geral, utilizam um tipo, ou um método de representação geométrica diferente para representar sua imagem. Cada um desses modelos, possuem características diferentes, e com isso, incorrem em diferentes erros na representação virtual de sua imagem. Logo, conhecer, mesmo que de maneira sutil, esses modelos de representação, suas vantagens e características, se torna importante para fundamentarmos nossas decisões sobre como vamos salvar os nossos gráficos R.Nós temos atualmente, dois modelos principais de representação geométrica que são utilizados para representar imagens, ao longo de toda indústria da computação gráfica, sendo elas:Vetorial.Vetorial.Matricial.Matricial.representação vetorial (figura 8.3), como o próprio nome dá entender, busca conectar um conjunto de vetores (ou de linhas) para formar cada forma geométrica presente em sua imagem. Um arquivo de imagem que utiliza essa representação, possui uma descrição matemática dos elementos geométricos que compõe sua imagem (Murray vanRyper 1996). Essa descrição matemática possui informações como direção, o comprimento e coordenadas dos vetores (ou linhas) que formam cada forma geométrica de sua imagem. Em resumo, representação vetorial funciona como aqueles desenhos infantis de “conecte os pontos.” Nesse sistema, qualquer forma presente em nosso gráfico, seja ela um quadrado, um círculo, uma letra, ou uma garrafa, é formada por um conjunto de linhas que conectam os “vértices” de cada forma.\nFigure 8.3: Diferenças entre representações vetorial e matricial\nPor outro lado, imagens que se encontram em representação matricial (figura 8.3), são popularmente conhecidas por raster image, ou bitmap image, e utilizam-se de uma malha quadricular (ou de um grid), qual cada célula é preenchida, fim de representar cada parte de sua imagem. Uma forma típica de identificarmos esse tipo de representação, está efeito “escada,” ou efeito pixelado (ou quadriculado) que adquirimos ao darmos um zoom nesse tipo de imagem.Os principais devices gráficos disponíveis R, que utilizam representação vetorial, são os arquivos PDF (.pdf) e SVG (.svg). Além desses, temos alguns outros devices menos comuns, como os arquivos encapsulated PostScript (.eps) que são mais utilizados em programas da Adobe, como o PhotoShop. Imagens produzidas através de representações vetoriais, são em geral, mais bem definidas que imagens produzidas por representações matriciais, e mesmo que o usuário dê um zoom grande sobre imagem, elas são capazes de manter essa definição. Logo, como foi destacado por Wickham (2016, p 185), imagens de representações vetoriais parecem mais atraentes em um número maior de lugares. Especialmente pelo fato, de que o sistema vetorial consegue representar formas geométricas (principalmente polígonos), de maneira mais precisa, que o sistema matricial.Apesar dessa vantagem, não são todos os programas que suportam o uso de imagens provenientes de representações vetoriais (por exemplo, o Word aceita o uso de arquivos SVG, mas não aceita o uso de PDF’s para inserção de imagens). Em contrapartida, arquivos de raster image (ou bitmap image), são aceitos na grande maioria dos programas, e portanto, representam uma forma mais portátil de transportar os seus gráficos ao longo de diversos programas e sistemas. Tendo isso em mente, os devices gráficos mais conhecidos, que usam representação matricial, são os arquivos PNG (.png), JPEG/JPG (.jpeg) e TIFF (.tiff).Logo, ao escolher o device gráfico que irá gerar o seu arquivo de imagem, você deve refletir sobre qual o formato que mais se adequa suas necessidades. Mesmo que você possa produzir imagens mais fiéis através de uma representação vetorial, isso não se configura na maioria das ocasiões, como uma grande vantagem. Pois, você pode se aproveitar da maior flexibilidade dos devices de representação matricial, e ainda sim, produzir imagens muito bem definidas e de alta resolução. Sobretudo com o uso de um arquivo PNG (.png) ou TIFF (.tiff), que produzem em geral, resultados melhores que um arquivo JPEG/JPG (.jpeg).Em resumo, caso o uso de um arquivo PDF (.pdf), ou SVG (.svg), não represente uma limitação para o seu trabalho, você geralmente vai preferí-los em detrimento de outros devices gráficos. Entretanto, caso você precise de uma maior portabilidade de seu gráfico, você ainda pode atingir ótimos resultados com um device gráfico de representação matricial, como um arquivo PNG (.png) ou TIFF (.tiff). Basta que você utilize uma resolução alta, e aplique um anti-aliasing sobre o arquivo em que você irá salvar o gráfico. Um bom nível de resolução para esses tipos de arquivos, se encontra na casa dos 300 dpi, sendo essa resolução mínima requisitada pela maioria dos jornais e revistas científicas.Concluindo, podemos utilizar diferentes tipos de representações geométricas para guardarmos informações visuais em nosso computador, com o objetivo de representarmos virtualmente uma mesma imagem. Caso queira conhecer mais fundo essas representações, você pode consultar  e Câmara Monteiro (2001) para uma introdução útil, e para uma visão mais técnica e aprofundada, você pode consultar  e .","code":""},{"path":"visualização-de-dados-com-ggplot2.html","id":"sec:anti_aliasing","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.7.2 Pontos importantes sobre anti-alising","text":"O device gráfico utilizado pelo RStudio, em seu painel de Plots, depende sistema operacional em que você está trabalhando. caso Windows, o RStudio irá utilizar o device gráfico nativo sistema, e infelizmente, como foi pontuado por Chase (2019), esse device não é muito bom. Um de seus principais problemas, é que ele não possui um mecanismo de anti-aliasing.O anti-aliasing, é um recurso muito utilizado em diversos programas que trabalham com imagens. Um grande exemplo disso, se encontra nos videogames, que quase sempre possuem uma opção em suas configurações gráficas, que lhe permite aplicar esse recurso sobre o gráfico game. Esse recurso, conciste em um método de suavização de imagens produzidas por representações matriciais, onde o computador tenta preencher certas áreas ao redor dos limites de cada forma geométrica representada na imagem, de forma que os contornos fiquem mais suaves e precisos, eliminando grande parte efeito pixelado (ou quadriculado) presente em imagens desse tipo.Portanto, se você, assim como eu, trabalha Windows, todas imagens (produzidas por devices gráficos que usam representação matricial) que você exportar R, não vão incluir o uso de um anti-aliasing, por padrão device gráfico utilizado pelo sistema. Isso significa, que grande parte das suas imagens, vão apresentar o efeito pixelado, mesmo que você utilize resoluções altas. Por exemplo, você pode ver na figura 8.4, especialmente na imagem com 300 dpi, que aumentar resolução da imagem, ajuda bastante quanto ao efeito pixelado, mas que ainda não é o suficiente para eliminá-lo (se você der um zoom grande sobre imagem de 300 dpi, você ainda é capaz de ver alguns resquícios efeito “escada” que estamos tentando eliminar). Portanto, poderíamos atingir um resultado ainda melhor nessas imagens, com o uso de um anti-aliasing.\nFigure 8.4: Aumentar resolução de uma imagem ajuda, mas ainda não é o suficiente\nIsso é um problema particular Windows, que ocorre sempre que utilizamos algum dos devices gráficos que utilizam representação matricial. Pois os devices gráficos utilizados pelo RStudio em outros sistemas, como Mac e Linux, apresentam “de fábrica” um mecanismo de anti-aliasing. Apesar desse problema, os usuários de Windows possuem uma solução simples, que é descrita por Chase (2019). Isto é, o uso da engine gráfica Cairo Graphics, que está disponível normalmente nos sistemas Windows e oferece um recurso de anti-aliasing. O uso dessa engine também se torna essencial Windows, quando desejamos utilizar em nossos gráficos, fontes que estão instaladas nosso sistema.Para acessarmos engine gráfica Cairo Graphics, podemos utilizar o argumento type, tanto na função ggsave(), quanto nas funções pacote grDevices. Basta igualar esse argumento ao nome cairo, da seguinte forma: type = \"cairo\". caso da função ggsave(), ela não possui um argumento type definido, mas como essa função utiliza funções pacote grDevices, o argumento type será repassado às funções pacote grDevices durante sua execução.Para reforçarmos essa ideia, olhe para figura 8.5. Ambos os gráficos foram salvos em um arquivo PNG, com mesmas dimensões, e utilizando mesma resolução (300 dpi). Se você der um zoom muito grande sobre ambas imagens, você poderá perceber que o efeito pixelado está muito menor, na imagem em que o anti-aliasing foi aplicado, em relação outra imagem que não o possui.\nFigure 8.5: Além de usar resoluções altas, use também anti-aliasing\n","code":""},{"path":"visualização-de-dados-com-ggplot2.html","id":"a-função-ggsave","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.7.3 A função ggsave()","text":"Como definimos anteriormente, função ggsave() pacote ggplot, representa apenas um atalho para o método descrito por Murrell (2006), sendo portanto, um método menos verboso que o método tradicional de se exportar gráficos R. Para utilizar função ggsave(), você precisa primeiro gerar o seu gráfico, ou melhor dizendo, o seu gráfico deve estar aparecendo na área direita e inferior seu RStudio, na seção de Plots. Pois é partir cache dessa seção, que função irá extrair o seu gráfico, e portanto, salvá-lo em algum local de seu computador.Dessa forma, o código necessário para o uso dessa função, vai em geral, ser semelhante ao código abaixo. Você primeiro gera o gráfico, e em seguida, utiliza função ggsave(), para salvar o gráfico correspondente.O primeiro argumento (filename) da função ggsave(), corresponde ao nome que você deseja dar ao arquivo onde seu gráfico será salvo. O segundo argumento (device), é onde você irá selecionar o device gráfico desejado para o arquivo onde o gráfico será salvo. Vale ressaltar, que você não precisa definir esse argumento. Pois você pode escolher implicitamente o device desejado, através da extensão que você define nome arquivo - primeiro argumento (filename). Ou seja, se primeiro argumento, eu colocar o nome arquivo como output.pdf, devido extensão .pdf ao final nome, função ggsave() vai gerar um arquivo PDF para você. Mas caso o nome arquivo seja output.png, função ggsave() vai construir um arquivo PNG. E assim por diante. Em resumo, você pode utilizar em todos os sistemas operacionais, através da função ggsave(), seguintes extensões:eps - encripted PostScript.eps - encripted PostScript.ps - PostScript.ps - PostScript.tex - PicTex.tex - PicTex.pdf - Portable Document Format (PDF).pdf - Portable Document Format (PDF).jpeg - Arquivo JPEG.jpeg - Arquivo JPEG.tiff - Tag Image File Format (TIFF).tiff - Tag Image File Format (TIFF).png - Portable Network Graphics (PNG).png - Portable Network Graphics (PNG).bmp - Bitmap Image File (BMP).bmp - Bitmap Image File (BMP).svg - Scalable Vector Graphics (SVG).svg - Scalable Vector Graphics (SVG).Caso você deseje salvar o arquivo gráfico, em um diretório diferente de seu diretório de trabalho atual R, você pode utilizar o terceiro argumento (path), para selecionar uma pasta. Basta que você forneça um caminho absoluto até pasta. Por exemplo, caso eu queira salvar o arquivo em minha pasta de Gráficos, localizada em minha pasta de Pesquisa, eu posso utilizar os seguintes comandos:Outros argumentos muito importantes serem utilizados, são os argumentos width, height e dpi, que definem largura, altura e resolução arquivo resultante, respectivamente. É importante frisar que os argumentos width e height, trabalham com unidade de polegadas (inches - ), sendo uma unidade menos comum em imagens. Como uma dica, você pode primeiro imaginar largura e altura de sua imagem, em pixels, que é uma unidade mais comumente utilizada em situações como essa, e em seguida, converter esses pixels para polegadas (1 polegada equivale 60 pixels), encontrando assim, o valor que você deseja fornecer aos argumentos supracitados.Dando prosseguimento à descrição, os argumentos width e height são muito importantes, pois eles afetam diretamente escala (ou o aspect ratio) da imagem. Dito de outra forma, esses argumentos acabam afetando disposição dos elementos gráfico, ao longo espaço da imagem resultante. Com isso, o uso desses argumentos, envolve encontrar um certo equilíbrio, ou uma relação entre altura e largura da imagem, que melhor represente o seu gráfico. Por exemplo, os dois gráficos mostrados na figura 8.6, foram salvos utilizando-se função ggsave(). Ambos os gráficos, foram salvos em um arquivo PNG (.png), e utilizaram uma resolução de 300 de dpi. única diferença entre esses gráficos, se encontra nos valores de altura e largura utilizados em cada imagem.\nFigure 8.6: Efeitos da relação entre altura e largura com ggsave(), sobre uma imagem\nPortanto, ao aumentarmos altura e largura da imagem, o gráfico resultante tende ser mais “disperso,” e os seus elementos, menores. Essa característica é relevante, pois nós geralmente desejamos evitar um gráfico muito “disperso,” e com elementos muito pequenos. Isso se deve à função que um gráfico usualmente cumpre em uma análise. Nós frequentemente utilizamos gráficos, para nos comunicar com o nosso leitor, ao mostrarmos de forma visual, informações que são relevantes e que trazem novas perspectivas e questões sobre uma determinada análise. Se essas informações ficam menores e muito “dispersas” ao longo espaço nosso gráfico, o nosso leitor tem maior dificuldade de enxergar o padrão geral (ou informação principal) nosso gráfico. Não apenas porque sua visão precisa cobrir um espaço mais amplo da tela, mas também porque formas geométricas que representam os nossos dados, podem ficar muito pequenas, e com isso, mais difíceis de se identificar.Por outro lado, resolução (argumento dpi) definida na função ggsave(), funciona somente com devices gráficos que utilizam representações matriciais (e.g. PNG, TIFF e JPEG/JPG). resolução da imagem, é responsável por modificar apenas dimensão da matriz, ou da malha quadricular que será utilizada para representar sua imagem. Resoluções maiores, vão utilizar matrizes de maiores dimensões (ou em outras palavras, uma matriz com maior número de células) para representar o seu gráfico, e portanto, imagem resultante será mais precisa, e irá sofrer de maneira menos intensa com o efeito “pixelado” produzido por representações matriciais.Como exemplo prático, veja imagens dos gráficos na figura 8.7. Ambos os gráficos foram salvos em um arquivo PNG, e utilizaram os mesmos valores de altura e largura. Porém, foi aplicado diferentes valores de resolução em ambas imagens. Se você der um zoom sobre imagens, você irá perceber que imagem de 100 dpi, sofre de maneira muito mais acentuada efeito granulado (ou pixelado), em relação imagem de 300 dpi.\nFigure 8.7: Efeitos da resolução com ggsave() sobre uma imagem\nLembre-se que podemos melhorar ainda mais aparência dessas imagens, ao utilizarmos um recurso de anti-aliasing. Como já definimos na seção de Pontos importantes sobre anti-aliasing, para utilizarmos tal recurso, precisamos acessar engine Cairo Graphics, e para isso, precisamos apenas definir o argumento type para o nome cairo.","code":"\nggplot(mpg, aes(displ, cty)) + geom_point()\nggsave(\"output.pdf\")\nggplot(mpg, aes(displ, cty)) + geom_point()\nggsave(\n  filename = \"output.pdf\",\n  path = \"C:/Users/Pedro/Pesquisa/2020-08/Gráficos/\"\n)\nggplot(mpg, aes(displ, cty)) + geom_point()\nggsave(\n  filename = \"output.png\",\n  path = \"C:/Users/Pedro/Pesquisa/2020-08/Gráficos/\",\n  width = 7,\n  height = 5,\n  type = \"cairo\"\n)"},{"path":"visualização-de-dados-com-ggplot2.html","id":"a-forma-tradicional-de-se-exportar-gráficos-no-r","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.7.4 A forma tradicional de se exportar gráficos no R","text":"Apesar da função ggsave() ser um atalho útil, eu (Pedro) particularmente prefiro usar diretamente funções pacote grDevices, sempre que desejo exportar algum gráfico produzido R. Parte dessa preferência, reside fato de que função ggsave() não oferece até o momento, suporte para função cairo_pdf(), que se torna essencial quando desejamos exportar gráficos que utilizam fontes personalizadas, ou que estão instaladas em nosso sistema. Vale lembrar, que o pacote grDevices já está incluso nos pacotes básicos R, e por essa razão, ele é carregado automaticamente em toda sessão R que você inicia.Como é descrito por , o processo tradicional de exportação de gráficos R, é bem simples, e envolve três passos diferentes: 1) abrir um arquivo construído por algum device gráfico; 2) gerar o seu gráfico; 3) fechar o arquivo produzido pelo device gráfico.Portanto, primeiro passo, vamos criar um novo arquivo de imagem (vazio) em nosso computador, de acordo com um device gráfico de nossa preferência. Dessa forma, o arquivo fica em aberto, espera de algum input gráfico ser armazenado. Em seguida, nós podemos gerar o nosso gráfico. Sendo que diferentemente da função ggsave(), quando abrimos um arquivo de imagem (como fizemos passo 1), qualquer gráfico que geramos não será mostrado painel direito e inferior (seção Plots) nosso RStudio. Pois ele é diretamente levado para o arquivo que abrimos. Por último, podemos fechar o arquivo que abrimos primeiro passo, encerrando dessa forma, o processo de exportação.Para abrirmos um novo arquivo de imagem em nosso computador, temos funções disponíveis abaixo. Perceba que lista de arquivos abaixo, é praticamente idêntica à lista que mostramos na seção anterior. Pois como já destacamos anteriormente, função ggsave() vai utilizar “por trás dos bastidores,” todas essas funções abaixo (exceto função svg()31) para construir os seus arquivos de imagem.postscript() - encripted PostScript e PostScript.postscript() - encripted PostScript e PostScript.pictex() - PicTex.pictex() - PicTex.pdf() e cairo_pdf() - Portable Document Format (PDF).pdf() e cairo_pdf() - Portable Document Format (PDF).jpeg() - Arquivo JPEG.jpeg() - Arquivo JPEG.tiff() - Tag Image File Format (TIFF).tiff() - Tag Image File Format (TIFF).png() - Portable Network Graphics (PNG).png() - Portable Network Graphics (PNG).bmp() - Bitmap Image File (BMP).bmp() - Bitmap Image File (BMP).svg() - Scalable Vector Graphics (SVG).svg() - Scalable Vector Graphics (SVG).Independente de qual o device gráfico, ou função que você escolher para abrir um arquivo em seu computador, você irá fechar esse arquivo (terceiro passo), por meio da função dev.(). Dessa forma, o código necessário para gerarmos, por exemplo, um arquivo PNG, através desse método de exportação, é semelhante aos comandos abaixo. De certa forma, você utiliza funções pacote grDevices, de modo que elas “contornem,” ou “envolvam” os comandos que geram o seu gráfico.Assim como na função ggsave(), o primeiro argumento (filename ou file) de todas funções pacote grDevices, é responsável por definir o nome arquivo onde o seu gráfico será salvo. Porém, semelhanças com função ggsave() acabam por aqui.Diferentemente da função ggsave(), você precisa ficar mais atento ao definir dimensões de sua imagem nas funções pacote grDevices, pois unidades utilizadas nos argumentos height e width ao longo dessas funções, variam. Uma boa forma de guardar essas unidades, é categorizar funções de acordo com representação geométrica que elas utilizam. funções que utilizam representações vetoriais (PDF, SVG e EPS) usam unidade de polegadas (inches), para definir dimensões de sua imagem. Já funções que utilizam representações matriciais (PNG, JPEG/JPG, TIFF, BMP) usam unidade de pixels.Uma outra diferença presente nas funções pacote grDevices, é que o argumento responsável por definir resolução da imagem, se chama res (abreviação para resolution), ao invés de dpi como ocorre em ggsave(). Entretanto, unidade utilizada argumento res, permanece mesma, em relação ao argumento dpi.","code":"\n# Abra um arquivo de imagem\n# com algum device gráfico\npng(\"output.png\")\n\n# Construa algum gráfico\nggplot(mpg, aes(displ, cty)) + geom_point()\n\n# Feche o arquivo que você criou\n# com dev.off()\ndev.off()"},{"path":"visualização-de-dados-com-ggplot2.html","id":"arquivos-png-jpegjpg-tiff-e-bmp","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.7.4.1 Arquivos PNG, JPEG/JPG, TIFF e BMP","text":"Para os exemplos dessa seção, vou utilizar função png(), com o objetivo de criar um modelo guia, sobre como você pode configurar esse conjunto de funções, que se referem devices gráficos que utilizam representações matriciais. Ou seja, você pode replicar normalmente o método de uso da função png(), ou os seus argumentos, para demais funções desse conjunto (que funcionam de maneira idêntica), basta trocar função png() por uma dessas funções: jpeg(), tiff() e bmp().Em todas ocasiões que você utilizar uma dessas funções, você possui ao menos 5 argumentos que você provavelmente irá definir. O primeiro argumento (file ou filename) de todas essas funções, é onde você irá definir o nome arquivo, em que você está salvando o seu gráfico. Além dele, temos também os dois argumentos que definem largura (width) e altura (height) arquivo resultante (lembre-se que esses argumentos trabalham com unidade de pixels). Em seguida, temos o argumento res, que é responsável por definir resolução arquivo de imagem. Por último, mas não menos importante, temos o argumento type, que é responsável por definir se o R irá utilizar o device gráfico nativo sistema, ou engine Cairo Graphics para construir sua imagem.Tendo esses argumentos em mente, temos logo abaixo um código modelo, sobre como poderíamos configurar essa função. caso de arquivos PNG, você ainda pode utilizar o valor cairo-png argumento type, para utilizar uma outra engine interna Cairo Graphics. Porém, os resultados produzidos por cairo e cairo-png através argumento type, são virtualmente idênticos (ao menos olho nu). Você pode encontrar mais detalhes sobre diferença entre esses dois métodos, na documentação da função png() (execute o comando ?png console para acessar essa documentação).Agora, é muito importante destacar que resolução da imagem (que você define argumento res) construída por essas funções, possui um efeito diferente que vimos na função ggsave(). Quando estávamos discutindo função ggsave(), vimos que resolução definida argumento dpi dessa função, cumpria o trabalho para o qual foi desenvolvida, que concistia aumento ou redução da malha quadricular responsável pela representação da imagem. Em outras palavras, resolução afetava diretamente precisão da imagem construída.Porém, em comparação com função ggsave(), resolução definida argumento res, possui um efeito extra nas funções png(), jpeg(), tiff() e bmp(). Em resumo, ao modificarmos resolução nessas funções, nós também afetamos o espaço da imagem, da mesma forma como ocorre ao modificarmos altura e largura da imagem. Por isso, ao utilizar essas funções, você possui mais um item considerar, ao procurar pelo equilíbrio que melhor representa o seu gráfico.Descrevendo esse efeito em mais detalhes, nas funções png(), jpeg(), tiff() e bmp(), caso nós mantivermos altura e largura da imagem constantes, ao aumentarmos sua resolução, estamos de certa forma comprimindo o gráfico um espaço menor. Por outro lado, ao reduzirmos essa resolução, estamos produzindo o efeito contrário, e como resultado, nós aumentamos o espaço que o gráfico irá ocupar na imagem.Isto significa, que para você utilizar altos níveis de resolução em suas imagens, você terá que compensar os efeitos dessa resolução, com maiores valores para altura e largura de sua imagem. Veja por exemplo, imagens mostradas na figura 8.8. Ambas imagens apresentam exatamente o mesmo gráfico. Sendo que ambos os gráficos foram salvos em um arquivo PNG (construídos pela função png()), e utilizaram mesmas dimensões (altura = 900 pixels, largura = 1500 pixels). Entretanto, os dois arquivos de imagem usaram resoluções diferentes. Perceba que o gráfico presente na imagem com maior resolução (300 dpi), está mais “comprimido,” enquanto o gráfico com menor resolução (180 dpi) traz um visual mais “natural,” como se o gráfico tivesse um espaço mais ideal para ocupar na imagem.\nFigure 8.8: Efeitos da resolução em png() sobre uma imagem\n","code":"\npng(\n  filename = \"um_nome_qualquer.png\", \n  width = 2800,\n  height = 1800,\n  res = 300,\n  type = \"cairo\"\n)\nggplot(mpg, aes(displ, cty)) + geom_point()\ndev.off()"},{"path":"visualização-de-dados-com-ggplot2.html","id":"sec:cairo_pdf","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"8.7.4.2 Arquivos PDF e SVG","text":"Nessa seção, vamos discutir três funções utilizadas para construirmos dois tipos de arquivos de imagem, que utilizam representações vetoriais, mais especificamente PDF (pdf() e cairo_pdf()) e SVG (svg()).Você pode configurar funções pdf(), cairo_pdf() e svg(), de maneira muito parecida com função ggsave(). Dessa forma, você possui três argumentos principais serem tratados nessas funções. O argumento file, para dar um nome ao arquivo que você está criando. E os argumentos height e width para definir altura e largura da imagem. Lembre-se que para funções de drives gráficos que utilizam representação vetorial, dimensões da imagem são definidas em polegadas (inches), e não em pixels. Abaixo temos um exemplo de uso dessas funções.Curiosamente, se você está exportando um arquivo PDF, você pode salvar múltiplos gráficos em um mesmo arquivo, de modo que cada gráfico terá sua própria página. Como Chang (2012, p 324) descreve, caso você abra um arquivo PDF (com função pdf() ou cairo_pdf()), e gere mais de um gráfico antes de encerrar esse arquivo com função dev.(), cada gráfico gerado terá sua própria página arquivo resultante.Para fazer isso, nenhuma nova configuração é necessária sobre função pdf(). Logo, independentemente de quantos gráficos você esteja planejando guardar nesse arquivo, você não precisa alterar nenhum argumento, em relação aos comandos anteriores. Tudo o que você precisa fazer, é abrir um novo arquivo com função, e criar quantos gráficos você desejar antes de fechar o arquivo.Porém, para atingir esse mesmo resultado com função cairo_pdf(), você precisa ainda adicionar um novo argumento, chamado onefile. Tudo o que você deve fazer, é configurar esse argumento para verdadeiro (TRUE), como exemplo abaixo. Dessa forma, todos os gráficos gerados por você, serão guardados em um mesmo arquivo.Como o próprio nome da função cairo_pdf() dá entender, essa função utiliza engine gráfica Cairo Graphics para construir o seu arquivo PDF. Como o recurso de anti-aliasing só é aplicado sobre imagens produzidas por representações matriciais, o uso Cairo Graphics possui um papel diferente em representações vetoriais. Em resumo, você só vai precisar da função cairo_pdf(), caso você tenha utilizado em seu gráfico, fontes personalizadas, ou que estão instaladas em seu sistema.Ao executar função pdfFonts(), você pode encontrar uma lista, contendo informações sobre todas fontes atualmente disponíveis em sua sessão, que podem ser utilizadas ao exportarmos o nosso gráfico através da função pdf(). Em outras palavras, essa lista mostra todas fontes que você pode utilizar em seu gráfico R, e que vão estar disponíveis ao salvar esse gráfico em um arquivo PDF. Adicionar novas fontes essa lista mostrada pela função pdfFonts(), não é algo simples. Por isso, diversos pacotes tem sido desenvolvidos com o objetivo de facilitar o uso de fontes personalizadas em gráficos R. Dentre eles, o pacote extrafont é o que mais tem se destacado.próximo capítulo, vou mostrar como podemos aplicar esse pacote. Mas resumidamente, com o uso pacote extrafont, o processo para o uso de fontes sistema em seus gráficos R, conciste em duas etapas: 1) “importar” fontes para o R, de forma que ele guarde um registro da localização, e de outras informações sobre cada fonte instalada em seu sistema; 2) após o passo 1, você precisa sempre “carregar” essas fontes, durante toda sessão R, em que você desejar utilizá-las.Porém, caso específico de uma exportação para um arquivo PDF, mesmo após utilizarmos funções pacote extrafont, para carregarmos fontes que desejamos utilizar em nossa sessão R - como demonstrado por Qiu (2015, p 101), função pdf(), ainda sim, costuma não ser capaz de incorporar fontes utilizadas, ao arquivo PDF resultante. Apesar da dificuldade inerente ao processo, engine interna Cairo Graphics, oferece suporte para criação de arquivos PDF, e ainda mais importante, oferece um excelente suporte para o processo de incorporação de fontes (ou font embedding, como é comumente chamado) de seu computador para o arquivo PDF criado.O processo de font embedding, conciste em incluir dentro de seu arquivo PDF, uma descrição completa das fontes utilizadas ao longo de seu PDF. Com essa descrição, fontes utilizadas em seu arquivo PDF, se tornam independentes sistema qual elas estão sendo mostradas ou impressas. Em outras palavras, fontes de seu PDF vão ser corretamente mostradas na tela de qualquer computador, independentemente se esse computador possui ou não aquelas fontes presentes em seu sistema. O ponto forte da função cairo_pdf(), é que ela realiza esse processo de font embedding automaticamente.Por exemplo, o gráfico mostrado na figura 8.9, utiliza fonte Comic Sans MS (uma fonte normalmente disponível em todo sistema Windows) e foi salvo utilizando função cairo_pdf().\nFigure 8.9: Um gráfico que utiliza fonte Comic Sans MS\n","code":"\npdf(\"output.pdf\", width = 8, height = 5)\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\ndev.off()\n\ncairo_pdf(\"output.pdf\", width = 8, height = 5)\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\ndev.off()\n\nsvg(\"output.svg\", width = 8, height = 5)\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\ndev.off()\npdf(\"output.pdf\", width = 8, height = 5)\n\n# Gráfico 1\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\n# Gráfico 2\nggplot(mpg) + geom_bar(aes(x = cyl))\n# Gráfico 3\nggplot(mpg) + geom_histogram(aes(x = hwy), color = \"black\")\n\ndev.off()\ncairo_pdf(\"output.pdf\", width = 8, height = 5, onefile = TRUE)\n\n# Gráfico 1\nggplot(mpg) + geom_point(aes(x = displ, y = hwy))\n# Gráfico 2\nggplot(mpg) + geom_bar(aes(x = cyl))\n# Gráfico 3\nggplot(mpg) + geom_histogram(aes(x = hwy), color = \"black\")\n\ndev.off()"},{"path":"visualização-de-dados-com-ggplot2.html","id":"exercícios-6","chapter":"Capítulo 8 Visualização de dados com ggplot2","heading":"Exercícios","text":"Questão 8.1. Descubra qual o problema dos comandos abaixo, porque eles não geram um gráfico conforme esperado? Ou porque eles sequer geram algum gráfico? Vale destacar que, tabelas mpg e diamonds estão disponíveis através próprio pacote ggplot2. Portanto, assim que você chamar por esse pacote em sua sessão através comando library(), você terá acesso essas tabelas.8.1.) Os comandos abaixo deveriam gerar um simples gráfico de dispersão, porém, um erro é criado. Porque esse erro ocorre? Copie e cole em seu R e veja esse erro com seus próprios olhos.8.1.B) Os comandos abaixo deveriam gerar um gráfico de dispersão, onde os pontos seriam coloridos de acordo com os valores da coluna cut. Porém, o resultado é um gráfico de dispersão onde todos os pontos continuam pretos! O que ocorreu de errado nesses comandos?8.1.C) Os comandos abaixo deveriam gerar um simples gráfico de barras, onde todas barras deveriam ser coloridas pela cor azul (blue), porém, o resultado é um gráfico com barras coloridas de um vermelho salmão. Porque isso ocorre? Como podemos corrigir esses comandos para que todas barras estejam coloridas de azul?32.Questão 8.2. Como exercício prático, utilize funções pacote ggplot para desenhar os objetos abaixo:8.2.) Desenha bandeira movimento LGBTQ+. Como uma ajuda, nós temos abaixo um vetor contendo os códigos de cada cor presente nessa bandeira:8.2.B) Considerando função quadrática \\(y = x^2 + 15x + 32\\), desenhe curva dessa função para o intervalo de 0 < \\(x\\) < 1000.8.2.C) Desenhe um conjunto de setas apontando para o texto \"Uma anotação muito importante\". Ou seja, desenhe o texto guardado objeto anotacao abaixo em seu ggplot e, em seguida, tente desenhar um conjunto de setas apontando para essa anotação.Questão 8.3. Na média qual qualidade de corte (cut) na tabela diamonds que gera o maior preço (price). Dito de outra forma, utilize um gráfico ggplot para responder à seguinte pergunta: tendo tabela diamonds em mãos, quais são os cortes descritos na coluna cut que geram os diamantes mais caros mercado, isto é, que possuem os maiores preços na coluna price. Lembre-se que tabela diamonds advém próprio pacote ggplot2, logo, se você chamou por esse pacote em sua sessão com um comando library(), você já tem acesso à tabela diamonds.","code":"\nggplot(data = mpg) %>% \n  geom_point(\n    aes(x = displ, y = hwy)\n  )\nggplot(data = diamonds) +\n  geom_point(\n    aes(x = carat, y = price, fill = cut)\n  )\nggplot(diamonds) +\n  geom_bar(\n    aes(x = cut, fill = \"blue\")\n  )\nvec_colors <- c(\n  \"#a319ff\",\n  \"#1294ff\",\n  \"#19bf45\",\n  \"#ffdc14\",\n  \"#ff6a00\",\n  \"#ff1919\"\n)\nanotacao <- \"Uma anotação\\nmuito importante\"\nlibrary(ggplot2)\n\n### Ao chamar pelo pacote\n### ggplot2, você terá acesso\n### à tabela diamonds\ndiamonds## # A tibble: 53,940 x 10\n##    carat cut       color clarity depth table price     x     y     z\n##    <dbl> <ord>     <ord> <ord>   <dbl> <dbl> <int> <dbl> <dbl> <dbl>\n##  1  0.23 Ideal     E     SI2      61.5    55   326  3.95  3.98  2.43\n##  2  0.21 Premium   E     SI1      59.8    61   326  3.89  3.84  2.31\n##  3  0.23 Good      E     VS1      56.9    65   327  4.05  4.07  2.31\n##  4  0.29 Premium   I     VS2      62.4    58   334  4.2   4.23  2.63\n##  5  0.31 Good      J     SI2      63.3    58   335  4.34  4.35  2.75\n##  6  0.24 Very Good J     VVS2     62.8    57   336  3.94  3.96  2.48\n##  7  0.24 Very Good I     VVS1     62.3    57   336  3.95  3.98  2.47\n##  8  0.26 Very Good H     SI1      61.9    55   337  4.07  4.11  2.53\n##  9  0.22 Fair      E     VS2      65.1    61   337  3.87  3.78  2.49\n## 10  0.23 Very Good H     VS1      59.4    61   338  4     4.05  2.39\n## # ... with 53,930 more rows"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"configurando-componentes-estéticos-do-gráfico-no-ggplot2","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","text":"","code":""},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"introdução-e-pré-requisitos-4","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.1 Introdução e pré-requisitos","text":"primeiro capítulo sobre o ggplot, vimos quatro das várias camadas que compõe um gráfico estatístico segundo abordagem de Wilkinson (2005). Mais especificamente, vimos três camadas essenciais que estão presentes em qualquer gráfico: os dados utilizados (data), o mapeamento (aesthetic mapping) de variáveis de sua tabela para atributos estéticos gráfico, e formas geométricas (geom’s) que representam os seus dados gráfico. Além dessas camadas essenciais, também explicamos como você pode criar diferentes facetas de um mesmo gráfico.Neste capítulo, estaremos focando nas outras camadas, mais especificamente, aquelas que controlam aspectos visuais e estéticos gráfico. Estaremos utilizando novamente neste capítulo, o mesmo gráfico (plot_exemplo) como base para os nossos exemplos.","code":"\ninstall.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"tema-theme-do-gráfico","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.2 Tema (theme) do gráfico","text":"O tema gráfico, diz respeito todos os elementos e configurações estéticos que não afetam, ou que não estão conectadas aos dados dispostos gráfico. Ou seja, os temas não alteram propriedades perceptívies gráfico, mas ajuda você torná-lo esteticamente agradável (Wickham 2016, p 169). Em outras palavras, o tema lhe dá controle sobre fontes utilizadas, o alinhamento texto, grossura grid e das marcações, cor plano de fundo gráfico, etc.Todos os aspectos temáticos gráfico são configurados pela função theme(), que possui vários argumentos. Cada argumento dessa função, lhe permite configurar um elemento de seu gráfico. Onde cada um destes elementos, são associados um tipo de elemento diferente. Por exemplo, o título gráfico, é um texto, logo, ele é associado ao elemento tipo texto - element_text(), já retas dos eixos são associadas ao elemento tipo linha - element_line().Os tipos de elemento são apenas uma convenção, para que você saiba qual função element_*() é apropriada para configurar o elemento desejado. Por exemplo, se o título gráfico, é um elemento associado ao tipo “texto,” você deve usar função element_text() para modificar este elemento. Porém, se você quer configurar o background gráfico, você deve utilizar função element_rect(), pois este elemento está associado ao tipo “retângulo.” Os diversos tipos de elemento são:Texto: element_text().Texto: element_text().Retângulo: element_rect().Retângulo: element_rect().Linha: element_line().Linha: element_line().Branco ou vazio: element_blank().Branco ou vazio: element_blank().Você provavelmente está se perguntando o porquê da existência de um tipo de elemento “vazio.” O jornalista americano William Chase, apresentou um ditado na última conferência internacional RStudio, que representa bem o papel que este tipo de elemento tem cumprir ggplot. O ditado diz o seguinte:“O espaço em branco gráfico é como o alho que tempera sua comida. Pegue o tanto que você acha necessário, e então triplique essa quantidade.” William Chase, Glamour Graphics, rstudio::conf, 2020.noção de espaço, é muito importante seu gráfico, seja porque você tem itens que estão tomando muito espaço das formas geométricas que estão representando os seus dados gráfico, ou então, porque você quer tornar visão de seu gráfico mais leve (ou mais “dispersa”) para o leitor. Por isso, o elemento tipo “vazio” serve para eliminar elementos que são desnecessários em seu gráfico, dando assim, maior espaço para aqueles elementos que são de fato importantes.Ao longo dessa seção, estarei utilizando um mesmo gráfico, para exemplificar algumas das principais configurações possíveis em theme(). Para não repetir o código que gera o gráfico, toda vez que alterarmos algo nele, eu vou guardar este gráfico em um objeto que dou o nome de plot_exemplo. Dessa forma, toda vez que quiser alterar algum elemento gráfico, basta que eu adicione função theme() este objeto, onde o gráfico está guardado.","code":"\nplot_exemplo <- ggplot(data = penguins) +\n  geom_point(\n    aes(\n      x = flipper_length_mm,\n      y = body_mass_g,\n      color = species\n    )\n  ) +\n  labs(\n    title = \"Relação entre peso e comprimento da nadadeira \n    em diferentes\\nespécies de pinguim\",\n    x = \"Comprimento da nadadeira\",\n    y = \"Peso corporal\",\n    color = \"Espécie\"\n  )\n\nprint(plot_exemplo)"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"eliminando-elementos-do-gráfico","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.3 Eliminando elementos do gráfico","text":"Como eu disse, você muitas vezes vai querer eliminar elementos desnecessários e que estão tomando muito espaço de seu gráfico. Para esta tarefa, basta utilizar element_blank() sobre o argumento de theme() que controla este elemento em questão. exemplo abaixo, estou eliminando o título da legenda, que é controlada por legend.title, e também estou eliminando o título eixo y com axis.title.y.","code":"\nplot_exemplo +\n  theme(\n    legend.title = element_blank(),\n    axis.title.y = element_blank()\n  )"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"alterando-a-temática-de-textos","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.4 Alterando a temática de textos","text":"Você possui diversos elementos textuais em seu gráfico, logo abaixo, na figura 9.1, estou relacionando cada elemento textual ao seu respectivo argumento em theme(). Vale ressaltar, que há outros elementos textuais, como o subtítulo gráfico, que não está presente em nosso plot_exemplo. Portanto, até os próprios valores eixo são tratados como textos gráfico. Como mencionei antes, você precisa da função element_text() para configurar este tipo de elemento.\nFigure 9.1: Principais elementos textuais gráfico e seus respectivos argumentos na função theme()\nVamos pensar primeiro título, que é uma parte importante de seu gráfico e que deve possuir algum tipo de destaque. Por enquanto, o único fator que destaca o título gráfico dos outros elementos textuais, é o tamanho da fonte usada. Porém, e se quiséseemos adicionar outros fatores de destaque? Como por exemplo, utilizar uma fonte em itálico, ou em negrito.O argumento de theme() responsável por controlar o título gráfico, é o plot.title, e portanto, utilizo função element_text() sobre este argumento, para acrescentarmos novos destaques este título. O argumento de element_text() que afeta o estilo da fonte (negrito, itálico, etc.) é o face. exemplo abaixo, eu dou o valor \"italic\" indicando função que use o estilo itálico sobre o título:Eu posso também destacar outras áreas gráfico, como o título da legenda, que é controlado pelo argumento legend.title. Eu costumo reduzir o tamanho deste título, e colocá-lo em negrito, e para isso, utilizo os argumentos size e face. Para colocar algum texto em negrito, você deve utilizar o valor \"bold\", em face. Eu poderia inclusive, colocar este texto em itálico e negrito (para isso, você deve utilizar o valor \"bold.italic\").Vale também destacar, que o argumento size, trabalha por padrão com unidade milímetros (mm). Porém, como é um pouco contraintuitivo trabalhar com tamanho de fontes nesta unidade, eu costumo transformá-la para pontos (pt). Para isso, o ggplot oferece uma variável (.pt) que já contém o valor necessário para essa transformação. Assim, o que você precisa fazer é colocar o valor em pontos (pt) desejado, e dividí-lo por essa variável (.pt), que contém o valor necessário para conversão. exemplo abaixo, estou reduzindo o título da legenda ao tamanho 26 pt.Além destas modificações, você talvez queira mudar o alinhamento título gráfico. Atualmente, você pode reparar que este título está alinhado à esquerda gráfico, ou em outras palavras, está alinhado em relação borda esquerda gráfico.Neste caso, estou referindo ao alinhamento horizontal título, e por isso, utilizo o argumento hjust. Este argumento funciona da mesma forma em que o vimos anteriormente, ele pega um número de 0 1. Sendo que o valor 0 representa o alinhamento totalmente à esquerda, o valor 0.5 centraliza o texto, e o valor 1 representa o alinhamento totalmente à direita. exemplo abaixo, estou centralizando o título gráfico.Um outro ponto, que talvez seja de seu interesse, é alterar o espaço entre os elementos gráfico. Você pode controlar este fator, através da função margin(), sobre o argumento margin de element_text(). Dentro da função margin(), temos 4 argumentos que se referem bordas seu texto. Dito de outra forma, esses argumentos definem borda texto, na qual você deseja acrescentar o espaço: t (top) se refere ao topo texto; r (right) se refere à direita texto; l (left) se refere à esquerda texto; e b (bottom) se refere à base (ou borda inferior) texto.Por exemplo, podemos dar mais destaque ao título gráfico, ao adicionar um pouco mais de espaço entre ele e borda gráfico. Neste caso, o gráfico está abaixo título, logo, estamos querendo adicionar espaço na borda inferior (argumento b) título gráfico. Em seguida, basta que eu defina argumento, quanto de espaço eu desejo adicionar.","code":"\nplot_exemplo +\n  theme(\n    plot.title = element_text(face = \"italic\")\n  )\nplot_exemplo +\n  theme(\n    plot.title = element_text(face = \"italic\"),\n    legend.title = element_text(face = \"bold\", size = 26/.pt)\n  )\nplot_exemplo +\n  theme(\n    plot.title = element_text(face = \"italic\", hjust = 0.5),\n    legend.title = element_text(face = \"bold\", size = 26/.pt)\n  )\nplot_exemplo +\n  theme(\n    plot.title = element_text(\n      face = \"italic\",\n      hjust = 0.5,\n      margin = margin(b = 20)\n    ),\n    legend.title = element_text(face = \"bold\", size = 26/.pt)\n  )"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"plano-de-fundo-background-e-grid","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.5 Plano de fundo (background) e grid","text":"O tema padrão ggplot pode ser muito esquisito, ou simplesmente “feio” para muita gente. Um de seus elementos que mais recebem críticas, é o plano de fundo gráfico, que por padrão é colorido de cinza claro. Todos os argumentos de theme(), que controlam os elementos que se encontram plano de fundo, começam por panel.*. Você pode, por exemplo, alterar configurações gerais plano de fundo pelo argumento panel.background, que é associado ao tipo “retângulo” - element_rect().exemplo abaixo, estou alterando cor deste plano de fundo, para uma cor levemente “amarelada.” Lembra quando eu defini que o ggplot trata de forma distinta formas geométricas de área, onde se você quisesse preencher esta forma com uma cor, você deveria utilizar o argumento fill, ao invés de color? Aqui mesma coisa ocorre, pois o plano de fundo gráfico é associado um formato de área (retângulo).Por isso, se utilizar o color, você irá colorir apenas bordas gráfico, e não preencher o plano de fundo com uma cor. Em ambos argumentos, você pode fornecer um dos nomes de cor que o R consegue reconhecer (por exemplo, \"white\", \"black\")33, ou então, você pode fornecer um código HTML dessa cor.Se antes você não gostava cinza, você provavelmente esta gostando menos ainda dessa cor amarelada. Bem, neste caso podemos ficar então com o branco padrão, que está na grande maioria dos gráficos. linhas grid já estão na cor branca, por isso, podemos colorir também essas linhas para um cor diferente, de modo mantê-las visíveis.Apesar gráfico estar agora em um tema mais “padrão,” você talvez você ache estranho forma como linhas grid estão momento. Pois elas estão sem um “limite,” ou aparentam estar “invadindo” o espaço de outros elementos gráfico. Talvez o que você precise, seja marcar borda gráfico, para construir uma caixa, e definir estes limites grid. Tudo que você precisa fazer, é usar o color em panel.background, para colorir essas bordas.Um outro componente que faz parte gráfico, é o plano de fundo de toda área gráfico. Ou seja, toda área de sua tela que engloba os títulos, os valores, legendas e o espaço gráfico. Essa área é controlada pelo argumento plot.background. Não sei por que você faria isso, mas com esse argumento, você pode por exemplo, pintar toda área gráfico de azul claro.","code":"\nplot_exemplo +\n  theme(\n    panel.background = element_rect(fill = \"#fffab3\")\n  )\nplot_exemplo +\n  theme(\n    panel.background = element_rect(fill = \"white\"),\n    panel.grid = element_line(color = \"#d4d4d4\")\n  )\nplot_exemplo +\n  theme(\n    panel.background = element_rect(\n      fill = \"white\",\n      color = \"#222222\"\n    ),\n    panel.grid = element_line(color = \"#d4d4d4\")\n  )\nplot_exemplo +\n  theme(\n    panel.background = element_rect(\n      fill = \"white\",\n      color = \"#222222\"\n    ),\n    panel.grid = element_line(color = \"#d4d4d4\"),\n    plot.background = element_rect(fill = \"#abb3ff\")\n  )"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"eixos-do-gráfico","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.6 Eixos do gráfico","text":"Todos os elementos que se encontram nos eixos gráfico, são controlados pelos argumentos de theme() que se iniciam por axis.*. Você pode ver os argumentos que controlam cada um dos componentes eixo, pela figura abaixo.\nFigure 9.2: Elementos que compõe um eixo gráfico\ntema padrão ggplot, linha eixo (axis.line) já não aparece. Portanto, se você quiser eliminar completamente um eixo seu gráfico, você precisa apagar apenas os outros três componentes. Sendo este, um outro motivo de estranhamento de várias pessoas sobre o tema padrão ggplot. Por isso, talvez seja interessante para você incluir seu gráfico, linhas eixo, e para esse fim, basta redefinir o seu argumento (axis.line) com element_line().Um detalhe muito importante, é que função theme() possui tanto o argumento geral componente eixo (e.g. axis.line), que afeta ambos os eixos (x e y) ao mesmo tempo, quanto o argumento que afeta os eixos individualmente (e.g. axis.line.x e axis.line.y). Isso vale para todos os outros três componentes eixo, e portanto, caso você queira que modificação afete apenas um dos eixos, você deve utilizar os argumentos que possuem o eixo nome, ao invés dos argumentos gerais.Uma configuração que aplico com bastante frequência em meus gráficos, é escurecer os valores eixo (axis.text). Por padrão, os valores vem em um cinza claro, e por causa disso, leitura desses valores pode ficar muito prejudicada ao exportar esse gráfico, e incluí-lo em um artigo, informativo ou relatório que estou escrevendo. Desse modo, exemplo abaixo, além de reposicionar linhas dos eixos, eu também utilizo o argumento color em axis.text, para colorir esses valores com uma cor mais escura.Além dessas modificações, para garantir que o meu leitor consiga ler esses números, eu ainda aumento levemente o tamanho dos valores eixo, pelo argumento size. Como eu disse anteriormente, esse argumento trabalha, por padrão, com milímetros. Você pode novamente utilizar variável .pt para transformar esse valor para pontos (pt).","code":"\nplot_exemplo +\n  theme(\n    axis.line = element_line(size = 0.8, color = \"#222222\"),\n    axis.text = element_text(size = 11, color = \"#222222\")\n  )"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"configurações-temáticas-em-uma-legenda","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.7 Configurações temáticas em uma legenda","text":"legenda de seu gráfico, é um guia que lhe mostra como os elementos visuais percebidos em seu gráfico, se traduzem de volta aos valores observados em sua base de dados. Em outras palavras, é legenda que mapeia cores, formas e tamanhos dos elementos de seu gráfico, de volta aos valores apresentados em sua base de dados (Wilkinson 2005; Wickham 2016). Sem legenda, nós não sabemos qual o valor que cor vermelha em nosso gráfico se refere, nem quanto o tamanho de um objeto, representa em nível de uma variável numérica.\nFigure 9.3: Itens que compõe uma legenda\nTemos na figura 9.3, os componentes de uma legenda em um gráfico ggplot, e os seus respectivos argumentos em theme(). Há outros argumentos relacionados em theme(), como legend.text.align, legend.margin e legend.position, que não afetam temática de algum componente específico da legenda, mas sim, o alinhamento de certos componentes, ou margem da legenda em relação ao gráfico, ou posição geral da legenda.Como exemplo, podemos preencher o plano de fundo da legenda com alguma cor específica em legend.background (argumento fill), assim como podemos contornar bordas dessa legenda com alguma outra cor (argumento color). Podemos alterar o alinhamento texto da legenda, ou mais especificamente, os rótulos de cada item da legenda, através de legend.text.align, ao fornecermos um número entre 0 (alinhado totalmente à esquerda) e 1 (alinhado totalmente à direita). Também podemos utilizar função element_text() em legend.title, para alterarmos fonte (argumento family), o tamanho (argumento size) o estilo da fonte (argumento face: bold - negrito, italic - itálico, bold.italic - negrito e itálico), e inclusive cor (argumento color) utilizada título dessa legenda.Além dessas configurações, possuímos um bom controle sobre posição da legenda ao longo da área gráfico, através argumento legend.position. Por padrão, toda legenda gerada pelo ggplot, será posicionada à direita gráfico, entretanto, esse padrão tende ocupar muito espaço gráfico, por isso eu particularmente prefiro posicionar minhas legendas, na parte inferior gráfico. Para isso podemos fornecer o valor bottom ao argumento. O argumento legend.position, aceita outros quatro valores pré-definidos: top (topo gráfico); left (esquerda gráfico); right (direita gráfico); none (nenhum local gráfico).Você pode utilizar o valor pré-definido none em legend.position, para eliminar completamente legenda gráfico. Isso é uma boa forma de aumentar o espaço gráfico, porém, você elimina uma fonte importante de informação, portanto, considere com cuidado se informações dispostas em sua legenda, são irrelevantes para o seu gráfico. Para além das posições pré-definidas, podemos inclusive posicionar nossa legenda, para dentro gráfico, através de legend.position. Para isso, você precisa fornecer dentro de um vetor, posição (x, y) plano cartesiano em que você deseja centralizar sua legenda, de acordo com um valor entre 0 e 1. Você pode interpretar esse sistema, como percentis da distribuição dos valores presentes eixo. Ou seja, se você fornecer o vetor c(0.1, 0.9), legenda será posicionada 10° percentil da escala eixo x, e 90° percentil da escala eixo y.Para mais, temos algumas outras configurações possíveis sobre margem da legenda em relação à area gráfico, através argumento legend.margin e da função margin(). Ou seja, nós podemos afastar legenda da área gráfico, ou da base gráfico. Em outras palavras, nós podemos adicionar espaço na base (b), topo (t), à direita (r), ou à esquerda (l) da legenda, através da função margin().Por último, nós também podemos configurar os itens da legenda, através argumento legend.key. Neste argumento, você possui todas opções de customização oferecidas pela função element_rect(). Além de preencher o plano de fundo dos itens (argumento fill), ou de criar uma borda (argumento color), também temos opção de alterar o tamanho desses itens (argumento size).","code":"\nplot_exemplo + theme(\n  legend.background = element_rect(fill = \"#cffff0\", color = \"black\"),\n  legend.text.align = 0.5,\n  legend.title = element_text(face = \"bold\", color = \"#008059\"),\n)## Warning: Removed 2 rows containing missing values (geom_point).\nplot_exemplo + theme(\n  legend.position = \"bottom\"\n)## Warning: Removed 2 rows containing missing values (geom_point).\nplot_exemplo + theme(\n  legend.position = \"none\"\n)## Warning: Removed 2 rows containing missing values (geom_point).\nplot_exemplo + theme(\n    legend.position = c(0.1, 0.8)\n)## Warning: Removed 2 rows containing missing values (geom_point).\nplot_exemplo + theme(\n  legend.margin = margin(l = 90, b = 70)\n)## Warning: Removed 2 rows containing missing values (geom_point).\nplot_exemplo + theme(\n  legend.key = element_rect(fill = \"#c4e2ff\", color = \"black\")\n)## Warning: Removed 2 rows containing missing values (geom_point)."},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"alterando-a-temática-em-facetas","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.8 Alterando a temática em facetas","text":"Quando você adiciona facetas um gráfico, você possui novos elementos que talvez sejam de seu interesse configurá-los. Por exemplo, o título de cada faceta, ou o plano de fundo desse título. Todos os argumentos de theme() que controlam elementos das facetas gráfico, começam por strip.*. exemplo abaixo, eu estou redefinindo cores interior e das bordas plano de fundo da faceta, além da cor título da faceta.","code":"\nplot_exemplo +\n  facet_wrap(~island, nrow = 3) +\n  theme(\n    strip.background = element_rect(color = \"#222222\", fill = \"#d1fff4\"),\n    strip.text = element_text(color = \"black\")\n  )"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"alterando-as-fontes-do-seu-gráfico","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.9 Alterando as fontes do seu gráfico","text":"Este é provavelmente o tópico de maior interesse para você ao customizar os seus gráficos, pois você sabe muito bem o potencial impacto que tipografia pode gerar sobre ele. Eu separei uma seção para discutir apenas esse assunto, pois como você descobrirá bem cedo, inserir fontes de seu sistema (ou fontes customizadas) em seu gráfico pode ser uma dor de cabeça bem grande.Essa dificuldade ocorre em qualquer programa34, linguagem ou sistema que trabalha com diversos device’s gráficos, como é o caso R. Como comentamos na seção Exportando os seus gráficos ggplot, um device gráfico é engine que vai gerar o arquivo de imagem, onde o seu gráfico será guardado. Diferentes engine’s, geram um arquivo de tipo diferente, como .png, ou .jpeg, ou .tiff, ou um arquivo .pdf. Ou seja, cada um desses formatos de arquivo, utilizam um device gráfico diferente para construir o arquivo que irá guardar o seu gráfico.Antes de definirmos os problemas existentes, e explicar quais são os processos necessários, para que você possa utilizar qualquer fonte que esteja em sua máquina, em seus gráficos ggplot. Eu vou mostrar quais são três opções de fonte, que são garantidas de funcionar em seus gráficos ggplot, e em qualquer máquina. Essas três opções são:sans: Fonte Arial.sans: Fonte Arial.serif: Fonte Times New Roman.serif: Fonte Times New Roman.mono: Fonte Courier New.mono: Fonte Courier New.Portanto, em qualquer máquina que você estiver, você pode utilizar um desses três nomes (sans, serif e mono) para se referir uma dessas três fontes acima, em seu gráfico ggplot. Se você quer utilizar diferentes fontes ao longo dos dados mostrados em seu gráfico, você deve definir como essas fontes utilizadas, vão variar ao longo gráfico, através da função aes(). Mais especificamente, você deve utilizar o argumento family na função aes(), dentro das funções que estão desenhando os textos em seu gráfico, de acordo com os dados presentes em sua tabela, como funções geom_text() e geom_label(). Ou seja, não estamos falando tema gráfico, e sim dos pontos que representam os seus dados plano cartesiano. Um exemplo de uso dessa ideia, é mostrado logo abaixo.Neste momento, você deve pensar se você deseja variar fontes utilizadas ao longo gráfico, ou se você quer manter ela fixa, ou em outras palavras, que uma mesma fonte seja utilizada em todos os rótulos e textos dispostos gráfico. Se você quer variar fonte, você deve criar uma nova variável em sua tabela, contendo os nomes dessas fontes, e em seguida, conectar essa variável ao argumento family, dentro de aes(). Mas se você quer manter essa fonte fixa, basta fornecer o nome dela à family, fora de aes().Portanto, é dessa forma que podemos definir fonte utilizada nas funções geom que representam os nossos dados gráfico. Entretanto, para alterarmos fonte em elementos temáticos (elementos que não dizem respeito, ou que não estão diretamente conectados com os seus dados) gráfico, essas configurações devem ser realizadas dentro da função theme. Basta utilizarmos o argumento family presente em element_text(), e definirmos o nome da fonte que desejamos empregar.Um atalho útil, caso você deseja utilizar mesma fonte em todos os elementos temáticos gráfico, se trata argumento text (que se refere todos os elementos temáticos tipo “texto”) na função theme(), e definir com função element_text() fonte utilizada. Ou seja, basta adicionar seguinte estrutura dentro de theme(): text = element_text(family = <fonte>). Porém, caso você deseja utilizar uma fonte diferente em cada componente temático gráfico, você obrigatoriamente deve definir separadamente fonte ser utilizada, em cada argumento de theme() que corresponde esses componentes estéticos.","code":"\nset.seed(1)\ntab <- data.frame(\n  x = rnorm(100),\n  y = runif(100),\n  fonte = sample(\n    c(\"sans\", \"serif\", \"mono\"),\n    size = 100,\n    replace = TRUE\n  )\n)\n\n### Variar a fonte utilizada ao longo do gráfico\nggplot(tab) +\n  geom_text(\n    aes(x = x, y = y, family = fonte, label = fonte)\n  )\n### Ou mater a fonte fixa ao longo de todo o gráfico\nggplot(tab) +\n  geom_text(\n    aes(x = x, y = y, label = fonte),\n    family = \"serif\"\n  )\nggplot(tab) +\n  geom_point(aes(x = x, y = y)) +\n  labs(\n    title = \"Um título interessante\",\n    subtitle = \"Um subtítulo também interessante\"\n  ) +\n  theme(\n    plot.title = element_text(family = \"serif\"),\n    plot.subtitle = element_text(family = \"mono\"),\n    axis.text = element_text(family = \"serif\")\n  )"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"importando-novas-fontes-para-o-r","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"9.9.1 Importando novas fontes para o R","text":"“core text fonts just messy, differences operating systems font file formats name challenges.” (Pedersen 2020).Agora que vimos como implementar o que o ggplote o R oferecem já de “fábrica” ao usuário, vou explicar como podemos expandir para demais fontes presentes em sua máquina. Para isso, você irá precisar de pacotes que facilitam esse processo, sendo o principal deles, o extrafont. É importante destacar, que o métodos que vou explicar aqui, permite o uso apenas de fontes TrueType, ou em outras palavras, fontes onde o seu arquivo possui extensão .ttf. Tendo essas considerações em mente, se você não possui este pacote instalado seu computador, você deve rodar o comando abaixo.Uma das dificuldades uso de diferentes fontes R, é encontrar os arquivos dessas fontes. Pois forma e o local em que os arquivos dessas fontes estão guardados, varia ao longo dos sistemas operacionais. Além disso, também não há um padrão definido nome desses arquivos. Mais especificamente, existe uma forma de interpretarmos classes e famílias de cada fonte, porém, não há um padrão muito bem definido de como os arquivos dessas fontes deveriam ser nomeados para tal processo. Logo, os nomes dos arquivos dessa fonte, podem gerar incongruências e conflitos com os arquivos de outras fontes, e com isso, o R talvez não consiga diferenciar uma fonte da outra.Um outro grande problema, está fato de que cada device gráfico, possui em geral, exigências diferente quanto aos arquivos dessas fontes. Por exemplo, engines que produzem arquivos PDF, precisam obrigatoriamente de um arquivo .afm (Adobe Font Metrics File) para cada fonte utilizada, e você muito provavelmente não possui tal arquivo (Qiu 2015).Esses dois problemas podem ser resolvidos com o uso das funções provenientes pacote extrafont. Tendo isso em mente, primeira coisa que você deve fazer, sempre que definir localização de uma nova fonte que você acabou de baixar da internet, ou de uma fonte que já está instalada seu sistema operacional, é reiniciar o R. RStudio, você possui o atalho Ctrl + Shift + F10, ou então se preferir, você pode ir à aba Session, e escolher opção Restart R.Muitas vezes o processo que vamos executar seguir, falha de alguma forma caso você já tenha outros pacotes conectados sua sessão atual. Devido isso, é importante que você inicie o processo com uma sessão limpa. Após reiniciar o R, chame pelo pacote extrafont com função library().O que vamos fazer seguir, é “importar” fontes para uma base de dados, ou dito de outra forma, vamos guardar localização dos arquivos dessas fontes, em um local que seja de fácil acesso ao R. Logo, o papel que o pacote extrafont vai desempenhar, será construir uma planilha onde ele irá guardar localização desses arquivos, e diversas outras informações como o nome e classe de cada fonte. Assim, sempre que você precisar dessa fonte e chamar por ela, o R irá procurar pela localização dos arquivos dessa fonte, nessa base de dados criada por extrafont.Para executar esse passo, você deve utilizar função font_import(). Essa função procura automaticamente pelas fontes instaladas em seu sistema operacional. Eu trabalho com o Windows, que possui uma pasta específica onde ele guarda os arquivos de cada uma dessas fontes instaladas. Logo, ao rodar função font_import() Windows, ela irá procurar automaticamente por essa pasta. Mas caso função, por algum motivo não estiver encontrando essa pasta, você pode tentar definir o caminho até essa pasta, direcionando assim função. caso Windows, essa pasta fica na localização de seu computador definida abaixo.Ao rodar função font_import() console, ela irá lhe mostrar mensagem abaixo, perguntando se você deseja continuar o processo. Para continuar, basta enviar para o console, letra “y.” partir daí, função irá iniciar o processo, encontrando todas fontes disponíveis em seu sistema, e guardando informações dessas fontes.Ao terminar o processo, você terá definido localização dos arquivos e coletado informações necessárias da fonte, e você não precisará realizar novamente este processo, pois essas informações estão salvas na base de dados criada por extrafont. Você irá rodar novamente função font_import(), apenas caso em que você quiser adicionar uma nova fonte, que não estava instalada anteriormente em seu sistema.Apesar de já muito útil, você talvez queira mudar o comportamento da função font_import(), que vai procurar pelos arquivos presentes apenas na pasta principal de fontes de seu sistema operacional. Por exemplo, talvez você queira importar uma fonte que ainda não está instalada em seu computador, por exemplo, uma fonte que você acabou de baixar Google Fonts.Para essas ocasiões, eu recomendo que você instale essas fontes em seu sistema operacional, antes de prosseguir para os próximos passos. Após instalação, você pode utilizar novamente o argumento paths da função, onde você pode definir pasta na qual função irá procurar pelos arquivos dessas fontes (arquivos com extensão .ttf) que você acaba de instalar. Eu caso, recomendo que você crie uma pasta, e guarde nela todos os arquivos de fontes que você deseja importar. Por exemplo, eu tenho uma pasta onde guardo todas fontes que baixo Google Fonts, e portanto, caso eu queira importar uma nova fonte que eu acabei de baixar, para o R, eu coloco os arquivos dessa fonte dentro dessa pasta, e forneço o endereço dessa pasta para font_import().Portanto, após esse passo, onde importamos essas fontes para o R, fontes ainda não estão disponíveis para serem utilizadas ggplot. Você até o momento, guardou informações necessárias dessas fontes, mas ainda não forneceu essas informações ao R. Por isso, para utilizar fontes que você salvou, você deve rodar função loadfonts(), para “carregar” essas fontes para sua sessão atual R. É importante também destacar, que você deve sempre rodar essa função antes mesmo de chamar pelo pacote ggplot2, para evitar bugs indesejados.Ou seja, em toda sessão R, em que você estiver gerando um gráfico ggplot, e deseja utilizar alguma fonte que já esteja registrada na planilha de extrafont, você muito provavelmente terá que reiniciar o R, chamar pelo pacote extrafont, e carregar fontes salvas pela função loadfonts(), antes mesmo de chamar pelo pacote ggplot2 e de recriar o seu gráfico. Apesar deste processo não ser sempre necessário, ele é em geral opção mais segura. Após esse passo, você pode utilizar fonte desejada normalmente em seu gráfico de ggplot, basta se referir ela pelo seu nome nos argumentos family.Caso você não se lembre nome exato da fonte que deseja, ao executar função fonts(), você pode acessar uma lista que contém os nomes de todas fontes que foram importadas para sua sessão - através da função loadfonts(), e que portanto, estão disponíveis para uso em sua sessão.Depois desses passos, ao conseguir gerar o gráfico que você queria, utilizando fontes que você desejava, será provavelmente de seu desejo, salvar esse gráfico, exportá-lo para algum arquivo. Você pode fazer isso normalmente pelos métodos que mostramos na seção Exportando os seus gráficos ggplot, especialmente se você escolher exportar o seu gráfico, para algum tipo de arquivo bitmap, ou uma imagem tipo raster (arquivos PNG, JPEG/JPG, BMP ou TIFF). Porém, se você escolheu exportar o seu gráfico para um arquivo PDF, você talvez enfrente alguns problemas, como suas fontes desaparecerem resultado!. Nós mostramos na seção Arquivos PDF e SVG, como resolver esse problema, que envolve o uso da função cairo_pdf().","code":"\ninstall.packages(\"extrafont\")\nlibrary(extrafont)### Pasta do Windows que contém\n### as fontes instaladas em seu sistema\nC:\\Windows\\Fonts\n\n### Basta fornecer este endereço no\n### argumento paths de font_import()\nfont_import(paths = \"C:/Windows/Fonts\")Importing fonts may take a few minutes, depending on the number\nof fonts and the speed of the system.\nContinue? [y/n] \nfont_import(paths = \"C:/Users/Pedro/Downloads/Google Fonts\")\nlibrary(extrafont)\nloadfonts()\n\nlibrary(ggplot2)\n\n### O meu gráfico\nggplot(mpg) +\n  geom_point(aes(x = displ, y = hwy)) +\n  theme(\n    text = element_text(family = \"Segoe UI\"),\n    plot.title = element_text(face = \"bold\")\n  ) +\n  labs(\n    title = \"Relação entre o volume do cilindro e o consumo de combustível\",\n    subtitle = \"Baseado em uma amostra de 234 veículos\"\n  )"},{"path":"configurando-componentes-estéticos-do-gráfico-no-ggplot2.html","id":"exercícios-7","chapter":"Capítulo 9 Configurando componentes estéticos do gráfico no ggplot2","heading":"Exercícios","text":"Questão 9.1. Voltando ao gráfico salvo objeto plot_exemplo, o qual utilizamos ao longo de todo este capítulo. Seu objetivo nessa questão é criar um objeto tema que seja capaz de aproximar plot_exemplo o máximo possível gráfico abaixo.Questão 9.2. Em cada item abaixo, vamos utilizar novamente o gráfico salvo objeto plot_exemplo. Esses itens vão lhe questionar sobre algum erro específico, ou, lhe requisitar.9.2.) Faça legenda gráfico plot_exemplo desaparecer.9.2.B) Identifique porque o erro abaixo ocorre, e tente corrigí-lo.9.2.C) Contorne área grid (isto é, área em que formas geométricas gráfico são desenhadas pela função geom_*()) por uma linha de cor \"#222222\".","code":"\nlibrary(ggplot2)\nlibrary(palmerpenguins)\n\nplot_exemplo <- ggplot(data = penguins) +\n  geom_point(\n    aes(\n      x = flipper_length_mm,\n      y = body_mass_g,\n      color = species)\n  ) +\n  labs(\n    title = \"Relação entre peso e comprimento da nadadeira \n    em diferentes\\nespécies de pinguim\",\n    x = \"Comprimento da nadadeira\",\n    y = \"Peso corporal\",\n    color = \"Espécie\"\n  )\n\n\ntema <- theme(\n  # Coloque as específicações necessárias\n  # para que plot_exemplo se torne\n  # o gráfico abaixo\n)\n\nplot_exemplo + tema## Warning: Removed 2 rows containing missing values (geom_point).\nplot_exemplo +\n  theme(\n    text = element_text(color = \"#6E1450\"),\n    panel.grid = element_rect(fill = \"#6E1450\")\n  )"},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"manipulação-e-transformação-de-strings-com-stringr","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"Capítulo 10 Manipulação e transformação de strings com stringr","text":"","code":""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"sec:stringr_capitulo","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.1 Introdução e pré-requisitos","text":"Neste capítulo, vamos aprender mais sobre operações especializadas em dados textuais (dados tipo character), ou como são mais comumente denominados em programação, strings. Esse capítulo também oferece uma introdução um dos principais e mais importantes tópicos em processamento de texto, expressões regulares (regular expression), ou regex como é mais conhecida. Para aplicarmos diversas operações expostas, vamos utilizar funções disponíveis pacote stringr. Esse pacote está incluso tidyverse, logo, para ter acesso às funções apresentadas, você pode chamar pelo tidyverse ou pacote stringr diretamente, por meio comando library().","code":"\nlibrary(stringr)\nlibrary(tidyverse)"},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"algumas-noções-básicas","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.2 Algumas noções básicas","text":"Textos ou strings R, são criados ao contornarmos um determinado texto por aspas (duplas - \", ou simples - '), e cada letra, espaço, símbolo ou número que compõe esse texto, é comumente denominado de caractere. Caso você se esqueça de fechar o par de aspas que contorna o seu texto, o R vai esperar até que você complete expressão. Ou seja, em seu console, estaria acontecendo algo parecido com o que está abaixo. Lembre-se que você pode apertar tecla Esc, para abortar operação, caso você não consiga completá-la.Como aspas são responsáveis por delimitar esse tipo de dado, para que você possa incluir esse caractere em alguma cadeia de texto, você tem duas alternativas: 1) se você está contornando o texto com aspas duplas, utilize aspas simples, ou vice-versa; 2) contornar o comportamento especial das aspas, ao posicionar uma barra inclinada esquerda antes de cada aspa (\\\" ou \\').Além disso, textos podem incluir diversos outros caracteres especiais. Sendo os principais exemplos, os caracteres de tabulação (\\t), e de quebra de linha (\\n). Entretanto, uma quantidade muito grande desses caracteres especiais, podem dificultar nossa compreensão conteúdo presente em um texto. Logo, há vários momentos em que desejamos visualizar o texto representado em um string de maneira “crua.” Para isso, podemos aplicar função writeLines() sobre o texto em questão.Outro exemplo clássico de caracteres especiais, que são muito encontrados em páginas da internet (e.g. dados coletados em operações de web scrapping), são os códigos hexadecimais ou code points correspondentes uma determinada letra presente sistema Unicode. Descrevemos brevemente na seção Um pouco sobre fontes, encoding e tipografia, importância Unicode para universalização dos sistemas de encoding, e consequentemente, para internacionalização de conteúdo.Cada caractere sistema Unicode, é representado por um unicode code point (Haralambous 2007). Em resumo, um code point é um número inteiro que pode identificar unicamente um caractere presente sistema Unicode. Porém, caracteres que são codificados nesse sistema, são normalmente representados pelo código hexadecimal que equivale ao seu respectivo code point. Logo, ao invés de um número específico, você normalmente irá encontrar em strings, códigos que se iniciam por \\u, ou \\U, ou ainda U+, seguidos por uma combinação específica de letras e números. Como exemplo, os códigos hexadecimais abaixo equivalem aos code points que formam palavra “Arigatōgozaimashita,” ou “Muito obrigado” em japonês.Um outro ponto muito importante em strings está uso de barras inclinadas à esquerda. Nós já vimos na seção Definindo endereços disco rígido R, que para representarmos uma barra inclinada à esquerda em um string R, precisarmos duplicar essa barra. Logo, em strings, sequência \\\\ significa para o R \\. Existem alguns comandos e caracteres especiais que não requerem essa prática, como o comando que forma um Unicode code point (como demonstrado acima), que sempre se inicia por uma letra “u” antecedida por uma barra inclinada à esquerda (ex: \\u3042). Um outro exemplo são os comandos para tabulações e quebra de linha que acabamos de mostrar (\\t e \\n). Entretanto, essas excessões são minoria. Portanto, tenha esse cuidado ao utilizar barras inclinadas à esquerda em seus strings.","code":"> x <- \"Olá eu sou Pedro!\n+ \n+ \n\"Olá! Esse é um texto qualquer\"## [1] \"Olá! Esse é um texto qualquer\"\n\"Para incluir aspas ('') em um string\"## [1] \"Para incluir aspas ('') em um string\"\n\"Será que \\\"alienígenas\\\" existem de fato?\"## [1] \"Será que \\\"alienígenas\\\" existem de fato?\"\ntexto <- \"Receita:\\n\\t\\t2 ovos\\n\\t\\t3 copos e meio de farinha\n\\t\\t2 copos de achocolatado\\n\\t\\t1 copo de açúcar\\n\\t\\tMeio copo de óleo\n\\t\\t1 colher (de sopa) de fermento\n\\t\\t1 colher (de café) de bicabornato de sódio\\n\\t\\t...\"\nwriteLines(texto)## Receita:\n##      2 ovos\n##      3 copos e meio de farinha\n##      2 copos de achocolatado\n##      1 copo de açúcar\n##      Meio copo de óleo\n##      1 colher (de sopa) de fermento\n##      1 colher (de café) de bicabornato de sódio\n##      ...\ntexto <- \"Será que \\\"alienígenas\\\" existem de fato?\"\nwriteLines(texto)## Será que \"alienígenas\" existem de fato?\nx <- \"\\u3042\\u308a\\u304c\\u3068\\u3046\\u3054\\u3056\\u3044\\u307e\\u3057\\u305f\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"concatenando-ou-combinando-strings-com-paste-e-str_c","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.3 Concatenando ou combinando strings com paste() e str_c()","text":"Concatenar, significa unir diferentes valores. Porém, essa união pode ocorrer de diferentes maneiras, e como ela ocorre, tende depender das funções que você utiliza, como você configura, e com quais tipos de estruturas você está trabalhando. Com isso, eu quero destacar, que o termo concatenar, pode se referir muitas coisas (ou operações) diferentes. Na linguagem R, uma das principais operações de concatenação está presente na formação de vetores atômicos, mais especificamente, uso da função c() (abreviação para combine), que introduzimos na seção de Vetores.O papel da função c() é criar uma sequência partir de um conjunto de valores. Essa sequência de valores, é o que forma um vetor, e é o que estabelece uma relação de dependência ou de união entre esses valores, pois os torna parte de uma mesma estrutura. Cada um deles possuem uma ordem, ou uma posição dentro dessa sequência, mas nenhum deles é capaz de gerar essa sequência sozinho.Entretanto, ao concatenarmos textos, nós geralmente estamos nos referindo uma operação um pouco diferente. Tradicionalmente, ao concatenarmos um conjunto de textos, nós já possuímos um vetor (ou mais vetores) em nossas mãos, e desejamos unir cada elemento, ou cada texto contido nesse vetor, de alguma forma lógica. Dentre os pacotes básicos R, principal função que realiza esse tipo de operação, é função paste(). Um detalhe importante sobre essa função, é que ela converte, por padrão, qualquer tipo de input que você fornecer ela, para o tipo character. Logo, você pode incluir dados numéricos ou de qualquer outro tipo nos input’s dessa função.forma como função paste() realiza essa união entre os textos, depende diretamente de como você configura os argumentos da função, sep e collapse, e de quais input’s você fornece à função. Se você está fornecendo um único input à função, é certo que você está preocupado apenas com o argumento collapse (em outras palavras, sep é irrelevante nesse caso). Em resumo, o argumento collapse define qual o texto que irá separar os diferentes elementos input que você forneceu função. Em outras palavras, se o input que fornecemos é, por exemplo, um vetor de textos, ao definirmos o argumento collapse, estamos pedindo à paste() que junte todos os diferentes elementos vetor, dentro de um único texto, separando-os pelo texto que você definiu argumento collapse.Por exemplo, se eu possuo o vetor vec abaixo, e utilizo função paste() sobre ele, veja o que ocorre ao definirmos o argumento collapse. Perceba exemplo abaixo, que todos os elementos vetor vec, foram unidos dentro de um mesmo texto, onde cada um desses elementos são separados pelo texto \" : \" que definimos argumento collapse.Portanto, o texto que você define em collapse, será o texto que vai separar cada um dos elementos vetor que você fornece como input à função paste(). Por padrão, o argumento collapse é setado para nulo (NULL). Isso significa, que se você não definir algum texto para o argumento collapse, nada acontece ao aplicarmos função paste() sobre o vetor. Como o argumento sep é irrelevante para um único input, se você não está interessado nesta operação que ocorre ao definirmos collapse, função paste() não é o que você está procurando.Por outro lado, se você está fornecendo dois ou mais inputs à função paste(), é provável que você esteja interessado em definir apenas o argumento sep, apesar de que o argumento collapse pode também ser útil para o seu caso. Ao fornecermos dois ou mais vetores como inputs, função paste(), por padrão, tenta unir os elementos desses vetores, de forma produzir um novo vetor de texto. Por exemplo, se eu forneço dois vetores à função paste(), como os vetores vec e id abaixo, o primeiro elemento vetor resultante de paste() vai possuir os textos presentes primeiro elemento de ambos os vetores.O argumento sep é responsável por definir o texto que vai separar os valores de diferentes input’s da função paste(). Perceba exemplo acima, os valores dos vetores id e vec, estão todos separados por um espaço em branco. Isso significa, que por padrão, o argumento sep é configurado como um espaço em branco (\" \"), e portanto, você não precisa definir o argumento sep, caso você deseja separar esses valores por um espaço. Mas se há interesse em um texto diferente, para separar esses valores, você deve definí-lo através argumento sep. Por exemplo, você talvez deseja que não haja espaço algum entre esses valores, como exemplo abaixo.Assim sendo, em uma representação visual, podemos identificar os papéis dos argumentos sep e collapse da forma apresentada na figura 10.1.\nFigure 10.1: Resumo dos papéis desempenhados pelos argumentos sep e collapse em paste()\nPorém, na maioria das aplicações práticas dessa função, pelo menos um dos input’s fornecidos será constante. Por exemplo, uma situação muito comum de uso dessa função, é construção de caminhos (ou paths) para diferentes arquivos. Essa é exatamente aplicação que utilizamos na seção Um estudo de caso: uma demanda real sobre distribuição de ICMS.Nessa seção, em uma das primeiras etapas descritas, precisávamos ler ao todo 12 planilhas diferentes, e como descrevemos capítulo 3, para importarmos qualquer arquivo, nós precisamos fornecer o caminho até esse arquivo para o R. Com isso, teríamos tarefa tediosa de construirmos 12 caminhos diferentes (imagine se fossem 36, ou 320 planilhas diferentes serem lidas). Porém, como todas essas planilhas se encontravam dentro mesmo diretório de meu computador, eu aproveitei dessa regularidade, para fabricar esses caminhos de uma maneira prática, através da função paste().Lembre-se, que inicialmente tínhamos apenas os nomes dessas planilhas contidos objeto planilhas (que está replicado abaixo).Para criarmos o endereço até cada uma dessas planilhas, necessitávamos juntar o caminho até o diretório em que elas se encontravam (\"planilhas/\"), ao seus nomes. Com isso, podemos utilizar função paste() da seguinte maneira. Perceba que dois input’s foram fornecidos função: o primeiro, conciste apenas texto \"planilhas/\"; o segundo, são os nomes das planilhas contidos objeto planilhas. Além disso, repare que pelo fato de que o texto \"planilhas/\" ser “constante,” paste() acaba replicando ele para todos os 12 nomes presentes objeto planilhas.Você talvez tenha percebido, especialmente durante o capítulo 4, que temos uma variante da função paste(), chamada paste0(). Essa irmã, nada mais é que um atalho para função paste(), que utiliza por padrão, configuração sep = \"\". Ou seja, em todas ocasiões em que você estiver concatenando textos de diferentes input’s com função paste(), e deseja utilizar nenhum espaço como separador entre os valores de cada input, você pode rapidamente executar essa ação por meio da função paste0().","code":"\nvec <- c(\"a\", \"b\", \"c\", \"d\", \"e\")\n\nconc_vec <- paste(vec, collapse = \" : \")\n\nconc_vec## [1] \"a : b : c : d : e\"\n## --------------------------\n## Um outro exemplo:\nnomes <- c(\"Ana\", \"Fabrício\", \"Eduardo\", \"Mônica\")\n\nmensagem <- paste(nomes, collapse = \" e \")\n\nmensagem## [1] \"Ana e Fabrício e Eduardo e Mônica\"\nid <- 1:5\nvec <- c(\"a\", \"b\", \"c\", \"d\", \"e\")\n\nconc_vec <- paste(id, vec)\n\nconc_vec## [1] \"1 a\" \"2 b\" \"3 c\" \"4 d\" \"5 e\"\nid <- 1:5\nvec <- c(\"a\", \"b\", \"c\", \"d\", \"e\")\n\nconc_vec <- paste(id, vec, sep = \"\")\n\nconc_vec## [1] \"1a\" \"2b\" \"3c\" \"4d\" \"5e\"\nplanilhas <- list.files(\"planilhas/\")\n\nplanilhas##  [1] \"Abril_2019.xlsx\"     \"Agosto_2019.xlsx\"    \"Dezembro_2019.xlsx\" \n##  [4] \"Fevereiro_2019.xlsx\" \"Janeiro_2019.xlsx\"   \"Julho_2019.xlsx\"    \n##  [7] \"Junho_2019.xlsx\"     \"Maio_2019.xlsx\"      \"Marco_2019.xlsx\"    \n## [10] \"Novembro_2019.xlsx\"  \"Outubro_2019.xlsx\"   \"Setembro_2019.xlsx\"\ncaminhos <- paste(\"planilhas/\", planilhas, sep = \"\")\n\ncaminhos##  [1] \"planilhas/Abril_2019.xlsx\"     \"planilhas/Agosto_2019.xlsx\"   \n##  [3] \"planilhas/Dezembro_2019.xlsx\"  \"planilhas/Fevereiro_2019.xlsx\"\n##  [5] \"planilhas/Janeiro_2019.xlsx\"   \"planilhas/Julho_2019.xlsx\"    \n##  [7] \"planilhas/Junho_2019.xlsx\"     \"planilhas/Maio_2019.xlsx\"     \n##  [9] \"planilhas/Marco_2019.xlsx\"     \"planilhas/Novembro_2019.xlsx\" \n## [11] \"planilhas/Outubro_2019.xlsx\"   \"planilhas/Setembro_2019.xlsx\"\ncaminhos <- paste0(\"planilhas/\", planilhas)\n\ncaminhos##  [1] \"planilhas/Abril_2019.xlsx\"     \"planilhas/Agosto_2019.xlsx\"   \n##  [3] \"planilhas/Dezembro_2019.xlsx\"  \"planilhas/Fevereiro_2019.xlsx\"\n##  [5] \"planilhas/Janeiro_2019.xlsx\"   \"planilhas/Julho_2019.xlsx\"    \n##  [7] \"planilhas/Junho_2019.xlsx\"     \"planilhas/Maio_2019.xlsx\"     \n##  [9] \"planilhas/Marco_2019.xlsx\"     \"planilhas/Novembro_2019.xlsx\" \n## [11] \"planilhas/Outubro_2019.xlsx\"   \"planilhas/Setembro_2019.xlsx\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"a-função-str_c-como-uma-alternativa-para-concatenação-de-strings","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.3.1 A função str_c() como uma alternativa para concatenação de strings","text":"Por ser uma operação muito comum e útil, o pacote stringr nos oferece função str_c(), como uma alternativa à função paste(). Suas diferenças se restringem dois pontos. Primeiro, função str_c() foi escrita em C++, e consegue hoje, atingir uma maior eficiência se comparada função paste(), como demonstrado abaixo. Logo, str_c() pode oferecer uma vantagem considerável, caso você esteja trabalhando com um grande conjunto de textos.Segundo, temos também uma diferença importante sobre configurações nativas utilizadas por essas funções. Pois função str_c() adota  como sua configuração padrão para o argumento sep (se igualando assim, à função paste0()), ao invés de sep = \" \", que é o padrão adotado por paste(). Veja um exemplo abaixo.Para além dessas diferenças, função str_c() se comporta exatamente da mesma maneira que função paste(). Por isso, pode ser interessante que você adote essa função como o seu padrão para concatenação de textos, especialmente levando-se em conta, sua maior eficiência.","code":"\nlibrary(stringr)\nlibrary(microbenchmark)\ntexto <- sample(letters, size = 1e6, replace = TRUE)\n\nmicrobenchmark(\n  paste(texto, collapse = \"\"),\n  str_c(texto, collapse = \"\")\n)Unit: milliseconds\n                        expr      min       lq      mean\n paste(texto, collapse = \"\") 104.7202 107.8384 124.43956\n str_c(texto, collapse = \"\")  26.3803  26.9155  28.33062\n   median        uq      max neval\n 115.8264 129.90345 277.5362   100\n  27.1933  29.02705  33.3686   100\nstr_c(\"Dia\", 1:7)## [1] \"Dia1\" \"Dia2\" \"Dia3\" \"Dia4\" \"Dia5\" \"Dia6\" \"Dia7\"\nstr_c(\"Dia\", 1:7, sep = \" \")## [1] \"Dia 1\" \"Dia 2\" \"Dia 3\" \"Dia 4\" \"Dia 5\" \"Dia 6\" \"Dia 7\"\nstr_c(\"Dia\", 1:7, collapse = \"-\")## [1] \"Dia1-Dia2-Dia3-Dia4-Dia5-Dia6-Dia7\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"vantagens-do-pacote-stringr","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.4 Vantagens do pacote stringr","text":"Os pacotes básicos da linguagem R oferecem algumas ferramentas para trabalharmos com strings, como função paste() e família grep(). Porém, essas ferramentas são em grande parte, inconsistentes em seus nomes e formas e, por isso, são mais difíceis de se lembrar. Mesmo com essa consideração, eu decidi mostrar função paste() na seção anterior, pelo fato de que ela continua sendo uma função extremamente popular, e que você irá encontrar em todo lugar.De qualquer forma, partir de agora, vamos focar apenas nas funções pacote stringr. funções desse pacote, são em geral, mais rápidas que funções ofertadas pelos pacotes básicos. Além disso, os nomes de todas funções pacote stringr começam pela sequência str_*(), o que facilita muito sua memorização de cada função.","code":""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"comprimento-de-strings-com-str_length","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.5 Comprimento de strings com str_length()","text":"função str_length() lhe permite contabilizar o número de caracteres presentes em um string. Essa função é extremamente útil, quando desejamos aplicar operações que se baseiam em uma determinada posição de um string, como extrair uma seção específica desse string. Perceba abaixo, que ao se deparar com valores NA, função nos retorna um valor NA correspondente. Repare também, pelo resultado quarto elemento, referente palavra “Partindo,” que espaços em branco também são contabilizados como caracteres, portanto, fique atento este detalhe.","code":"\nvec <- c(\n  \"Fui ao Paraná, e encontrei o Varadá\",\n  \"Abril\", \n  \"!\",\n  \"Partindo \",\n  NA\n)\n\nstr_length(vec)## [1] 35  5  1  9 NA"},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"lidando-com-capitalização-e-espaços-em-branco","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.6 Lidando com capitalização e espaços em branco","text":"Diversas empresas que utilizam formulários, ou outros sistemas de registro, precisam estar constantemente corrigindo input’s fornecidos por seus usuários. Talvez, os erros mais comumente gerados, sejam uso da capitalização e de espaços em branco. Por exemplo, ao preenchermos formulários, é muito comum que: 1) esqueçamos tecla Caps Lock ligada; 2) ou simplesmente ignoramos o uso de capitalização por simplesmente estarmos com pressa para finalizar o formulário; 3) acrescentar espaços desnecessários ao final ou meio input.Como exemplo, suponha que você possua tabela usuarios. Repare que os valores da coluna cidade, variam bastante quanto ao uso da capitalização. Repare também, que em alguns valores na coluna nome, temos para além de problemas com capitalização, espaços em branco desnecessários, que vezes se encontram direita, ou esquerda, ou em ambos os lados nome.Excel, você normalmente utilizaria função ARRUMAR() para resolver os excessos de espaços, e funções MAIÚSCULA(), MINÚSCULA() e PRI.MAIÚSCULA() para alterar capitalização de todas letras de cada nome. Sendo funções str_trim(), str_to_upper(), str_to_lower() e str_to_title(), os seus equivalentes pacote stringr, respectivamente.Como os próprios nomes das funções str_to_upper() e str_to_lower() dão entender, elas convertem todos letras contidas em um vetor tipo character, para letras maiúsculas (upper) e minúsculas (lower). Por exemplo, ao aplicarmos essas funções sobre coluna cidade, temos o seguinte resultado:Por outro lado, função str_to_title() representa alternativa meio, ao converter primeira letra de cada palavra, para maiúsculo, e letras restantes, para minúsculo, como demonstrado abaixo:Quanto ao excedente de espaços na coluna nome, podemos aplicar função str_trim(). Por padrão, essa função retira qualquer espaço remanescente em ambos os lados de seu string. Mas caso seja de seu desejo, você pode especificar um lado específico para retirar espaços, por meio argumento side, que aceita os valores \"\", \"left\" ou \"right\".Vale destacar também, que str_trim() é capaz apenas de remover excessos de espaços que se encontram ao redor de seu texto. Logo, forma mais direta de resolvermos esse tipo de excesso, seria utilizarmos o método mais “abrangente” da função str_trim(), aplicado pela função str_squish(). Além de remover os espaços ao redor da palavra, função str_squish() também é capaz de remover espaços repetidos que se encontram entre palavras. Veja abaixo, o exemplo texto \"  São Carlos de   Santana   \".","code":"\nusuarios <- tibble(\n  nome = c(\"Ana\", \" Eduardo\", \" Cláudio   \", \"VerÔNiCA \",\n           \"  hugo    \", \"JULIANA\", \"  Vitor de paula   \"),\n  cidade = c(\"BELÉM\", \"goiânia\", \"são paulo\", \"São paulo\", \"SÃO pAULO\",\n             \"rIO DE janeiro\", \"rio de janeiro\"),\n  profissao = c(\"Bióloga\", \"Biólogo\", \"Químico\", \"Socióloga\",\n                \"Administrador\", \"Administradora\", \"Economista\")\n)\n\nusuarios## # A tibble: 7 x 3\n##   nome                  cidade         profissao     \n##   <chr>                 <chr>          <chr>         \n## 1 \"Ana\"                 BELÉM          Bióloga       \n## 2 \" Eduardo\"            goiânia        Biólogo       \n## 3 \" Cláudio   \"         são paulo      Químico       \n## 4 \"VerÔNiCA \"           São paulo      Socióloga     \n## 5 \"  hugo    \"          SÃO pAULO      Administrador \n## 6 \"JULIANA\"             rIO DE janeiro Administradora\n## 7 \"  Vitor de paula   \" rio de janeiro Economista\nusuarios %>% \n  mutate(cidade = str_to_upper(cidade))## # A tibble: 7 x 3\n##   nome                  cidade         profissao     \n##   <chr>                 <chr>          <chr>         \n## 1 \"Ana\"                 BELÉM          Bióloga       \n## 2 \" Eduardo\"            GOIÂNIA        Biólogo       \n## 3 \" Cláudio   \"         SÃO PAULO      Químico       \n## 4 \"VerÔNiCA \"           SÃO PAULO      Socióloga     \n## 5 \"  hugo    \"          SÃO PAULO      Administrador \n## 6 \"JULIANA\"             RIO DE JANEIRO Administradora\n## 7 \"  Vitor de paula   \" RIO DE JANEIRO Economista\nusuarios %>% \n  mutate(cidade = str_to_lower(cidade))## # A tibble: 7 x 3\n##   nome                  cidade         profissao     \n##   <chr>                 <chr>          <chr>         \n## 1 \"Ana\"                 belém          Bióloga       \n## 2 \" Eduardo\"            goiânia        Biólogo       \n## 3 \" Cláudio   \"         são paulo      Químico       \n## 4 \"VerÔNiCA \"           são paulo      Socióloga     \n## 5 \"  hugo    \"          são paulo      Administrador \n## 6 \"JULIANA\"             rio de janeiro Administradora\n## 7 \"  Vitor de paula   \" rio de janeiro Economista\nusuarios %>% \n  mutate(cidade = str_to_title(cidade))## # A tibble: 7 x 3\n##   nome                  cidade         profissao     \n##   <chr>                 <chr>          <chr>         \n## 1 \"Ana\"                 Belém          Bióloga       \n## 2 \" Eduardo\"            Goiânia        Biólogo       \n## 3 \" Cláudio   \"         São Paulo      Químico       \n## 4 \"VerÔNiCA \"           São Paulo      Socióloga     \n## 5 \"  hugo    \"          São Paulo      Administrador \n## 6 \"JULIANA\"             Rio De Janeiro Administradora\n## 7 \"  Vitor de paula   \" Rio De Janeiro Economista\nusuarios <- usuarios %>% \n  mutate(nome = str_trim(nome))\n\nusuarios## # A tibble: 7 x 3\n##   nome           cidade         profissao     \n##   <chr>          <chr>          <chr>         \n## 1 Ana            BELÉM          Bióloga       \n## 2 Eduardo        goiânia        Biólogo       \n## 3 Cláudio        são paulo      Químico       \n## 4 VerÔNiCA       São paulo      Socióloga     \n## 5 hugo           SÃO pAULO      Administrador \n## 6 JULIANA        rIO DE janeiro Administradora\n## 7 Vitor de paula rio de janeiro Economista\nstr_trim(\"  São Carlos de   Santana   \")## [1] \"São Carlos de   Santana\"\nstr_squish(\"  São Carlos de   Santana   \")## [1] \"São Carlos de Santana\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"extraindo-partes-ou-subsets-de-um-string-com-str_sub","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.7 Extraindo partes ou subsets de um string com str_sub()","text":"Para extrairmos partes de um string, podemos utilizar função str_sub(), que se baseia na posição dos caracteres que delimitam o intervalo que você deseja capturar. Ou seja, nessa função, precisamos definir posições dos caracteres que iniciam e terminam o intervalo que estamos extraindo. Como exemplo, eu posso extrair primeiro ao quarto caractere de cada texto presente na coluna nome, da seguinte maneira:De forma semelhante, podemos extrair terceiro ao quinto caractere dessa mesma coluna, de acordo com o seguinte comando:Além desses pontos, vale esclarecer que os textos inclusos em seu vetor, não precisam obrigatoriamente se encaixar intervalo de caracteres que você delimitou. Por exemplo, veja abaixo que eu forneci um vetor contendo dois nomes (Ana e Eduardo), um possui 3 caracteres, enquanto o outro, possui 7. Logo, ao pedir à str_sub(), que retire primeiro ao sexto caractere de cada texto contido vetor, função vai tentar extrair o máximo de caracteres possíveis que se encaixam nesse intervalo. Mesmo que algum desses textos não encaixe por completo nesse intervalo.","code":"\nusuarios %>% \n  mutate(parte = str_sub(nome, start = 1, end = 4))## # A tibble: 7 x 4\n##   nome           cidade         profissao      parte\n##   <chr>          <chr>          <chr>          <chr>\n## 1 Ana            BELÉM          Bióloga        Ana  \n## 2 Eduardo        goiânia        Biólogo        Edua \n## 3 Cláudio        são paulo      Químico        Cláu \n## 4 VerÔNiCA       São paulo      Socióloga      VerÔ \n## 5 hugo           SÃO pAULO      Administrador  hugo \n## 6 JULIANA        rIO DE janeiro Administradora JULI \n## 7 Vitor de paula rio de janeiro Economista     Vito\nusuarios %>% \n  mutate(parte = str_sub(nome, start = 3, end = 5))## # A tibble: 7 x 4\n##   nome           cidade         profissao      parte\n##   <chr>          <chr>          <chr>          <chr>\n## 1 Ana            BELÉM          Bióloga        a    \n## 2 Eduardo        goiânia        Biólogo        uar  \n## 3 Cláudio        são paulo      Químico        áud  \n## 4 VerÔNiCA       São paulo      Socióloga      rÔN  \n## 5 hugo           SÃO pAULO      Administrador  go   \n## 6 JULIANA        rIO DE janeiro Administradora LIA  \n## 7 Vitor de paula rio de janeiro Economista     tor\nstr_sub(c(\"Ana\", \"Eduardo\"), start = 1, end = 6)## [1] \"Ana\"    \"Eduard\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"aliando-str_sub-com-str_length-para-extrair-partes-de-tamanho-variável","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.7.1 Aliando str_sub() com str_length() para extrair partes de tamanho variável","text":"Talvez você se recorde, que nós utilizamos funções str_sub() e str_length anteriormente, mais especificamente, na seção Um estudo de caso: uma demanda real sobre distribuição de ICMS. Nessa seção, possuíamos um sistema que coletava o nome de cada planilha que importávamos para o R, e por que precisávams dessa informação? Porque o nome de cada planilha especificava o mês e o ano que os seus dados se referiam. Logo, os dados presentes na planilha Abril_2019.xlsx diziam respeito ao mês de Abril ano de 2019, e assim por diante.Portanto, ao final da coleta desses nomes, inseríamos esses nomes em uma coluna de nosso data.frame, tendo como resultado algo parecido com coluna origem, que se encontra na tabela periodo, e que pode ser recriada através dos comandos abaixo.Com essa informação, podíamos facilmente rastrear origem de cada linha de nossa tabela. Entretanto, mesmo com essa informação ainda não éramos capazes de para ordenarmos base de maneira útil. Pois da forma como informações são apresentadas na coluna origem, uma ordenação alfabética seria empregada sobre coluna. Logo, valores como Abril_2018.xlsx e Abril_2017.xlsx, viriam aparecer antes de valores como Março_2019.xlsx.Por isso, ainda tínhamos necessidade de extrair o mês e o ano desses nomes, e em seguida, alocar essas informações em colunas separadas. Com esse objetivo, utilizamos função str_sub() para extrairmos parte, ou seção de cada nome, que correspondia ao mês que ele se referia. Porém, como você pode ver acima, o número de caracteres presentes em cada mês, ou em cada nome, varia de maneira drástica.Em momentos como esse, você pode tentar identificar se parte final ou parte inicial dos textos inclusos em sua coluna, são de alguma maneira, constantes. Ou seja, mesmo que o número de caracteres varie muito ao longo da coluna, talvez exista uma parte específica desses textos que sempre possui mesma quantidade de caracteres.caso da coluna origem, temos três partes que são sempre constantes, que são parte dos anos (mesmo que os anos variem, eles sempre são formados por 4 números, ou 4 caracteres), parte da extensão arquivo (.xlsx), e o underscore (_), que sempre separa duas partes anteriores mês em cada nome. Somando os caracteres dessas três partes, temos sempre 10 caracteres ao final nome arquivo, ao qual podemos eliminar para chegarmos seção texto que contém o nome mês. Com isso, podemos utilizar função str_length() para calcular o número total de caracteres de cada texto, e subtrair 10 desse valor, para chegarmos ao caractere que delimita o fim mês em cada texto.Podemos empregar mesma linha de raciocínio, para chegarmos aos limites intervalo que contém o ano em cada texto. Contudo, tanto o limite inicial quanto o limite final desse intervalo, variam. Logo, teremos de utilizar o resultado de str_length() para descobrirmos os dois limites dessa seção. Como estamos empregando os valores produzidos por str_length() em três locais diferentes, eu guardo o resultado dessa função em uma coluna denominada num, para não ter o trabalho de digitar repetidamente função str_length().","code":"\nmeses <- c(\"Janeiro\", \"Fevereiro\", \"Março\", \"Abril\",\n           \"Maio\", \"Junho\", \"Julho\", \"Agosto\",\n           \"Setembro\", \"Outubro\", \"Novembro\", \"Dezembro\")\nmeses <- rep(meses, times = 6)\nanos <- rep(2015:2020, each = 12)\n\nperiodo <- tibble(\n  origem = str_c(str_c(meses, anos, sep = \"_\"), \".xslx\")\n)\n\nperiodo## # A tibble: 72 x 1\n##    origem             \n##    <chr>              \n##  1 Janeiro_2015.xslx  \n##  2 Fevereiro_2015.xslx\n##  3 Março_2015.xslx    \n##  4 Abril_2015.xslx    \n##  5 Maio_2015.xslx     \n##  6 Junho_2015.xslx    \n##  7 Julho_2015.xslx    \n##  8 Agosto_2015.xslx   \n##  9 Setembro_2015.xslx \n## 10 Outubro_2015.xslx  \n## # ... with 62 more rows\nperiodo %>% \n  mutate(\n    num = str_length(origem),\n    mes = str_sub(origem, start = 1, end = num - 10),\n    ano = str_sub(origem, start = num - 8, end = num - 5) %>% as.integer()\n  )## # A tibble: 72 x 4\n##    origem                num mes         ano\n##    <chr>               <int> <chr>     <int>\n##  1 Janeiro_2015.xslx      17 Janeiro    2015\n##  2 Fevereiro_2015.xslx    19 Fevereiro  2015\n##  3 Março_2015.xslx        15 Março      2015\n##  4 Abril_2015.xslx        15 Abril      2015\n##  5 Maio_2015.xslx         14 Maio       2015\n##  6 Junho_2015.xslx        15 Junho      2015\n##  7 Julho_2015.xslx        15 Julho      2015\n##  8 Agosto_2015.xslx       16 Agosto     2015\n##  9 Setembro_2015.xslx     18 Setembro   2015\n## 10 Outubro_2015.xslx      17 Outubro    2015\n## # ... with 62 more rows"},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"sec:stringr_regex","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8 Expressões regulares (ou regex) com str_detect()","text":"Expressões regulares (regular expressions), ou simplesmente regex, são uma ferramenta extremamente poderosa para processamento de texto. Por essa característica, praticamente toda linguagem de programação possui em algum nível, uma implementação dessa funcionalidade. Você talvez não saiba ainda, mas expressões regulares estão em todo lugar. Como exemplo, quando você pesquisa por uma palavra em um PDF, você está aplicando uma expressão regular ao longo arquivo.Em síntese, expressões regulares são como uma mini-linguagem que lhe permite descrever de maneira concisa, um pedaço de texto (Friedl 2006). Para utilizar uma expressão regular, você precisa utilizar uma função que possa aplicar esse tipo de mecanismo. Nos pacotes básicos R, essa funcionalidade está disponível através das funções da família grep() (sendo grep(), grepl() e gsub(), principais funções dessa família).Por outro lado, o pacote stringr oferece uma família um pouco maior de funções que são capazes de aplicar tal mecanismo. Sendo funções str_which(), str_detect(), str_replace() e str_split(), principais representantes dessa família.Em grande parte desse capítulo, estaremos utilizando função str_detect() como nossa ponte de acesso ao mundo das expressões regulares. Assim como todas funções str_*() que citamos parágrafo anterior, função str_detect() aceita um vetor contendo os textos serem pesquisados como primeiro argumento (string), e uma expressão regular como seu segundo argumento (pattern).função str_which() é praticamente idêntica à str_detect(). Pois ambas funções vão pesquisar pelos textos que são descritos pela expressão regular que você forneceu, e ambas funções vão gerar um vetor contendo índices, que definem quais foram os textos encontrados. Entretanto, funções se divergem tipo de resultado gerado. função str_which() nos retorna um vetor contendo índices numéricos. Em contrapartida, função str_detect() gera um vetor de valores lógicos. Portanto, você pode utilizar o resultado de ambas funções dentro da função de subsetting ([) para filtrar os textos encontrados, sendo única diferença, o tipo de índice empregado filtro.","code":""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"a-expressão-regular-mais-simples-de-todas","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.1 A expressão regular mais simples de todas","text":"maneira mais simples de utilizarmos uma expressão regular, seria pesquisarmos por uma sequência específica de letras. Por exemplo, suponha que eu possua o conjunto de palavras presentes em vec, e desejasse encontrar palavra “emissão.”Com o conhecimento que você já possui, você provavelmente tentaria algo como o comando abaixo para encontrar essa palavra.Porém, você também poderia encontrar essa palavra inclusa vetor vec, ao fornecer uma expressão regular que seja capaz de descrever o texto “emissão.” Em seu primeiro instinto, você provavelmente aplicaria o simples texto \"emissão\", todavia, como vemos abaixo, esse não é exatamente o resultado que desejamos.O erro acima, está fato de que estamos interpretando expressão regular \"emissão\", como palavra “emissão.” Você rapidamente irá descobrir, que expressões regulares não possuem qualquer noção que é uma palavra, muito menos de onde uma começa ou termina. Ou seja, quando estiver utilizando expressões regulares, menos que você defina explicitamente os limites físicos da pesquisa, o mecanismo estará procurando por uma sequência específica de caracteres, independente local em que essa sequência seja detectada.Por isso, é importante que você começe interpretar qualquer expressão regular, como uma descrição de uma sequência específica de caracteres, ao invés de uma palavra. Logo, quando fornecemos o texto \"emissão\" à str_detect() acima, estávamos na verdade, buscando qualquer texto que contesse os caracteres “e-m--s-s-ã-o,” precisamente nessa ordem. Com isso, palavra “demissão” foi incluída resultado acima, pelo fato de possuir tal sequência de caracteres, mesmo que essa sequência esteja acompanhada por um “d,” o qual não faz parte da expressão regular definida.Como um outro exemplo, suponha que eu utilize expressão \"\". Lembre-se que nós não estamos procurando pela palavra , mas sim, por qualquer texto que contenha um “” imediatamente seguido por um “s.” Marcando de negrito, apenas partes dos textos abaixo, que foram de fato encontradas pela expressão \"\", temos: satisfação, demissão, permissão, emissão, jurisdição.Porém, partir momento em que acrescento um segundo “s” à expressão, palavras “jurisdição” e “satisfação” não mais se encaixam na descrição fornecida pela expressão. Pois nenhuma dessas duas palavras possuem, em algum lugar, um “” imediatamente seguido por duas letras “s.” Com isso, temos que partes localizadas pela expressão são: permissão, demissão, emissão.Apenas para que os pontos abordados fiquem claros, figura exposta abaixo, lhe permite visualizar correspondências (marcadas em cinza) encontradas por cada uma das expressões regulares mostradas anteriormente.\nFigure 10.2: Correspondências encontradas por cada expressão regular, além de suas respectivas descrições.\n","code":"\nvec <- c(\"permissão\", \"demissão\", \"emissão\", \"penitência\",\n         \"jurisdição\", \"ordenação\", \"concluio\", \"vantagem\",\n         \"natação\", \"satisfação\", \"conclusão\", \"ilusão\")\nvec[vec == \"emissão\"]## [1] \"emissão\"\nteste <- str_detect(vec, \"emissão\")\nvec[teste]## [1] \"demissão\" \"emissão\"\nteste <- str_detect(vec, \"is\")\nvec[teste]## [1] \"permissão\"  \"demissão\"   \"emissão\"    \"jurisdição\" \"satisfação\"\nteste <- str_detect(vec, \"iss\")\nvec[teste]## [1] \"permissão\" \"demissão\"  \"emissão\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"caracteres-literais-e-metacharacters","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.2 Caracteres literais e metacharacters","text":"Expressões regulares são uma linguagem formada por duas categorias de caracteres (Friedl 2006): 1) Caracteres literais, ou simples letras e números pelos quais pesquisamos; e 2) metacharacters, que são um conjunto de caracteres especiais que delimitam o escopo de sua pesquisa, ou maneira como ela será executada.Até o momento, utilizamos apenas caracteres literais, ao pesquisarmos pelas sequências \"emissão\" ou \"\". Ou seja, qualquer número ou letra que formam uma sequência de caracteres são considerados caracteres literais. Alguns símbolos também são considerados caracteres literais, pois não possuem nenhum comportamento especial que altere o comportamento da pesquisa. Como exemplo, expressão \"A1_z-4!D8\" é formada apenas por caracteres literais, mesmo que ela descreva uma sequência bem esquisita (e provavelmente inútil) de caracteres.Qualquer expressão que utilize apenas caracteres literais, busca efetuar uma simples pesquisa por uma sequência particular de caracteres. Consequentemente, expressão \"1\" é capaz de detectar o texto “Álvaro chegou em 1° lugar!” assim como “O aluguel chegou R$3250,10 nesse mês.” Como um outro exemplo, ao empregarmos expressão \"regi\", ela é capaz de encontrar os textos “região” e “registro,” mas não é capaz de detectar o nome “Reginaldo,” pelo simples fato de que primeira letra nome é um “r” maiúsculo, ao invés de um “r” minúsculo.Em síntese, expressões regulares já são uma ferramenta útil apenas com o uso de caracteres literais. Contudo, elas se tornam bastante limitadas sem o uso de metacharacters, que ampliam em muito suas funcionalidades, e mudam drasticamente forma como pesquisa ocorre. Neste ponto, também reside uma importante dificuldade domínio de expressões regulares. Pois são muitos metacharacters disponíveis e, por isso, memorizar o que cada um deles fazem, e quais são suas aplicações mais úteis, não se trata de uma tarefa simples.Apesar disso, haverá momentos em que você deseja encontrar ou incluir em sua expressão regular o caractere literal que um certo metacharacter representa. Em outras palavras, há ocasiões em que você deseja que certos metacharacters se comportem como caracteres literais. Por exemplo, um dos metacharacters que vamos mostrar nas próximas seções é ? (ponto de interrogação). Portanto, o caractere ? possui um comportamento especial em expressões regulares, mas se quisermos encontrar o caractere ? em si, ao longo texto, nós precisamos contornar o comportamento especial desse metacharacter. Para isso, basta anteceder esse caractere por uma barra inclinada à esquerda (\\?).Porém, lembre-se que para escrevermos uma barra inclinada à esquerda, nós temos que digitar duas barras inclinadas à esquerda! Logo, para escrever em sua expressão regular, o termo \\?, você deve na verdade, digitar o termo \\\\?. Isso funciona para praticamente qualquer metacharacter. Logo, sempre que você precisar utilizar um certo metacharacter como um caractere literal, tente antecedê-lo por duas barras inclinadas à esquerda.","code":""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"sec:regex_ancoras","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.3 Âncoras (anchors)","text":"O primeiro tipo de metacharacters que vou apresentar, são os tipo “âncora.” Esse conjunto é composto pelos caracteres ^ e $, que são responsáveis por delimitar o início e o fim de uma linha, respectivamente.Logo, ao utilizar expressão \"^emissão$\", eu estou pedindo à str_detect() que localize um texto que contém: o início de uma linha imediatamente seguido pela sequência “e-m--s-s-ã-o” de caracteres, que por sua vez, deve ser imdeiatamente seguido pelo fim dessa mesma linha. Com essa expressão, somos capazes de encontrar apenas palavra “emissão” que está entre os valores vetor vec.É importante destacar, que os caracteres ^ e $ são capazes de encontrar os limites de uma linha, e não de uma palavra. Por isso, partir momento em que sequência “e-m--s-s-ã-o” não estiver encostando em pelo menos um dos limites da linha, str_detect() não será mais capaz de encontrar tal conjunto de caracteres. Como exemplo, perceba abaixo, que apenas o primeiro elemento de text pôde corresponder à expressão empregada em str_detect(). Ou seja, mesmo que o quarto, quinto e sexto elementos de text possuam palavra “emissão,” eles não puderam ser encontrados pela expressão \"^emissão$\", devido ao fato de não estarem localizados em pelo menos um dos limites da linha.Vale destacar que você não precisa necessariamente utilizar os dois metacharacters ao mesmo tempo. Logo, temos opção de construir uma expressão que possa encontrar uma certa sequência de caracteres ao final ou início de uma linha. Por exemplo, expressão abaixo, busca encontrar sequência “e-m--s-s-ã-o” de caracteres quando ela é imediatamente seguida pelo final da linha.Alguns outros exemplos de expressões regulares que empregam metacharacters tipo âncora, além de uma rápida reflexão sobre os caracteres ^ e $, são oferecidos na figura abaixo. Repare que todas partes texto que foram detectadas pela expressão regular, foram novamente marcadas de cinza. Perceba também, que cada seta presente na figura, busca conectar cada uma das partes detectadas texto, ao componente específico da expressão regular que foi responsável por detectá-la.\nFigure 10.3: Exemplos e uma reflexão sobre correspondências encontradas por metacharacters tipo âncora.\n","code":"\nteste <- str_detect(vec, \"^emissão$\")\nvec[teste]## [1] \"emissão\"\ntext <- c(\n  \"emissão\",\n  \"A Ford Brasil executou recentemente uma demissão em massa\",\n  \"remissão\",\n  \"Para mais, a emissão de CO2 cresceu no Brasil\",\n  \"emissão de S02 faz parte do processo\",\n  \"A firma foi processada por tal emissão\"\n)\n\nteste <- str_detect(text, \"^emissão$\")\ntext[teste]## [1] \"emissão\"\nteste <- str_detect(text, \"emissão$\")\ntext[teste]## [1] \"emissão\"                               \n## [2] \"remissão\"                              \n## [3] \"A firma foi processada por tal emissão\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"classes-de-caracteres-character-classes","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.4 Classes de caracteres (character classes)","text":"Uma estrutura muito importante em expressões regulares são classes de caracteres, ou character classes. Sendo construída partir de um par de colchetes ([]), essa estrutura lhe permite listar os possíveis caracteres que você deseja encontrar em um ponto da sequência descrita por sua expressão regular.Por exemplo, suponha que você esteja lendo um livro-texto sobre linguagem R, e que você queira encontrar todas instâncias livro que se referem ao termo regex. Você sabe que regiões que descrevem o assunto qual você está interessado, vão conter o termo regex, mas você não sabe como o termo regex está citado texto. Digo, será que o autor está colocando primeira letra em maiúsculo (Regex)? Ou será que todo o termo está em maiúsculo (REGEX)?Tendo essa dúvida em mente, você pode criar uma expressão regular, que permita certas variações da palavra regex, ao listar todas possibilidades em uma dada posição termo. Primeiro, vamos imaginar que você deseja permitir que primeira letra termo seja tanto maicúsula quanto minúscula. exemplo abaixo, ao incluirmos letras “r” e “R” dentro da classe de caracteres ([]), estamos estabelecendo que primeiro caractere da sequência, podemos ter uma letra “r” ou uma letra “R.”Ou seja, uma classe de caracteres busca descrever os caracteres possíveis para uma única e particular posição da sequência. Logo, expressão \"[Rr]egex\" não está descrevendo sequência “[-R-r-]-e-g-e-x,” mas está afirmando que “r-e-g-e-x” e “R-e-g-e-x” são duas sequências de caracteres que queremos encontrar em nossa pesquisa. Com isso, se tivéssemos de permitir todas possibilidades de capitalização em cada letra termo, poderíamos fornecer seguinte expressão à str_detect():Dessa maneira, estamos permitindo que str_detect() encontre todas possibilidades termo regex, quanto ao uso de capitalização (regex, Regex, REGEX, rEgex, reGex, regEx, regeX, …).classes de caracteres também são muito utilizadas para criar um intervalo de caracteres possíveis em um determinado ponto. Esses intervalos são rapidamente formados pelo metacharacter - (sinal de menos). Como exemplo, podemos utilizar o atalho [0-9] para listarmos todos os números de 0 9 dentro da classe. Esse atalho é extremamente útil quando desejamos encontrar alguma parte numérica em nosso texto, mas nós não sabemos previamente quais números em particular vão estar presentes nesse item.Por exemplo, suponha que uma comissão nacional tenha divulgado colocações de diversos participantes em um torneio de xadrex. Você deseja analisar os participantes e suas respectivas colocações, entretanto, comissão divulgou os dados como um texto simples em sua página da internet, ao invés de guardar esses dados em uma tabela, ou em alguma outra estrutura que fosse de fácil transposição para o R.Com isso, você precisa utilizar uma expressão regular que possa encontrar essas colocações ao longo texto. Uma possibilidade, seria tentarmos localizar ocorrências de um número seguido símbolo de grau (°), ao longo texto. exemplo abaixo, colocações variam de 1 6 e, por isso, precisamos listar todos os números neste intervalo dentro de uma classe, e acrescentar o símbolo de grau, formando assim, expressão \"[123456]°\". Porém, ao invés de listarmos número por número, podemos aplicar o atalho [1-6] para criarmos uma lista contendo todos os números de 1 6.Como podemos ver acima, conseguimos localizar todas colocações. entanto, perceba que expressão \"[1-6]°\" também pôde encontrar informações que se referem temperaturas (celsius e fahrenheit). Portanto, expressão \"[1-6]°\" é muito abrangente para o nosso caso e, em função disso, precisamos descrever em mais detalhes o texto que desejamos. Tudo o que precisamos fazer para corrigir o resultado acima, é incluir uma expressão que encontre um número seguido por um símbolo de grau, exceto quando letras C ou F estão logo após o símbolo de grau.Para essa tarefa, podemos utilizar o comportamento negativo de uma classe. Em outras palavras, além de listar os caracteres aceitos em uma certa posição, nós também temos capacidade de utilizar uma classe de caracteres para listar todos os caracteres que não podem estar situados em uma determinada posição da sequência.Para definir os caracteres não desejados em uma posição, você deve iniciar sua classe, por um acento circunflexo, logo antes de listar os caracteres em questão ([^...]). Com isso, se desejamos evitar letras C e F (independente de sua capitalização) precisaríamos da sub-expressão [^CcFf] logo após o símbolo de grau, formando assim, expressão regular abaixo:Portanto, sempre que você encontrar uma classe que contém um acento circunflexo como seu primeiro item, você sabe que essa classe está negando os caracteres listados dentro dela (exemplo: \"[^1-6_!]\", não são permitidos nessa posição qualquer número entre 1 e 6, o símbolo underscore ou um ponto de exclamação). Logo, na posição que essa classe representa, não devem ser encontrados os caracteres que estão listados dentro dela. Mas se essa classe não possui tal acento, ou se esse acento circunflexo se encontra partir segundo caractere listado, classe em análise está utilizando seu comportamento positivo (ou afirmativo), de modo que os caracteres listados em seu interior, podem sim estar naquela posição.Como um outro exemplo, veja abaixo, correspondências geradas pela expressão \"[0-9][^Ffh]\", que utiliza ambos os modos de classe (negativa e positiva). Essa expressão, busca encontrar um número entre 0 e 9, que é imediatamente seguido por um caractere qualquer (que não seja letras “F,” “f”e “h”). Repare caso texto \"A5\", qual expressão não é capaz de localizá-lo pelo simples fato de que o texto acaba dígito 5. Lembre-se que cada classe de caracteres representa um caractere ser encontrado em uma determinada posição da sequência. Logo, mesmo que parte [^Ffh] esteje listando os caracteres que não podem ser encontrados, ela está automaticamente definindo que algum caractere deve ser encontrado na segunda posição da sequência.\nFigure 10.4: Um exemplo de expressão regular que emprega ambos os modos de classes de caractere (positiva e negativa)\nAlém desses pontos, repare acima, que o metacharacter ^ (acento circunflexo) tem um papel completamente diferente dentro de uma classe de caracteres, se comparado ao papel que ele exerce fora dela. Em resumo, o caractere ^ fora de uma classe, é um metacharacter tipo âncora, sendo capaz de definir o início de uma linha; mas dentro de uma classe, ele está determinando o comportamento adotado pela classe em questão, de forma que os caracteres listados nessa classe não devem ser encontrados na posição que essa classe simboliza.Logo, é muito importante destacar o fato de que diversos caracteres possuem um comportamento produndamente diferente, quando inseridos em uma classe de caracteres. Fique atento isso! Se algum metacharacter estiver se comportando de maneira inesperada, é possível que essa diferença entre os mundos de dentro e de fora de uma classe seja fonte de sua surpresa. De certo modo, você pode compreender essa situação, como se classes possuíssem sua própria mini-linguagem, com o seu próprio conjunto de metacharacters, separados da realidade de fora delas (Friedl 2006).Por outro lado, e se você desejasse incluir os metacharacters - e ^ como possíveis caracteres para uma determinada posição? Como o caractere - cria uma sequência, basta que você liste ele logo início de sua classe (ex: \"[-1-6]\", que permite um número entre 1 e 6, além de um sinal de menos). Já o caractere ^, precisa ser posicionado como primeiro item da classe para exercer o seu comportamento especial e, por essa razão, você precisa apenas listá-lo em uma outra posição para se comportar como um simples acento circunflexo (ex: \"[ABC^]\", que permite letras , B e C, além de um acento circunflexo).Até o momento, mostramos apenas o atalho para listar uma sequência numérica (ex: \"[0-9]\"). Mas também temos um outro atalho para listarmos um intervalo específico (ou todas letras) alfabeto. Para isso, podemos utilizar o atalho [-z] para letras minúsculas, e [-Z] para letras maiúsculas. Por exemplo, suponha que você possua o conjunto de códigos mostrados objeto codes. Suponha também, que os códigos que contém letras de “” “F,” correspondem unidades manufaturadas em Belo Horizonte, enquanto os códigos que contém letras de “G” “Z” dizem respeito unidades fabricadas na região de São Paulo.Com isso em mente, para reunirmos todos os códigos de produtos construídos em Belo Horizonte, precisaríamos apenas encontrar os códigos que contém qualquer letra dentro intervalo de “” e “F.” Todavia, repare que capitalização das letras presentes nos códigos, varia. Por isso, precisamos combinar o mesmo intervalo de letras em ambos os estilos de capitalização. Dessa maneira, geramos expressão abaixo, que contém ambos os intervalos (\"[-fA-F]\").","code":"\ntexto <- c(\n  \"Cada letra, número, ou símbolo presente no texto é um caractere.\",\n  \"Textos são criados ao contornados por aspas (duplas ou simples).\",\n  \"O termo regex é uma abreviação para regular expressions.\",\n  \"Regex é um termo comum no mundo da computação.\",\n  \"Metacharacters alteram consideravelmente o comportamento de um REGEX.\",\n  \"ReGEx? Ou reGex? Talvez RegEX?.\"\n)\n\nteste <- str_detect(texto, \"[Rr]egex\")\ntexto[teste]## [1] \"O termo regex é uma abreviação para regular expressions.\"\n## [2] \"Regex é um termo comum no mundo da computação.\"\nteste <- str_detect(texto, \"[Rr][Ee][Gg][Ee][Xx]\")\ntexto[teste]## [1] \"O termo regex é uma abreviação para regular expressions.\"             \n## [2] \"Regex é um termo comum no mundo da computação.\"                       \n## [3] \"Metacharacters alteram consideravelmente o comportamento de um REGEX.\"\n## [4] \"ReGEx? Ou reGex? Talvez RegEX?.\"\ncolocacoes <- c(\n  \"1°: Álvaro\",\n  \"2°: Melissa\",\n  \"3°: Ana\",\n  \"4°: Eduardo\",\n  \"5°: Daniela\",\n  \"6°: Matheus\",\n  \"Não é uma colocação\",\n  \"Também não é uma colocação\",\n  \"31°C\",\n  \"24°F\"\n)\n\nteste <- str_detect(colocacoes, \"[1-6]°\")\ncolocacoes[teste]## [1] \"1°: Álvaro\"  \"2°: Melissa\" \"3°: Ana\"     \"4°: Eduardo\" \"5°: Daniela\"\n## [6] \"6°: Matheus\" \"31°C\"        \"24°F\"\nteste <- str_detect(colocacoes, \"[1-6]°[^CcFf]\")\ncolocacoes[teste]## [1] \"1°: Álvaro\"  \"2°: Melissa\" \"3°: Ana\"     \"4°: Eduardo\" \"5°: Daniela\"\n## [6] \"6°: Matheus\"\na <- c(\"A-B\", \"CDE-F\", \"12^54\", \"R$1230,2\", \"BRA\")\nteste <- str_detect(a, \"[-^]\")\na[teste]## [1] \"A-B\"   \"CDE-F\" \"12^54\"\ncodes <- c(\"AeF15\", \"CCd31\", \"17GHJ\", \"Lmm96\", \"ee3f8\", \"BA45B\",\n           \"EccF2\", \"675Cc\", \"hkJ78\", \"q401Q\", \"iop67\", \"DCa98\")\nteste <- str_detect(codes, \"[a-fA-F]\")\ncodes[teste]## [1] \"AeF15\" \"CCd31\" \"ee3f8\" \"BA45B\" \"EccF2\" \"675Cc\" \"DCa98\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"conclusão-e-algumas-dicas-extras","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.4.1 Conclusão e algumas dicas extras","text":"Portanto, uma classe de caracteres busca listar os caracteres que podem ou não ser encontrados na posição da sequência que essa classe representa. Em síntese, podemos interpretar o seu uso da seguinte maneira:[abc]: encontre ou b ou c.[abc]: encontre ou b ou c.[^abc]: encontre qualquer caractere, exceto , b ou c.[^abc]: encontre qualquer caractere, exceto , b ou c.Além disso, uma classe de caracteres lhe permite criar ranges, ou intervalos de caracteres possíveis, como:[0-9]: encontre qualquer número entre 0 e 9.[0-9]: encontre qualquer número entre 0 e 9.[-z]: encontre qualquer letra (minúscula) entre e z.[-z]: encontre qualquer letra (minúscula) entre e z.[-Z]: encontre qualquer letra (maiúscula) entre e Z.[-Z]: encontre qualquer letra (maiúscula) entre e Z.Porém, para além dos usos apresentados até aqui, o R nos oferece alguns atalhos para essas construções, sendo os principais:\\d: encontre um dígito (atalho para [0-9]).\\d: encontre um dígito (atalho para [0-9]).\\s: encontre qualquer espaço em branco (atalho para [ \\t\\n]).\\s: encontre qualquer espaço em branco (atalho para [ \\t\\n]).\\w: encontre um caractere alfanumérico ou um underline (atalho para [-zA-Z0-9_])\\w: encontre um caractere alfanumérico ou um underline (atalho para [-zA-Z0-9_])Lembre-se que, R, para inserirmos uma barra inclinada à esquerda em um string, nós precisamos escrever duas barras inclinadas à esquerda. Logo, para inserirmos, por exemplo, o atalho \\d em alguma de nossas expressões regulares, somos obrigados digitar \\\\d.","code":""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"representando-qualquer-caractere-com-um-ponto","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.5 Representando qualquer caractere com um ponto","text":"Você pode representar qualquer caractere em uma expressão regular, por meio metacharacter . (ponto final). Ou seja, um ponto final em uma expressão regular é capaz de encontrar qualquer caractere (seja ele um número, um símbolo ou uma letra) na posição que ele representa. Logo, expressão \"B.3\" significa na prática: uma letra “B,” imediatamente seguida por um caractere qualquer, que por sua vez, é imediatamente seguido por um número 3.Por exemplo, suponha que você queira encontrar data “20/02/2019,” mas você sabe que essa data pode se encontrar em diferentes formatos, como 20.02.2019, ou 20-02-2019. Tendo isso em mente, você provavelmente tentaria uma expressão como \"20[-/.]02[-/.]2019\". Por outro lado, poderíamos atingir o mesmo resultado ao substituirmos classes de caracteres por pontos finais, gerando assim, expressão \"20.02.2019\".Porém, é importante que você tenha cuidado ao utilizar esse metacharacter. Pois como podemos ver acima, expressão \"20.02.2019\" também é capaz de encontrar o texto “20$02#2019,” assim como o texto “senha é 2060212019.” Portanto, chances de você encontrar o que você não deseja, podem aumentar depender da maneira em que você aplica esse metacharacter em sua expressão.","code":"\nvec <- c(\"20.02.2019\", \"20-02-2019\", \"20/02/2019\",\n         \"A senha é 2060212019\", \"20$02#2019\")\n\nteste <- str_detect(vec, \"20.02.2019\")\nvec[teste]## [1] \"20.02.2019\"           \"20-02-2019\"           \"20/02/2019\"          \n## [4] \"A senha é 2060212019\" \"20$02#2019\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"criando-alternativas-alternation","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.6 Criando alternativas (alternation)","text":"Há certos momentos, em que não conseguimos expor todos os nossos desejos com uma única expressão. Por essa razão, temos o metacharacter | (barra vertical) que nos permite combinar diferentes sub-expressões em uma só. Dessa maneira, função responsável pela pesquisa, irá procurar por qualquer texto que atenda pelo menos uma dessas sub-expressões. Sendo este efeito, comumente denominado de alternação (ou alternation).Como exemplo, na seção anterior estávamos tentando encontrar o termo regex, ao longo de várias sentenças, que estão reproduzidas logo abaixo, vetor texto. Na primeira instância, fizemos uso de uma classe de caracter para permitirmos uma letra “r” tanto minúscula quanto maiúscula, primeiro caractere da sequência de nossa expressão (\"[Rr]egex\").Porém, temos capacidade de atingir o mesmo resultado, com o uso de alternação. Basta separarmos os dois casos que estamos tentando representar, pelo metacharacter |, formando assim, expressão abaixo (\"Regex|regex\"):Lembre-se que realidade dentro de uma classe de caracteres é completamente diferente de seu exterior. Logo, dentro de uma classe de caracteres, o caractere | é simplesmente um caractere literal, assim como letras “x” e “r.” Por isso, uma expressão como \"Rege[x|r]egex\", estaria na verdade procurando por sequências como “R-e-g-e-x-e-g-e-x,” “R-e-g-e-|-e-g-e-x” e “R-e-g-e-r-e-g-e-x.”Para mais, é importante que você entenda que cada sub-expressão conectada pelo metacharacter |, representa uma expressão regular diferente das demais.Veja como exemplo, expressão abaixo. primeira sub-expressão (\"[3-6]°\") seleciona um texto que contenha um número entre 3 e 6 imediatamente seguido de um símbolo de grau. segunda sub-expressão (\"[ao]\") seleciona um texto que contenha sequência “-s-” ou “-s-o” de caracteres. Já terceira sub-expressão (R\\\\$[0-9]+(,[0-9][0-9])?), que é bem mais elaborada que outras duas, busca selecionar um texto que contenha um valor monetário. Com isso, qualquer texto que se encaixe em alguma dessas condições, será selecionado pela função.Um outro detalhe importante, é que você pode limitar o alcance das alternativas, ao contorná-las com parênteses. Em outras palavras, ao invés de fornecer várias sub-expressões, você pode fornecer diferentes sub-expressões dentro de uma expressão “geral.”Por exemplo, vamos voltar à expressão \"Regex|regex\". Se nós isolarmos seção \"ex|re\", temos um resultado completamente diferente que vimos anteriormente, pois sub-expressões passam ser “e-x” e “r-e,” e não “r-e-g-e-x” e “R-e-g-e-x” como anteriormente. Dessa maneira, estamos na verdade procurando por textos que contenham sequência “R-e-g-e-x-g-e-x” ou sequência “R-e-g-r-e-g-e-x.”Dessa vez, importando um exemplo diretamente da obra de Friedl (2006), suponha que você possua um arquivo de texto, contendo uma lista de todos os emails de sua caixa de entrada. Com esse arquivo, poderíamos utilizar expressão \"^(|Subject|Date):\" para extraírmos apenas linhas arquivo que contém referência remetente (:), assunto (Subject:) e da data de envio (Date:) de cada email. Perceba também, que expressão \"^(|Subject|Date):\" é equivalente à expressão \"^:|^Subject:|^Date:\".","code":"\ntexto <- c(\n  \"Cada letra, número, ou símbolo presente no texto é um caractere.\",\n  \"Textos são criados ao contornados por aspas (duplas ou simples).\",\n  \"O termo regex é uma abreviação para regular expressions.\",\n  \"Regex é um termo comum no mundo da computação.\",\n  \"Metacharacters alteram consideravelmente o comportamento de um REGEX.\",\n  \"ReGEx? Ou reGex? Talvez RegEX?.\"\n)\n\nteste <- str_detect(texto, \"Regex|regex\")\ntexto[teste]## [1] \"O termo regex é uma abreviação para regular expressions.\"\n## [2] \"Regex é um termo comum no mundo da computação.\"\nvec <- c(\"1230\", \"Tenho consulta no dia 25\", \"R$12,45\", \n         \"Essa máquina custa R$320,21\", \"Márcia\", \"Isotônico\",\n         \"Álcool isopropílico\", \"Hoje fez 30°\", \"4° é muito frio!\")\nteste <- str_detect(vec, \"[3-6]°|is[ao]|R\\\\$[0-9]+(,[0-9][0-9])?\")\nvec[teste]## [1] \"R$12,45\"                     \"Essa máquina custa R$320,21\"\n## [3] \"Álcool isopropílico\"         \"4° é muito frio!\"\nvec <- c(\"regex\", \"Regex\", \"ISORegex-18930\", \"Regexgexgexgexgex\")\nteste <- str_detect(vec, \"Reg(ex|re)gex\")\nvec[teste]## [1] \"Regexgexgexgexgex\"\nemail <- readr::read_lines(\"\nFrom: elena_campaio@gmail.com Jun 15 2019 07:05\nReceived: from elena_campaio@gmail.com\nTo: pedropark99@gmail.com\nDate: Thu, Jun 15 2019 07:05\nMessage-Id: <20190322145154232.elena_campaio@gmail.com>\nSubject: Nova reunião\nX-Mailer: by mailbox (Version 8.5.1) BellM Company, Copyright 2005-2019\n\nBom dia Pedro, poderíamos nos encontrar às 10hrs?\n\n\nFrom: pedropark99@gmail.com Jun 15 2019 08:10 \nReceived: from elena_campaio@gmail.com\nTo: elena_campaio@gmail.com\nDate: Thu, Jun 15 2019 08:10\nMessage-Id: <20190322145155198.elena_campaio@gmail.com>\nSubject: Re: Nova reunião\nReply-To: elena_campaio@gmail.com <20190322145154232.elena_campaio@gmail>\nX-Mailer: by mailbox (Version 8.5.1) BellM Company, Copyright 2005-2019\n\nOk Elena! Podemos nos encontrar esse horário.\")\n\n\nteste <- str_detect(email, \"^(From|Subject|Date):\")\nemail[teste]## [1] \"From: elena_campaio@gmail.com Jun 15 2019 07:05\"\n## [2] \"Date: Thu, Jun 15 2019 07:05\"\n## [3] \"Subject: Nova reunião\"\n## [4] \"From: pedropark99@gmail.com Jun 15 2019 08:10 \"\n## [5] \"Date: Thu, Jun 15 2019 08:10\"\n## [6] \"Subject: Re: Nova reunião\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"quantificadores-quantifiers-ou-definindo-repetições","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.7 Quantificadores (quantifiers) ou definindo repetições","text":"Há certos momentos em que precisamos permitir que um certo conjunto de caracteres sejam encontrados múltiplas vezes em uma mesma sequência de caracteres. Um bom exemplo disso, é expressão que utilizamos na seção anterior \"R\\\\$[0-9]+(,[0-9][0-9])?\" para encontrarmos um valor monetário. Temos três partes principais nessa expressão, sendo elas: 1) R\\\\$; 2) [0-9]+; e 3) (,[0-9][0-9])?.Primeiro, o que seria um valor monetário? Certamente seria um valor numérico. Porém, um número pode significar qualquer coisa! Talvez uma medida de peso (Kg), idade (anos), volume (L) ou qualquer outra variável contínua que você imaginar. Logo, precisamos de algum item que possa identificar esse número como uma medida de valor, e esse item se trata símbolo da moeda brasileira (R$). Qualquer valor numérico presente em seu texto que estiver acompanhado desse símbolo é um valor monetário.Com isso, teríamos expressão \"R\\\\$[0-9]\" como uma tentativa inicial. Perceba que eu tive de contornar o comportamento especial metacharacter $, ao antecedê-lo por duas barras inclinadas. Dessa maneira, expressão \"\\\\$\" significa de fato o caractere $ (cifrão), e não o fim de uma linha como definimos na seção Âncoras (anchors).Entretanto, não há um limite específico para o número que um valor monetário pode atingir. Em outras palavras, podemos estar nos referindo míseros centavos ou milhões de reais. Traduzindo essa afirmação na prática, podemos ter uma quantidade variável de dígitos em nosso valor monetário. O valor R$5 possui apenas 1 dígito, enquanto o valor R$1245 possui 4 dígitos.princípio, essa questão não é tão importante, já que fomos capazes de encontrar todos os textos que contém algum valor monetário, com apenas expressão \"R\\\\$[0-9]\". Ou seja, mesmo que alguns desses valores possuam 3, 4 ou 6 dígitos, precisamos apenas detectar o seu primeiro dígito antecedido pelo símbolo R$.Todavia, essa questão passa ser crucial, na hipótese de aplicarmos alguma transformação sobre os valores monetários encontrados. Ou seja, se vamos, por exemplo, extrair os valores encontrados; ou substituí-los por algum outro texto; ou utilizá-los como pontos de quebra texto que os contém; ou empregá-los em algum cálculo, é de extrema importância que possamos detectar todo o valor com nossa expressão. Apenas para que fique claro, veja representação abaixo, que mostra os resultados de ambas expressões mostradas até aqui sobre o valor R$6530,58.\nFigure 10.5: Expressões regulares sobre valores monetários\nTendo como início, expressão \"R\\\\$[0-9]\", precisamos permitir uma quantidade variável de dígitos, mais especificamente na parte \"[0-9]\". Em ocasiões como essa, nós podemos utilizar os metacharacters tipo quantificadores, que incluem os caracteres ? (ponto de interrogação), + (sinal de mais), * (asterisco) e {} (par de chaves). Como o próprio nome tipo dá entender, esses metacharacters buscam delimitar quantidade de vezes que podemos encontrar um certo caractere em nossa sequência. Em outras palavras, esses metacharacters definem o número mínimo e máximo de ocorrências possíveis para um caractere específico de nossa expressão.Primeiro, o metacharacter * representa 0 ocorrências como mínimo e infinitas ocorrências como máximo. Com isso, podemos dizer que o metacharacter * significa: “tente encontrar esse caractere, o maior número de vezes possíveis, contudo, está tudo bem se não conseguirmos encontrá-lo em algum lugar.” Logo, expressão \"A6*\" nos permite encontrar uma letra “,” quando acompanhada, por exemplo, pelo “número diabo” (“A666”), ou por qualquer outra quantidade número 6, como o texto “A6,” ou “A6666666.” Porém, o metacharacter * também nos dá possibilidade de não encontrarmos o número 6. Por isso, expressão \"A6*\" também é capaz de encontrar o texto “Ana Luísa,” mesmo que ele não possua um número 6.Segundo, o metacharacter + representa 1 ocorrência como mínimo e infinitas ocorrências como máximo. Por consequência, o metacharacter + expressa: “tente encontrar esse caractere pelo menos uma vez!” Como exemplo, expressão \"Isa+\" é capaz de encontrar os textos “Isadora,” “Isaac Newton” e “Isaaaaaa3210.” Mas não é capaz de encontrar o texto “Isótopo,” pois esse texto não possui pelo menos um “” logo após os caracteres “.”Terceiro, o metacharacter ? representa 0 repetições como mínimo e 1 repetição como máximo. Isto é, o metacharacter ? busca tornar um caractere completamente opcional. Em outras palavras, ao conectarmos um caractere ou uma sub-expressão ao metacharacter ? estamos dizendo algo como: “se esse caractere encontrado, ótimo! Se não, sem problemas!” Como exemplo, expressão \"dr?\" busca encontrar uma letra “d” imediatamente seguida pelos caracteres “ra.” Mas pelo fato de termos incluído o metacharacter ? logo à frente da letra “r,” tornamos essa letra opcional. Por isso, expressão \"dr?\" é capaz de encontrar textos como “engendrar,” “dragão” ou “dramin,” assim como os textos “Adaga” e “reciprocidade.”Quarto, o metacharacter {} representa forma geral de um quantificador. Pois ele nos permite especificar exatamente quais quantidades mínima e máxima que desejamos para um determinado caractere. Basta preencher o par de chaves com essas duas quantidades, separadas por uma vírgula ({min, max}). Por exemplo, expressão \"31[0-9]{4,5}\" é capaz de encontrar um código IBGE referente um município estado de Minas Gerais (os dígitos 31 representam o código estado de MG). Esses códigos IBGE possuem uma versão curta, que pode variar de 2 4 dígitos, entretanto, suas versões mais comumente utilizadas são de 6 e de 7 dígitos. Como exemplo, os códigos 310620 e 3106200\nse referem ao município de Belo Horizonte. Com isso, ao estabelecermos 4 e 5 dígitos como os limites intervalo representado pela sub-expressão [0-9]{4,5}, somos capazes de detectar códigos como 310620 e 3106200, e ao mesmo tempo, descartar códigos como 31062, que possui menos de 4 dígitos após os dígitos 31.Além disso, vale destacar que o objetivo de qualquer metacharacter tipo quantificador, não é o de determinar o número de vezes que um caractere pode aparecer ao longo texto, mas sim, o número de vezes que um caractere pode ocorrer em sequência. Por exemplo, expressão \"(25){2,3}\" busca detectar um número arbitrário de 25’s. Assim sendo, essa expressão é capaz de detectar valores como 25, 252, e 2525, da mesma maneira que o texto “Estive na 25 de Março último dia 25.”Porém, muitas pessoas interpretam que os dois 25’s presentes texto “Estive na 25 de Março último dia 25” são detectados pela expressão \"(25){2,3}\", quando na verdade, apenas o primeiro 25 é localizado. Pois o segundo 25 texto, se encontra mais de 20 caracteres frente primeiro 25. Logo, ao utilizarmos um metacharacter tipo quantificador, estamos geralmente preocupados com possibilidade de o mesmo caractere aparecer múltiplas vezes em sequência (um atrás outro).Voltando à expressão \"R\\\\$[0-9]\", com tudo o que descrevi nos parágrafos anteriores, nós podemos adicionar um + logo após [0-9]. Dessa maneira, estamos desejando encontrar pelo menos um número qualquer entre 0 e 9, logo após o símbolo monetário R$. Com isso, temos expressão \"R\\\\$[0-9]+\", que é capaz de encontrar tanto “R$3” quanto “R$3050.”entanto, ainda temos possibilidade de encontrarmos um valor monetário que inclui centavos. Ou seja, podemos encontrar um número que seja seguido por uma vírgula e dois outros dígitos que definem os centavos. Por isso, podemos ainda acrescentar parte \",[0-9][0-9]\" para captar essa possível parte de nosso valor monetário.Porém, repare ainda, que ao adicionarmos seção \",[0-9][0-9]\", nossa expressão regular não é mais capaz de detectar valores que não possuem uma parte para os centavos, como R$21 e R$43026. É por essa razão, que eu contorno essa seção por parênteses, e adiciono o metacharacter ? logo em seguida. Pois dessa forma, essa seção passa ser opcional, de forma que parte para os centavos deixa de ser obrigatória.","code":"\nvec <- c(\"Eu peso em torno de 65Kg\", \"Tenho consulta no dia 25\",\n         \"R$1630,45\", \"Eu possuo uma conta de R$74,85 a pagar\", \n         \"R$400\", \"R21\", \"Hoje, R$30 equivale a $5,77 dólares\")\nteste <- str_detect(vec, \"R\\\\$[0-9]\")\nvec[teste]## [1] \"R$1630,45\"                             \n## [2] \"Eu possuo uma conta de R$74,85 a pagar\"\n## [3] \"R$400\"                                 \n## [4] \"Hoje, R$30 equivale a $5,77 dólares\"\nvec <- c(\"8730\", \"R$21\", \"R$3120,50\", \"R$43026\", \"R$45,10\")\nteste <- str_detect(vec, \"R\\\\$[0-9]+,[0-9][0-9]\")\nvec[teste]## [1] \"R$3120,50\" \"R$45,10\"\nvec <- c(\"8730\", \"R$21\", \"R$3120,50\", \"R$43026\", \"R$45,10\")\nteste <- str_detect(vec, \"R\\\\$[0-9]+(,[0-9][0-9])?\")\nvec[teste]## [1] \"R$21\"      \"R$3120,50\" \"R$43026\"   \"R$45,10\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"conclusão-e-algumas-dicas-extras-1","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.7.1 Conclusão e algumas dicas extras","text":"Recaptulando o que vimos até aqui, temos que os números de ocorrências representados por cada metacharacter tipo “quantificador” são:?: 0 ou 1 ocorrência.?: 0 ou 1 ocorrência.+: 1 ou mais ocorrências.+: 1 ou mais ocorrências.*: 0 ou mais ocorrências.*: 0 ou mais ocorrências.{min, max}: entre min e max ocorrências.{min, max}: entre min e max ocorrências.Para além que ainda não foi comentado nessa seção, você pode utilizar novamente o metacharacter {}, para especificar um número específico de ocorrências que você deseja para um caractere, ou então, definir apenas o numéro mínimo ou o número máximo de repetições. Com isso, temos que:{n}: exatamente n ocorrências.{n}: exatamente n ocorrências.{min,}: pelo menos min ocorrências.{min,}: pelo menos min ocorrências.{,max}: até max ocorrências.{,max}: até max ocorrências.","code":""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"determinando-os-limites-de-uma-palavra","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.8 Determinando os limites de uma palavra","text":"Como estabelecemos anteriormente, expressões regulares não tem capacidade de diferenciar palavras, e muito menos, de identificar os seus limites. Por essa razão, para termos garantia de que vamos encontrar uma palavra específica resultado de uma expressão regular, precisamos estabelecer limites para pesquisa.Na seção sobre Âncoras (anchors), utilizamos os metacharacters tipo âncora (^ e $) para estipularmos os limites da palavra ser pesquisada. Porém, esses metacharacters não foram criados para esse objetivo. Essa afirmação fica clara, ao retornarmos ao exemplo utilizado na seção supracitada.Naquela ocasião, estávamos tentando encontrar todos os textos contidos vetor text, que possuíssem palavra “emissão.” Entretanto, ao utilizarmos expressão \"^emissão$\", fomos capazes de encontrar apenas o primeiro elemento de text. Sendo que, de acordo com o nosso objetivo, também desejamos localizar o quarto, quinto e sexto elementos de text. Pois eles também possuem palavra “emissão” em alguma instância.Por isso, precisamos de uma nova estratégia para estipularmos esses limites. Lembre-se que uma expressão regular, nada mais é, que uma descrição concisa de uma sequência específica de caracteres. Logo, precisamos encontrar alguma forma de descrevermos os caracteres que podem representar os limites de uma palavra.Todavia, para isso, nós precisamos primeiro identificar o que é o limite de uma palavra. Ou redefinindo questão, o que exatamente separa uma palavra das demais? Com algum tempo de reflexão, você talvez chegue conclusão de que o que separa uma palavra da outra, são espaços em branco, ou então, símbolos de pontuação, como um ponto final, ou uma vírgula.Portanto, precisamos incluir em ambos os lados da palavra “emissão” alguma expressão que possa descrever especificamente esses caracteres, como expressão \"(\\\\s|[!.,?])\". Repare que o par de parênteses nessa expressão, busca apenas limitar o alcance metacharacter |, que está separando duas alternativas, ou duas sub-expressões (\\\\s e [!.,?]) que podem descrever os caracteres de nosso interesse. Lembre-se que o termo \\\\s representa o comando \\s, que é um atalho para uma classe de caracteres que busca localizar qualquer tipo de espaço em branco.Contudo, perceba acima, que o resultado de nossa pesquisa continua incorreta. Há algum outro detalhe que estamos esquecendo de incluir em nossa expressão. Pois dessa vez, apenas o quarto elemento de text foi retornado. Isso ocorre, porque estamos ignorando possibilidade da palavra de nosso interesse, ser responsável por iniciar ou terminar uma linha texto. Logo, precisamos acrescentar os metacharacters ^ e $, em nossa descrição dos limites de uma palavra. Com isso, temos expressões (^|\\\\s|[!.,?]) e ($|\\\\s|[!.,?]).Agora sim, fomos capazes de encontrar todos os textos presentes em text que possuem palavra “emissão.”","code":"\ntext <- c(\n  \"emissão\",\n  \"A Ford Brasil executou recentemente uma demissão em massa\",\n  \"remissão\",\n  \"Para mais, a emissão de CO2 cresceu no Brasil\",\n  \"emissão de S02 faz parte do processo\",\n  \"A firma foi processada por tal emissão\"\n)\n\nteste <- str_detect(text, \"^emissão$\")\ntext[teste]## [1] \"emissão\"\nteste <- str_detect(text, \"(\\\\s|[!.,?])emissão(\\\\s|[!.,?])\")\ntext[teste]## [1] \"Para mais, a emissão de CO2 cresceu no Brasil\"\nteste <- str_detect(text, \"(^|\\\\s|[!.,?])emissão($|\\\\s|[!.,?])\")\ntext[teste]## [1] \"emissão\"                                      \n## [2] \"Para mais, a emissão de CO2 cresceu no Brasil\"\n## [3] \"emissão de S02 faz parte do processo\"         \n## [4] \"A firma foi processada por tal emissão\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"conclusão-e-algumas-dicas-extras-2","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.8.1 Conclusão e algumas dicas extras","text":"Para pesquisarmos por palavras específicas em uma expressão regular, nós precisamos incluir uma descrição dos caracteres que podem representar os limites físicos de uma palavra. Os limites de uma palavra geralmente assumem formato de:Um espaço em branco (descrito por [ ] ou por \\\\s).Um espaço em branco (descrito por [ ] ou por \\\\s).Pontuações (vírgulas, ponto final, etc.; descrito por [!.,?]).Pontuações (vírgulas, ponto final, etc.; descrito por [!.,?]).Início ou o fim de uma linha (descrito por ^ e $).Início ou o fim de uma linha (descrito por ^ e $).Vale ainda destacar, o fato de que o R nos oferece um atalho para indicarmos o limite de uma palavra, que se trata comando \\b, ou como deve ser escrito R, \\\\b. Consequentemente, se você desejasse encontrar, por exemplo, palavra “camisa,” você poderia utilizar expressão \"\\\\bcamisa\\\\b\".","code":""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"agrupamentos-e-backreferencing","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.9 Agrupamentos e backreferencing","text":"Em vários estilos de expressões regulares, parênteses são capazes de “lembrar” o texto encontrado pela sub-expressão que eles encapsulam (Friedl 2006, p 21). Em expressões regulares, esse mecanismo é comumente denominado de backreferencing.Em resumo, ao contornarmos uma sub-expressão com um par de parênteses, nós estamos formando um “grupo,” e qualquer que seja o pedaço de texto encontrado especificamente por esse grupo, nós somos capazes de reutilizar esse texto dentro da mesma expressão que o localizou, por meio de suas referências numéricas, como \\\\1, \\\\2, \\\\3, e assim por diante. Entenda que essas referências numéricas, nada mais são que índices de cada par de parênteses, ou de cada grupo presente em sua expressão regular. Logo, o índice \\\\1 se refere ao texto localizado pela sub-expressão primeiro par de parênteses. Já o índice \\\\2, se refere ao texto descrito pela sub-expressão segundo par de parênteses. E assim segue.O exemplo clássico desse tipo de operação, está na localização de letras ou palavras repetidas, em uma determinada cadeia de texto. Por exemplo, expressão abaixo (\"(..)\\\\1\"), citada por Wickham Grolemund (2017, p 206), busca encontrar dentro vetor fruit, alguma palavra que possua um par de letras repetido em sequência. Por isso, palavras como “banana” e “coconut” são encontradas por essa expressão.Portanto, dentro da expressão \"(..)\\\\1\", o índice \\\\1 está fazendo alusão ao par de caracteres encontrados pela sub-expressão \"(..)\". Entretanto, é importante que você tenha cuidado aqui. Pois o índice \\\\1 não corresponde à expressão regular \"(..)\". Ou seja, expressão \"(..)\\\\1\" não é equivalente à expressão \"(..)(..)\". Perceba que caso essas expressões fossem iguais, estaríamos simplesmente pesquisando por uma sequência de 4 caracteres quaisquer. Logo, não apenas correspondência detectada pela expressão seria “banana,” mas também, palavras como “raspberry” e “pomegranate” estariam inclusas resultado (o que não ocorre acima).\nFigure 10.6: Como o mecanismo de pesquisa funciona quando utilizamos backreferencing\nPor isso, utilizamos o índice \\\\1 quando desejamos encontrar o mesmo pedaço de texto, ou mesma sequência de caracteres encontrada pelo grupo que se refere. Com isso, backreferencing se torna um mecanismo útil quando ainda não conhecemos o texto repetido ser encontrado, ou quando sabemos que esse texto pode variar violentamente ao longo texto. Por exemplo, suponha que exista em nosso texto, três casos de palavras repetidas (“que que,” “da da” e “ele ele”). Para encontrar esses casos, você talvez tentaria expressão \"\\\\bque que\\\\b|\\\\bda da\\\\b|\\\\bele ele\\\\b\". Porém, seria muito desgastante escrever uma alternativa para cada variação.Por esse motivo, poderíamos resumir esses casos com o uso de backreferencing. Um exemplo de expressão seria \"\\\\b(.+) \\\\1\\\\b\". Dessa forma, expressão \"(.+)\" busca encontrar uma sequência qualquer de caracteres, e o índice \\\\1 tenta encontrar essa mesma sequência de caracteres logo após um espaço em branco.Além desses pontos, repare que utilizamos o atalho \\\\b (que apresentamos ao final da seção anterior) para definirmos os limites de palavras, ao longo de várias dessas expressões. Se você está querendo descobrir palavras repetidas em seus textos, você com certeza deseja definir esses limites de palavras. Pois caso você não o faça, repetições de uma sequência específica de caracteres, pelas quais você estaria pesquisando, poderiam ocorrer em qualquer lugar e invadir o espaço de outras palavras.\nFigure 10.7: importância de se incluir os limites de palavras em pesquisas que utilizam backreferencing\nIsso significa, que expressão \"(que) \\\\1\" seria capaz de encontrar o texto “imagem de Nakaque queima em meu corpo,” ou o texto “É claro que quero!” Ampliando esse exemplo para uma expressão mais geral, poderíamos rapidamente realizar que expressão \"(.+) \\\\1\" seria capaz de encontrar textos como “Sutil ilustração,” assim como “fez-se engendrado.” Dessa forma, o atalho \\\\b impõe limites nossa pesquisa, que evitam esse tipo de inconveniência.","code":"\nteste <- str_detect(fruit, \"(..)\\\\1\")\nfruit[teste]## [1] \"banana\"      \"coconut\"     \"cucumber\"    \"jujube\"      \"papaya\"     \n## [6] \"salal berry\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"mais-sobre-padrões","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.8.10 Mais sobre padrões","text":"Mesmo estando presente em diversos programas e linguagens, expressões regulares possuem certa variabilidade, ou apresentam diferentes “gostos” ou “estilos” em cada uma dessas plataformas. Ou seja, linguagens JavaScript, Perl, Python e R, oferecem um mecanismo próprio de expressões regulares, porém, forma como esse mecanismo é implementado e quais são funcionalidades que ele permite, variam em cada linguagem. Por exemplo, em Perl, você normalmente contorna sua expressão regular, por barras inclinadas direita, acompanhadas de um “m” na primeira barra (m/expressao/). Já na R, não se utiliza tal cápsula, e apenas expressão regular é fornecida.Por padrão, funções da família grep() adotam o padrão POSIX 1003.2 de expressões regulares estendidas (extended regular expressions), que é equivalente ao estilo oferecido pelo programa egrep. Entretanto, essas funções também permitem o uso de expressões regulares estilo adotado pela linguagem Perl. Basta configurar o seu argumento perl para TRUE.Por outro lado, funções pacote stringr utilizam bibliotecas em C projeto ICU (International Components Unicode). O estilo de expressões regulares oferecido por essa biblioteca é muito inspirado estilo adotado pelo linguagem Perl e, por essa razão, está um pouco mais próximo estilo tradicionalmente adotado pela grande maioria das linguagens de programação que oferecem esse recurso. Para mais detalhes sobre essa biblioteca, além de uma lista bem útil de todos os metacharacters disponíveis, você pode consultar o site projeto.","code":""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"substituindo-partes-de-um-texto-com-str_replace","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.9 Substituindo partes de um texto com str_replace()","text":"função str_replace() e sua variante str_replace_all(), lhe permite aplicar uma expressão regular sobre o seu texto, e substituir área encontrada (ou áreas encontradas) por um novo valor de seu interesse. Por exemplo, se eu possuo o conjunto de palavras abaixo, e desejo substituir qualquer vogal por um underline, eu precisaria seguinte comando.Entretanto, perceba acima, que apenas primeira vogal é alterada. Isso não apenas é um comportamento natural da função str_replace(), mas também é um padrão adotado por muitos dos sistemas de expressão regular. Como foi colocado por Friedl (2006, p 148): “match begins earlier (leftmost) string always preferred plausible match begins later”. Com isso, o autor quis destacar que o ato de parar pesquisa na primeira correspondência encontrada, faz parte dos princípios de muitas expressões regulares.Porém, em muitos momentos, haverá necessidade de sobrepor esse comportamento, de forma que sua expressão possa encontrar todas correspondências presentes em um string. Por esse motivo, o pacote stringr oferece diversas funções variantes que terminam com o padrão *_all(). Essas funções buscam justamente solucionar esse problema e, por isso, aplicam expressão regular sobre todo o texto, com o objetivo de encontrar o maior número possível de correspondências.Portanto, ao empregarmos variante str_replace_all(), desejamos substituir todas correspondências encontradas por uma expressão regular em cada string, por um novo valor textual. Veja que o exemplo abaixo é praticamente idêntico ao anterior, apenas função str_replace() foi alterada para str_replace_all().Como um outro exemplo, poderíamos simular o trabalho executado pela função str_trim(), com funções str_replace() e str_replace_all(). O comando str_replace(vec, \"^( )+\", \"\") estaria procurando por qualquer linha que se inicia por uma quantidade \\(y\\) (sendo \\(y > 0\\)) de espaços em branco, e substituindo esses espaços por nada (). Dessa maneira, este comando equivale à str_trim(vec, side = \"left). Já o comando str_replace_all(vec, \"^( )+|( )+$\", \"\"), buscaria qualquer linha que se inicia ou termina por uma quantidade x de espaços em branco, e em seguida, substituiria esses espaços por nada. Sendo assim, esse comando equivale à str_trim(vec, side = \"\").Para mais, backreferencing se torna uma ferramenta extremamente útil em conjunto com str_replace(). Por exemplo, suponha que você tenha se esquecido de adicionar o símbolo da moeda brasileira em cada valor numérico. Com expressão regular \"([0-9]+(,[0-9]+)?)\" podemos encontrar esses valores numéricos. Repare que toda expressão está contornada por parênteses, logo, todo o número é salvo para o índice \\\\1. Dessa maneira, basta antecedermos esse índice pelo símbolo que desejamos inserir (\"R$\\\\1\").","code":"\npalavras <- c(\"arquivo\", \"estante\", \"livro\", \"estiagem\",\n              \"dinheiro\", \"paz\")\n\npalavras <- str_replace(palavras, \"[aeiou]\", \"_\")\n\npalavras## [1] \"_rquivo\"  \"_stante\"  \"l_vro\"    \"_stiagem\" \"d_nheiro\" \"p_z\"\npalavras <- str_replace_all(palavras, \"[aeiou]\", \"_\")\n\npalavras## [1] \"_rq__v_\"  \"_st_nt_\"  \"l_vr_\"    \"_st__g_m\" \"d_nh__r_\" \"p_z\"\nvec <- c(\n  \"  Russo é a língua oficial da Rússia   \",\n  \"   Japão se encontra na Ásia\",\n  \"Português nunca foi tão difícil!   \",\n  \"  224,90 \"\n)\n\nstr_replace(vec, \"^( )+\", \"\")## [1] \"Russo é a língua oficial da Rússia   \"\n## [2] \"Japão se encontra na Ásia\"            \n## [3] \"Português nunca foi tão difícil!   \"  \n## [4] \"224,90 \"\nstr_replace_all(vec, \"^( )+|( )+$\", \"\")## [1] \"Russo é a língua oficial da Rússia\"\n## [2] \"Japão se encontra na Ásia\"         \n## [3] \"Português nunca foi tão difícil!\"  \n## [4] \"224,90\"\nvec <- c(\"O litro de leite custa 3,50\", \"O ingresso foi caro. Mais de 500 reais!\", \n         \"230015\")\n\nstr_replace(vec, \"([0-9]+(,[0-9]+)?)\", \"R$\\\\1\")## [1] \"O litro de leite custa R$3,50\"            \n## [2] \"O ingresso foi caro. Mais de R$500 reais!\"\n## [3] \"R$230015\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"dividindo-strings-com-str_split","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.10 Dividindo strings com str_split()","text":"Você também pode utilizar uma expressão regular para detectar “pontos de quebra” em uma cadeia de texto e, em seguida, quebrar essa cadeia nesses pontos determinados. Repare exemplo abaixo, que função str_split() nos retorna como resultado, uma lista de vetores, onde cada elemento dessa lista, contém os “pedaços” de cada elemento vetor original (vec). Logo, se você está aplicando str_split() sobre um vetor com 34 elementos, você terá uma lista com 34 elementos em seu produto final.Contudo, depender que você planeja fazer em seguida, pode ser difícil trabalhar com uma lista. Por isso, função str_split() nos oferece o argumento simplify, qual podemos requisitar função que simplifique o resultado para uma matriz.","code":"\nvec <- c(\n  \"1 : 2 : 3 : 4 : 5 : 6 : 7\",\n  \"Faria, Pedro Duarte : 1290321_1\",\n  \"Objeto não localizado : 10_0x341167\",\n  \"A732 : B3 : 24 : C1 : 90 : 89 : QUA : ABD : AQZ29 : C11 : 01ER\"\n)\n\nstr_split(vec, \" : \")## [[1]]\n## [1] \"1\" \"2\" \"3\" \"4\" \"5\" \"6\" \"7\"\n## \n## [[2]]\n## [1] \"Faria, Pedro Duarte\" \"1290321_1\"          \n## \n## [[3]]\n## [1] \"Objeto não localizado\" \"10_0x341167\"          \n## \n## [[4]]\n##  [1] \"A732\"  \"B3\"    \"24\"    \"C1\"    \"90\"    \"89\"    \"QUA\"   \"ABD\"  \n##  [9] \"AQZ29\" \"C11\"   \"01ER\"\nstr_split(vec, \" : \", simplify = TRUE)##      [,1]                    [,2]          [,3] [,4] [,5] [,6] [,7]  [,8] \n## [1,] \"1\"                     \"2\"           \"3\"  \"4\"  \"5\"  \"6\"  \"7\"   \"\"   \n## [2,] \"Faria, Pedro Duarte\"   \"1290321_1\"   \"\"   \"\"   \"\"   \"\"   \"\"    \"\"   \n## [3,] \"Objeto não localizado\" \"10_0x341167\" \"\"   \"\"   \"\"   \"\"   \"\"    \"\"   \n## [4,] \"A732\"                  \"B3\"          \"24\" \"C1\" \"90\" \"89\" \"QUA\" \"ABD\"\n##      [,9]    [,10] [,11] \n## [1,] \"\"      \"\"    \"\"    \n## [2,] \"\"      \"\"    \"\"    \n## [3,] \"\"      \"\"    \"\"    \n## [4,] \"AQZ29\" \"C11\" \"01ER\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"extraindo-apenas-a-correspondência-de-sua-expressão-regular-com-str_extract","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"10.11 Extraindo apenas a correspondência de sua expressão regular com str_extract()","text":"Assim como substituir suas correspondências por novos valores, você também tem capacidade de extrair essas correspondências isoladamente, por meio da função str_extract(). Essa funcionalidade se torna extremamente importante quando não apenas estrutura de cada elemento de seu vetor difere, mas também, quando posição de seu alvo ao longo da cadeia de texto varia. Essas características tornam impossível extração de nosso alvo com função str_sub() (que apresentamos anteriormente), que se baseia diretamente na posição dos caracteres ao longo texto.Por isso, melhor alternativa para superarmos esse empecilho, é empregar uma expressão regular que possa detectar os nossos alvos e, com isso, extraí-los por meio da função str_extract(). Como exemplo, podemos extrair todos os anos presentes em cada elemento vetor per, através seguinte comando:Ou melhor, podemos colocar o texto original e parte extraída em uma tabela:Assim como str_replace(), str_extract() é capaz de extrair apenas primeira correspondência encontrada por sua expressão regular. Por esse motivo, você irá precisar de sua variante, str_extract_all(), em todas ocasiões em que você tiver mais de um alvo ser extraído em cada texto. Por exemplo, podemos extrair o valor de cada medida presente em medidas, por meio da expressão \"([0-9]+)([.][0-9]+)?\".","code":"\nper <- c(\"Janeiro_2020\", \"Visitei Pará de Minas em Fevereiro de 2019\",\n         \"2020 foi um ano terrível\", \"O Brasil era a 11° economia do mundo em 2005\")\n\nstr_extract(per, \"\\\\d{4}\")## [1] \"2020\" \"2019\" \"2020\" \"2005\"\ntibble(\n  text = per,\n  ano = str_extract(per, \"\\\\d{4}\")\n)## # A tibble: 4 x 2\n##   text                                         ano  \n##   <chr>                                        <chr>\n## 1 Janeiro_2020                                 2020 \n## 2 Visitei Pará de Minas em Fevereiro de 2019   2019 \n## 3 2020 foi um ano terrível                     2020 \n## 4 O Brasil era a 11° economia do mundo em 2005 2005\n### Largura X Altura X Profundidade (Peso, Classe)\nmedidas <- c(\n  \"8.15 m X 2.23 m X 4.5 m (240 Kg, B)\",\n  \"1.14 m X 3.1 m X 0.9 m (15 Kg, A)\",\n  \"4.98 m X 9.2 m X 5.25 m (120 Kg, A)\",\n  \"3.14 m X 3.89 m X 3.41 m (86 Kg, C)\"\n)\n\ntab <- str_extract_all(\n  medidas,\n  \"([0-9]+)([.][0-9]+)?\",\n  simplify = TRUE\n)\n\ncolnames(tab) <- c(\n  \"Largura\", \"Altura\", \"Profundidade\", \"Peso\"\n)\n\ntab##      Largura Altura Profundidade Peso \n## [1,] \"8.15\"  \"2.23\" \"4.5\"        \"240\"\n## [2,] \"1.14\"  \"3.1\"  \"0.9\"        \"15\" \n## [3,] \"4.98\"  \"9.2\"  \"5.25\"       \"120\"\n## [4,] \"3.14\"  \"3.89\" \"3.41\"       \"86\""},{"path":"manipulação-e-transformação-de-strings-com-stringr.html","id":"exercícios-8","chapter":"Capítulo 10 Manipulação e transformação de strings com stringr","heading":"Exercícios","text":"Questão 10.1. Em cada item dessa questão, você deve criar uma expressão regular que represente sequência de caracteres descrita enunciado. Em seguida, você deve aplicar essa expressão regular sobre o vetor words, com o objetivo de extrair todas palavras desse vetor que se encaixam nessa determinada expressão. O vetor words advém pacote stringr, logo, se você conseguiu chamar por esse pacote em sua sessão através comando library(), você já possui acesso esse vetor.10.1.) Um “b” ou “c” seguidos de um “” e um “l.”10.1.B) Um caractere qualquer (exceto letra “”) imediatamente seguido por um “c,” que por sua vez, é seguido pelo final string.10.1.C) sequência “s-p--c-e” de caracteres, ou, um “e” imediatamente seguido por duas letras “s,” que por sua vez são seguidos imediatamente pelo final da linha.10.1.D) Crie uma expressão regular que possa encontrar todas palavras presentes em words que contém exatos 3 caracteres. Você pode solucionar essa questão com função str_length(). Porém, você deve utilizar uma expressão regular para encontrar essas palavras de 3 caracteres, portanto, esqueça momentaneamente que função str_length() existe35.Questão 10.2. Os itens desta questão vão trabalhar com o vetor compras. Para importar esse vetor para sua sessão R, copie e cole os comandos abaixo em seu console. Como você pode ver abaixo, cada elemento vetor compras contém uma string bastante longa, tão longa que fui obrigado utilizar função str_trunc() para cortar parte texto e apresentar abaixo apenas os 50 primeiros caracteres de cada string. Dentro de cada string, você possui um conjunto de dados referentes uma compra realizada em uma loja durante o ano de 2020.10.2.) Como você pôde ver acima, os dados estão misturados em cada string. Em outras palavras, loja que coletou esses dados não se preoucupou em utilizar um separador especial para separar variáveis em diferentes colunas. Agora, eles estão todos juntos, um lado outro, em uma única coluna.Em resumo, cada string guarda informações de 7 variáveis diferentes: nome consumidor; CPF consumidor; código de identificação da venda; código de identificação produto comprado; valor pago por unidade; quantidade adquirida; horário da compra. Precisamente nessa ordem. Como um guia, temos figuras 10.8 e 10.9 abaixo. Cada figura apresenta uma “metade” específica primeiro string presente vetor compras (o string é muito grande, por isso, optou-se por dividí-lo em duas figuras). Cada figura, busca descrever estrutura seguida por cada string vetor compras.\nFigure 10.8: Descrição dos 39 primeiros caracteres de cada string presente em compras\n\nFigure 10.9: Descrição dos 43 últimos caracteres de cada string presente em compras\nO seu trabalho é utilizar ferramentas que você viu nesse capítulo, para extrair essas 7 variáveis e alocá-las em colunas separadas de um data.frame. Esse não é um exercício muito simples, mas ele também transmite certa realidade. Há diversas bases de dados e análises reais na indústria, que exigem um uso intensivo de ferramentas de extração e localização de texto, como é o caso desse exercício sobre o vetor compras.Para realizar essa atividade, você não precisa necessariamente utilizar apenas expressões regulares por todo o caminho. Dado complexidade desses strings, é interessante e, até mais simples, que você misture um pouco suas técnicas, ao trabalhar com partes (ou subsets) específicos dos strings com str_length() e str_sub() e, em seguida, aplicar expressões regulares sobre partes restantes dos strings.Caso você opte por utilizar uma única expressão regular para resolver esse item, é fundamental que você compreenda bem como os valores de cada variável podem variar em cada string. Em outras palavras, para que você seja capaz de descrever, com precisão, cada parte da sequência de caracteres que compõe esses strings, você precisa saber, por exemplo: quais caracteres podem aparecer, na parte que apresenta o código de identificação da venda; ou ainda, quantos dígitos são permitidos campo valor unitário produto? Para ter essa compreensão, leia atentamente às figuras 10.8 e 10.9.10.2.B) Volte ao vetor compras e extraia de cada string, apenas parte correspondente à data e horário da compra. Com esses valores em mãos, tente capturar o dia de cada data, por último, realize uma contagem sobre esses dias, e descubra o dia mês em que essa loja possui o maior número de vendas.10.2.C) Selecione os 3 primeiros dígitos CPF consumidor de cada string.","code":"\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo <- \"compras_completo.txt\"\n\ncompras <- read_lines(paste0(github, pasta, arquivo))\n\nstr_trunc(head(compras), width = 50, ellipsis = \"~\")## [1] \"Márcio390.287.917-210akqzS2tk$URMcLOk5Q2356772.25~\"\n## [2] \"Igor944.236.416-254tLo8&S9WtXg05fsdU2188525.212/0~\"\n## [3] \"Márcio395.304.955-57pfwji9Z4Q6dZxSWZV7#7Z$J218160~\"\n## [4] \"Isabela322.900.842-74K5D6b$xAnY&QJ1$XQzE2f1554399~\"\n## [5] \"Álvaro475.767.740-583WWonElfbisKD1GiIVS225066.161~\"\n## [6] \"Rafael031.357.966-89bOzZ7#2JBcsd!sWzaeNY1866117.7~\""},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"introduzindo-fatores-factors-com-forcats","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","text":"","code":""},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"introdução-e-pré-requisitos-5","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.1 Introdução e pré-requisitos","text":"capítulo de Fundamentos da Linguagem R, introduzimos os 4 tipos básicos de dados disponíveis R, sendo eles: integer; double; character; e logical. Entretanto, também destacamos que outros tipos de dados “mais complexos” estão presentes na linguagem R, e, que eles serão tão importantes quanto os tipos básicos em suas análises.Os exemplos mais importantes desses tipos são os fatores (factor) e variáveis de tempo, isto é, datas e horários (Date ou POSIXct). Neste capítulo, vamos focar discussão tipo factor, e, próximo capítulo, discutiremos os tipos referentes às variáveis de tempo.Parte dos exemplos deste capítulo, envolvem o uso de funções pacote forcats, portanto, não se esqueça de instalar esse pacote (com o comando install.packages()), e, logo depois, chamar pelo pacote para sua sessão (com o comando library()). O pacote forcats está incluso pacote tidyverse, e, por isso, o tidyverse representa um caminho alternativo para você acessar funções deste pacote.","code":"\nlibrary(forcats)\n## Ou\nlibrary(tidyverse)"},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"o-que-são-fatores","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.2 O que são fatores ?","text":"Um fator (ou factor) é um tipo de dado R desenvolvido para o trabalho com variáveis categóricas, ou variáveis qualitativas. Ou seja, o tipo de dado factor lhe permite armazenar características e qualidades que um indivíduo carrega, ou de outra forma, qual “categoria” ou grupo em que cada indivíduo de sua tabela se encaixa.O sexo e cor de pele são dois exemplos clássicos de variáveis qualitativas, pois elas identificam uma característica física indivíduo. Características essas que determinam se o indíviduo pertence ou não um grupo específico de pessoas (mulheres pardas, homens brancos, etc.). faixa etária é um outro exemplo muito comum, sendo uma varíavel que busca separar indivíduos em vários grupos de acordo com suas idades.Entretanto, para além de características e categorias, também podemos identificar uma variável categórica, ao percebermos se essa variável pode (ou deve) assumir um conjunto muito específico e muito bem definido de valores (R Core Team 2020b, p 8). Por exemplo, uma variável que apresente o sexo de uma pessoa pode assumir apenas dois valores diferentes (Homem ou Mulher; Masculino ou Feminimo; H ou M; ou alguma outra variação desses valores). Pode haver ainda, necessidade de incluir um terceiro valor para casos especiais, como “Indefinido,” mas em geral, o sexo assume apenas os dois valores supracitados36. Como um outro exemplo, uma variável que guarda o mês ano ao qual os dados de sua tabela se referem pode assumir apenas doze valores diferentes (Janeiro, Fevereiro, Março, …, Novembro, Dezembro), logo, essa também é uma variável categórica sob essa perspectiva.","code":""},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"como-construir-um-fator","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.3 Como construir um fator","text":"Suponha que você tenha questionado o sexo de várias pessoas, e anotado suas respostas vetor abaixo (entrevista):Se você deseja transformar esse vetor acima (que momento é um vetor tipo character) em um vetor tipo factor, você deve primeiro pensar sobre o atributo levels que será utilizado neste vetor. Ou seja, todo objeto tipo factor R possui um atributo chamado levels, que representa o conjunto de valores que variável em questão pode assumir. Como estamos anotando o sexo de algumas pessoas entrevistadas, sabemos que essa variável pode assumir apenas dois valores diferentes. Eu crio o vetor abaixo (niveis_sexo) com o objetivo de guardar essas informações.Agora que temos o vetor com informação original (entrevista) e um vetor com os níveis, ou, os valores permitidos para essa variável (niveis_sexo), podemos criar o nosso fator através da função factor().Perceba acima, que ao chamarmos pelo novo fator criado, os níveis da variável (atributo levels) são mostrados logo abaixo dos valores armazenados. Repare também, que todos os valores presentes vetor original (entrevista) e que estejam fora dos níveis da variável (niveis_sexo) são silenciosamente convertidos para valores NA. Isto é, qualquer valor que esteja minimamente divergente dos valores presentes em levels, ou que contenha algum erro ortográfico, será convertido para um valor NA.Você sempre pode acessar os níveis (isto é, o atributo levels) de um fator por meio da função levels(). Basta aplicá-la diretamente sobre o fator, que um vetor contendo esses níveis será retornado para você.Vale destacar, que para o R, um vetor tipo factor, é na verdade, um vetor tipo integer que carrega uma classe factor, e que possui um atributo chamado levels. Esse é um dos principais motivos pelos quais os tipos factor, Date e POSIXct são caracterizados como tipos “mais complexos” da linguagem R. Pois esses tipos são construídos partir dos quatro tipos básicos, mas eles também acumulam novas características ou propriedades que não estão presentes nesses tipos básicos.caso tipo factor, ele é construído partir tipo integer devido forma como o R guarda os valores presentes em um vetor tipo factor (R Core Team 2020b, p 8). Por exemplo, os valores “Homem” e “Mulher” vetor vec_fator acima, são guardados pelo R como valores 1 e 2, e são posteriormente traduzidos como valores “Homem” e “Mulher” quando chamamos pelo vetor vec_fator. Tudo isso ocorre, devido às propriedades e atributos que um vetor tipo factor carrega, e que o diferenciam de um vetor tipo integer.","code":"\nentrevista <- c(\"Mulher\", \"Homem\", \"Homem\", \"Mulher\", \"Mum\")\nniveis_sexo <- c(\"Homem\", \"Mulher\")\nvec_fator <- factor(entrevista, levels = niveis_sexo)\nvec_fator## [1] Mulher Homem  Homem  Mulher <NA>  \n## Levels: Homem Mulher\nlevels(vec_fator)## [1] \"Homem\"  \"Mulher\"\ntypeof(vec_fator)## [1] \"integer\"\nclass(vec_fator)## [1] \"factor\"\nattributes(vec_fator)## $levels\n## [1] \"Homem\"  \"Mulher\"\n## \n## $class\n## [1] \"factor\""},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"porque-utilizar-fatores-se-eu-posso-armazenar-como-texto","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.4 Porque utilizar fatores se eu posso armazenar como texto ?","text":"Você provavelmente está se perguntando qual necessidade verdadeira dos fatores, levando em conta que você pode utilizar o tipo character para armazenar os dados de um variável qualitativa. Wickham Grolemund (2017, p 224) nos concede um ótimo exemplo de como um fator pode fazer toda diferença.Por exemplo, suponha que você possua o vetor abaixo contendo alguns meses ano. Em geral, há dois problemas uso de um vetor tipo character para guardar essas informações.Primeiro, você não está prevenido contra possíveis erros ortográficos. Isso pode ser um problema de pouca importância caso esses dados estejam sendo gerados por uma máquina ou programa, mas ele se torna um problema sério caso você esteja anotando esses valores na mão, ou esteja constantemente corrigindo-os de alguma maneira que seja suscetível ao erro. Logo, se algum mês incorretamente gravado, nenhum erro ou medida cautelar será acionada pelo R para corrigir esse problema.Segundo, quando essas informações estão sendo guardadas pelo tipo character, o sistema de ordenação utilizado pelo R (ordenação alfabética) é de pouca utilidade. Como você pode ver abaixo, o R acabou colocando o mês de Abril antes dos meses de Fevereiro e Janeiro.O uso tipo factor consegue resolver ambos desses problemas. Pois você já sabe que qualquer valor disposto em vec, que possua algum erro ortográfico em comparação com os meses dispostos atributo levels fator será automaticamente convertido para um valor NA. Além disso, ao ordenar um objeto tipo factor, o R sempre vai utilizar como referência, ordem na qual os valores estão apresentados atributo levels.Como o vetor vec guarda alguns meses ano, o vetor meses abaixo, representa o atributo levels fator ser criado partir de vec. Lembre-se que, ordem na qual os meses estão dispostos atributo levels, afeta diretamente maneira como o R ordena o fator. Logo, ordem em que você fornece os valores em meses, será ordem utilizada pelo R ao ordenar os valores de vec_fator.","code":"\nvec <- c(\"Mar\", \"Fev\", \"Jan\", \"Set\", \"Out\", \"Abr\")\nsort(vec)## [1] \"Abr\" \"Fev\" \"Jan\" \"Mar\" \"Out\" \"Set\"\nmeses <- c(\"Jan\", \"Fev\", \"Mar\", \"Abr\", \"Mai\", \"Jun\",\n           \"Jul\", \"Ago\", \"Set\", \"Out\", \"Nov\", \"Dez\")\n\nvec_fator <- factor(vec, levels = meses)\nvec_fator## [1] Mar Fev Jan Set Out Abr\n## Levels: Jan Fev Mar Abr Mai Jun Jul Ago Set Out Nov Dez\nsort(vec_fator)## [1] Jan Fev Mar Abr Set Out\n## Levels: Jan Fev Mar Abr Mai Jun Jul Ago Set Out Nov Dez"},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"não-construir-o-atributo-levels-é-contraintuitivo","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.5 Não construir o atributo levels é contraintuitivo","text":"Apesar de ser o ideal, você não precisa obrigatoriamente construir o atributo levels ao formar um fator. Pois você tem opção de delegar esse trabalho para própria função factor(), ao aplicá-la diretamente sobre o seu vetor de interesse.Porém, ao escolher esse caminho, factor() vai extrair todos os valores únicos de seu vetor, e posicioná-los em ordem alfabética atributo levels. Ou seja, supondo que o seu vetor de interesse se chame x, é como se o atributo levels de seu fator, equivalesse ao resultado dos comandos: unique(x) %>% sort(); ou de outra forma: sort(unique(x)). Veja o exemplo abaixo:Perceba acima, que tal comportamento de factor() torna o uso de fatores, algo inútil ou desnecessário. Pois ordenação de seu fator será idêntica à ordenação alfabética utilizada sobre um vetor tipo character. Lembre-se que para ordenação de um fator, é utilizada ordem na qual os valores são apresentados em levels(). Tal ponto pode ser inferido pelo exemplo abaixo, em que ordenação produzida sobre os valores de v_letras é mesma (em comparação com o resultado acima) quando ela se encontra tipo character.","code":"\nv_letras <- c(\"e\", \"a\", \"b\", \"c\", \"a\", \"b\", \"d\")\nf <- factor(v_letras)\nf## [1] e a b c a b d\n## Levels: a b c d e\nsort(f)## [1] a a b b c d e\n## Levels: a b c d e\nv_letras <- c(\"e\", \"a\", \"b\", \"c\", \"a\", \"b\", \"d\")\ntypeof(v_letras)## [1] \"character\"\nsort(v_letras)## [1] \"a\" \"a\" \"b\" \"b\" \"c\" \"d\" \"e\""},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"alterando-a-ordem-dos-níveis-de-um-fator","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.6 Alterando a ordem dos níveis de um fator","text":"Portanto, o sistema de ordenação é um dos principais recursos tipo factor R, e tal sistema está diretamente conectado com o seu atributo levels. Por isso, uma das principais atividades com fatores está na reordenação e atributo levels, ou em sua reatribuição.","code":""},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"a-maneira-mais-simples-e-direta","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.6.1 A maneira mais simples e direta","text":"forma mais “simples” de alterarmos esse atributo é redefinindo-o por completo através da função levels(). Repare exemplo abaixo, que apenas letra “” foi reposicionada atributo.Tal operação poderia ser realizada de diversas formas. Por exemplo, caso o seu fator possua um número muito grande de níveis, ao invés de reescrevê-los na mão, talvez seja mais rápido utilizar técnicas de subsetting para reordenar os níveis da maneira desejada.","code":"\nlevels(f) <- c(\"b\", \"c\", \"d\", \"e\", \"a\")\nsort(f)## [1] b b c c d e a\n## Levels: b c d e a\n## Criando um fator com muitos níveis\nf <- c(\"a\", \"b\", \"c\", \"d\", \"e\")\nlevels(f) <- c(\n  \"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\",\n  \"h\", \"i\", \"j\", \"k\", \"l\", \"m\", \"n\",\n  \"o\", \"p\", \"q\", \"r\", \"s\", \"t\", \"u\",\n  \"v\", \"w\", \"x\", \"y\", \"z\"\n)\n\n## Selecionando os níveis atuais\n## e reordenando-os com subsetting\nniveis_atuais <- levels(f)\nn_niveis <- length(niveis_atuais)\nnovos_niveis <- niveis_atuais[c(4:2, 5:n_niveis, 1)]\n\n## Redefinindo os níveis do fator\nlevels(f) <- novos_niveis\nf## [1] \"a\" \"b\" \"c\" \"d\" \"e\"\n## attr(,\"levels\")\n##  [1] \"d\" \"c\" \"b\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\"\n## [18] \"s\" \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\" \"a\""},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"maneiras-alternativas-que-podem-fazer-a-diferença","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.6.2 Maneiras alternativas que podem fazer a diferença","text":"O pacote forcats oferece várias funções voltadas especificamente para o trabalho com fatores R. Dentre essas funções, temos fct_infreq(), que lhe permite reordenar o atributo levels de acordo com frequência em que cada nível aparece vetor (nível mais frequente para o menos frequente).Além disso, você também pode estar interessado em ordenar os níveis de um fator, de acordo com ordem da primeira aparição de cada nível. Para isso, nós podemos utilizar função fct_inorder(). Perceba pelo resultado exemplo abaixo, que letras “e,” “d” e “c” antecedem letras “” e “b” atributo levels fator gerado, pois essas letras aparecem primeiro vetor original.Para mais, haverá momentos em que você deseja ordenar os níveis de seu fator, de acordo com uma segunda variável. Essa situação ocorre principalmente quando o seu fator está incluso em um data.frame, junto de várias outras variáveis de seu interesse. Para tal ação, temos função fct_reorder(), que lhe permite fornecer uma segunda variável na qual ordenação atributo levels será baseada.Como exemplo, suponha que você possua seguinte tabela contendo receitas mensais de algums lojas:exemplo abaixo, ao transformarmos variável unidade em um fator, os níveis da variável são organizados em ordem alfabética, como era esperado.função fct_reorder() vai sempre ordenar o seu fator de acordo com um sumário, ou alguma estatística descritiva da segunda variável. Por isso, você deve se perguntar qual estatística descritiva você deseja utilizar sobre segunda variável em questão. Como exemplo, você talvez queira ordenar os níveis de unidade, de acordo com receita média mensal de cada loja.Logo, desejamos aplicar uma função de média sobre variável receita ao longo de cada nível fator unidade. Por isso, eu forneço função mean() ao argumento .fun de fct_reorder(). Como podemos ver abaixo, unidades Centro e da Savassi possuem receitas médias menores que unidades da Pampulha e da Gameleira, pois essas unidades se encontram nas primeiras posições atributo levels fator resultante de fct_reorder(). Ou seja, função fct_reorder() utiliza, por padrão, uma ordem crescente atributo levels. Caso você deseje inverter esse comportamento, basta configurar o argumento .desc da função para TRUE.","code":"\nv_letras <- c(\"e\", \"d\", \"d\", \"c\", \"a\", \"a\", \"a\", \"c\",\n              \"b\", \"d\", \"d\", \"e\", \"d\", \"a\", \"d\", \"c\")\nf <- factor(v_letras)\nfct_infreq(f)##  [1] e d d c a a a c b d d e d a d c\n## Levels: d a c e b\nfct_inorder(f)##  [1] e d d c a a a c b d d e d a d c\n## Levels: e d c a b\nunidades <- c(\"Savassi\", \"Centro\", \"Gameleira\", \"Pampulha\")\nset.seed(3)\ntab <- tibble(\n  ano = 2021,\n  mes = rep(1:12, each = 4),\n  unidade = rep(unidades, times = 12),\n  receita = rnorm(48, 17000, 4800)\n)\ntab <- arrange(tab, mes, unidade)\ntab## # A tibble: 48 x 4\n##      ano   mes unidade   receita\n##    <dbl> <int> <chr>       <dbl>\n##  1  2021     1 Centro     15596.\n##  2  2021     1 Gameleira  18242.\n##  3  2021     1 Pampulha   11470.\n##  4  2021     1 Savassi    12383.\n##  5  2021     2 Centro     17145.\n##  6  2021     2 Gameleira  17410.\n##  7  2021     2 Pampulha   22360.\n##  8  2021     2 Savassi    17940.\n##  9  2021     3 Centro     23083.\n## 10  2021     3 Gameleira  13425.\n## # ... with 38 more rows\ntab$unidade <- factor(tab$unidade)\ntab$unidade##  [1] Centro    Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha \n##  [8] Savassi   Centro    Gameleira Pampulha  Savassi   Centro    Gameleira\n## [15] Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi   Centro   \n## [22] Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi  \n## [29] Centro    Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha \n## [36] Savassi   Centro    Gameleira Pampulha  Savassi   Centro    Gameleira\n## [43] Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi  \n## Levels: Centro Gameleira Pampulha Savassi\n## Utilize: fct_reorder(unidade, receita, .fun = mean, .desc = TRUE)\n## para utilizar uma ordenação crescente no atributo levels\ntab <- tab %>% \n  mutate(\n    unidade = fct_reorder(unidade, receita, .fun = mean)\n  )\n\ntab$unidade##  [1] Centro    Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha \n##  [8] Savassi   Centro    Gameleira Pampulha  Savassi   Centro    Gameleira\n## [15] Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi   Centro   \n## [22] Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi  \n## [29] Centro    Gameleira Pampulha  Savassi   Centro    Gameleira Pampulha \n## [36] Savassi   Centro    Gameleira Pampulha  Savassi   Centro    Gameleira\n## [43] Pampulha  Savassi   Centro    Gameleira Pampulha  Savassi  \n## Levels: Centro Savassi Pampulha Gameleira"},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"reordenando-fatores-em-gráficos","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.7 Reordenando fatores em gráficos","text":"ordem na qual apresentamos certas informações pode mudar drasticamente não apenas características físicas e visuais de seu gráfico, mas também, pode afetar e muito clareza ou ênfase em certas informações que são cruciais em nosso gráfico. Por essa razão, reordenar variáveis categóricas em seu gráfico pode ser fundamental. Veja o primeiro exemplo abaixo, dado por Wickham Grolemund (2017, p 228).Dentre funções que mostramos na seção passada, função fct_reorder() é talvez mais útil delas em gráficos. Por exemplo, gráfico abaixo, temos certa dificuldade em comparar e, principalmente, classificar os vários tempos médios gastos dentro de cada grupo religioso.Tal problema, pode ser rapidamente resolvido ao aplicarmos função fct_reorder() sobre variável eixo y, para que ela seja reordenada de acordo com os valores da variável eixo x gráfico. Perceba abaixo, que agora temos uma facilidade muito maior em comparar e classificar os vários tempos médios gastos em cada grupo religioso. Com essa nova ordenação, podemos rapidamente identificar que pessoas que não sabem (“Don’t know”) sua religião (ou que são ateus), são aquelas que mais gastam seu tempo em frente uma televisão.Como um outro exemplo, pode haver certas variáveis que não necessitam de uma reordenação acentuada. Além disso, tais variáveis podem possuir uma ordem própria, que não depende de uma segunda variável. Ou seja, essas variáveis podem possuir uma “ordem natural.” Essa característica, torna o uso de fct_reorder() inadequado (lembre-se que fct_reorder() busca reordenar um fator de acordo com os valores de uma segunda variável).Por exemplo, se você olhar para o gráfico abaixo, você poderá perceber que temos uma variável de faixa etária eixo y, e que apenas faixa de “Menos de 10” está incorretamente posicionada eixo. Pelo fato das faixas etárias possuírem uma “ordem natural,” isto é, faixas “mais altas” são aquelas referentes às idades mais elevadas, enquanto faixas “mais baixas” são aquelas referentes às idades “mais baixas,” não faz sentido reordenarmos essa variável de acordo com os valores de uma segunda variável.Portanto, faixa de “Menos de 10” é única faixa ser reposicionada, e podemos realizar tal ação com função fct_relevel(). Repare exemplo abaixo, que após o ajuste, faixa “Menos de 10” foi realocada para posição mais inferior eixo.Além dessas opções, função fct_infreq() é muito útil para gráficos de barras ggplot, que incluem por padrão um cálculo de frequência. Em outras palavras, ao lembrarmos que fct_infreq() busca reordenar um fator de acordo com frequência em que os seus níveis aparecem em seus dados, se torna muito natural aliarmos essa função um gráfico de barras ggplot.Por exemplo, se gerarmos um gráfico de barras partir de cada cor de pele presente em nossa tabela datasus, temos o seguinte resultado:Agora, com o uso de fct_infreq() podemos reposicionar essas barras em um sentido mais lógico, como está demonstrado abaixo:","code":"\nrelig <- gss_cat %>%\n  group_by(relig) %>%\n  summarize(\n    age = mean(age, na.rm = TRUE),\n    tvhours = mean(tvhours, na.rm = TRUE),\n    n = n()\n  )\n\nrelig %>% \n  ggplot() + \n  geom_point(aes(tvhours, relig))\nrelig %>% \n  ggplot() + \n  geom_point(\n    aes(tvhours, fct_reorder(relig, tvhours))\n  )\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\narquivo <- \"Curso-R/master/Dados/datasus.csv\"\ndatasus <- read_csv2(paste0(github, arquivo))\n\ntotais <- datasus %>% \n  group_by(`Faixa etaria`) %>% \n  summarise(\n    Total = sum(Contagem)\n  )\ntotais %>% \n  ggplot() +\n  geom_col(\n    aes(y = `Faixa etaria`, x = Total)\n  )\ntotais %>% \n  mutate(\n    `Faixa etaria` = fct_relevel(`Faixa etaria`, \"Menos de 10\")\n  ) %>% \n  ggplot() +\n  geom_col(\n    aes(y = `Faixa etaria`, x = Total)\n  )\ndatasus %>% \n  ggplot() +\n  geom_bar(\n    aes(x = Cor)\n  )\ndatasus %>% \n  ggplot() +\n  geom_bar(\n    aes(x = fct_infreq(Cor))\n  )"},{"path":"introduzindo-fatores-factors-com-forcats.html","id":"modificando-os-níveis-de-um-fator","chapter":"Capítulo 11 Introduzindo fatores (factor’s) com forcats","heading":"11.8 Modificando os níveis de um fator","text":"Até o momento, demos bastante foco sobre ordenação dos valores presentes atributo levels. Justamente pelo fato de que essa característica define uma das principais vantagens tipo factor R, que é de modificar forma como linguagem ordena os valores presentes em um vetor. Porém, ainda não discutimos o que ocorre quando nós deliberadamente alteramos um dos valores presentes atributo levels.Por exemplo, suponha que eu possua o fator abaixo. Nesse caso, o fator f possui quatro níveis, sendo eles: , b, c, e d.Agora, o que ocorre se eu tentar modificar o primeiro nível () desse fator? De maneira elegante e surpreendente, o R irá substituir todos os valores presentes fator, pelo novo valor definido, como está demonstrado abaixo:Assim como nas seções anteriores, o pacote forcats também oferece algumas funções muito úteis para esse procedimento. Veja o exemplo abaixo, em que eu utilizo função fct_recode() para reconfigurar todos os níveis (ou valores) presentes coluna Cor em nossa tabela datasus.Caso você precise unir diversos níveis em um só, ou, em outras palavras, se você precisa agregar vários níveis, função fct_collapse() é uma melhor escolha. Pois ela lhe permite fornecer um vetor contendo todos os níveis antigos serem agregados em um só. Veja o exemplo abaixo, em que eu agrego diversas faixas etárias, gerando assim, uma descrição etária menos detalhada:","code":"\nvec <- c(\"a\", \"c\", \"c\", \"d\", \"b\", \"a\", \"b\")\nf <- factor(vec, levels = c(\"a\", \"b\", \"c\", \"d\"))\nf## [1] a c c d b a b\n## Levels: a b c d\nlevels(f) <- c(\"m\", \"b\", \"c\", \"d\")\nf## [1] m c c d b m b\n## Levels: m b c d\ndatasus %>% \n  mutate(\n    Cor = fct_recode(\n      Cor,\n      \"Carmim\" = \"Parda\",\n      \"Azul\" = \"Amarela\",\n      \"Bronze\" = \"Branca\",\n      \"Roxo\" = \"Indígena\"\n    )\n  )## # A tibble: 1,836 x 6\n##    `Faixa etaria` Genero    Cor    `Nome UF` UF    Contagem\n##    <chr>          <chr>     <fct>  <chr>     <chr>    <dbl>\n##  1 10 a 14        Feminino  Carmim Acre      AC           4\n##  2 10 a 14        Masculino Carmim Acre      AC           4\n##  3 15 a 19        Feminino  Bronze Acre      AC           2\n##  4 15 a 19        Feminino  Carmim Acre      AC           4\n##  5 15 a 19        Masculino Bronze Acre      AC           6\n##  6 15 a 19        Masculino Carmim Acre      AC          65\n##  7 15 a 19        Masculino Preta  Acre      AC           1\n##  8 20 a 24        Feminino  Roxo   Acre      AC           1\n##  9 20 a 24        Feminino  Carmim Acre      AC           4\n## 10 20 a 24        Masculino Bronze Acre      AC           7\n## # ... with 1,826 more rows\ndatasus %>% \n  mutate(\n    `Faixa etaria` = fct_collapse(\n      `Faixa etaria`,\n      \"Menos de 19 anos\" = c(\"Menos de 10\", \"10 a 14\", \"15 a 19\"),\n      \"Entre 20 e 64 anos\" = c(\"20 a 24\", \"25 a 29\", \"30 a 34\",\n                               \"35 a 39\", \"40 a 44\", \"45 a 49\",\n                               \"50 a 54\", \"55 a 59\", \"60 a 64\"),\n      \"Acima de 64 anos\" = c(\"65 a 69\", \"Mais de 70\")\n    )\n  )## # A tibble: 1,836 x 6\n##    `Faixa etaria`     Genero    Cor      `Nome UF` UF    Contagem\n##    <fct>              <chr>     <chr>    <chr>     <chr>    <dbl>\n##  1 Menos de 19 anos   Feminino  Parda    Acre      AC           4\n##  2 Menos de 19 anos   Masculino Parda    Acre      AC           4\n##  3 Menos de 19 anos   Feminino  Branca   Acre      AC           2\n##  4 Menos de 19 anos   Feminino  Parda    Acre      AC           4\n##  5 Menos de 19 anos   Masculino Branca   Acre      AC           6\n##  6 Menos de 19 anos   Masculino Parda    Acre      AC          65\n##  7 Menos de 19 anos   Masculino Preta    Acre      AC           1\n##  8 Entre 20 e 64 anos Feminino  Indígena Acre      AC           1\n##  9 Entre 20 e 64 anos Feminino  Parda    Acre      AC           4\n## 10 Entre 20 e 64 anos Masculino Branca   Acre      AC           7\n## # ... with 1,826 more rows"},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"introdução-à-variáveis-de-tempo-com-lubridate","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"Capítulo 12 Introdução à variáveis de tempo com lubridate","text":"","code":""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"sec:lubridate_var_tempo","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.1 Introdução e pré-requisitos","text":"Variáveis de tempo são aquelas que guardam informações que se encontram em alguma unidade de tempo. Exemplos são: datas (.e. 20 de março de 2020), ou horários - que preferencialmente são acompanhados por uma data (.e. 11:45 da manhã dia 12 de fevereiro de 2001; ou, 12/02/2001 11:45:00), ou ainda, duração (ou o tempo) de algum evento (12 segundos, 12 dias, 2 semanas, 1 mês e meio, etc.).Tais variáveis podem ser interpretadas R por meio de quatro tipos de dados diferentes, sendo eles: Date, POSIXlt, POSIXct e difftime. Logo, neste capítulo, vamos focar nesses quatro tipos de dados, e, introduzir várias ferramentas e operações comumente aplicadas sobre eles. Parte dessas ferramentas advém pacote lubridate e, portanto, para acompanhar os exemplos deste capítulo, você deve (após instalar esse pacote em sua máquina) chamar por esse pacote em sua sessão, através comando library().","code":"\nlibrary(lubridate)"},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"o-pacote-lubridate","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.2 O pacote lubridate","text":"Como é bem descrito por Ripley Hornik (2001) e Grothendieck Petzoldt (2004), desde sua versão 1.9, o R oferece “de fábrica” um excelente suporte para variáveis de tempo. Suas funções são capazes de lidar muito bem com diferenças entre fusos horários, além de incluírem anos bissextos e horários de verão. Porém, mesmo com esse potencial, essas funções (.Date(), .POSIXct(), strptime(), dentre outras) tendem aplicar definições muito formais, tornando-assim, pouca intuitivas para muitos usuários.Por esse motivo, o pacote lubridate tem tido muito sucesso ao longo da comunidade, ao prover funções que realizam grande parte trabalho irritante com essas funções. Ou seja, fundo, várias das funções pacote lubridate são apenas wrappers, isto é, são construídas partir das funções pacote básico R. Significa que o pacote lubridate foi criado, em grande parte, com o intuito de facilitar o nosso trabalho com ferramentas que o R já oferece, ao invés de remodelá-las por completo.Portanto, ao longo deste capítulo, você irá aprender primeiro sobre funções pacote lubridate, e, em seguida, funções básicas R são apresentadas para aqueles que desejam conhecer mais fundo tal sistema. Dessa forma, nós estaremos apresentando primeiro, o atalho, e, em seguida, o caminho completo.","code":""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"datas-com-o-tipo-date","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.3 Datas com o tipo Date","text":"R, datas são normalmente interpretadas através tipo de dado Date. Temos 3 métodos principais de se criar uma data R (existem outros métodos menos intuitivos37), os quais estão resumidos na figura 12.1 abaixo, e que são apresentados seguir: 1) partir de strings (um vetor tipo character); 2) partir de cada componente da data (dia, mês e ano); e 3) partir de números.\nFigure 12.1: Principais métodos para se criar datas R\nDentre funções dos pacotes básicos R, função .Date() é principal função responsável por criar vetores tipo Date. Todavia, ao longo dessa seção, estaremos focados nas funções pacote lubridate, em especial, função as_date(). De qualquer forma, saiba que, fim das contas, funções desse pacote vão utilizar função .Date() para criar o vetor contendo suas datas. funções as_date() e .Date() são muito semelhantes entre si, logo, grande parte conhecimento mostrado em as_date(), pode ser diretamente aplicado em .Date().Ao longo das próximas seções, você pode rapidamente perceber que formação de dados tipo Date (assim como dos tipos POSIXct e POSIXlt) R, envolve o ato de coerção de vetores que se encontram em outros tipos (como character ou double) para o tipo Date. Em outras palavras, não é possível criarmos diretamente um vetor tipo Date. O motivo para tal prática, pode ser atribuído às diversas maneiras em que uma mesma data (além das outras variáveis de tempo) pode ser escrita, ou representada. Por essa diversidade, o R busca oferecer flexibilidade aos seus usuários, através de diferentes métodos de coerção. figura 12.1, resume os principais métodos que vamos aprender ao longo dessa seção, além de algumas características importantes que envolvem o tipo Date.","code":""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"a-partir-de-strings","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.3.1 A partir de strings","text":"Como exemplo inicial, podemos fornecer à função as_date() (pacote lubridate), data 01 de Abril de 2020 como um string. Repare abaixo, que o resultado final da operação é um vetor tipo Date (e não tipo character).Entretanto, você talvez tenha achado estranho o formato em que data foi escrita na função as_date(). Pois Brasil, datas são normalmente escritas padrão “dia/mês/ano” (ex: 01/04/2020), e não “ano-mês-dia.” Este é o formato estipulado pelo padrão internacional ISO-8601, que é o padrão adotado pelo R. Ou seja, R, datas são manipuladas, estocadas, fornecidas e apresentadas formato “ano-mês-dia.”Você irá rapidamente perceber que, muitos países podem escrever uma mesma data de maneiras muito diferentes. Por exemplo, nos EUA, datas são usualmente escritas formato “mês-dia-ano” (ex: 02-18-2021), mas também aparecem muitas vezes em sua forma extensa (ex: February 18, 2021). Em algumas regiões da Espanha, datas são escritas formato “ano/dia/mês” (ex: 2020/15/08). Também não é incomum encontrarmos em países nórdicos (Suécia, Finlândia, Dinamarca), datas escritas com o uso de pontos separando cada componente (ex: 2020.08.15).Toda essa variedade só torna o nosso trabalho mais complicado, especialmente se gente não sabe qual origem, ou, o padrão adotado por essas datas. E não há nada que você possa fazer respeito, não ser, identificar o padrão adotado e ajustar função empregada de acordo com esse padrão.","code":"\nd <- as_date(\"2020-04-01\")\nd## [1] \"2020-04-01\"\nclass(d)## [1] \"Date\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"sec:formato_diferente_date","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.3.2 O que devo fazer se minhas datas se encontram em um formato diferente?","text":"Portanto, caso você possua um conjunto de datas como strings (ou seja, em um vetor tipo character), e, essas datas estejam em um formato diferente estipulado pela ISO-8601, você tem 2 opções rápidas para transportar corretamente essas datas para o tipo Date.Primeiro, todas funções R que lidam com variáveis de tempo, geralmente oferecem um argumento format, qual você pode definir o formato, ou o padrão adotado por suas datas. Logo, você precisa apenas definir o argumento format em as_date(), ou em qualquer outra função que você esteja utilizando para essa coerção.Segundo, você também pode utilizar funções rápidas pacote lubridate, ymd(), dmy(), dym() e mdy(), que já possuem uma ordem implícita, ou um format padrão. Dessa maneira, você economiza certo tempo, ao não ter que se preocupar com o argumento format nessas funções.Por exemplo, suponha que você possua um conjunto de datas escritas Brasil, guardadas vetor datas, e que você deseja converter esse vetor (que se encontra momento, tipo character) para o tipo Date. Como os componentes da data estão na ordem “dia \\(\\rightarrow\\) mês \\(\\rightarrow\\) ano,” eu utilizo função dmy() para ler essas datas.Isso significa que, ordem na qual letras “d,” “m” e “y” aparecem nome da função, representa ordem adotada pelo argumento format dessa função. Em outras palavras, letra “d” simboliza o “dia”; letra “m” por sua vez, o “mês”; e letra “y,” o “ano,” ou, em inglês, “year”. Ou seja, função dmy() espera como input, datas cujos componentes estejam na ordem “dia \\(\\rightarrow\\) mês \\(\\rightarrow\\) ano” (ou “d \\(\\rightarrow\\) m \\(\\rightarrow\\) y”). Já função ymd(), tem como expectativa, datas cujos componentes estejam na ordem “ano \\(\\rightarrow\\) mês \\(\\rightarrow\\) dia” (ou “y \\(\\rightarrow\\) m \\(\\rightarrow\\) d”).Portanto, funções rápidas dmy(), ymd() e suas irmãs, possuem implicitamente uma ordem esperada para os componentes de suas datas. Para mais, essas funções identificam automaticamente qualquer caractere que não seja um dígito, e os trata como os delimitadores que separam cada componente da data. Logo, não importa se cada componente está sendo separado por um hífen (-), ponto (.), cifrão ($) ou barra inclinada (/), essas funções serão capazes de detectar esses caracteres e ignorá-los durante conversão.Como já foi descrito acima, segunda alternativa seria definirmos explicitamente o argumento format em as_date(). Neste argumento, você deve fornecer uma pequena definição38 que descreve o padrão qual sua data se encontra. Para construir tal definição, você irá utilizar um conjunto de códigos, que são formados pelo símbolo de porcentagem acompanhado de uma letra específica. Cada um desses códigos, podem representar um dos três componentes de uma data (dia, mês e ano). tabela abaixo apresenta um resumo desses códigos.\nFigure 12.2: Códigos que representam cada componente de uma data\nTendo os códigos acima, se uma data Brasil é escrita formato “dia/mês/ano,” uma descrição que representa tal padrão é \"%d/%m/%Y\". Como um outro exemplo, se temos datas \"2021, 30-12\" e \"97,10,January\", podemos utilizar respectivamente os valores \"%Y, %d-%m\" e \"%y,%d,%B\" para descrever os padrões adotados por cada uma. Veja os exemplos abaixo:Um detalhe importante é que os códigos %b e %B são capazes de representar apenas os nomes dos meses em inglês (ex: April, December, October). Por isso, se suas datas possuem os nomes dos meses, em qualquer outra língua que não seja o inglês, você terá que, obrigatoriamente, traduzir esses nomes para o inglês, ou convertê-los para sua versão numérica (Março = 03; Abril = 04; Maio = 05; e assim por diante).","code":"\ndatas <- c(\"15/03/2020\", \"16/03/2020\", \"18/03/2020\", \"24/03/2020\")\ndmy(datas)## [1] \"2020-03-15\" \"2020-03-16\" \"2020-03-18\" \"2020-03-24\"\ndatas <- c(\"15/03/2020\", \"16/03/2020\", \"18/03/2020\", \"24/03/2020\")\nas_date(datas, format = \"%d/%m/%Y\")## [1] \"2020-03-15\" \"2020-03-16\" \"2020-03-18\" \"2020-03-24\"\nas_date(\"2021, 30-12\", format = \"%Y, %d-%m\")## [1] \"2021-12-30\"\nas_date(\"97,10,January\", format = \"%y,%d,%B\")## [1] \"1997-01-10\"\nas_date(\"12-30-1997\", format = \"%m-%d-%Y\")## [1] \"1997-12-30\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"a-partir-de-cada-componente","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.3.3 A partir de cada componente","text":"Também é muito comum, termos cada um dos componentes separados em uma coluna específica de nossa tabela. Como exemplo, temos abaixo tabela registros, onde o ano, mês e dia estão separados em uma determinada coluna da tabela.Para unirmos esses componentes em uma data, nós podemos utilizar função make_date(). Por meio dessa função, você precisa apenas conectar os argumentos year, month e day, aos nomes das colunas que contém o ano, mês e dia (respectivamente), de cada observação da tabela, como demonstrado abaixo.Além disso, é importante frisar que, os seus componentes não precisam necessariamente estar dentro de um data.frame. Dito de outra forma, você também pode fornecer cada componente de sua data como um vetor. Veja o exemplo abaixo:","code":"\nregistros <- tibble(\n  valor = c(5.50, 4.25, 1.32, 24.10, 12.50),\n  dia = c(5, 6, 8, 12, 15),\n  mes = c(4, 4, 4, 4, 4),\n  ano = c(2021, 2021, 2021, 2021, 2021)\n)\n\nregistros <- mutate(\n  registros,\n  data = make_date(year = ano, month = mes, day = dia)\n)\n\nregistros## # A tibble: 5 x 5\n##   valor   dia   mes   ano data      \n##   <dbl> <dbl> <dbl> <dbl> <date>    \n## 1  5.5      5     4  2021 2021-04-05\n## 2  4.25     6     4  2021 2021-04-06\n## 3  1.32     8     4  2021 2021-04-08\n## 4 24.1     12     4  2021 2021-04-12\n## 5 12.5     15     4  2021 2021-04-15\ndias <- c(1, 4, 12, 15, 7)\nmes <- c(1, 1, 2, 2, 2)\nano <- c(2020, 2020, 2020, 2020, 2021)\n\nmake_date(year = ano, month = mes, day = dias)## [1] \"2020-01-01\" \"2020-01-04\" \"2020-02-12\" \"2020-02-15\" \"2021-02-07\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"a-partir-de-números","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.3.4 A partir de números","text":"Para mais, o R também nos permite criar uma data partir de um número. Por exemplo, eu posso criar data \"2020-04-01\" (01 de Abril de 2020) através número 18353. Repare abaixo, que ao invés de um vetor tipo double contendo o número inicial (18353), operação retorna um vetor tipo Date, contendo data supracitada.Quando você fornece um vetor numérico à função as_date(), todos os números contidos neste vetor são tratados como o número de dias desde data \"1970-01-01\", ou, 01 de janeiro de 1970. Em outras palavras, o R utiliza uma “escala de dias,” e data \"1970-01-01\" representa origem, ou o ponto zero dessa escala (para representar dias anteriores essa data, utilizamos números negativos). Nós denominamos essa data, como data de origem.Portanto, o número 18353 nos retorna data \"2020-04-01\", pelo fato de que este dia está 18353 dias de distância da data \"1970-01-01\". Caso você ainda sinta certa confusão, visite seção Como variáveis de tempo são interpretadas pelo R ?, que busca prover uma descrição mais formal e mais detalhada dos conceitos de data de origem e escala de tempo.","code":"\nd <- as_date(18353)\nd## [1] \"2020-04-01\"\nclass(d)## [1] \"Date\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"fique-atento-aos-tipos-de-dados-empregados","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.3.5 Fique atento aos tipos de dados empregados!","text":"Vale pena destacar que, apesar de serem apresentadas você como strings, dados tipo Date são guardados e interpretados de uma maneira completamente diferente dos dados tipo character. Ou seja, quando valores tipo Date aparecem em seu console, eles sempre aparecem contornados por aspas duplas, como se fossem dados tipo character. E não há qualquer informação aparente console, que te indique qual dos dois tipos (Date ou character) está sendo empregado sobre esses valores.Por isso, é muito importante que você esteja atento à forma como o R está interpretando os seus dados. Use e abuse de funções e de testes lógicos que possam lhe assegurar que os seus dados estão sendo interpretados da maneira esperada! Tendo essas considerações em mente, forma mais rápida de identificarmos se um vetor é tipo character, ou tipo Date, é descobrirmos sua classe, por meio da função class(). Repare exemplo abaixo, que o primeiro valor pertence ao tipo character, enquanto o segundo, está sendo interpretado pelo tipo Date.Por outro lado, caso suas datas estejam dentro de um tibble, tal problemática perde um pouco de sua importância. Pois comos descrevemos na seção tibble’s como uma alternativa moderna aos data.frame’s, quando um tibble aparece em seu console, ele sempre disponibiliza uma pequena descrição logo abaixo nome de cada coluna, indicando o tipo de dado contido nela. Portanto, exemplo abaixo, podemos rapidamente identificar pela descrição <date>, que os dados presentes na coluna data pertencem ao tipo de dado Date.","code":"\ntexto <- \"2020-08-01\"\ndata <- as.Date(\"2020-08-01\")\nclass(texto)## [1] \"character\"\nclass(data)## [1] \"Date\"\n### Um teste lógico para o tipo Date\nclass(texto) == \"Date\"## [1] FALSE\nclass(data) == \"Date\"## [1] TRUE\nlibrary(tibble)\n\ntibble(\n  data = dmy(c(\"20/05/2020\", \"21/05/2020\", \"22/05/2020\", \"23/05/2020\"))\n)## # A tibble: 4 x 1\n##   data      \n##   <date>    \n## 1 2020-05-20\n## 2 2020-05-21\n## 3 2020-05-22\n## 4 2020-05-23"},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"datas-horários-e-fusos-horários-com-posixct-e-posixlt","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.4 Datas, horários e fusos horários com POSIXct e POSIXlt","text":"Em várias ocasiões, empresas, agentes e governos, precisam registrar o instante de ocorrência de algum episódio com um alto nível de precisão. Com isso, eu quero dizer que em certas situações, precisamos não apenas da data, mas também horário e fuso horário em que certo evento ocorre. Para isso, o R nos oferece os tipos POSIXct e POSIXlt, que são capazes de guardar não apenas datas, mas também horários além de fusos horários.\nFigure 12.3: Como um ponto tempo é definido nos tipos POSIXct e POSIXlt\nfundo, o R utiliza funções .POSIXct() e .POSIXlt() para criar um objeto dos tipos POSIXct e POSIXlt, respectivamente. Portanto, mesmo que ferramentas apresentadas nessa seção pertençam (em sua maioria) ao pacote lubridate, saiba que fundo, funções .POSIXct() e .POSIXlt() são empregadas para criar o seu vetor tipo POSIXct e POSIXlt.Dentro da comunidade de R, vários usuários costumam se referir aos tipos POSIXct e POSIXlt, em uma forma mais intuitiva. Sendo o termo date-time, o mais utilizado para tal referência. Portanto, date-time é um sinônimo (ou uma gíria) utilizado para se referir à “espécie” de dado (isto é, uma data acompanhada de um horário e de um fuso horário) armazenado pelos tipos POSIXct e POSIXlt.Por isso, ao longo dessa seção, quando estivermos descrevendo características gerais que se aplicam ambos os tipos, vamos utilizar o termo date-time como um sinônimo aos tipos POSIXct e POSIXlt. Por outro lado, quando estivermos descrevendo características específicas de cada um, vamos utilizar o nome tipo correspondente.","code":""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"criando-vetores-do-tipo-date-time","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.4.1 Criando vetores do tipo date-time","text":"Para criarmos um vetor contendo dados tipo date-time, podemos utilizar exatamente os mesmos métodos empregados tipo Date, com pequenas modificações. Isto é, podemos criar um vetor dos tipos POSIXct e POSIXlt: 1) partir de strings; 2) partir de números; e 3) partir de cada componente deste date-time. Um resumo de tais métodos, além de algumas observações quanto ao tipo date-time, são apresentados na figura 12.3.Para realizar cada um desses métodos, o pacote lubridate nos oferece função as_datetime(). Todavia, vale apontar que essa função sempre gera um vetor tipo POSIXct como resultado. Por isso, se você deseja converter o seu objeto para o tipo POSIXlt, aplique função .POSIXlt() sobre o resultado de as_datetime().\nFigure 12.4: Principais métodos para se criar dados tipo date-time R\n","code":""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"a-partir-de-strings-1","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.4.2 A partir de strings","text":"Assim como descrevemos durante seções tipo Date, o R segue regras definidas padrão internacional ISO-8601 para armazenar e interpretar suas variáveis de tempo. Esse padrão delimita que, dados tipo date-time devem ser escritos formato “ano-mês-dia hora:minuto:segundo.” figura 12.4, provê uma representação visual de tal formato.\nFigure 12.5: Formato padrão R para dados tipo date-time\nMais abaixo, temos um exemplo em que um objeto chamado dt é criado, com o objetivo de guardar o seguinte ponto tempo: 10 horas, 40 minutos e 35 segundos dia 01 de janeiro de 2020. Repare nesse exemplo, que nós não incluímos string inicial qualquer informação respeito fuso horário utilizado. Mesmo assim, função as_datetime() automaticamente configurou o horário com o fuso UTC, que corresponde à Coordinated Universal Time. Portanto, sempre que você não definir explicitamente um fuso horário, função as_datetime() vai utilizar o fuso horário UTC.Para mais, isso demonstra que não é necessário incluirmos o fuso horário utilizado, diretamente string ser fornecido. Pois tal informação é definida separadamente argumento tz da função.Isso não significa que, os strings não devem ou não podem conter qualquer informação respeito fuso horário. Mas significa que essas informações serão, por padrão, ignoradas pela função, que vai utilizar o fuso UTC para qualquer input. Veja o exemplo abaixo, em que dois fusos horários diferentes são testados, e o mesmo resultado é gerado em ambos.Portanto, maneira correta de definir o fuso horário ser empregado, é por meio argumento tz, como demonstrado abaixo:Fusos horários são usualmente fornecidos ao argumento tz por meio de um código (e.g. \"WET\", \"UTC\", \"ROK\", \"CET\", etc.), ou por meio de uma referência de região ou cidade específica (e.g. \"Europe/Paris\", \"Pacific/Auckland\", \"America/Toronto\", etc.). Para consultar lista completa de valores reconhecidos pelo R, execute função OlsonNames() em seu console.Dito de outra forma, valores como \"ROK\" (abreviação para Republic Korea), \"CET\" (Central European Time), \"America/Sao_Paulo\" (cidade de São Paulo) e \"Pacific/Auckland\" (cidade de Auckland), são aceitos pelo argumento tz, porque eles estão inclusos resultado da função OlsonNames(). Em contraste, valores como \"São Paulo\", \"WST\", e \"+11\", não são aceitos pelo argumento tz, pois não estão presentes em OlsonNames().","code":"\ndt <- as_datetime(\"2020-01-01 10:40:35\")\ndt## [1] \"2020-01-01 10:40:35 UTC\"\nas_datetime(\"2020-01-01 10:40:35 Portugal\")## [1] \"2020-01-01 10:40:35 UTC\"\nas_datetime(\"2020-01-01 10:40:35 America/Sao_Paulo\")## [1] \"2020-01-01 10:40:35 UTC\"\nas_datetime(\"2020-01-01 10:40:35\", tz = \"Portugal\")## [1] \"2020-01-01 10:40:35 WET\"\nas_datetime(\"2020-01-01 10:40:35\", tz = \"America/Sao_Paulo\")## [1] \"2020-01-01 10:40:35 -03\"\nas_datetime(\"2020-01-01 10:34:12\", tz = \"CET\")## [1] \"2020-01-01 10:34:12 CET\"\nas_datetime(\"2020-01-01 10:34:12\", tz = \"ROK\")## [1] \"2020-01-01 10:34:12 KST\"\nas_datetime(\"2020-01-01 10:34:12\", tz = \"Pacific/Auckland\")## [1] \"2020-01-01 10:34:12 NZDT\"\n### Quando incluímos um fuso horário desconhecido\n### pelo R, a seguinte mensagem de erro aparece:\nas_datetime(\"2020-01-01 10:34:12\", tz = \"WST\")Error in C_force_tz(time, tz = tzone, roll) : \n  CCTZ: Unrecognized output timezone: \"WST\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"sec:date_time_formato_diferente","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.4.3 O que devo fazer se meus dados se encontram em um formato diferente?","text":"Da mesma maneira que uma mesma data pode ser escrita de várias formas, horários também podem assumir formatos diferentes. Sendo que, diferentemente das datas, algumas partes de um horário (hora, minuto e segundo) podem ser ignoradas, depender da precisão de tempo necessária. De qualquer modo, em casos como este, soluções serem empregadas são exatamente mesmas que descrevemos na seção O que devo fazer se minhas datas se encontram em um formato diferente?, que são:Utilizar os códigos oferecidos pelo R argumento format da função.Utilizar os códigos oferecidos pelo R argumento format da função.Ou utilizar funções rápidas pacote lubridate (dmy_h(), dmy_hm(), dmy_hms(), etc.) que possuem uma ordem implícita para cada componente.Ou utilizar funções rápidas pacote lubridate (dmy_h(), dmy_hm(), dmy_hms(), etc.) que possuem uma ordem implícita para cada componente.tabela abaixo, apresenta os principais códigos oferecidos pelo R para cada componente de um dado tipo date-time. Porém, há vários outros códigos, os quais são menos comuns e, que por isso, foram omitidos da tabela abaixo. Você pode encontrar uma lista completa desses códigos, ao consultar documentação interna da função strptime(), com o comando ?strptime.\nFigure 12.6: Códigos que podem representar cada componente de um dado tipo date-time\nPelas informações dispostas na tabela abaixo, sabemos que o formato delineado pelo padrão ISO-8601, isto é, “ano-mês-dia hora:minuto:segundo,” pode ser descrito pelo padrão \"%Y-%m-%d %H:%M:%S\", ou, de forma mais sucinta, \"%F %T\". Como exemplo, repare abaixo que ambas descrições geram os mesmos resultados, quando aplicadas sobre os valores presentes vetor pontos:caso Brasil, valores tipo date-time costumam se apresentar formato “dia/mês/ano hora:minuto:segundo.” Logo, uma descrição capaz de representar tal formato é \"%d/%m/%Y %H:%M:%S\", ou então, uma alternativa mais curta é \"%d/%m/%Y %T\".Vale ressaltar que, em todos os exemplos mostrados até agora, todos os componentes de um date-time foram fornecidos nos strings utilizados como input. Dito de outra forma, em nenhum exemplo mostrado até o momento, os segundos, os minutos ou horas estavam ausentes dos strings utilizados como input. Esse cenário perfeito nem sempre ocorre, e isso não necessariamente é um problema sério. Pois, em alguns processos, empresa nem sempre precisa de uma precisão muito alta em seus registros de tempo.Por exemplo, uma indústria de aço não recebe matérias primas cada segundo. Muitas vezes, firma encomenda um grande estoque de materiais, combustíveis e minérios ao final de cada mês. Por esse motivo, firma talvez precise registrar apenas horas e minutos dia, em que cada entrega (ou carregamento de matéria-prima) chegou sua sede, em um determinado mês.Tendo isso em mente, se eu possuo o string abaixo, contendo o valor \"2020-04-15 10:30\", eu poderia utilizar descrição \"%F %H:%M\" para descrever o formato em que esse valor se encontra. Contudo, uma alternativa eficiente e intuitiva, é utilizar função ymd_hm(). Perceba pelo resultado abaixo, que ao não possuírmos um determinado componente de um dado tipo date-time, esse componente faltante é preenchido por zeros.mesmo modo que descrevemos anteriormente, funções rápidas como ymd_hm() possuem uma ordem para cada componente que está implícita nome dessa função. novidade em relação às funções ymd(), dmy() e suas irmãs, é que essas funções focadas em dados tipo date-time, incluem três novas letras que se referem hora (h), minuto (m) e segundo (s). Portanto, sabemos pelo nome da função, que ymd_hm() espera um input onde os componentes se apresentam na ordem “ano \\(\\rightarrow\\) mês \\(\\rightarrow\\) dia \\(\\rightarrow\\) hora \\(\\rightarrow\\) minuto.”Por isso, função dmy_hms() é uma alternativa ideal para ler dados tipo date-time que foram escritos segundo o padrão brasileiro. Pois essa função espera como input, um dado em que os componentes seguem ordem “dia \\(\\rightarrow\\) mês \\(\\rightarrow\\) ano \\(\\rightarrow\\) hora \\(\\rightarrow\\) minuto \\(\\rightarrow\\) segundo.” Veja o exemplo abaixo:Para além dos códigos mais tradicionais, parte inferior da tabela x.x descreve alguns códigos menos comuns, como o código %z. Esse código em específico, é capaz de identificar um ajuste (em horas e minutos) presente string de input, e adicioná-lo ao fuso horário aplicado sobre o resultado da função. Porém, como veremos mais frente, lidar com fusos horários não é algo muito simples, e para piorar, o cálculo aritmético por trás da adição de um ajuste com o código %z, é mínimo, peculiar.Portanto, o uso de ajustes representados pelo código %z, é algo mais complicado que uma simples adição39. Sendo que, o cálculo aritmético aplicado por tal código, está demonstrado em detalhes na seção Quando fusos horários diferentes geram uma grande confusão. Por esses motivos, o código %z é algo difícil de se trabalhar, especialmente levando-se em conta que: em certas situações, o código %z gera resultados diferentes entre funções as_datetime() e .POSIXct().Tal diferença, se baseia puramente fato de que função as_datetime() escolhe, por padrão, o fuso horário UTC, enquanto função .POSIXct(), tende escolher o fuso horário padrão de seu sistema operacional (o qual não necessariamente é o fuso horário UTC). Como exemplo, temos abaixo um vetor chamado dt, que contém o instante: 8 horas dia 01 de janeiro de 2020. Ademais, podemos identificar um ajuste negativo (ou “para trás”) de 3 horas (-0300), ao final string. Perceba abaixo, que ambas funções nos retornam horários diferentes. Esse problema vale certa reflexão sua, porque essa diferença existe? Como ela ocorre? Vamos dar respostas para essas perguntas mais frente. Até lá, pense um pouco sobre esses resultados.Como uma dica, repare como os resultados mudam quando adicionamos uma hora ao ajuste, gerando assim, um desvio negativo de 2 horas (-0200).","code":"\npontos <- c(\"2018-06-15 08:11:05\", \"2018-07-22 21:09:05\")\nas_datetime(pontos, format = \"%Y-%m-%d %H:%M:%S\")## [1] \"2018-06-15 08:11:05 UTC\" \"2018-07-22 21:09:05 UTC\"\n### Ou de forma análoga\nas_datetime(pontos, format = \"%F %T\")## [1] \"2018-06-15 08:11:05 UTC\" \"2018-07-22 21:09:05 UTC\"\npontos_br <- c(\"15/06/2018 08:11:05\", \"22/07/2018 21:09:05\")\nas_datetime(pontos_br, format = \"%d/%m/%Y %H:%M:%S\")## [1] \"2018-06-15 08:11:05 UTC\" \"2018-07-22 21:09:05 UTC\"\n### Ou de forma análoga\nas_datetime(pontos_br, format = \"%d/%m/%Y %T\")## [1] \"2018-06-15 08:11:05 UTC\" \"2018-07-22 21:09:05 UTC\"\ndt <- \"2020-04-15 10:30\"\nas_datetime(dt, format = \"%F %H:%M\")## [1] \"2020-04-15 10:30:00 UTC\"\nymd_hm(dt)## [1] \"2020-04-15 10:30:00 UTC\"\ndts <- c(\"12/10/1998 19:19:32\", \"12/10/1998 22:15:09\")\nsem_segundo <- c(\"12/10/1998 19:19\", \"12/10/1998 22:15\")\nsem_minuto_e_segundo <- c(\"12/10/1998 19\", \"12/10/1998 22\")\n\ndmy_hms(dts)## [1] \"1998-10-12 19:19:32 UTC\" \"1998-10-12 22:15:09 UTC\"\ndmy_hm(sem_segundo)## [1] \"1998-10-12 19:19:00 UTC\" \"1998-10-12 22:15:00 UTC\"\ndmy_h(sem_minuto_e_segundo)## [1] \"1998-10-12 19:00:00 UTC\" \"1998-10-12 22:00:00 UTC\"\ndt <- \"2020-01-01 08:00:00 -0300\"\nstrptime(dt, format = \"%F %T %z\")## [1] \"2020-01-01 08:00:00\"\nas_datetime(dt, format = \"%F %T %z\")## [1] \"2020-01-01 11:00:00 UTC\"\ndt <- \"2020-01-01 08:00:00 -0200\"\nstrptime(dt, format = \"%F %T %z\")## [1] \"2020-01-01 07:00:00\"\nas_datetime(dt, format = \"%F %T %z\")## [1] \"2020-01-01 10:00:00 UTC\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"a-partir-de-cada-componente-1","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.4.4 A partir de cada componente","text":"Caso você possua, separadamente, cada um dos itens que compõe um dado tipo date-time (dia, mês, ano, hora, minuto e segundo), você pode utilizar função make_datetime() para uní-los em um único vetor tipo date-time. Por exemplo, suponha que você possua um data.frame parecido com tabela tab abaixo.Em relação à função make_date(), função make_datetime() introduz três novos argumentos, sendo eles: hour, min e sec, que se referem às horas, os minutos e os segundos, respectivamente.","code":"\ntab <- tibble(\n  ano = 2020,\n  mês = 5,\n  dia = c(15, 16, 16, 18, 19),\n  hora = c(9, 11, 12, 8, 14),\n  minuto = c(7, 23, 19, 15, 30),\n  segundo = c(34, 11, 5, 17, 49)\n)\n\ntab ## # A tibble: 5 x 6\n##     ano   mês   dia  hora minuto segundo\n##   <dbl> <dbl> <dbl> <dbl>  <dbl>   <dbl>\n## 1  2020     5    15     9      7      34\n## 2  2020     5    16    11     23      11\n## 3  2020     5    16    12     19       5\n## 4  2020     5    18     8     15      17\n## 5  2020     5    19    14     30      49\ntab <- mutate(\n  tab,\n  date_time = make_datetime(\n    year = ano, month = mês, day = dia,\n    hour = hora, min = minuto, sec = segundo\n  )\n)\n\ntab## # A tibble: 5 x 7\n##     ano   mês   dia  hora minuto segundo date_time          \n##   <dbl> <dbl> <dbl> <dbl>  <dbl>   <dbl> <dttm>             \n## 1  2020     5    15     9      7      34 2020-05-15 09:07:34\n## 2  2020     5    16    11     23      11 2020-05-16 11:23:11\n## 3  2020     5    16    12     19       5 2020-05-16 12:19:05\n## 4  2020     5    18     8     15      17 2020-05-18 08:15:17\n## 5  2020     5    19    14     30      49 2020-05-19 14:30:49"},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"a-partir-de-números-1","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.4.5 A partir de números","text":"Assim como ocorre tipo Date, dados tipo date-time também podem ser criados partir de números. O mecanismo de conversão é muito semelhante ao que mostramos com o tipo Date. Porém, ao invés de representar o número de dias desde uma data de origem, ao ser convertido para os tipos POSIXct e POSIXlt, o número que estamos tentando converter, será interpretado como o número de segundos desde meia-noite de 01 de janeiro de 1970 (de outra forma, 1970-01-01 00:00:00).Por isso, podemos chegar ao instante “08 horas dia 01 de janeiro de 2005,” ao convertermos o número 1.104.566.400 (que representa aproximadamente 1,104 bilhões de segundos) para o tipo date-time. Em outras palavras, 08 horas dia 01 de janeiro de 2005 está 1.104.566.400 segundos de distância da meia-noite dia 01 de janeiro de 1970.Para mais detalhes sobre os conceitos de ponto de origem e escala temporal (que são essenciais para se compreender corretamente essa conversão entre números e instantes tempo), consulte seção Como variáveis de tempo são interpretadas pelo R ?.","code":"\nas_datetime(1104566400)## [1] \"2005-01-01 08:00:00 UTC\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"novamente-fique-atento-aos-tipos-empregados","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.4.6 Novamente, fique atento aos tipos empregados!","text":"Assim como ocorre com o tipo Date, dados tipo POSIXct e POSIXlt também aparecem em seu console, contornados por aspas duplas e, novamente, não há qualquer informação aparente, que nos informe se os dados em questão encontram-se tipo character ou em algum dos tipos date-time. Da mesma forma que descrevemos tipo Date, uma maneira simples e prática de identificar se um objeto pertence ao tipo POSIXct ou POSIXlt, é olhar para classe desse objeto, com função class(). Entretanto, de maneira diferente tipo Date, que continha apenas um valor para sua classe, repare abaixo que, objetos dos tipos POSIXct e POSIXlt sempre possuem um segundo valor para sua classe (POSIXt).Por esse detalhe, quando você estiver criando o seu teste lógico, utilize o operador %%, ao invés operador ==.Um outro método útil de identificarmos se um objeto pertence aos tipos POSIXct e POSIXlt, é através da função inherits(), como está demonstrado abaixo:","code":"\nv_POSIXct <- as.POSIXct(\"2020-01-01 10:40:35\")\nv_POSIXlt <- as.POSIXlt(\"2020-01-01 10:40:35\")\n\nclass(v_POSIXct)## [1] \"POSIXct\" \"POSIXt\"\nclass(v_POSIXlt)## [1] \"POSIXlt\" \"POSIXt\"\n### Para identificar se o objeto é do\n### tipo POSIXct, utilize:\n\"POSIXct\" %in% class(v_POSIXct)## [1] TRUE\n### Já para o tipo POSIXlt, utilize:\n\"POSIXlt\" %in% class(v_POSIXlt)## [1] TRUE\ninherits(v_POSIXct, \"POSIXct\")## [1] TRUE\ninherits(v_POSIXlt, \"POSIXlt\")## [1] TRUE"},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"diferenças-entre-posixct-e-posixlt","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.5 Diferenças entre POSIXct e POSIXlt","text":"Até o momento, nós não descrevemos quais são características que diferem os tipos POSIXct e POSIXlt um outro. Em resumo, os valores tipo POSIXct são guardados dentro de em um vetor e, os valores tipo POSIXlt, em uma lista nomeada contendo vários vetores que guardam cada componente desses valores.Em mais detalhes, quando utilizamos o tipo POSIXct, o R vai apenas construir um vetor contendo os nossos dados tipo date-time. Apesar desses valores serem apresentados nós, formato “ano-mês-dia hora:minuto:segundo,” em uma camada mais produnda, o R vai armazená-los como o número de segundos desde o instante 1970-01-01 00:00:00 (meia-noite de 01 de janeiro de 1970). Por outro lado, quando empregamos o tipo POSIXlt, o R vai construir uma lista nomeada contendo vários vetores, onde cada um desses vetores possui um componente específico (dia, mês, ano, hora, etc.) de seu dado tipo date-time. figura 12.5, fornece uma representação visual dessa diferença.\nFigure 12.7: Representação visual das estruturas formadas pelos tipos POSIXct e POSIXlt\nPara mais detalhes, você pode conferir documentação interna desses tipos, com ?POSIXct ou ?POSIXlt. Para mais, vale destacar que, dados que se encontram em qualquer um desses dois tipos, são apresentados da mesma maneira nós. Em outras palavras, quando aparecem em seu console R, os dados tipo POSIXct e POSIXlt sempre aparecem como um vetor cotendo valores formato “ano-mês-dia hora:minuto:segundo.”Porém, como eu descrevi acima, forma como esses dados estão estruturados dentro objeto é completamente diferente. Por exemplo, eu posso extrair os segundos (35) valor (ou valores) em questão, ao acessar o item de nome sec da lista que compõe o objeto v_POSIXlt. Da mesma forma, caso eu precise extrair o dia (01) de cada data presente objeto v_POSIXlt, basta acessar o item de nome mday dessa lista.Na hipótese de, realizarmos mesma tarefa com um valor tipo POSIXct, sem que ele seja convertido para o tipo POSIXlt, nossa melhor opção seria implantarmos um string subsetting, com funções que já vimos capítulo Manipulação e transformação de strings com stringr.Portanto, podemos dizer que o tipo POSIXlt provê um formato mais próximo da maneira como nós, seres humandos, pensamos sobre um valor tipo date-time. Ou seja, diversos componentes (dia, mês, ano, hora, etc.) que, em conjunto, formam um dado tipo date-time, mas que ainda representam unidades ou informações diferentes. Todavia, o tipo POSIXct fornece uma estrutura muito mais ideal para o uso em data.frame’s e, em geral, operações e cálculos aritméticos. Dito de outra forma, seja em uma coluna de um data.frame ou em qualquer outra estrutura, é mais fácil trabalhar R com dados tipo date-time, quando eles se encontram tipo POSIXct.Você também pode encarar escolha entre esses dois tipos da seguinte maneira: se você deseja extrair um componente específico de cada data (dia, mês, ano, hora, etc.), você pode transformar os seus valores para o tipo POSIXlt, com função .POSIXlt() e, em seguida, extrair o item da lista resultante que contém o componente desejado; caso você não tenha pretensões de extrair algum componente, sempre utilize o tipo POSIXct. Pois esse tipo provê um formato mais natural para diversas operações e cálculos aritméticos que você venha realizar sobre os seus valores.","code":"\nv_POSIXct <- as.POSIXct(\"2020-01-01 10:40:35\")\nv_POSIXlt <- as.POSIXlt(\"2020-01-01 10:40:35\")\n\nprint(v_POSIXct)## [1] \"2020-01-01 10:40:35 -03\"\nprint(v_POSIXlt)## [1] \"2020-01-01 10:40:35 -03\"\nv_POSIXlt$sec## [1] 35\nv_POSIXlt$mday## [1] 1\nlibrary(stringr)\ncomo_texto <- as.character(v_POSIXct)\n\n### Por exemplo, para extrair os segundos faríamos:\nas.integer(str_sub(como_texto, 18, 19))## [1] 35\n### Para extrair o dia:\nas.integer(str_sub(como_texto, 9, 10))## [1] 1\n### Para extrair o ano:\nas.integer(str_sub(como_texto, 1, 4))## [1] 2020"},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"extraindo-os-componentes-de-uma-variável-de-tempo","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.6 Extraindo os componentes de uma variável de tempo","text":"Você já sabe que, nós podemos extrair cada componente de maneira simples e intuitiva, ao transformarmos os dados em questão para o tipo POSIXlt, e utilizar os itens da lista resultante para chegarmos ao componente desejado. Porém, também vamos mostrar nessa seção, algumas funções rápidas presentes pacote lubridate, que tornam esse processo de extração ainda mais simples.Primeiro, essas funções rápidas e partes extraídas por cada uma delas, são:day(), dia mês (1-31).month(), mês ano (1-12).year(), ano (número de 4 dígitos).hour(), hora dia (0-23).minute(), minutos (0-59).second(), segundos (0-61).Tendo essas funções em mente, se nós desejamos extrair apenas horas de cada valor presente vetor dt abaixo, nós podemos simplesmente aplicar função hour() sobre este vetor. De modo análogo, se desejamos calcular o dia mês correspondente cada valor, nós podemos utilizar função day():Essas funções rápidas são particularmente úteis, quando desejamos extrair os componentes de de alguma coluna de um data.frame’s. Como exemplo, podemos visitar novamente tabela transf que vimos ao longo capítulo 4, e extrair os componentes de cada valor presente em sua coluna Data.Para mais, o vetor dt, assim como coluna Data da tabela transf, que utilizamos nos exemplos anteriores, são vetores tipo POSIXct. Contudo, funções mostradas acima, funcionam exatamente da mesma forma com valores tipo Date. Ou seja, o processo é o mesmo, basta aplicar função que extrai o componente qual você está interessado sobre o seu vetor tipo Date.Em outras palavras, isso é mesma coisa que dizer: “um vetor tipo Date pode ser convertido diretamente para o tipo POSIXlt e, com isso, podemos extrair os componentes que compõe cada data presente nesse vetor.” Tal fato está exposto exemplo abaixo:Como definimos na seção anterior, um objeto tipo POSIXlt é na realidade, uma lista nomeada, e, você pode descobrir quais são os nomes de cada item dessa lista, ao acessar o atributo names desse objeto, com função attr(), como demonstrado abaixo. Dessa maneira, o nome \"hour\" indica que há um item chamado hour nessa lista, e, ao acessar esse item com o comando v_POSIXlt$hour, eu posso identificar o que se encontra dentro desse item. Você pode encontrar mais detalhes sobre cada item dessa lista, ao ler documentação interna tipo POSIXlt, com o comando ?POSIXlt.","code":"\ndt <- c(\"21/02/2020 10:22:53\", \"01/11/2019 20:13:01\", \"19/07/2018 15:24:20\")\ndt <- dmy_hms(dt)\n\nhour(dt)## [1] 10 20 15\nminute(dt)## [1] 22 13 24\nday(dt)## [1] 21  1 19\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo <- \"transf_reform.csv\"\n\nlibrary(readr)\ntransf <- read_csv2(paste0(github, pasta, arquivo))\n\ntransf <- transf %>% \n  select(-Descricao) %>% \n  mutate(\n    hora = hour(Data),\n    minuto = minute(Data),\n    segundo = second(Data)\n  )\ntransf## # A tibble: 20,006 x 8\n##    Data                Usuario  Valor TransferID Pais   hora minuto segundo\n##    <dttm>              <chr>    <dbl>      <dbl> <chr> <int>  <int>   <dbl>\n##  1 2018-12-06 22:19:19 Eduardo   599.  116241629 Alem~    22     19      19\n##  2 2018-12-06 22:10:34 Júlio    4611.  115586504 Alem~    22     10      34\n##  3 2018-12-06 21:59:50 Nathál~  4418.  115079280 Alem~    21     59      50\n##  4 2018-12-06 21:54:13 Júlio    2740.  114972398 Alem~    21     54      13\n##  5 2018-12-06 21:41:27 Ana      1408.  116262934 Alem~    21     41      27\n##  6 2018-12-06 21:18:40 Nathál~  5052.  115710402 Alem~    21     18      40\n##  7 2018-12-06 20:54:32 Eduardo  5665.  114830203 Alem~    20     54      32\n##  8 2018-12-06 20:15:46 Sandra   1474.  116323455 Alem~    20     15      46\n##  9 2018-12-06 20:04:35 Armando  8906.  115304382 Alem~    20      4      35\n## 10 2018-12-22 20:00:56 Armando 18521.  114513684 Alem~    20      0      56\n## # ... with 19,996 more rows\nv_Date <- c(\"21/02/2020\", \"01/11/2019\", \"19/07/2018\")\nv_Date <- dmy(v_Date)\n\nday(v_Date)## [1] 21  1 19\nmonth(v_Date)## [1]  2 11  7\nyear(v_Date)## [1] 2020 2019 2018\nv_Date <- c(\"21/02/2020\", \"01/11/2019\", \"19/07/2018\")\nv_Date <- as.POSIXlt(dmy(v_Date))\n\nv_Date$mday## [1] 21  1 19\nattr(v_POSIXlt, \"names\")##  [1] \"sec\"    \"min\"    \"hour\"   \"mday\"   \"mon\"    \"year\"   \"wday\"  \n##  [8] \"yday\"   \"isdst\"  \"zone\"   \"gmtoff\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"fusos-horários","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.7 Fusos horários","text":"","code":""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"como-identificar-o-fuso-horário-associado-a-um-valor-do-tipo-date-time","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.7.1 Como identificar o fuso horário associado a um valor do tipo date-time","text":"É importante destacar que, todo dado tipo POSIXct ou POSIXlt estará sempre ligado algum fuso-horário de referência, mesmo que esse fuso não esteja evidente primeira vista. Há duas maneiras principais de se identificar o fuso utilizado: primeiro, veja se alguma informação aparece ao lado horário presente em seu valor tipo date-time; segundo, veja informação armazenada atributo tzone de seu objeto. partir desses métodos de conferência, existem três possibilidades para identificação desse fuso, quais estão resumidas na figura 12.6.\nFigure 12.8: Métodos para se identificar o fuso horário empregado em dados tipo POSIXct e POSIXlt\nPortanto, busque primeiro, reconhecer se alguma informação aparece à direita horário. Se não há alguma informação nesse local, verifique o atributo tzone desse objeto. Quando utilizamos funções dos pacotes básicos R para criar o nosso objeto, e não definimos algum fuso horário específico argumento tz, o atributo tzone objeto resultante estará quase sempre vazio. Em casos como esse, o R vai automaticamente utilizar o fuso horário de seu sistema operacional, que pode ser identificado pelo resultado da função Sys.timezone(). Perceba abaixo, que o sistema operacional meu computador, utiliza o horário de São Paulo, que é equivalente ao fuso horário de Brasília.Esse fuso horário (de Brasília) se encontra 3 desvios negativos fuso horário UTC (vamos explicar mais frente o que isso significa). Por esse motivo que, exemplo abaixo, um -03 aparece ao final valor de vec. Em outras palavras, essa informação (-03) está nos dizendo que o fuso horário empregado sobre o valor de vec, é o fuso horário que se encontra 3 desvios negativos fuso horário UTC, que pelos motivos apresentados acima, é o fuso horário de Brasília, ou, o fuso horário padrão sistema operacional de meu computador.Em outras situações, o fuso horário presente à direita horário será informado em seu código padrão. Veja o exemplo abaixo, em que utilizamos o fuso horário de Paris (França). Como resultado, o atributo tzone é preenchido pelo valor \"Europe/Paris\". Mas quando o valor de vec é desenhado em nosso console, o código CET é posicionado à direita horário. Esse código se refere à Central European Time (ou “Tempo da Europa Central”), que é o fuso horário usufruído por diversos países europeus, incluindo França.Sendo assim, você pode aplicar dois métodos diferentes sobre um valor tipo POSIXct ou POSIXlt, para se identificar o fuso horário de referência. Para mais, compreenda que ao longo desses métodos, o fuso horário aplicado pode se apresentar em 3 formatos diferentes: por meio de um código (como CET, para Central European Time, ou UTC, para Coordinated Universal Time); por meio de uma região, ou uma cidade específica (como America/Sao_Paulo, ou Europe/Paris); ou então, por um desvio positivo ou negativo em relação ao fuso horário UTC (como -03, +05, ou +11).","code":"\nSys.timezone()## [1] \"America/Sao_Paulo\"\nvec <- as.POSIXct(\"2020-01-01 10:34:12\")\nattr(vec, \"tzone\")## [1] \"\"\nvec## [1] \"2020-01-01 10:34:12 -03\"\nvec <- as_datetime(\"2020-01-01 10:34:12\", tz = \"Europe/Paris\")\nattr(vec, \"tzone\")## [1] \"Europe/Paris\"\nvec## [1] \"2020-01-01 10:34:12 CET\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"zonas-horárias-e-o-coordinated-universal-time-utc-como-horário-internacional","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.7.2 Zonas horárias e o Coordinated Universal Time (UTC) como horário internacional","text":"O planeta Terra é divido em 24 zonas horárias, que são apresentadas na figura abaixo. centro, se encontra zona horária de número 0, que é zona em que se encontra o famoso Meridiano de Greenwhich, que por convenção, é o meridiano que divide terra ao meio, ou, em outras palavras, que separa formalmente o oriente ocidente. Cada zona horária, representa um fuso horário diferente, e, por isso, podemos dizer que há 24 fusos horários diferentes ao redor mundo.\nFigure 12.9: diferentes zonas horárias presentes planeta Terra\nMesmo que cada zona horária seja determinada geograficamente, cada país ou cada nação tem o direito político de decidir qual zona horária qual ele pertence. Por esse motivo, mesmo que países como Argélia, Espanha e França estejam geograficamente sobre zona horária de número 0, por decisão política própria, tais países foram inclusos na zona horária de número +1.zona horária de número 0, é zona horária em que é calculado e utilizado o horário internacional, que é comumente denominado de Coordinated Universal Time (UTC), ou, Tempo Universal Coordenado. Sendo que todos os fusos horários utilizados ao redor mundo, são calculados partir horário UTC. Dito de outra forma, UTC é o nome fuso horário utilizado na zona horária de número 0, (isto é, zona em que se encontra o Meridiano de Greenwhich) e tal horário, é base para determinarmos todos os outros horários empregados mundo.Sendo assim, o UTC é oficialmente o horário universal ou internacional utilizado mundo. passado, o sistema UTC era formalmente chamado de Tempo Médio de Greenwhich, ou, Greenwhich Mean Time (GMT), o qual sofreu alterações metodológicas importantes, que o transformaram sistema UTC que conhecemos e utilizamos hoje. Por isso, caso você encontre algum horário acompanhado da sigla GMT, saiba que ele está se referindo ao “antigo UTC.”","code":""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"fusos-horários-como-desvios-do-horário-utc","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.7.3 Fusos horários como desvios do horário UTC","text":"É muito importante destacar que, o UTC é o horário internacional, não sentido de que ele é o horário utilizado fora dos limites de qualquer país, mas sim, sentido de que todos os outros fusos horários utilizados planeta, são calculados partir dele.Em resumo, o fuso horário aplicado em uma determinada zona horária, apresenta 1 hora de diferença em relação aos fusos horários empregados em suas zonas vizinhas. Tal efeito é de certa forma, uma consequência fato da Terra levar aproximadamente 24 horas para dar volta completa em torno de seu próprio eixo (esse movimento é chamado de rotação da Terra). Por esse motivo, cada uma das 24 zonas horárias possuem 15 graus de longitude (ou de “largura”). Pois cada 15 graus que Terra rotaciona, 1 hora se passa em nosso horário.Essa afirmação pode ser posta matematicamente. Ao partirmos princípio de que Terra é uma esfera perfeita, sabemos que o planeta possui 360 graus de circunferência. Levando-se em conta que o planeta demora 24 horas para rotacionar-se em torno de seu próprio eixo, temos que \\(360 / 24 = 15\\) graus por hora. Por essa razão que, cada zona horária, ou, cada fuso horário apresenta 1 hora de diferença em relação aos seus vizinhos.Com isso, podemos interpretar fusos horários como desvios de \\(x\\) horas em relação ao horário UTC (ou zona horária de número 0). Ao analisarmos um determinado fuso horário, é muito importante identificarmos o lado Meridiano de Greenwhich (à esquerda ou à direita) qual esse fuso se encontra, pois tal informação determinará se o desvio de \\(x\\) horas (em relação ao horário UTC) é negativo (à esquerda) ou positivo (à direita). Se o desvio negativo, significa que o desvio deve ser subtraído horário internacional (ou seja, o horário país em questão, está atrasado em relação ao horário UTC). Por outro lado, se o desvio positivo, significa que esse desvio deve ser acrescido ao horário internacional (o país está com horário adiantado).Portanto, um fuso horário é calculado partir de um desvio de \\(x\\) horas em relação ao horário UTC. Para sabermos o número \\(x\\) de horas serem descontadas (ou adicionadas) horário UTC, temos que saber distância da zona horária em análise da zona horária de número 0. Por exemplo, ao voltarmos para figura 12.7, podemos identificar que Finlândia está inclusa na zona horária de número +2 e, por estar duas zonas horárias de distância da zona horária de número 0, sabemos que o horário empregado na Finlândia possui um desvio positivo de 2 horas em relação ao horário UTC. Isso significa que Finlândia está 2 horas adiantada em relação ao horário internacional.Como um outro exemplo, o Brasil participa de 4 zonas horárias diferentes (de números -2, -3, -4 e -5). Logo, o Brasil possui 4 fusos horários diferentes ao longo de suas regiões, sendo o fuso horário de Brasília o mais comum dentre eles. zona horária que representa o fuso horário de Brasília, é zona de número -3. Isso significa que o horário de Brasília está 3 desvios negativos horário UTC, ou, dito de outra forma, o horário de Brasília é equivalente ao horário internacional subtraído de 3 horas (ou atrasado em 3 horas). Tal relação está exposta pela figura 12.8.\nFigure 12.10: O Brasil possui quatro fusos horários diferentes\n","code":""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"sec:datetime_confusoes_cod_z","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.7.4 Quando fusos horários diferentes geram uma grande confusão","text":"Uma das principais características pacote lubridate é de que suas funções tentam utilizar o fuso horário UTC em todo lugar. Por isso, em todas ocasiões em que não definirmos explicitamente um fuso horário ser empregado argumento tz de as_datetime(), ou de dmy_hms(), o valor resultante dessas funções vai utilizar o fuso UTC.entanto, funções dos pacotes básicos R adotam um protocolo diferente. Ao não definirmos um fuso horário argumento tz das funções .POSIXct() e strptime(), o fuso horário padrão sistema operacional será automaticamente empregado sobre o resultado. caso Brasil, enfrentamos 4 fusos horários diferentes. Logo, depender de onde você se encontra país, você talvez tenha resultados diferentes dos que são apresentados seguir. Mas o raciocínio permanece o mesmo, independente de onde você se encontra planeta.Na prática, essa diferença entre padrões só impacta em seus resultados, caso você esteja trabalhando com diversos fusos horários ao mesmo tempo, ou, se você deseja aplicar alguma operação que lida diretamente com o fuso horário de um dado tipo date-time. Um exemplo de operação que lida diretamente com o fuso de referência dos dados e, que, portanto, possui diferentes resultados entre as_datetime() e .POSIXct(), é o uso código %z em format, para incluir um desvio (em horas e minutos) sobre o fuso horário ser aplicado sobre o resultado final.Na seção O que devo fazer se meus dados se encontram em um formato diferente?, demos um exemplo prático que demonstra esse efeito, que nasce da diferença entre os fusos horários padrões adotados pelas funções. Nesse exemplo possuíamos um vetor chamado dt, contendo o instante: 8 horas dia 01 de janeiro de 2020. O objetivo principal desse exemplo era demonstrar que, se não definirmos algum fuso horário argumento tz, funções as_datetime() e .POSIXct() nos trazem resultados diferentes, quando aplicadas sobre os mesmos valores tipo date-time. Tal exemplo está reproduzido abaixo:Lembre-se que o valor -0300 presente ao final string armazenado em dt, representa um desvio negativo de 3 horas que será interpretado pelo código %z. Para mais, lembre-se que o valor -03 presente ao final resultado de .POSIXct() representa apenas o fuso horário empregado nesse resultado e, portanto, não possui qualquer relação com o desvio de -0300 código %z.Primeiro, ao observarmos o resultado de .POSIXct(), percebemos que o desvio de 3 horas (-0300) não gerou alterações horário (8 horas em ponto) contido em dt. Entretanto, nós também podemos observar abaixo, que função as_datetime() “adicionou” esse desvio ao valor presente em dt, gerando assim, um horário adiantado em 3 horas. lógica por trás desses resultados, começa ficar mais clara, medida em que alteramos o valor desvio, como demonstrado abaixo.Como um outro exemplo, podemos alterar o sinal desvio. Porém, ao contrário que você provavelmente está pensando, mesmo um desvio positivo acaba sendo subtraído horário. Dessa vez, .POSIXct() subtraiu 5 horas horário original de dt, enquanto em as_datetime(), redução foi de apenas 2 horas.medida em que testamos diferentes valores para esse desvio, podemos perceber que adição desvio representado pelo código %z segue fórmula:Sendo que, variáveis presentes nessa equação são:\\(H\\): hora presente resultado final da função.\\(h\\): hora inicial, ou, em outras palavras, hora que está presente string de input.\\(d\\): número de desvios (em relação ao fuso UTC) que representa o fuso horário empregado resultado final da função.\\(z\\): o valor desvio presente string de input, e que é representado pelo código %z.Desse modo, ao olharmos para o string armazenado em dt, identificamos que o valor de \\(h\\) nessa equação, corresponde 8 horas. Como nós não alteramos o horário presente nesse string em nenhum dos exemplos anteriores, o valor de \\(h\\) esteve sempre fixo. O que estava variando de um exemplo para o outro, era o valor de \\(z\\) e o valor de \\(d\\).valor da variável \\(d\\) depende apenas de qual o fuso horário adotado pela função que estamos utilizando. Quando utilizamos função as_datetime(), o valor de \\(d\\) será igual zero, pois essa função sempre tenta adotar o fuso horário UTC em seus resultados. Contudo, quando utilizamos funções dos pacotes básicos R, o valor de \\(d\\) vai depender de qual é o fuso horário padrão de seu sistema operacional. meu caso, o valor de \\(d\\) em meu computador (quando função .POSIXct() ou strptime() é empregada) é igual -3 (que é o desvio que representa o fuso horário de Brasília).Tendo essas informações em mente, podemos concluir que diferença entre os resultados das funções .POSIXct() e as_datetime() se deve apenas à divergência entre os fusos horários adotados por cada função, o que impacta diretamente valor da variável \\(d\\) para cada função. Em outras palavras, se \\(H_{lubr}\\) e \\(H_{base}\\) são horas calculadas por as_datetime() e .POSIXct(), e, se \\(d_{lubr}\\) e \\(d_{base}\\) são os desvios que representam os fusos horários adotados por cada função, respectivamente, podemos expor essa diferença de forma matemática:\\(H_{lubr} = 8 - [(d_{lubr} \\times -1) + z] = 8+d_{lubr}-z\\)\\(H_{base} = 8 - [(d_{base} \\times -1) + z] = 8+d_{base}-z\\)\\(H_{base} - H_{lubr} = 8+d_{base}-z - (8+d_{lubr}-z)\\)Com essas equações, podemos rapidamente identificar que se ambas funções aplicarem o mesmo fuso horário, variáveis \\(d_{lubr}\\) e \\(d_{base}\\) serão iguais e, consequentemente, essa diferença entre \\(H_{base}\\) e \\(H_{lubr}\\) desaparece. Como exemplo, perceba abaixo que ambas funções retornam o mesmo resultado, ao escolhermos um fuso horário específico argumento tz de cada função, como por exemplo, o horário de Toronto (Canadá).Portanto, fique atento possíveis diferenças entre os horários que resultam de funções que, em tese, deveriam ser “equivalentes” e, que portanto, deveriam gerar os mesmos resultados. Essa seção, buscou demonstrar que tal diferença pode nascer da divergência entre os fusos horários adotados por cada função. Caso você encontre uma diferença dessa natureza, busque pela documentação interna de cada função, e procure entender como essas funções trabalham com o fuso horário.","code":"\ndt <- \"2020-01-01 08:00:00 -0300\"\nas.POSIXct(dt, format = \"%F %T %z\")## [1] \"2020-01-01 08:00:00 -03\"\nas_datetime(dt, format = \"%F %T %z\")## [1] \"2020-01-01 11:00:00 UTC\"\ndt <- \"2020-01-01 08:00:00 -0200\"\nas.POSIXct(dt, format = \"%F %T %z\")## [1] \"2020-01-01 07:00:00 -03\"\nas_datetime(dt, format = \"%F %T %z\")## [1] \"2020-01-01 10:00:00 UTC\"\ndt <- \"2020-01-01 08:00:00 +0200\"\nas.POSIXct(dt, format = \"%F %T %z\")## [1] \"2020-01-01 03:00:00 -03\"\nas_datetime(dt, format = \"%F %T %z\")## [1] \"2020-01-01 06:00:00 UTC\"\ndt <- \"2020-01-01 08:00:00 +0200\"\n### Quando ambas as funções utilizam o mesmo fuso horário\n### a inserção do código %z gera o mesmo resultado\nas.POSIXct(dt, format = \"%F %T %z\", tz = \"America/Toronto\")## [1] \"2020-01-01 01:00:00 EST\"\nas_datetime(dt, format = \"%F %T %z\", tz = \"America/Toronto\")## [1] \"2020-01-01 01:00:00 EST\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"interpretando-um-mesmo-ponto-no-tempo-em-diferentes-fusos-horários","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.7.5 Interpretando um mesmo ponto no tempo em diferentes fusos horários","text":"Vamos construir mentalmente duas pessoas. Cláudio mora e trabalha Rio de Janeiro, e tem feito alguns projetos internacionais na área de marketing. Um de seus principais parceiros é Ryuichi, um grande empresário Japão. Suponha que Cláudio e Ryuichi tenham marcado uma reunião entre eles, às 9hrs da manhã horário Japão (isto é, horário local para o Ryuichi). Qual será o horário da reunião Brasil? Ou seja, que horas Cláudio deve ligar o seu computador e acessar sala de reunião para conversar com Ryuichi?Podemos rapidamente responder essa questão, com função with_tz(). Precisamos primeiro, criar um objeto que guarde o horário de 9hrs segundo o fuso horário Japão e, em seguida, pedimos à função, que nos mostre esse mesmo instante segundo o horário de São Paulo. Como você pode ver abaixo, Cláudio teria que entrar na reunião às 21hrs dia anterior ao dia marcado por Ryuichi.Portanto, o horário Japão está 12 horas adiantado em relação ao horário utilizado por Cláudio. Isso significa que, poderíamos chegar ao mesmo resultado mostrado pela função with_tz(), ao subtraírmos 12 horas valor presente horario_japao. Lembre-se que, valores tipo POSIXct são armazenados em segundos, logo, para subtrairmos 12 horas, precisamos multiplicar essas 12 horas com os 60 minutos (de cada hora) e com os 60 segundos (de cada minuto).entanto, ao invés de adicionar ou subtrair segundos, fundo, o que função with_tz() faz, é retornar o mesmo objeto contendo um atributo tzone diferente. Em outras palavras, podemos ainda chegar ao mesmo resultado de with_tz(), ao alterarmos o valor atributo tzone em horario_japao para o fuso horário de Cláudio, como demonstrado abaixo.Por isso, fique atento aos seus dados tipo POSIXct e POSIXlt. Na hipótese desses dados se alterarem repentinamente, sem alguma explicação clara, pode ser que alguma operação que você realizou tenha alterado o valor conectado ao atributo tzone desses dados e, com isso, provocado esse efeito.","code":"\nhorario_japao <- ymd_hm(\"2020-01-01 09:00\", tz = \"Japan\")\nwith_tz(horario_japao, \"America/Sao_Paulo\")## [1] \"2019-12-31 21:00:00 -03\"\nhorario_japao - (12 * 60 * 60)## [1] \"2019-12-31 21:00:00 JST\"\nhorario_brasil <- horario_japao\nattr(horario_brasil, \"tzone\") <- \"America/Sao_Paulo\"\nhorario_brasil## [1] \"2019-12-31 21:00:00 -03\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"calculando-intervalos-com-o-tipo-difftime","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.8 Calculando intervalos com o tipo difftime","text":"O R oferece de forma nativa, um outro tipo de variável de tempo que é útil para calcularmos intervalos ou diferenças entre dois pontos tempo. Esse tipo é comumente chamado de difftime, e é representado principalmente pela função difftime().O tipo difftime é na verdade, um tipo de dado muito simples. Em resumo, um dado tipo difftime é um dado tipo double, acompanhado de um atributo chamado units, que guarda unidade na qual o valor double se encontra. Porém, o papel que esse tipo busca cumprir não é nada simples.Por exemplo, vamos supor dois horários em um mesmo dia, como 09 horas e 16 horas. diferença entre esses dois pontos é de 7 horas. Tudo que o tipo difftime faz é, armazenar unidade “horas” atributo units que está conectado ao número 7. Dito de outra forma, um dos papéis que o tipo difftime cumpre é manter o controle das unidades de tempo empregadas em valores que representam um intervalo de tempo (ou duração de algum evento).Devido esse controle, o tipo difftime é capaz de eficientemente calcular o intervalo de tempo, entre valores que se encontram em unidades de tempo diferentes. Por exemplo, qual diferença entre 14 horas e 14000 segundos? Ao convertermos esses números para valores tipo difftime, o R se torna capaz de identificar unidades de cada um. Dessa forma, o R pode reconhecer qual maneira ideal de converter ambos os valores para mesma unidade, e com isso, calcular corretamente diferença entre os dois.Além disso, função difftime() lhe permite escolher unidade que você deseja para o resultado. Logo, se você deseja saber quantas semanas estão entre datas 14 de março de 2020 e 01 de janeiro de 2020, você pode rapidamente calcular esse valor da seguinte maneira:Caso você não precise de um nível de precisão muito elevado, você aplicar funções como round(), ceiling() e floor() sobre o resultado de difftime(). Por exemplo, parte decimal valor que calculamos acima (10,42857 semanas) é de pouco valor para nós. Digo, quanto é 0,42857 ou 42,857% de uma semana? Por essa questão, seria interessante aplicarmos função floor() sobre este resultado, para sabermos qual o número de semanas completas que existem entre datas de marco e janeiro.","code":"\ndt1 <- ymd_h(\"2020-01-01 09\")\ndt2 <- ymd_h(\"2020-01-01 16\")\n\ndifftime(dt2, dt1)## Time difference of 7 hours\nhoras <- as.difftime(14, units = \"hours\")\nsegundos <- as.difftime(14000, units = \"secs\")\n\nhoras - segundos## Time difference of 36400 secs\njaneiro <- ymd(\"2020-01-01\")\nmarco <- ymd(\"2020-03-14\")\n\ndifftime(marco, janeiro, units = \"weeks\")## Time difference of 10.42857 weeks\nfloor(difftime(marco, janeiro, units = \"weeks\"))## Time difference of 10 weeks"},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"sec:interp_var_tempo","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.9 Como as variáveis de tempo são interpretadas pelo R ?","text":"Em resumo, qualquer informação que represente uma data (ex: 20/12/2020) é geralmente interpretada pelo R por meio tipo Date; já datas que são acompanhadas de algum horário (ex: 20/12/2020 10:32:41) são assimiladas pelo R através dos tipos POSIXlt e POSIXct (Peng 2015); e, por último, quando temos duração de algum evento, ou principalmente, diferença de tempo entre duas datas (ex: diferença entre 12 de Março e 15 de Março é de três dias, ou, 72 horas, ou, 4.320 minutos, ou, 259.200 segundos), temos opção de empregarmos o tipo difftime sobre essas informações (mas nem sempre isso é necessário).fundo, qualquer dado que interpretado pelos tipos Date, POSIXlt, POSIXct, ou difftime, é armazenado pelo R como um número real, isto é, um dado tipo double. Ou seja, da mesma forma em que descrevemos (capítulo anterior) o tipo factor como um “parente” tipo básico integer, os tipos Date, POSIXlt, POSIXct e difftime são na realidade, parentes tipo básico double, ou, dito de outra forma, são construídos partir dele. E o que diferencia esses tipos tipo básico double, são suas classes e atributos.Assim sendo, em termos técnicos, podemos dizer que um dado que se encontra tipo Date, POSIXlt, POSIXct, ou difftime, é na verdade, um dado tipo double que possui classe Date, POSIXlt, POSIXct, ou difftime, respectivamente. Para mais, um objeto que se encontra tipo POSIXlt ou POSIXct, inclui um atributo chamado tzone. Já um objeto tipo difftime, possui um atributo chamado units. Dito de outra forma, os tipos Date, POSIXlt, POSIXct e difftime são armazenados por meio tipo double, mas apresentam diferentes classes e atributos que os diferenciam uns dos outros.Isso significa que, por exemplo, para testarmos corretamente se um objeto R se encontra tipo Date, nós devemos aplicar um teste lógico parecido com o teste abaixo. Ambos os vetores (double_vec e date_vec) conseguem passar (isto é, adquirem um valor TRUE) na primeira parte teste (.double(x)), pois ambos os vetores são tipo double. Entretanto, apenas o vetor date_vec é capaz de passar também na segunda parte teste (class(x) == \"Date\"), pois apenas date_vec possui classe Date.Uma segunda forma mais direta de realizarmos esse teste é através da função inherits(), que é capaz de identificar se um objeto específico R “herda,” ou apresenta características específicas de um tipo em questão.","code":"\ndouble_vec <- c(0.5, 1.2, 1.5, 2.4)\ndate_vec <- as.Date(c(\"2020-09-10\", \"2020-09-11\", \"2020-09-12\"))\n\nis.double(double_vec) & class(double_vec) == \"Date\"## [1] FALSE\nis.double(date_vec) & class(date_vec) == \"Date\"## [1] TRUE\ninherits(double_vec, \"Date\")## [1] FALSE\ninherits(date_vec, \"Date\")## [1] TRUE"},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"escala-de-tempo-e-o-conceito-de-data-de-origem","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.9.1 Escala de tempo e o conceito de data de origem","text":"Para que essa característica fique clara, veja o exemplo abaixo. Primeiro, eu guardo data 10 de março de 2020 objeto d. Ao questionarmos o R sobre o tipo de dado e classe utilizados pelo objeto d, vemos que ele é um vetor tipo double com classe Date. Em seguida, eu aplico função unclass() sobre o objeto d, para que o R mostre exatamente como essa data está sendo armazenada.Repare abaixo, que o R está guardando data 2020-03-10 (quer dizer, 10 de março de 2020) como o número 18331. Agora, você provavelmente está se questionando: o que esse número 18331 significa? Como ele é traduzido para data 10 de março de 2020? Essas questões são respondidas pelo conceito de data de origem.Este número, pelo qual o R guarda data 2020-03-10, representa o número de dias decorridos desde data de origem até data 2020-03-10. Digo, 18331 dias se passaram desde data de origem até atingirmos o dia 10 de março de 2020. Portanto, data de origem representa o “marco zero,” ou o ponto zero da escala de tempo, e podemos descobrir qual é essa “data de origem” utilizada pelo R, ao subtrairmos da data armazenada o número que representa.Por exemplo, se o número 18331 representa data 2020-03-10, ao subtrairmos esse número dessa data, o R acaba nos retornando data 1970-01-01. Portanto, o “dia zero” segundo perspectiva R, é o dia 01 de janeiro de 1970. Isso significa que, todos os seus dados R que estiverem sendo interpretadas pelo tipo Date, vão ser (obrigatoriamente) armazenados pelo R como o número de dias entre data de origem R (o dia 01 de janeiro de 1970) e suas datas em questão.Essa característica é muito importante, e não é particular ao R. Diversas linguagens de programação, e programas comuns (como o Excel) implementam variáveis de tempo desta mesma maneira40. Logo, R, qualquer informação que descreva um ponto específico tempo é armazenada como um número, e, tal número representa (de certa maneira) uma “medida de distância” entre o ponto zero da escala de tempo e o ponto tempo com o qual você está trabalhando.Tendo isso em mente, qual é o número que representa data 10 de janeiro de 1970 R? Se você compreendeu os conceitos apresentados nessa seção, você certamente respondeu que esse valor é o número 9. Pois partindo dia 01 de janeiro de 1970 até o dia 10 de janeiro, temos 9 dias de diferença.Mas e datas anteriores ao dia 01 de janeiro de 1970? Como o R representa essas datas? Mesmo nessa situação, o R não muda o seu comportamento. Contudo, como essas datas se encontram atrás “ponto zero” na escala tempo utilizada, o R vai representar essas datas com números negativos. Por exemplo, o dia 30 de dezembro de 1969 é representado por meio número -2. Pois essa data se encontra 2 dias atrás dia 01 de janeiro de 1970.Portanto, quanto você aplica uma ordenação sobre um vetor tipo Date, POSIXlt, POSIXct ou difftime, ao invés de o R comparar o dia, mês e ano de cada data, ele vai utilizar os números que representam cada ponto tempo presente nesse vetor para calcular essa ordenação. Em outras palavras, esses valores são ordenados de acordo com suas distâncias em relação à data de origem utilizada pelo R.","code":"\n## O objeto d guarda a data\n## 10 de março de 2020\nd <- as.Date(\"2020-03-10\")\ntypeof(d)## [1] \"double\"\nclass(d)## [1] \"Date\"\nunclass(d)## [1] 18331\nas.Date(\"2020-03-10\") - 18331## [1] \"1970-01-01\"\nd <- as.Date(\"1970-01-10\")\nunclass(d)## [1] 9\nd <- as.Date(\"1969-12-30\")\nunclass(d)## [1] -2"},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"a-unidade-ou-a-escala-de-tempo-muda-com-o-tipo-de-dado","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"12.9.2 A unidade ou a escala de tempo muda com o tipo de dado","text":"Nós sabemos que o tipo Date é armazenado como o número de dias em relação à data de origem. Porém, um choque ocorre quando tentamos transportar isso para os tipos POSIXlt e POSIXct. Pois qualquer dado que interpretado por algum desses dois tipos, vai ser armazenado como os segundos em relação ao ponto de origem.Ou seja, teoria continua mesma; sua informação continua sendo armazenada como um número, que representa uma “medida de distância” até o “ponto zero” da escala de tempo. Entretanto, unidade utilizada nessa escala de tempo muda de acordo com o tipo de dado que você emprega. Logo, quando estamos discutindo o tipo Date, o R recorre à uma escala de tempo em dias. Mas quando estamos nos referindo aos tipos POSIXlt e POSIXct, essa mesma escala de tempo é interpretada em segundos.\nFigure 12.11: Representação visual da escala de tempo utilizada por cada tipo de dado\nPara mais, data de origem é mesma em ambas escalas (01 de janeiro de 1970). Todavia, como os tipos POSIXlt e POSIXct são capazes de guardar horários, esses tipos vão utilizar um ponto específico dessa data de origem como referência. Isto é, ao invés de utilizar o dia 01 de janeiro de 1970 como um todo, os tipos POSIXlt e POSIXct empregam um ponto, ou, um horário específico desse dia como o ponto zero de sua escala de tempo. E esse horário é, de certa forma, o ponto zero desse dia, ou, de outra forma, meia noite desse dia fuso horário UTC. Logo, o ponto de origem na escala da qual os tipos POSIXlt e POSIXct usufruem é o horário 00:00:00 dia 01 de janeiro de 1970, especificamente fuso horário UTC.Com isso, se o dia 2020-03-10 está 18331 dias de distância dia 1970-01-01, quantos segundos o horário 14:30 desse mesmo dia (2020-03-10 14:30:00) está de distância ponto zero da escala (1970-01-01 00:00:00)? Para descobrirmos resposta, podemos aplicar o mesmo método que utilizamos com o tipo Date, por meio da função unclass(). Vemos abaixo, que tal horário é interpretado pelo R como o segundo 1583850600. Em outras palavras, esse horário está aproximadamente 1,583 bilhão de segundos de distância ponto zero da escala.","code":"\nhr <- as.POSIXct(\"2020-03-10 14:30:00\", tz = \"UTC\")\nunclass(hr)## [1] 1583850600\n## attr(,\"tzone\")\n## [1] \"UTC\""},{"path":"introdução-à-variáveis-de-tempo-com-lubridate.html","id":"exercícios-9","chapter":"Capítulo 12 Introdução à variáveis de tempo com lubridate","heading":"Exercícios","text":"Questão 12.1. Cada item abaixo pode lhe pedir para identificar origem de algum erro, ou de algum resultado inesperado, ou ainda, requisitar que você trabalhe com algum objeto específico para um dado fim.12.1.) Perceba abaixo, que ao transformarmos o vetor vec para o tipo Date, alguns elementos são transformados para valores NA. Porque essa transformação ocorre? Há alguma solução clara para isso?12.1.B) Que comandos você utilizaria para transportar o vetor vec abaixo para o tipo Date?12.1.C) Como definimos neste capítulo, R, dados tipo date-time são armazenados como o número de segundos desde meia noite de 01 de janeiro de 1970. Porém, por alguma razão inesperada, quando eu crio um objeto contendo este exato ponto tempo, e retiro sua classe com função unclass(), percebo que este ponto foi armazenado como o valor 10800. Porque isso ocorre? Ele não deveria ser armazenado como zero?Questão 12.2. Como definimos anteriormente neste capítulo, diversos programas, incluindo o Excel, armazenam valores tipo date-time como o número de dias ou de segundos, em relação um ponto específico de origem na escala tempo. Logo abaixo, temos tabela dados_excel. Essa tabela nos apresenta na coluna como_numero, o número aproximado Excel que representa os valores tipo date-time presentes na coluna como_data. Ou seja, Excel, o ponto \"20/02/2020 03:45:00\" é armazenada como o número decimal 43.881,15625. Considerando que, sistema Windows, o Excel utiliza data 30 de Dezembro de 1899 (ou \"1899-12-30\") como o seu ponto de origem, o seu trabalho nessa questão é converter os números presentes vetor numero_no_excel para o tipo POSIXct, de modo que o resultado contenha os mesmos instantes apresentados vetor datetime_no_excel. Dica: configure o argumento tz para o fuso horário UTC, dessa forma, você evita em sua conversão, possíveis adições/subtrações automáticas que emergem da diferença entre o fuso de seu sistema operacional e o fuso UTC.","code":"\nvec <- c(\"2020-01-17\", \"2020-02-21\", \"2020-02-30\", \n         \"2020-04-12\", \"2020-13-19\", \"2020-09-87\")\n\n\nas.Date(vec)## [1] \"2020-01-17\" \"2020-02-21\" NA           \"2020-04-12\" NA          \n## [6] NA\nvec <- c(\"02, 02, 2020\", \"15, 03, 2020\", \"21, 04, 2020\",\n         \"19, 09, 2020\", \"22, 06, 2020\", \"25, 12, 2020\")\nponto <- as.POSIXct(\"1970-01-01 00:00:00\")\nunclass(ponto)## [1] 10800\n## attr(,\"tzone\")\n## [1] \"\"\ndatetime_no_excel <- c(\n  \"20/02/2020 03:40:00\",\n  \"20/02/2020 03:45:00\",\n  \"20/02/2020 03:50:00\",\n  \"20/02/2020 03:55:00\",\n  \"20/02/2020 04:00:00\"\n)\n\nnumero_no_excel <- c(\n  43881.1527777778,\n  43881.15625,\n  43881.159722222226,\n  43881.1632060185, \n  43881.1666666667\n)\n\ndados_excel <- data.frame(\n  como_data = datetime_no_excel,\n  como_numero = numero_no_excel\n)\n\nprint(dados_excel)##             como_data como_numero\n## 1 20/02/2020 03:40:00    43881.15\n## 2 20/02/2020 03:45:00    43881.16\n## 3 20/02/2020 03:50:00    43881.16\n## 4 20/02/2020 03:55:00    43881.16\n## 5 20/02/2020 04:00:00    43881.17"},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"respostas-dos-exercícios-de-cada-capítulo","chapter":"Respostas dos exercícios de cada capítulo","heading":"Respostas dos exercícios de cada capítulo","text":"","code":""},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-1---noções-básicas-do-r","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 1 - Noções Básicas do R","text":"1.1.) Quando temos um conjunto pequeno de valores serem somados, podemos utilizar o operador +:1.1.B) Lembre-se que função sum() lhe permite calcular soma total de um conjunto de valores, de maneira rápida e eficiente. Lembre-se também de criar o objeto conj em seu console, antes de calcular soma. Pois se não você estaria pedindo à função sum(), que calculasse soma de um objeto que não existe em seu computador.1.1.C) Considerando \\(y = 3x^3 - 12x^2 + \\frac{1}{15}x+ 25\\), e \\(x = 5\\), temos que:1.2.) Qualquer erro tipo “objeto ‘x’ não encontrado,” significa que o objeto pelo qual você requisitou não existe atualmente em sua seção R. Portanto, o erro na questão que diz respeito um objeto chamado logica, está lhe dizendo que você não criou ainda nenhum objeto chamado logica em sua sessão. partir momento em que você define um valor para o nome logica, esse erro passa não ocorrer mais. Lembre-se que esse erro pode surgir em qualquer lugar (dentro de qualquer função, ou de qualquer operação), pois sem esse objeto (que não existe em seu computador) o R não é capaz de completar operação pela qual você requisitou.1.2.B) função bind_rows() (assim como função mutate()) pertence ao pacote dplyr, que está fora dos pacotes básicos R. Ou seja, sempre que você inicia uma nova sessão R, função bind_rows() não é automaticamente carregada para essa seção, pois ela pertence um pacote (dplyr) que está fora conjunto de pacotes básicos R.Logo, o erro disposto na questão surge quando tentamos acessar função bind_rows(), quando ela ainda não foi carregada para nossa seção R. Como comentamos ao longo da seção Pacotes, para acessarmos funções disponíveis dentro de um pacote, é necessário carregarmos esse pacote para nossa seção (através da função library()). E para carregarmos um pacote para nossa seção, é necessário que esse pacote esteja instalado em nosso computador.1.2.C) Como comentamos ao longo da seção Pacotes, para utilizarmos funções disponíveis em um pacote, precisamos carregar esse pacote para nossa seção R. E para carregarmos esse pacote para nossa seção, ele precisa estar instalá-em nosso computador. Logo, o erro da questão (que se refere ao pacote dplyr) está nos dizendo que o R não foi capaz de encontrar um pacote instalado em sua máquina, que tenha o nome de dplyr. Por esse motivo, para utilizar o pacote dplyr com o comando library(), você precisa primeiro instalar esse pacote em sua máquina, com o comando install.packages()1.3.) Lembre-se que fórmula índice \\(Z\\) de uma distribuição normal, usualmente assume forma:\\[Z = \\frac{X - \\bar{X}}{\\sigma}\\]Sendo que, variáveis nessa equação são:\\(X\\): variável em questão.\\(\\bar{X}\\): média da variável \\(X\\).\\(\\sigma\\): desvio padrão da variável \\(X\\).Logo, os comandos necessários para o cálculo são:1.3.B) Lembre-se que o desvio médio de uma variável é simplesmente uma média dos desvios de seus valores em relação sua média. Em outras palavras, fórmula de cálculo desvio médio (\\(DM\\)) de uma variável chamada \\(x\\), seria:\\[DM = \\frac{1}{n}\\displaystyle\\sum_{=1}^{n}|x - \\bar{x}|\\]Sendo que, variáveis nessa equação são:\\(n\\): número de observações (ou de valores) que variável contém.\\(\\bar{x}\\): média da variável \\(x\\).\\(x\\): o valor da variável \\(x\\).","code":"\n32397 + 55405## [1] 87802\n### Ou de forma análoga:\nn1 <- 32397\nn2 <- 55405\n\nn1 + n2## [1] 87802\n### Lembre-se de criar o objeto conj\nconj <- c(290, 34, 512, 54, 89)\n\nresposta <- sum(conj)\nprint(resposta)## [1] 979\n### Ou de uma maneira bem menos eficiente:\n\nconj[1] + conj[2] + conj[3] + conj[4] + conj[5]## [1] 979\nx <- 5\ny_resposta <- 3 * (x^3) - 12 * (x^2) + (1/15) * x + 25\nprint(y_resposta)## [1] 100.3333\n### Suponha que o erro tenha surgido a partir do comando abaixo\n### com a função sum()\n\nsum(logica)\n### A partir do momento em que defino um valor para logica\n### o comando volta a funcionar\n\nlogica <- 1:3\nsum(logica)## [1] 6\ndt1 <- data.frame(1:3)\ndt2 <- data.frame(1:5)\n### Não consigo acessar a função bind_rows()\nbind_rows(dt1, dt2)\nlibrary(dplyr)\n### Agora eu consigo acessar a função bind_rows()\nbind_rows(dt1, dt2)##   X1.3 X1.5\n## 1    1   NA\n## 2    2   NA\n## 3    3   NA\n## 4   NA    1\n## 5   NA    2\n## 6   NA    3\n## 7   NA    4\n## 8   NA    5\ninstall.packages(\"dplyr\")\n### Lembre-se que você precisa criar \n### o objeto vec (com o comando abaixo)\n### antes que você possa utilizá-lo em operações\n### no R\nvec <- c(0.5, 1.2, 2.5, 1.3, 2.2, 3.7)\n\ndesvio_padrao <- sd(vec)\nmedia <- mean(vec)\n\nresposta <- (media - vec) / desvio_padrao\nprint(resposta)## [1]  1.2278812  0.6139406 -0.5262348  0.5262348 -0.2631174 -1.5787044\n### Lembre-se que você precisa criar \n### o objeto vec (com o comando abaixo)\n### antes que você possa utilizá-lo em operações\n### no R\nvec <- c(0.5, 1.2, 2.5, 1.3, 2.2, 3.7)\n\ndesvios <- vec - mean(vec)\ntotal_desvio <- sum(abs(desvios))\n\nresposta <- (1 / length(vec)) * total_desvio\nprint(resposta)## [1] 0.9"},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-2---fundamentos-da-linguagem-r","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 2 - Fundamentos da Linguagem R","text":"2.1.) Uma lista contendo um vetor em seu primeiro (e único) elemento.2.1.B) Um vetor atômico contendo sequência de 1 10.2.1.C) Uma matriz \\(5\\times5\\) (5 linhas e 5 colunas) contendo valores tipo character.2.1.D) Um data.frame que possui 10 linhas e 2 colunas.2.1.E) Uma lista contendo 4 itens (ou 4 elementos).2.1.F) Um vetor atômico preenchido por 25 NA’s.2.2.) Essa é uma espécie de pegadinha, não porque ela seja maldosa, mas porque demonstra certos cuidados necessários. Provavelmente, o seu primeiro instinto nessa questão foi utilizar função .vector(), o que é um bom começo, pois ela é capaz de identificar os objetos v_rep e v_seq como vetores atômicos. Ao mesmo tempo, essa função também consegue caracterizar os objetos dt e mt como estruturas diferentes de um vetor atômico.Entretanto, função .vector() acaba considerando o objeto lst como um vetor também! Lembre-se que, uma lista é fundo, um vetor, onde cada elemento desse vetor é pode ser de tipo e estrutura diferentes de seus pares. Portanto, função .vector() é capaz de identificar se um objeto é um vetor, mas não necessariamente se ele é um vetor atômico. Por esse motivo, para nos certificarmos de que um dado objeto é um vetor atômico, temos que saber se ele, além de um vetor, também é um objeto diferente de uma lista, através da função .list().Utilizando o operador ! sobre .list(), podemos identificar se o objeto não é uma lista. Com isso, precisamos apenas conectar esse teste à função .vector() e, dessa maneira, temos um teste lógico que segue estrutura .vector(x) & !.list(x).2.2.B) Nesta questão, ao utilizar função .list(), você já tem metade teste lógico necessário para identificar o objeto lst como uma lista. Porém, esta questão, também inclui uma pegadinha parecida com questão anterior. Pois da mesma maneira que uma lista é, fundo, um vetor; um data.frame é, fundo, uma lista nomeada. Isso significa que, função .list() também vai nos retornar TRUE para qualquer data.frame, e se desejamos identificar apenas listas, precisamos incrementar o nosso teste lógico de modo que ele possa diferenciar data.frame’s de listas.função necessária para esse trabalho é .data.frame(), e utilizando novamente o operador ! sobre o resultado dessa função, podemos identificar qualquer objeto que não é um data.frame. Com isso, temos um teste lógico que segue estrutura .list(x) & !.data.frame(x).2.2.C) Quando temos uma lista nomeada (isto é, cada elemento dessa lista possui um nome), podemos descobrir os nomes de cada elemento dessa lista por meio da função names(). Logo, para descobrirmos se essa lista inclui um item chamado “estado,” precisamos apenas de um teste lógico que possa identificar se o valor \"estado\" está incluso resultado da função names().2.2.D) Basta utilizarmos função .double() sobre coluna total de tab, como está demonstrado abaixo:2.2.E) Lembre-se que três condições apresentadas enunciado da questão são dependentes. Logo, o objeto que você está testando deve se encaixar nas três condições ao mesmo tempo. Em termos técnicos, isso significa que os testes lógicos referentes cada uma das três condições, devem obrigatoriamente retornar TRUE para este objeto. Se ao aplicarmos pelo menos um desses testes, e o resultado FALSE, isso significa que o objeto em questão não se encaixa teste lógico com um todo, ou, o resultado geral teste lógico é FALSE. Para que o R entenda que essas condições são dependentes, e que devem ser satisfeitas ao mesmo tempo, você deve conectar três condições pelo operador &.Para satisfazer primeira condição posta enunciado, podemos conferir se o resultado da função nrow() (que nos retorna o número de linhas presente em um data.frame) é igual 10, construindo assim, o seguinte componente teste: nrow(x) == 10. Já para segunda condição, podemos pesquisar se o valor \"vendas\" aparece dentro resultado da função colnames() (uma outra alternativa seria função names() que gera o mesmo resultado de colnames()). Como colnames() geralmente nos retorna um conjunto de valores (ao invés de 1 único valor), é importante que você utilize o operador %% (ao invés operador ==) para pesquisar pelo valor \"vendas\". Dessa forma, temos o segundo componente teste \"vendas\" %% colnames(x). Por último, para conferirmos terceira condição teste, podemos aplicar função .character() sobre 3° coluna objeto em questão, criando assim o último componente teste .character(x[[3]]).Sendo assim, temos um teste com seguinte estrutura: nrow(x) == 10 & \"vendas\" %% colnames(x) & .character(x[[3]]). Perceba abaixo que, o resultado teste lógico foi FALSE quando aplicado sobre tab, indicando assim, que o objeto tab não se encaixa em pelo menos uma das condições teste. Para identificar qual dessas condições que tab não se encaixa, você pode observar o resultado de cada um dos três componentes teste de forma separada.Repare abaixo, que os testes nrow(tab) == 10 e \"vendas\" %% colnames(tab) nos retornam um valor TRUE, logo, tab satisfaz ambas condições. Contudo, o último teste resulta em FALSE. Portanto, tab não satisfaz última condição teste, ou, dito de outra forma, 3° coluna de tab não é tipo character.2.2.F) Lembre-se que condições serem satisfeitas, para que o ano seja considerado bissexto são: 1) o ano deve ser múltiplo de 4; 2) o ano não deve ser múltiplo de 100 não ser que ele seja múltiplo de 400; 3) se o ano é múltiplo de 400, ele é obrigatoriamente um ano bissexto.Para identificarmos se um dado número é múltiplo de um outro número, podemos observar se o resto da divisão entre esses dois números é igual zero. Em outras palavras, se desejamos saber que um dado valor \\(x\\) é múltiplo de um dado valor \\(y\\), podemos realizar o cálculo \\(x \\div y\\) e, observar se o resto dessa divisão é ou não igual zero. Lembre-se que R, temos o operador aritmético %%, que nos retorna justamente o resto da divisão entre dois números.Tendo isso em mente, para satisfazermos condições 1 e 3, podemos simplesmente conferir se os resultados das operações ano %% 4 e ano %% 400 são iguais zero, construindo assim os componentes ano %% 4 == 0 e ano %% 400 == 0. Entretanto, como condição 2 estabelece que o respectivo ano não deve ser múltiplo de 100, podemos aplicar o operador ! sobre o componente teste referente essa condição. Deste modo, temos o componente !(ano %% 100 == 0). Uma outra alternativa para essa condição 2, seria utilizarmos o operador !=, que significa “não igual ,” ou, “diferente de.” Com esse operador teríamos ano %% 100 != 0.Agora que definimos os componentes teste, precisamos nos atentar à relação de hierarquia entre essas condições. Pois condição 3 predomina sobre condições 1 e 2, assim como condições 3 e 2 prevalecem sobre condição 1. Com isso, se um dado ano é múltiplo de 400, não nos interessa se ele é ou não múltiplo de 100 ou de 4, ele é um ano bissexto e ponto final. Da mesma forma que, se o ano não é múltiplo de 400, mas ele é múltiplo de 100, ele não é um ano bissexto, mesmo que ele seja múltiplo de 4.Primeiro, para que o ano seja bissexto, temos duas possibilidades dentro da relação entre condições 2 e 3. Ou o número ano é múltiplo de 400, ou ele não é múltiplo de 100. Como essas duas possibilidades são independentes (ou seja, ou o ano é uma coisa, ou ele é outra), podemos conectar essas duas condições pelo operador |, construindo assim o componente (ano %% 100 != 0) | (ano %% 400 == 0) teste. Veja alguns exemplos abaixo:Devido independência entre essas condições (estabelecida pelo operador |), o R vai nos retornar TRUE caso o valor de ano se encaixe em pelo menos uma dessas duas condições. Isso significa que, se o valor de ano múltiplo de 400, ele adquire um valor TRUE para o teste ano %% 400 == 0 e, consequentemente, um valor TRUE para todo o componente (ano %% 100 != 0) | (ano %% 400 == 0).Com isso, precisamos apenas conectar esse componente ao outro componente (ano %% 4 == 0), que representa condição 1, formando assim estrutura final teste: (ano %% 4 == 0) & ((ano %% 100 != 0) | (ano %% 400 == 0)). Dessa vez, utilizamos o operador que indica dependência (&) entre esses dois componentes principais teste lógico, que são (ano %% 4 == 0) e (ano %% 100 != 0) | (ano %% 400 == 0), pois um número que é múltiplo de 4, ainda pode ser um múltiplo de 100. Portanto, essa condição de dependência apenas assegura que condição 2 seja respeitada, caso o número atenda condição 1.2.3.) O vetor resultante será tipo character.2.3.B) O vetor resultante será tipo double.2.3.C) O vetor resultante será tipo double2.3.D) O vetor resultante será tipo integer.2.3.E) O vetor resultante será tipo character.2.4.) Perceba que duas condições descritas enunciado são dependentes, logo, elas precisam ser atendidas ao mesmo tempo. Por isso, os dois componentes teste lógico são conectados pelo operador &.2.4.B) Primeiro, temos que calcular o tempo de atraso total de cada voô, ao somar os tempos de atraso momento de partida (dep_delay) e momento de chegada (arr_delay). Com isso, podemos apenas utilizar o operador > (“maior que”) para comparar o tempo de atraso total de cada voô com o resultado da função mean(). Como podemos ver abaixo, 95.685 voôs obtiveram um atraso acima da média.2.4.C) Perceba que ao todo, foram descritas 4 condições enunciado da questão. 1) arr_delay menor que 2; 2) dest igual \"BOS\"; 3) month igual 1; 4) sched_dep_time igual 600.","code":"\nlist(1:30)## [[1]]\n##  [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n## [24] 24 25 26 27 28 29 30\n1:10##  [1]  1  2  3  4  5  6  7  8  9 10\nset.seed(1)\na <- sample(\n  c(\"MG\", \"SP\", \"DF\", \"MS\"),\n  size = 25, replace = TRUE\n)\ndim(a) <- c(5,5)\nprint(a)##      [,1] [,2] [,3] [,4] [,5]\n## [1,] \"MG\" \"MG\" \"DF\" \"SP\" \"MG\"\n## [2,] \"MS\" \"DF\" \"DF\" \"SP\" \"DF\"\n## [3,] \"DF\" \"DF\" \"MG\" \"SP\" \"MG\"\n## [4,] \"MG\" \"SP\" \"MG\" \"SP\" \"MG\"\n## [5,] \"SP\" \"SP\" \"MG\" \"DF\" \"MG\"\ndata.frame(\n  id = 1:10,\n  valor = round(rnorm(10), 2)\n)##    id valor\n## 1   1 -0.29\n## 2   2 -0.30\n## 3   3 -0.41\n## 4   4  0.25\n## 5   5 -0.89\n## 6   6  0.44\n## 7   7 -1.24\n## 8   8 -0.22\n## 9   9  0.38\n## 10 10  0.13## $estado\n## [1] \"MG\"\n## \n## $cidade\n## [1] \"Belo Horizonte\"\n## \n## $n_municipios\n## [1] 853\n## \n## $regiao\n## [1] \"Sudeste\"##  [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n## [24] NA NA\nv_seq <- 10:25\nv_rep <- rep(\"abc\", times = 30)\nlst <- list(1:10)\nmt <- matrix(1:20, nrow = 4, ncol = 5)\ndt <- data.frame(15, \"A\", 1:10)\n\n\nis.vector(v_rep) & !is.list(v_rep)## [1] TRUE\nis.vector(v_seq) & !is.list(v_seq)## [1] TRUE\nis.vector(lst) & !is.list(lst)## [1] FALSE\nlst <- list(\n  estado = \"MG\",\n  cidade = \"Belo Horizonte\",\n  n_municipios = 853,\n  regiao = \"Sudeste\"\n)\n\n\nis.list(lst) & !is.data.frame(lst)## [1] TRUE\nlst <- list(\n  estado = \"MG\",\n  cidade = \"Belo Horizonte\",\n  n_municipios = 853,\n  regiao = \"Sudeste\"\n)\n\n\n\"estado\" %in% names(lst)## [1] TRUE\n### Repare que ao aplicarmos o mesmo\n### teste sobre o objeto lst_sem_estado\n### o resultado é FALSE, indicando que\n### essa lista não possui um item chamado\n### \"estado\"\n\nlst_sem_estado <- list(\n  regiao = \"Sudeste\",\n  n_municipios = 853\n)\n\n\"estado\" %in% names(lst_sem_estado)## [1] FALSE\ntab <- data.frame(\n  unidade = c(\"Centro\", \"Gameleira\", \"Santa Efigênia\", \"Centro\",\n              \"Barro Preto\", \"Centro\", \"Gameleira\", \"Centro\",\n              \"Barro Preto\", \"Santa Efigênia\"),\n  mes = c(1, 1, 1, 2, 2, 3, 3, 4, 4, 4),\n  vendas = c(1502, 1430, 1100, 1200, 1443, 1621, 1854, 2200,\n             1129, 1872),\n  total = c(5362.14, 5105.1, 3927, 4284, 5151.51, 5786.97, \n            6618.78, 7854, 4030.53, 6683.04)\n)\n\n\n### Use a função is.double() sobre a coluna\nis.double(tab$total)## [1] TRUE\nnrow(tab) == 10 & \"vendas\" %in% colnames(tab) & is.character(tab[[3]])## [1] FALSE\nnrow(tab) == 10## [1] TRUE\n\"vendas\" %in% colnames(tab)## [1] TRUE\nis.character(tab[[3]])## [1] FALSE\nano <- 1240\n(ano %% 100 != 0) | (ano %% 400 == 0)## [1] TRUE\nano <- 3200\n(ano %% 100 != 0) | (ano %% 400 == 0)## [1] TRUE\nano <- 100\n(ano %% 100 != 0) | (ano %% 400 == 0)## [1] FALSE\n### Por exemplo, 2006 não é um ano bissexto\nano <- 2006\n(ano %% 4 == 0) & ((ano %% 100 != 0) | (ano %% 400 == 0))## [1] FALSE\n### Mas o ano de 2004 é um ano bissexto\nano <- 2004\n(ano %% 4 == 0) & ((ano %% 100 != 0) | (ano %% 400 == 0))## [1] TRUE\nvec <- c(1.2, 2.4, \"3.1\", 1.9)\ntypeof(vec)## [1] \"character\"\nintegers <- 1:3\ndoubles <- c(2.23, 9.87, 3.2)\n\nvec <- c(integers, doubles)\ntypeof(vec)## [1] \"double\"\nvec <- c(1.56, 3L, 1L, 5L,  2.32, 9.87)\ntypeof(vec)## [1] \"double\"\nvec <- c(TRUE, 1L, FALSE)\ntypeof(vec)## [1] \"integer\"\nvec <- c(\"p\", \"b\", \"c\", TRUE, 2L, 4.318)\ntypeof(vec)## [1] \"character\"\nlibrary(nycflights13)\n\nteste <- flights$month == 5 & flights$carrier == \"B6\"\n\nflights[teste, ]\nlibrary(nycflights13)\n### Primeiro, vamos calcular o atraso total\n### de cada voô\natraso_total <- flights$dep_delay + flights$arr_delay\n\nteste <- atraso_total > mean(atraso_total, na.rm = TRUE)\n\nflights[teste, ]\nlibrary(nycflights13)\n\nteste <- (flights$arr_delay < 2 & flights$dest == \"BOS\") |\n  (flights$month == 1 & flights$sched_dep_time == 600)\n\nflights[teste, ]\n### Ou de forma um pouco mais organizada:\n###\ncondicao1 <- flights$arr_delay < 2 & flights$dest == \"BOS\"\ncondicao2 <- flights$month == 1 & flights$sched_dep_time == 600\n\nteste <- condicao1 | condicao2\n\nflights[teste, ]"},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-3---importando-e-exportando-dados-com-o-r","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 3 - Importando e exportando dados com o R","text":"3.1.) Primeiro, sempre comece identificando o caractere especial que está separando cada coluna nesse arquivo. caso objeto t abaixo, esse caractere especial é o til (~). Com isso, podemos utilizar o argumento delim, da função read_delim() para termos uma primeira leitura arquivo, como demonstrado abaixo:3.1.B) Ao observarmos com cuidado os resultados apresentados pela questão, podemos identificar que importação de ambos os arquivos (pac1 e pac2) apresentam erros. Focando primeiramente em pac1, perceba que os valores presentes em todas colunas numéricas (Produção, Receita e Gasto em P&D) estão muito altos. Esse erro ocorre, devido ao padrão empregado pela função read_delim(). Lembre-se que grande parte das funções pacote readr seguem o padrão americano, que utiliza o ponto como o separador decimal, e vírgula, como separador de milhares.Portanto, ao ler o número 10828,37, função read_delim() entende que esse valor corresponde ao número 1.082.837. Por esse motivo, precisamos sobrepor esse padrão, ao descrevermos explicitamente à função read_delim(), o padrão utilizado pelos valores numéricos presentes arquivo pac1. Lembre-se que uma descrição desse tipo é fornecida dentro da função locale(), mais especificamente, argumento locale da função que você está utilizando para importação.Por outro lado, podemos perceber que o arquivo pac2 enfrenta o mesmo problema de pac1. Pois valores como 18.828,37 e 69,99, foram interpretados pela função read_delim() como os números 18,828 e 6.999, respectivamente.Para corrigir esse problema, utilizamos novamente função locale(). Entretanto, um outro problema ainda persiste arquivo pac2. Pois o tipo character foi aplicado sobre coluna Gasto em P&D, qual é claramente uma coluna numérica.Tal erro, ocorre pelo simples fato de que segunda linha dessa coluna é preenchida por um “x.” Ao encontrar esse “x,” função read_delim() opta pelo tipo de dado mais flexível possível (o tipo character). Dessa maneira, precisamos apenas afirmar à função read_delim(), que essa coluna deve ser interpretada por um tipo numérico, como o tipo double.3.1.C) Quando erros desse tipo ocorrem, é interessante que você olhe para dentro arquivo, ou seja, abra primeiras milhares de linhas arquivo, e tente identificar algum fator que possa estar causando este erro. Como o arquivo challenge.csv é relativamente pequeno, você pode abrí-lo em uma janela de seu RStudio por meio dos comandos abaixo:Ao navegar em direção ao final arquivo, você vai perceber que os dados mudam drasticamente de formato partir da linha 1001 arquivo (veja abaixo, um retrato dessa porção arquivo).Logo, podemos inferir que o problema gerado na importação, se trata novamente de um chute errado da função read_csv(). Pois função interpretou que duas colunas arquivo, pertencem aos tipos double e logical, respectivamente, sendo que segunda coluna é, de forma clara, tipo Date, ao observarmos sua porção à frente da linha 1001.Lembre-se que, funções pacote readr vão, por definição, utilizar 1000 primeiras linhas arquivo para advinhar o tipo de dado contido em cada coluna arquivo. Devido ao fato de que mudança drástica nos dados armazenados em challenge.csv, ocorre após essas 1000 primeiras linhas, função read_csv() acaba não percebendo o seu erro. Por esses motivos, precisamos sobrepor essa decisão, ao definirmos explicitamente os tipos desejados para cada coluna argumento col_types.3.1.D) Novamente, sempre comece identificando o caractere especial que está separando cada coluna nesse arquivo. caso objeto t, esse caractere especial é o asterisco (*). Com isso, podemos utilizar o argumento delim, da função read_delim() para termos uma primeira leitura arquivo, como demonstrado abaixo:Ainda assim, há alguns pontos que precisamos melhorar. Primeiro, coluna Valor_compra está sendo atualmente interpretada pelo tipo character, sendo que ela claramente guarda valores numéricos, isto é, valores tipo double. O mesmo ocorre com coluna Data_execução, que armazena datas específicas, quais poderiam ser melhor interpretadas pelo tipo Date.Por isso, precisamos definir explicitamente os tipos dessas colunas à função read_delim(), como demonstrado abaixo. Repare que utilizamos col_number() sobre coluna Valor_compra, e não, col_double(). Pois col_double() não seria capaz de ler corretamente essa coluna, dado que os valores numéricos estão acompanhados de informações textuais (R$), quais col_double() não é capaz de compreender. Já col_number(), busca extrair qualquer valor numérico presente em um string e, por isso, acaba ignorando por padrão todas informações não-numéricas presentes neste mesmo string. Após extrair o valor numérico, col_number() ainda vai analisar esse valor, e decidir se ele deve ser convertido para o tipo integer, ou para o tipo double, o que nos dá bastante flexibilidade, e economiza certo trabalho de nossa parte.3.2) Primeiro, falando especificamente de planilhas Excel, mescla de células é uma ferramenta que pode deixar sua planilha esteticamente atraente. Porém, tal ferramenta gera sérias anomalias na estrutura de sua tabela. Pois duas células que foram mescladas, são apresentadas você como uma única célula. Mas fundo, o Excel armazena os valores presente nessa célula de uma maneira não uniforme (ou em uma estrutura não retangular) ao longo de sua tabela.caso arquivo emater_icms_solidario.xlsx, células mescladas se encontram cabeçalho da tabela. Com isso, essas células mescladas nos impedem de importar diretamente da planilha, os nomes de cada coluna da tabela. Por isso, é mais fácil simplesmente ignorarmos o fato de que cada coluna possui um nome, e tentarmos selecionar apenas parte da planilha que contém os dados em si, de forma crua. Por essa estratégia, podemos fornecer corretamente os nomes de cada coluna de forma separada, através argumento col_names.","code":"\nt <- \"\nID~Valor/Grupo~Unidade\n1~2,5488/Marketing~Kg\n2~4,0101/Análise~Kg\n3~1097/Vendas~g\n4~12,76/Logísitica~Kg\"\n\nreadr::read_delim(t, delim = \"~\")## # A tibble: 4 x 3\n##      ID `Valor/Grupo`    Unidade\n##   <dbl> <chr>            <chr>  \n## 1     1 2,5488/Marketing Kg     \n## 2     2 4,0101/Análise   Kg     \n## 3     3 1097/Vendas      g      \n## 4     4 12,76/Logísitica Kg\npac1 <- \"Setor;Produção;Receita;Gasto em P&D\nProdutos alimentícios;10828,37;199907,55;3358,36\nBebidas;759,53;28093,21;\nProdutos do fumo;69,99;8863,5;121,35\nProdutos têxteis;4153,97;25804,16;746,83\nProdutos de madeira;5088,78;15320,69;279,54\nCelulose e outras pastas;26,95;4245,19;216,7\nRefino de petróleo;75,48;114316,31;1550,73\nProdutos químicos;3179,52;133582,8;2914,09\nProdutos farmacêuticos;621,82;24972,07;1038,73\"\n\nreadr::read_delim(pac1, delim = \";\")## # A tibble: 9 x 4\n##   Setor                    Produção  Receita `Gasto em P&D`\n##   <chr>                       <dbl>    <dbl>          <dbl>\n## 1 Produtos alimentícios     1082837 19990755         335836\n## 2 Bebidas                     75953  2809321             NA\n## 3 Produtos do fumo             6999    88635          12135\n## 4 Produtos têxteis           415397  2580416          74683\n## 5 Produtos de madeira        508878  1532069          27954\n## 6 Celulose e outras pastas     2695   424519           2167\n## 7 Refino de petróleo           7548 11431631         155073\n## 8 Produtos químicos          317952  1335828         291409\n## 9 Produtos farmacêuticos      62182  2497207         103873\nreadr::read_delim(\n  pac1, delim = \";\",\n  locale = locale(grouping_mark = \".\", decimal_mark = \",\")\n)## # A tibble: 9 x 4\n##   Setor                    Produção Receita `Gasto em P&D`\n##   <chr>                       <dbl>   <dbl>          <dbl>\n## 1 Produtos alimentícios     10828.  199908.          3358.\n## 2 Bebidas                     760.   28093.            NA \n## 3 Produtos do fumo             70.0   8864.           121.\n## 4 Produtos têxteis           4154.   25804.           747.\n## 5 Produtos de madeira        5089.   15321.           280.\n## 6 Celulose e outras pastas     27.0   4245.           217.\n## 7 Refino de petróleo           75.5 114316.          1551.\n## 8 Produtos químicos          3180.  133583.          2914.\n## 9 Produtos farmacêuticos      622.   24972.          1039.\npac2 <- \"Setor;Produção;Receita;Gasto em P&D\nProdutos alimentícios;10.828,37;199907,55;3358,36\nBebidas;759,53;28093,21;x\nProdutos do fumo;69,99;8863,5;121,35\nProdutos têxteis;4.153,97;25804,16;746,83\nProdutos de madeira;5.088,78;15320,69;279,54\nCelulose e outras pastas;26,95;4245,19;216,7\nRefino de petróleo;75,48;114316,31;1550,73\nProdutos químicos;3.179,52;133582,8;2914,09\nProdutos farmacêuticos;621,82;24972,07;1038,73\"\n\nreadr::read_delim(pac2, delim = \";\")## # A tibble: 9 x 4\n##   Setor                    Produção  Receita `Gasto em P&D`\n##   <chr>                       <dbl>    <dbl> <chr>         \n## 1 Produtos alimentícios       10.8  19990755 3358,36       \n## 2 Bebidas                  75953     2809321 x             \n## 3 Produtos do fumo          6999       88635 121,35        \n## 4 Produtos têxteis             4.15  2580416 746,83        \n## 5 Produtos de madeira          5.09  1532069 279,54        \n## 6 Celulose e outras pastas  2695      424519 216,7         \n## 7 Refino de petróleo        7548    11431631 1550,73       \n## 8 Produtos químicos            3.18  1335828 2914,09       \n## 9 Produtos farmacêuticos   62182     2497207 1038,73\nreadr::read_delim(\n  pac2, delim = \";\",\n  locale = locale(grouping_mark = \".\", decimal_mark = \",\")\n)## # A tibble: 9 x 4\n##   Setor                    Produção Receita `Gasto em P&D`\n##   <chr>                       <dbl>   <dbl> <chr>         \n## 1 Produtos alimentícios     10828.  199908. 3358,36       \n## 2 Bebidas                     760.   28093. x             \n## 3 Produtos do fumo             70.0   8864. 121,35        \n## 4 Produtos têxteis           4154.   25804. 746,83        \n## 5 Produtos de madeira        5089.   15321. 279,54        \n## 6 Celulose e outras pastas     27.0   4245. 216,7         \n## 7 Refino de petróleo           75.5 114316. 1550,73       \n## 8 Produtos químicos          3180.  133583. 2914,09       \n## 9 Produtos farmacêuticos      622.   24972. 1038,73\nreadr::read_delim(\n  pac2, delim = \";\",\n  locale = locale(grouping_mark = \".\", decimal_mark = \",\"),\n  col_types = cols(\n    .default = col_number(), Setor = col_character()\n  )\n)## Warning: 1 parsing failure.\n## row          col expected actual         file\n##   2 Gasto em P&D a number      x literal data## # A tibble: 9 x 4\n##   Setor                    Produção Receita `Gasto em P&D`\n##   <chr>                       <dbl>   <dbl>          <dbl>\n## 1 Produtos alimentícios     10828.  199908.          3358.\n## 2 Bebidas                     760.   28093.            NA \n## 3 Produtos do fumo             70.0   8864.           121.\n## 4 Produtos têxteis           4154.   25804.           747.\n## 5 Produtos de madeira        5089.   15321.           280.\n## 6 Celulose e outras pastas     27.0   4245.           217.\n## 7 Refino de petróleo           75.5 114316.          1551.\n## 8 Produtos químicos          3180.  133583.          2914.\n## 9 Produtos farmacêuticos      622.   24972.          1039.\nfile.edit(readr_example(\"challenge.csv\"))998   1843,NA\n999   1687,NA\n1000  4569,NA\n1001  4548,NA\n1002  0.23837975086644292,2015-01-16\n1003  0.41167997173033655,2018-05-18\n1004  0.7460716762579978,2015-09-05\n1005  0.723450553836301,2012-11-28\n1006  0.614524137461558,2020-01-13\nread_csv(\n  readr_example(\"challenge.csv\"),\n  col_types = cols(\n    x = col_double(),\n    y = col_date()\n  )\n)## # A tibble: 2,000 x 2\n##        x y         \n##    <dbl> <date>    \n##  1   404 NA        \n##  2  4172 NA        \n##  3  3004 NA        \n##  4   787 NA        \n##  5    37 NA        \n##  6  2332 NA        \n##  7  2489 NA        \n##  8  1449 NA        \n##  9  3665 NA        \n## 10  3863 NA        \n## # ... with 1,990 more rows\nt <- \"Data_execução*Unidades*Valor_compra\n20/01/2020*21*R$ 3049,50\n23/01/2020*502*R$ 1289,03\n25/01/2020*90*R$ 678,00\n02/02/2020*123*R$ 5401\n05/02/2020*45*R$ 1450,10\n07/02/2020*67*R$ 2320,97\n09/02/2020*187*R$ 6231,76\"\n\nreadr::read_delim(t, delim = \"*\")## # A tibble: 7 x 3\n##   Data_execução Unidades Valor_compra\n##   <chr>            <dbl> <chr>       \n## 1 20/01/2020          21 R$ 3049,50  \n## 2 23/01/2020         502 R$ 1289,03  \n## 3 25/01/2020          90 R$ 678,00   \n## 4 02/02/2020         123 R$ 5401     \n## 5 05/02/2020          45 R$ 1450,10  \n## 6 07/02/2020          67 R$ 2320,97  \n## 7 09/02/2020         187 R$ 6231,76\nread_delim(\n  t, delim = \"*\",\n  col_types = cols(\n    col_date(format = \"%d/%m/%Y\"),\n    col_integer(),\n    col_number()\n  ),\n  locale = locale(\n    decimal_mark = \",\", grouping_mark = \".\"\n  )\n)## # A tibble: 7 x 3\n##   Data_execução Unidades Valor_compra\n##   <date>           <int>        <dbl>\n## 1 2020-01-20          21        3050.\n## 2 2020-01-23         502        1289.\n## 3 2020-01-25          90         678 \n## 4 2020-02-02         123        5401 \n## 5 2020-02-05          45        1450.\n## 6 2020-02-07          67        2321.\n## 7 2020-02-09         187        6232.\n### Nomes de cada coluna\nnomes <- c(\n  \"Semestre\", \"Ano\", \"Municipio\", \"Cod_IBGE\",\n  \"Area_2017\", \"Area_2018\", \"Area_Media\",\n  \"Pastagens_2006\", \"Area_Total\", \"N_pequeno_prod\",\n  \"Extensao_Rural\", \"PM_Fundo_Rotativo\", \"PM_Mecanizacao_Agr\",\n  \"PM_Sementes_Mudas\", \"PM_Calcario_Fertilizante\",\n  \"PM_Apoio_Comercializacao\"\n)\n\n### Lembre-se que o caminho até o arquivo\n### será diferente em sua máquina.\n### Pois muito provavelmente você não possui um\n### um usuário chamado Pedro.\nreadxl::read_excel(\n  \"C:/Users/Pedro/Downloads/emater_icms_solidario.xlsx\",\n  range = \"A6:P858\", \n  col_names = nomes\n)"},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-4---transformando-dados-com-dplyr","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 4 - Transformando dados com dplyr","text":"4.1.) Em resumo, os comandos abaixo calculam o número de linhas que descrevem um personagem masculino que possui olhos vermelhos. Primeiro, count() calcula o número de linhas por sexo e por cada coloração olho. Em seguida, função filter() seleciona apenas linhas que dizem respeito personagens masculinos e que possuem olhos vermelhos.4.1.B) Em resumo, os comandos abaixo calculam o peso médio de cada sexo descrito na tabela starwars. Primeiro, função select() vai selecionar todas colunas da tabela starwars, exceto colunas contidas vetor vec. Segundo, group_by() vai agrupar base de acordo com os valores dispostos na coluna sex. Terceiro, summarise() vai tratar de calcular o peso médio dentro de cada grupo da coluna sex. Em outras palavras, summarise() vai separar linhas da tabela de acordo com os grupos da coluna sex e, em seguida, vai aplicar função mean() sobre coluna mass de cada um desses grupos.4.1.C) O código abaixo aplica os seguintes passos sobre tabela mpg: primeiro, mutate() adiciona uma coluna chamada pais_origem, onde cada modelo de carro descrito na tabela é categorizado de acoro com o país de origem fabricante deste modelo; em seguida, count() contabiliza quantidade de modelos que pertencem cada país; por último, um novo mutate() é aplicado com o objetivo de calcular proporção de cada país em relação ao total de modelos descritos na tabela.4.2.) Primeiro, identifique principais colunas que são de seu interesse para responder pergunta estipulada na questão. Para responder pergunta, precisamos medir em quanto os preços cobrados por cada universidade aumentou e, para isso, não precisaremos das colunas net_cost, income_lvl e campus. Por isso, podemos rapidamente eliminar essas colunas com um select().Agora, temos um problema importante ser analisado: é possível que haja observações repetidas? Ou, será que há várias linhas descrevendo uma mesma universidade em um mesmo ano? primeiras linhas da tabela acima já nos mostram que sim, há repetição de observações ao longo da base. Para corrigir essa repetição podemos aplicar função distinct() sobre base.Lembre-se que, mesmo após aplicarmos distinct() sobre base, pode haver dois total_price’s para uma mesma universidade em um mesmo ano. Ou seja, distinct() tratou de eliminar observações repetidas da tabela, isto é, observações que possuem exatamente os mesmos valores em todas colunas. Sendo assim, podem existir na tabela, dois (ou mais) valores que se referem uma mesma universidade e um mesmo ano, mas que possuem valores diferentes na coluna total_price. O resultado dos comandos abaixo confirmam essa suspeita:São poucas universidades que possuem mais de um preço para um mesmo ano. Contudo, precisamos que cada ano de cada universidade possua um único preço. Logo, temos que encontrar um método que combine esses dois valores em um só. Calcular média desses dois valores é uma solução razoável. Repare abaixo, que aplicamos um group_by() sobre custos, antes summarise(), pois desejamos aplicar média sobre total_price, dentro de cada ano (year) de cada universidade (name):Resolvido esse problema, podemos nos preocupar em calcular variação anual preço de cada universidade. funções lead() e lag() são muito úteis para compararmos o valor de um determinado ano ao seu par ano anterior. Porém, para que lag() capture corretamente o valor ano anterior, é fundamental que esses anos estejam organizados dentro de cada universidade, em uma ordem crescente, ao longo de toda base. Por esse motivo, um arrange() é aplicado sobre base antes mutate().Com esses valores em mãos, podemos enfim responder à pergunta da questão. Basta reordenarmos base de acordo com maiores variações de preço (var_price) com arrange() e, em seguida, extraírmos 10 primeiras linhas com head(). Com isso, temos que o custo anual Los Medanos College subiu 95.944 dólares em 2012 (comparado ao valor ano anterior).4.2.B) Ao filtrarmos especificamente observações Los Medanos College, podemos identificar que variação de mais de 94 mil dólares ocorre entre os valores $18.139 e $114.083. Perceba que os demais preços referentes essa universidade se encontram entre 18 e 21 mil dólares. Logo, tal variação de mais 94 mil parece muito distoante para o padrão da universidade.Expondo essa variação de maneira visual, temos:Como definimos enunciado, não temos uma resposta certa ou errada para questão. O objetivo era apenas que você encontrasse esses dados e questionasse sua validade. Qual o motivo para uma variação dessa magnitude é principal questão aqui, e ela levanta altas suspeitas de que esse dado está incorreto, ou que foi alterado de alguma maneira durante o seu processo de coleta. Não sabemos exatamente o que ocorreu com esse dado, mas muito provavelmente há algo de errado com ele.4.3.) Primeiro, como vamos utilizar apenas da coluna 1 até coluna 11, podemos selecionar essas colunas da tabela com um select():Em seguida, temos que descobrir o número de valores únicos presentes em cada coluna tipo character de dados. Essas colunas são: name, hair_color, skin_color, eye_color, sex, gender, homeworld e species. Para esse cálculo, poderíamos aplicar funções length() e unique() separadamente em cada uma dessas colunas, como mostrado abaixo:Porém, uma forma muito mais eficiente de realizarmos esse mesmo cálculo, é com o uso da função across(), que lhe permite aplicar uma mesma função sobre várias colunas de seu data.frame. Detalhe que função n_distinct() pertence ao pacote dplyr, sendo apenas uma função equivalente e mais rápida que operação length(unique(x)). Em outras palavras, operações n_distinct(x) e length(unique(x)) trazem o mesmo resultado.Como resultado, temos um data.frame de uma única linha e várias colunas em contagens. Temos capacidade de transformar esse data.frame em um vetor, através da função unlist(). Dessa maneira, para descobrirmos o maior número de valores únicos em cada coluna, podemos simplesmente aplicar função sort() sobre o vetor resultante de unlist(). Repare abaixo, que colunas name e homeworld são colunas que contém mais valores únicos da coluna 1 até coluna 11 da base, contendo 87 e 49 valores únicos respectivamente.4.4.) Temos dois caminhos possíveis aqui, os quais se diferenciam apenas pelo posicionamento da função filter(). Em resumo, questão pede por uma média que diz respeito apenas ao atendente Eduardo, logo, vamos precisar, em algum momento, de aplicar um filter() com o objetivo de pegar apenas observações que dizem respeito ao Eduardo. Podemos: 1) filtrar base inteira para pegar apenas observações Eduardo e, em seguida, calcular média; ou, 2) agrupar base por cada atendente, calcular média de cada um e, em seguida, filtrar apenas média de Eduardo. Ambas opções chegam ao mesmo resultado de $3462 de receita média por parte de Eduardo.4.4.B) Como podemos observar abaixo, Ana tem maior costume de enviar transferências para o Equador, com um total de 302 transferências destinadas para esse país ao longo da base. Tal cálculo consiste em: 1) filtrar da base todas linhas que dizem respeito à Ana; 2) contar o número de linhas que dizem respeito cada país; 3) ordenar tabela resultante de acordo com contagem de cada país em ordem crescente; 4) com o resultado ordenado em ordem crescente, os países mais populares ficam nas últimas linhas resultado, logo, basta extraírmos última linha resultado que teremos o país de destino mais popular de todos.4.4.C) O pacote dplyr nos oferece função last(), que é capaz de extrair o último valor de um vetor específico. Perceba que eu ainda forneço coluna Data argumento order_by. Dessa forma, last() vai pegar o último valor de um vetor com base na ordem dos valores da coluna Data. Porém, como função last() é capaz de extrair o último valor de um vetor, eu preciso utilizar função across() para aplicar last() sobre cada uma das colunas da tabela.Uma outra alternativa é utilizar função slice_max(), que precisa apenas de uma coluna argumento order_by, que corresponde à coluna de referência, ou, coluna pela qual função vai determinar o último valor de cada atendente.","code":"\nstarwars %>% \n  count(sex, eye_color) %>% \n  filter(sex == \"male\", eye_color == \"red\")## # A tibble: 1 x 3\n##   sex   eye_color     n\n##   <chr> <chr>     <int>\n## 1 male  red           2\nvec <- c(\"species\", \"homeworld\", \"films\", \"vehicles\", \"starships\")\n\nstarwars %>% \n  select(-all_of(vec)) %>% \n  group_by(sex) %>% \n  summarise(peso_medio = mean(mass, na.rm = TRUE))## # A tibble: 5 x 2\n##   sex            peso_medio\n##   <chr>               <dbl>\n## 1 female               54.7\n## 2 hermaphroditic     1358  \n## 3 male                 81.0\n## 4 none                 69.8\n## 5 <NA>                 48\nmpg %>% \n  mutate(\n    pais_origem = case_when(\n      manufacturer %in% c(\"audi\", \"volkswagen\") ~ \"Alemanha\",\n      manufacturer %in% c(\"nissan\", \"honda\",\n                          \"subaru\", \"toyota\") ~ \"Japão\",\n      manufacturer == \"hyundai\" ~ \"Coréia do Sul\",\n      manufacturer == \"land rover\" ~ \"Inglaterra\",\n      manufacturer %in% c(\"dodge\", \"jeep\", \n                          \"chevrolet\", \"ford\",\n                          \"lincoln\", \"pontiac\",\n                          \"mercury\") ~ \"EUA\"\n    )\n  ) %>% \n  count(pais_origem) %>% \n  mutate(\n    prop = ( n * 100 ) / sum(n)\n  )## # A tibble: 5 x 3\n##   pais_origem       n  prop\n##   <chr>         <int> <dbl>\n## 1 Alemanha         45 19.2 \n## 2 Coréia do Sul    14  5.98\n## 3 EUA             101 43.2 \n## 4 Inglaterra        4  1.71\n## 5 Japão            70 29.9\ncustos <- dados %>%\n  select(-net_cost, -income_lvl, -campus)\n\ncustos## # A tibble: 209,012 x 4\n##    name                              state total_price  year\n##    <chr>                             <chr>       <dbl> <dbl>\n##  1 Piedmont International University NC          20174  2016\n##  2 Piedmont International University NC          20174  2016\n##  3 Piedmont International University NC          20174  2016\n##  4 Piedmont International University NC          20174  2016\n##  5 Piedmont International University NC          20514  2017\n##  6 Piedmont International University NC          20514  2017\n##  7 Piedmont International University NC          20514  2017\n##  8 Piedmont International University NC          20514  2017\n##  9 Piedmont International University NC          20514  2017\n## 10 Piedmont International University NC          20829  2018\n## # ... with 209,002 more rows\ncustos <- custos %>% \n  distinct()\n\ncustos## # A tibble: 40,991 x 4\n##    name                              state total_price  year\n##    <chr>                             <chr>       <dbl> <dbl>\n##  1 Piedmont International University NC          20174  2016\n##  2 Piedmont International University NC          20514  2017\n##  3 Piedmont International University NC          20829  2018\n##  4 Piedmont International University NC          23000  2016\n##  5 Piedmont International University NC          26430  2017\n##  6 Piedmont International University NC          26870  2018\n##  7 Kaplan University-Milwaukee       WI          22413  2017\n##  8 Kaplan University-Milwaukee       WI          22492  2018\n##  9 Kaplan University-Indianapolis    IN          22413  2017\n## 10 Kaplan University-Indianapolis    IN          22492  2018\n## # ... with 40,981 more rows\ncustos %>% \n  group_by(name, year) %>% \n  count(total_price) %>% \n  filter(n > 1)## # A tibble: 14 x 4\n## # Groups:   name, year [14]\n##    name                                  year total_price     n\n##    <chr>                                <dbl>       <dbl> <int>\n##  1 Academy of Interactive Entertainment  2015       30876     2\n##  2 Bryan University                      2010       32572     2\n##  3 Bryan University                      2011       40821     2\n##  4 Bryan University                      2013       24449     2\n##  5 Bryan University                      2014       25446     2\n##  6 Bryan University                      2016       25595     2\n##  7 Bryan University                      2017       25595     2\n##  8 Stevens-Henager College               2011       28414     2\n##  9 Stevens-Henager College               2012       29539     2\n## 10 Stevens-Henager College               2014       32312     2\n## 11 Stevens-Henager College               2015       32440     2\n## 12 Stevens-Henager College               2016       33960     2\n## 13 Stevens-Henager College               2017       33960     2\n## 14 Stevens-Henager College               2018       33489     2\ncustos <- custos %>% \n  group_by(name, year) %>% \n  summarise(mean_price = mean(total_price))## `summarise()` has grouped output by 'name'. You can override using the `.groups` argument.\ncustos## # A tibble: 30,066 x 3\n## # Groups:   name [3,664]\n##    name                          year mean_price\n##    <chr>                        <dbl>      <dbl>\n##  1 Aaniiih Nakoda College        2010      17030\n##  2 Aaniiih Nakoda College        2011      17030\n##  3 Aaniiih Nakoda College        2012      17030\n##  4 Aaniiih Nakoda College        2013      17030\n##  5 Aaniiih Nakoda College        2014      17030\n##  6 Aaniiih Nakoda College        2015      17030\n##  7 Aaniiih Nakoda College        2016      17030\n##  8 Aaniiih Nakoda College        2017      17030\n##  9 Aaniiih Nakoda College        2018      17030\n## 10 Abilene Christian University  2011      38250\n## # ... with 30,056 more rows\ncustos <- custos %>% \n  arrange(name, year) %>% \n  mutate(\n    var_price = mean_price - lag(mean_price)\n  ) %>% \n  ungroup()\n\ncustos## # A tibble: 30,066 x 4\n##    name                          year mean_price var_price\n##    <chr>                        <dbl>      <dbl>     <dbl>\n##  1 Aaniiih Nakoda College        2010      17030        NA\n##  2 Aaniiih Nakoda College        2011      17030         0\n##  3 Aaniiih Nakoda College        2012      17030         0\n##  4 Aaniiih Nakoda College        2013      17030         0\n##  5 Aaniiih Nakoda College        2014      17030         0\n##  6 Aaniiih Nakoda College        2015      17030         0\n##  7 Aaniiih Nakoda College        2016      17030         0\n##  8 Aaniiih Nakoda College        2017      17030         0\n##  9 Aaniiih Nakoda College        2018      17030         0\n## 10 Abilene Christian University  2011      38250        NA\n## # ... with 30,056 more rows\ncustos %>% \n  arrange(desc(var_price)) %>% \n  head(n = 10)## # A tibble: 10 x 4\n##    name                                           year mean_price var_price\n##    <chr>                                         <dbl>      <dbl>     <dbl>\n##  1 Los Medanos College                            2012    114083     95944 \n##  2 Webb Institute                                 2013     61820     43300 \n##  3 Jewish Theological Seminary of America         2016     75590     34140 \n##  4 Santa Barbara Business College-Ventura         2018     57535     31207 \n##  5 Rosedale Technical College                     2011     52240     21883 \n##  6 Michigan Career and Technical Institute        2011     28462.    19388.\n##  7 Hawaii Medical College                         2013     35918     18951 \n##  8 St Paul's School of Nursing-Queens             2016     56189     18065 \n##  9 Phillips School of Nursing at Mount Sinai Be~  2017     62850     17920 \n## 10 Trinity International University-Florida       2017     30468     17718\nlos_medanos <- custos %>% \n  filter(name == \"Los Medanos College\", !is.na(var_price)) \n\nlos_medanos## # A tibble: 8 x 4\n##   name                 year mean_price var_price\n##   <chr>               <dbl>      <dbl>     <dbl>\n## 1 Los Medanos College  2011      18139       427\n## 2 Los Medanos College  2012     114083     95944\n## 3 Los Medanos College  2013      19006    -95077\n## 4 Los Medanos College  2014      18686      -320\n## 5 Los Medanos College  2015      19200       514\n## 6 Los Medanos College  2016      19750       550\n## 7 Los Medanos College  2017      20700       950\n## 8 Los Medanos College  2018      21260       560\nnudge <- if_else(los_medanos$var_price > 0, 7000, -7000)\n\nlos_medanos %>% \n  ggplot(\n    aes(x = year, y = var_price)\n  ) +\n  geom_col(\n    fill = \"#0f5099\"\n  ) +\n  geom_text(\n    aes(label = round(var_price, 0)),\n    nudge_y = nudge\n  ) +\n  scale_y_continuous(\n    labels = function(x){\n      format(x, digits = 0, big.mark = \".\")\n    }\n  ) +\n  labs(\n    x = \"Ano\",\n    y = \"Variação de preço\"\n  )\ndados <- starwars %>% select(1:11)\nname_n <- length(unique(dados$name))\nhair_color_n <- length(unique(dados$hair_color))\nskin_color_n <- length(unique(dados$skin_color))\n    .\n    .\n    .\nspecies_n <- length(unique(dados$species))\ncolunas <- c(\"name\", \"hair_color\", \"skin_color\", \"eye_color\",\n             \"sex\", \"gender\", \"homeworld\", \"species\")\n\ncontagens <- dados %>% \n  summarise(\n    across(all_of(colunas), n_distinct)\n  )\n\ncontagens## # A tibble: 1 x 8\n##    name hair_color skin_color eye_color   sex gender homeworld species\n##   <int>      <int>      <int>     <int> <int>  <int>     <int>   <int>\n## 1    87         13         31        15     5      3        49      38\ncontagens %>% \n  unlist() %>% \n  sort(decreasing = TRUE)##       name  homeworld    species skin_color  eye_color hair_color \n##         87         49         38         31         15         13 \n##        sex     gender \n##          5          3\n## Opção 1:\ntransf %>% \n  filter(Usuario == \"Eduardo\") %>% \n  summarise(media = mean(Valor))## # A tibble: 1 x 1\n##   media\n##   <dbl>\n## 1 3462.\n## Opção 2:\ntransf %>% \n  group_by(Usuario) %>% \n  summarise(media = mean(Valor)) %>% \n  filter(Usuario == \"Eduardo\")## # A tibble: 1 x 2\n##   Usuario media\n##   <chr>   <dbl>\n## 1 Eduardo 3462.\ntransf %>% \n  filter(Usuario == \"Ana\") %>% \n  count(Pais) %>% \n  arrange(n) %>% \n  tail(n = 1)## # A tibble: 1 x 2\n##   Pais        n\n##   <chr>   <int>\n## 1 Equador   302\ntransf %>% \n  group_by(Usuario) %>% \n  summarise(across(.fns = last, order_by = Data))## # A tibble: 8 x 8\n##   Usuario  Data                 Valor TransferID Pais   hora minuto segundo\n##   <chr>    <dttm>               <dbl>      <dbl> <chr> <int>  <int>   <dbl>\n## 1 Ana      2018-12-23 22:06:50 16169.  115756250 Alem~    22      6      50\n## 2 Armando  2018-12-23 18:54:36 17630.  114268959 Alem~    18     54      36\n## 3 Eduardo  2018-12-23 23:49:44 16983.  115188827 Alem~    23     49      44\n## 4 Júlio    2018-12-23 13:29:04 15614.  114836120 Alem~    13     29       4\n## 5 Júlio C~ 2018-12-23 20:17:38 16601.  115054244 Alem~    20     17      38\n## 6 nathalia 2018-12-23 17:48:23 15256.  115476749 Alem~    17     48      23\n## 7 Nathália 2018-12-23 21:12:50 17621.  114970801 Alem~    21     12      50\n## 8 Sandra   2018-12-23 17:59:44 16081.  114979909 Alem~    17     59      44\ntransf %>% \n  group_by(Usuario) %>% \n  slice_max(order_by = Data)## # A tibble: 8 x 8\n## # Groups:   Usuario [8]\n##   Data                Usuario   Valor TransferID Pais   hora minuto segundo\n##   <dttm>              <chr>     <dbl>      <dbl> <chr> <int>  <int>   <dbl>\n## 1 2018-12-23 22:06:50 Ana      16169.  115756250 Alem~    22      6      50\n## 2 2018-12-23 18:54:36 Armando  17630.  114268959 Alem~    18     54      36\n## 3 2018-12-23 23:49:44 Eduardo  16983.  115188827 Alem~    23     49      44\n## 4 2018-12-23 13:29:04 Júlio    15614.  114836120 Alem~    13     29       4\n## 5 2018-12-23 20:17:38 Júlio C~ 16601.  115054244 Alem~    20     17      38\n## 6 2018-12-23 17:48:23 nathalia 15256.  115476749 Alem~    17     48      23\n## 7 2018-12-23 21:12:50 Nathália 17621.  114970801 Alem~    21     12      50\n## 8 2018-12-23 17:59:44 Sandra   16081.  114979909 Alem~    17     59      44"},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-6---introdução-a-base-de-dados-relacionais-no-r","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 6 - Introdução a base de dados relacionais no R","text":"6.1) Primeiro de tudo, precisamos identificar quais são informações que nós precisamos para calcular o indicador requisitado na questão. Queremos estimar o tempo de trabalho necessário (após graduação) para cobrir os custos totais curso de graduação em cada universidade. Portanto, precisamos saber qual o custo total curso em cada universidade, além salário estimado dos profissionais que formam nessa respectiva universidade.Por morarmos Brasil, universidades americanas nos cobrariam o preço de um estudante não residente estado de sua sede (state). O custo total para esse tipo de aluno está na coluna out_of_state_total da tabela tuition_cost. Já o salário potencial de um aluno que acaba de se formar, é descrito na coluna early_career_pay da tabela salary_potential.Porém, como os custos descritos na tabela tuition_cost são anuais, precisamos multiplicar esses custos pelo número de anos presentes na coluna degree_length. Para extrairmos o número de cada string da coluna degree_length, podemos utilizar função parse_number() pacote readr. Em seguida, utilizo função colnames() sobre duas primeiras colunas da tabela, com o objetivo de traduzir os nomes dessas colunas em uma linguagem mais acessível.Como precisamos apenas das colunas early_career_pay e name da tabela salary_potential, eu aplico um select() sobre tabela. Além disso, eu também renomeio colunas (para nomes mais fáceis de se interpretar) dessa tabela.Com essas informações em mãos, podemos utilizar função inner_join() para unir duas tabelas criadas (salario e custo) em uma só. Em seguida, precisamos apenas dividir o custo total curso pela renda esperada para adquirir uma estimativa dos anos de trabalho necessários para repor o investimento aplicado curso. Como você pode ver abaixo, um aluno formado na Adams State University levaria em torno de 2,63 anos (isto é, \\(2,63 \\times 365 \\approx 960\\) dias) de trabalho para recompor os valores dispendidos em sua graduação.6.2.) Na tabela consumidores, temos colunas Id_consumidor e Id_vendedor que representam keys nessa tabela. Já na tabela vendedores, temos apenas coluna Id_vendedor como key.6.2.B) Lembre-se que, uma primary key é uma variável capaz de identificar unicamente cada observação presente em sua tabela. Logo, podemos perceber que coluna Id_consumidor é primary key da tabela consumidores. Pois cada observação da tabela, possui um valor diferente na coluna Id_consumidor. Já uma foreign key é uma coluna que não é capaz de identificar unicamente cada uma das observações de uma tabela. Com isso, podemos chegar à conclusão de que coluna Id_vendedor é foreign key da tabela consumidores.Entenda que colunas que representam keys de uma tabela, podem mudar de acordo com o contexto. princípio, colunas Id_consumidor e Id_vendedor são keys, pelo simples fato de que elas identificam o objeto foco que está sendo descrito nas tabelas consumidores e vendedores. Em outras palavras, tabela consumidores apresenta um conjunto de dados sobre consumidores e, coluna Id_consumidor identifica unicamente esses consumidores.partir momento em que meu foco de atenção muda, eu posso estar preocupado em identificar unidades, pessoas, grupos, empresas e características diferentes. Por exemplo, se eu estou mais interessado nas cidades onde o atendimento foi realizado, é provável que coluna Cidade_atendimento seja uma key mais importante que colunas Id_vendedor e Id_consumidor.6.2.C) Após importarmos tabelas para o R, precisamos aplicar um join entre elas, para que possamos relacionar cidades de atendimento (Cidade_atendimento) aos respectivos vendedores (Nome_vendedor). Em seguida, podemos aplicar dois count()’s seguidos para chegarmos ao resultado desejado.6.3) Esse comando de join não funciona, pelo fato de que tabelas filmes e filmes_receita não possuem colunas de nomes congruentes. Ou seja, função left_join() procura por colunas de mesmo nome entre tabelas filmes e filmes_receita, para utilizar como key processo de join. Porém, ao não uma coluna de nome correspondente, o join acaba falhando.Para corrigirmos esse problema, podemos: 1) renomear uma das colunas que representa key join, de modo que os seus nomes fiquem iguais; ou 2) dizer explicitamente à left_join(), quais são colunas equivalente entre essas tabelas, através argumento da função. Temos capacidade de realizar segunda opção de uma maneira bem direta, como demonstrado abaixo:Por outro lado, primeira opção envolve o uso da função colnames() para renomear coluna desejada. Após esse passo, função left_join() volta funcionar normalmente.","code":"\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/rfordatascience/\"\npasta <- \"tidytuesday/master/data/2020/2020-03-10/\"\ncost <- \"tuition_cost.csv\"\nsalary <- \"salary_potential.csv\"\n\ntuition_cost <- read_csv(paste0(github, pasta, cost))## \n## -- Column specification ---------------------------------------------------\n## cols(\n##   name = col_character(),\n##   state = col_character(),\n##   state_code = col_character(),\n##   type = col_character(),\n##   degree_length = col_character(),\n##   room_and_board = col_double(),\n##   in_state_tuition = col_double(),\n##   in_state_total = col_double(),\n##   out_of_state_tuition = col_double(),\n##   out_of_state_total = col_double()\n## )\nsalary_potential <- read_csv(paste0(github, pasta, salary))## \n## -- Column specification ---------------------------------------------------\n## cols(\n##   rank = col_double(),\n##   name = col_character(),\n##   state_name = col_character(),\n##   early_career_pay = col_double(),\n##   mid_career_pay = col_double(),\n##   make_world_better_percent = col_double(),\n##   stem_percent = col_double()\n## )\ncusto <- tuition_cost %>% \n  select(name, degree_length, out_of_state_total) %>% \n  mutate(\n    anos = readr::parse_number(degree_length),\n    custo_total = anos * out_of_state_total\n  ) %>% \n  select(-degree_length)## Warning: 1 parsing failure.\n##  row col expected actual\n## 2632  -- a number  Other\ncolnames(custo)[1:2] <- c(\n  \"nome_universidade\", \"custo_anual\"\n)\n\ncusto## # A tibble: 2,973 x 4\n##    nome_universidade                    custo_anual  anos custo_total\n##    <chr>                                      <dbl> <dbl>       <dbl>\n##  1 Aaniiih Nakoda College                      2380     2        4760\n##  2 Abilene Christian University               45200     4      180800\n##  3 Abraham Baldwin Agricultural College       21024     2       42048\n##  4 Academy College                            17661     2       35322\n##  5 Academy of Art University                  44458     4      177832\n##  6 Adams State University                     29238     4      116952\n##  7 Adelphi University                         54690     4      218760\n##  8 Adirondack Community College               21595     2       43190\n##  9 Adrian College                             48405     4      193620\n## 10 Advanced Technology Institute              13680     2       27360\n## # ... with 2,963 more rows\nsalario <- salary_potential %>%\n  select(name, early_career_pay)\n\ncolnames(salario) <- c(\n  \"nome_universidade\", \"salario_inicio_carreira\"\n)\ncusto %>% \n  inner_join(\n    salario,\n    by = \"nome_universidade\"\n  ) %>% \n  mutate(\n    anos_necessarios = custo_total / salario_inicio_carreira\n  )## # A tibble: 728 x 6\n##    nome_universidade        custo_anual  anos custo_total salario_inicio_c~\n##    <chr>                          <dbl> <dbl>       <dbl>             <dbl>\n##  1 Adams State University         29238     4      116952             44400\n##  2 Adventist University of~       19350     4       77400             51600\n##  3 Agnes Scott College            53490     4      213960             46000\n##  4 Alabama State University       24818     4       99272             39800\n##  5 Alaska Pacific Universi~       28130     4      112520             50300\n##  6 Albany College of Pharm~       46025     4      184100             81000\n##  7 Albertus Magnus College        45260     4      181040             49700\n##  8 Albion College                 58155     4      232620             52100\n##  9 Alcorn State University        16752     4       67008             40900\n## 10 Allen College                  27252     4      109008             51600\n## # ... with 718 more rows, and 1 more variable: anos_necessarios <dbl>\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo1 <- \"consumidor.csv\"\narquivo2 <- \"vendedores.csv\"\n\nconsumidores <- read_csv2(paste0(github, pasta, arquivo1))\nvendedores <- read_csv2(paste0(github, pasta, arquivo2))\n### Resposta:\nconsumidores %>% \n  inner_join(vendedores) %>% \n  count(Nome_vendedor, Cidade_atendimento) %>% \n  count(Nome_vendedor)## Joining, by = \"Id_vendedor\"## # A tibble: 6 x 2\n##   Nome_vendedor           n\n##   <chr>               <int>\n## 1 Jaiminho da Cerveja     1\n## 2 Laura Lima              2\n## 3 Miguel Anabiguel        1\n## 4 Natália Vista           2\n## 5 Pablo Osmar             2\n## 6 Paulo Morato            2\nfilmes %>% \n  left_join(\n    filmes_receita,\n    by = c(\"FilmeId\" = \"Movie_id\")\n  )## # A tibble: 14 x 8\n##    FilmeId Titulo          Diretor       Ano DuracaoMinutos Nota_do_publico\n##      <dbl> <chr>           <chr>       <dbl>          <dbl>           <dbl>\n##  1       1 Toy Story       John Lasse~  1995             81              83\n##  2       2 A Bug's Life    John Lasse~  1998             95              72\n##  3       3 Toy Story 2     John Lasse~  1999             93              79\n##  4       4 Monsters, Inc.  Pete Docter  2001             92              81\n##  5       5 Finding Nemo    Andrew Sta~  2003            107              82\n##  6       6 The Incredibles Brad Bird    2004            116               8\n##  7       7 Cars            John Lasse~  2006            117              72\n##  8       8 Ratatouille     Brad Bird    2007            115               8\n##  9       9 WALL-E          Andrew Sta~  2008            104              85\n## 10      10 Up              Pete Docter  2009            101              83\n## 11      11 Toy Story 3     Lee Unkrich  2010            103              84\n## 12      12 Cars 2          John Lasse~  2011            120              64\n## 13      13 Brave           Brenda Cha~  2012            102              72\n## 14      14 Monsters Unive~ Dan Scanlon  2013            110              74\n## # ... with 2 more variables: Receita_interna <dbl>,\n## #   Receita_internacional <dbl>\ncolnames(filmes_receita)[1] <- \"FilmeId\"\n\nfilmes %>% \n  left_join(\n    filmes_receita\n  )## Joining, by = \"FilmeId\"## # A tibble: 14 x 8\n##    FilmeId Titulo          Diretor       Ano DuracaoMinutos Nota_do_publico\n##      <dbl> <chr>           <chr>       <dbl>          <dbl>           <dbl>\n##  1       1 Toy Story       John Lasse~  1995             81              83\n##  2       2 A Bug's Life    John Lasse~  1998             95              72\n##  3       3 Toy Story 2     John Lasse~  1999             93              79\n##  4       4 Monsters, Inc.  Pete Docter  2001             92              81\n##  5       5 Finding Nemo    Andrew Sta~  2003            107              82\n##  6       6 The Incredibles Brad Bird    2004            116               8\n##  7       7 Cars            John Lasse~  2006            117              72\n##  8       8 Ratatouille     Brad Bird    2007            115               8\n##  9       9 WALL-E          Andrew Sta~  2008            104              85\n## 10      10 Up              Pete Docter  2009            101              83\n## 11      11 Toy Story 3     Lee Unkrich  2010            103              84\n## 12      12 Cars 2          John Lasse~  2011            120              64\n## 13      13 Brave           Brenda Cha~  2012            102              72\n## 14      14 Monsters Unive~ Dan Scanlon  2013            110              74\n## # ... with 2 more variables: Receita_interna <dbl>,\n## #   Receita_internacional <dbl>"},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-7---tidy-data-uma-abordagem-para-organizar-os-seus-dados","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 7 - Tidy Data: uma abordagem para organizar os seus dados","text":"7.1.) Primeiro, comece sempre identificando unidade básica que está sendo tratada na tabela. Como foi definido enunciado, tabela world_bank_pop lhe apresenta série histórica de diversos indicadores populacionais de diferentes países. Com isso, podemos chegar à conclusão de que unidade básica dessa tabela são os países tratados nessa tabela.Caso houvesse um único indicador nessa tabela, como por exemplo, crescimento anual da população, poderíamos dizer que unidade básica da tabela seria o crescimento anual da população de cada país. Mas como há pelo menos 4 indicadores para cada país, e cada um deles apresenta uma característica diferente da população desse país, não podemos considerar todos eles como parte da unidade básica da tabela.Como você pode ver abaixo, temos 264 países diferentes ao longo da base, logo, se é de nosso desejo respeitar o pressuposto de que “cada observação deve possuir sua própria linha,” tabela world_bank_pop deve acomodar 264 linhas. Pelo fato dessa tabela possuir 1056 linhas, sabemos que esse pressuposto é violado pela tabela.Além disso, temos capacidade de rapidamente identificar que o pressuposto de que “cada variável deve possuir sua própria coluna” também é violado pelo formato da tabela. Pois os diferentes anos da série histórica de cada indicador estão espalhados ao longo de várias colunas, sendo que, esses anos deveriam estar concentrados em uma única coluna, assim como os valores de cada série histórica em si.7.1.B) Com resposta item anterior, podemos chegar aos seguintes passos serem realizados, com o objetivo de transportar tabela world_bank_pop para o formato tidy: 1) trazer os diversos anos para uma única coluna e, o mesmo deve ser feito para os valores de cada série histórica; 2) separar uma coluna diferente para cada um dos indicadores da coluna indicator. Podemos realizar esses passos com funções pivot_longer() e pivot_wider().7.1.C) Realizar o primeiro passo descrito enunciado item é muito simples com função filter(). Porém, ainda assim, o formato qual base se encontra, torna o cálculo da variação muito trabalhoso. Porque nós teríamos que calcular variação entre cada uma das colunas anuais. Como temos 18 anos diferentes em cada série histórica, precisaríamos calcular 17 variações diferentes. Isso significa que teríamos de construir 17 colunas diferentes com mutate() para chegarmos esses números.Por isso, é muito mais fácil calcularmos essa variação ao transportarmos esses anos para uma única coluna e, em seguida, subtraírmos o valor de uma linha específica valor da linha anterior, com função lag() que apresentamos Capítulo 4.","code":"\nn_indicadores <- n_distinct(world_bank_pop$indicator)\nn_indicadores## [1] 4\nn_paises <- n_distinct(world_bank_pop$country)\nn_paises## [1] 264\nnrow(world_bank_pop)## [1] 1056\ntab_tidy <- world_bank_pop %>% \n  pivot_longer(\n    cols = matches(\"[0-9]{4}\"),\n    names_to = \"ano\",\n    values_to = \"valor\"\n  ) %>% \n  pivot_wider(\n    id_cols = c(\"country\", \"ano\"),\n    names_from = \"indicator\",\n    values_from = \"valor\"\n  )\n\n\ntab_tidy## # A tibble: 4,752 x 6\n##    country ano   SP.URB.TOTL SP.URB.GROW SP.POP.TOTL SP.POP.GROW\n##    <chr>   <chr>       <dbl>       <dbl>       <dbl>       <dbl>\n##  1 ABW     2000        42444      1.18         90853      2.06  \n##  2 ABW     2001        43048      1.41         92898      2.23  \n##  3 ABW     2002        43670      1.43         94992      2.23  \n##  4 ABW     2003        44246      1.31         97017      2.11  \n##  5 ABW     2004        44669      0.951        98737      1.76  \n##  6 ABW     2005        44889      0.491       100031      1.30  \n##  7 ABW     2006        44881     -0.0178      100832      0.798 \n##  8 ABW     2007        44686     -0.435       101220      0.384 \n##  9 ABW     2008        44375     -0.698       101353      0.131 \n## 10 ABW     2009        44052     -0.731       101453      0.0986\n## # ... with 4,742 more rows\npop_total <- world_bank_pop %>% \n  filter(\n    indicator == \"SP.POP.TOTL\"\n  )\n\npop_total## # A tibble: 264 x 20\n##    country indicator   `2000`  `2001`  `2002`  `2003`  `2004` `2005` `2006`\n##    <chr>   <chr>        <dbl>   <dbl>   <dbl>   <dbl>   <dbl>  <dbl>  <dbl>\n##  1 ABW     SP.POP.TO~  9.09e4  9.29e4  9.50e4  9.70e4  9.87e4 1.00e5 1.01e5\n##  2 AFG     SP.POP.TO~  2.01e7  2.10e7  2.20e7  2.31e7  2.41e7 2.51e7 2.59e7\n##  3 AGO     SP.POP.TO~  1.64e7  1.70e7  1.76e7  1.82e7  1.89e7 1.96e7 2.03e7\n##  4 ALB     SP.POP.TO~  3.09e6  3.06e6  3.05e6  3.04e6  3.03e6 3.01e6 2.99e6\n##  5 AND     SP.POP.TO~  6.54e4  6.73e4  7.00e4  7.32e4  7.62e4 7.89e4 8.10e4\n##  6 ARB     SP.POP.TO~  2.84e8  2.90e8  2.96e8  3.02e8  3.09e8 3.16e8 3.24e8\n##  7 ARE     SP.POP.TO~  3.15e6  3.33e6  3.51e6  3.74e6  4.09e6 4.58e6 5.24e6\n##  8 ARG     SP.POP.TO~  3.71e7  3.75e7  3.79e7  3.83e7  3.87e7 3.91e7 3.96e7\n##  9 ARM     SP.POP.TO~  3.07e6  3.05e6  3.03e6  3.02e6  3.00e6 2.98e6 2.96e6\n## 10 ASM     SP.POP.TO~  5.75e4  5.82e4  5.87e4  5.91e4  5.93e4 5.91e4 5.86e4\n## # ... with 254 more rows, and 11 more variables: 2007 <dbl>, 2008 <dbl>,\n## #   2009 <dbl>, 2010 <dbl>, 2011 <dbl>, 2012 <dbl>, 2013 <dbl>,\n## #   2014 <dbl>, 2015 <dbl>, 2016 <dbl>, 2017 <dbl>\npop_total <- pop_total %>% \n  pivot_longer(\n    cols = matches(\"[0-9]{4}\"),\n    names_to = \"ano\",\n    values_to = \"valor\"\n  ) %>% \n  group_by(country) %>% \n  mutate(\n    variacao = valor - lag(valor)\n  )\n\npop_total## # A tibble: 4,752 x 5\n## # Groups:   country [264]\n##    country indicator   ano    valor variacao\n##    <chr>   <chr>       <chr>  <dbl>    <dbl>\n##  1 ABW     SP.POP.TOTL 2000   90853       NA\n##  2 ABW     SP.POP.TOTL 2001   92898     2045\n##  3 ABW     SP.POP.TOTL 2002   94992     2094\n##  4 ABW     SP.POP.TOTL 2003   97017     2025\n##  5 ABW     SP.POP.TOTL 2004   98737     1720\n##  6 ABW     SP.POP.TOTL 2005  100031     1294\n##  7 ABW     SP.POP.TOTL 2006  100832      801\n##  8 ABW     SP.POP.TOTL 2007  101220      388\n##  9 ABW     SP.POP.TOTL 2008  101353      133\n## 10 ABW     SP.POP.TOTL 2009  101453      100\n## # ... with 4,742 more rows"},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-8---visualização-de-dados-com-ggplot2","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 8 - Visualização de dados com ggplot2","text":"8.1.) O erro nesse item está uso pipe para conectar os componentes gráfico ggplot. Lembre-se que, camadas de um gráfico ggplot são adicionadas umas outras, por meio operador +. Logo, basta substituírmos o pipe pelo operador + que os comandos voltam funcionar normalmente.8.1.B) O erro nesse item está uso argumento fill ao invés argumento color. Lembre-se que, para colorir geometrias criadas por geoms individuais (como pontos - geom_point() e linhas - geom_line()), utiliza-se o argumento color. Já geomtrias que são criadas por geoms coletivos (como barras - geom_bar() ou boxplots - geom_boxplot()), utiliza-se o argumento fill. Logo, ao substituírmos o argumento fill pelo color, o resultado desejado é atingido.8.1.C) Lembre-se que, se desejamos manter uma característica gráfico (cores, formatos, posição, etc.) constante ao longo de todo o gráfico, nos definimos essa característica fora da função aes(). Portanto, para atingirmos o resultado desejado, precisamos apenas retirar o termo color = \"blue\" de dentro da função aes().8.2.) Antes de tudo, é interessante armazenarmos os códigos HEX das cores que formam bandeira LGBTQ+. Pode ser em um vetor qualquer, como o vec_colors abaixo.Agora, o pacote ggplot2 nos permite desenhar essa mesma bandeira de diversas formas, mas nessa seção vou mostrar apenas 2 formas intuitivas. Provavelmente, primeira estratégia que passou pela sua cabeça é simplesmente desenhar 6 faixas empilhadas uma em cima da outra, sendo uma de cada cor presente vetor vec_colors acima.Como desejamos desejar faixas (ou linhas retas consideravelmente largas), uma opção seria utilizarmos função geom_bar() para construírmos 6 barras de mesma altura. Perceba abaixo, que em geom_bar() essas barras são posicionadas (horizontalmente) uma lado da outra. Porém, utilizo logo em seguida função coord_flip() para inverter o plano cartesiano por completo, isto é, trocar o eixo x pelo eixo y, e, trocar o eixo y pelo eixo x. Dessa forma, barras que estavam uma lado da outra, passam estar uma em cima da outra, ou, são empilhadas verticalmente. Por último, precisamos apenas colorir essas barras com cores da bandeira. Para isso, basta conectarmos o argumento fill ao vetor vec_colors e, utilizar função scale_fill_identity() para ler os códigos das cores presentes nesse vetor.Esse é certamente um método simples e eficaz de desenhar essa bandeira. Entretanto, uma outra forma de desenharmos essa bandeira, seria desenhando 6 retângulos, um sobre o outro. Podemos realizar esse processo por meio de geom_rect(). Todos os retângulos possuem mesma largura (de 10 unidades), porém, alturas se reduzem em 1 unidade (6, 5, 4, 3,…) em cada retângulo. Ou seja, o primeiro retângulo (de cor vermelha) é o maior de todos, ou, dito de outra forma, sua altura cobre todas 6 faixas da bandeira. Já o último retângulo (de cor roxa), é o menor de todos, pois sua altura cobre apenas 1 única faixa.8.2.B) Primeiro, precisamos calcular os valores de \\(y\\) medida em que \\(x\\) varia de 0 1000. Lembre-se que função é \\(y = x^2 + 15x + 32\\). Com os valores de \\(x\\) e os seus respectivos valores de \\(y\\) calculados, precisamos apenas fornecer esses vetores ao aes() de geom_line() para atingirmos o resultado esperado.8.2.C) Com os comandos abaixo, você poderia desenhar o texto “Uma anotação muito importante” em seu gráfico. Com isso, precisamos agora incrementar esses comandos com novas camadas gráfico que vão desenhar setas desejadas.função geom_segment() serve para desenhar linhas retas (ou “segmentos”) em seu gráfico. Para mais, essa função oferece um argumento arrow que permite desenhar cabeça de uma seta de forma automática em cada segmento. Portanto, preciso apenas definir coordenadas de cada seta (valores da tabela setas) e deixar que o argumento arrow desenhe cabeças de cada seta.8.3) Poderíamos responder essa pergunta de diversas formas e, utilizando diferentes tipos de gráfico. Por exemplo, uma primeira aproximação da resposta, seria empregarmos um simples gráfico de boxplot, com função geom_boxplot(). Ainda podemos empregar função reorder() sobre o variável cut, para reordenarmos o eixo x de maneira crescente segundo mediana de price. Dessa maneira, podemos observar facilmente que os diamantes que possuem corte “Ideal” são os de menor preço na média. Enquanto isso, também identificamos que os diamentes de pior corte (isto é, os de corte “Fair” ou “justo”) são, na média, os diamantes mais caros mercado.Uma alternativa, seria primeiro calcular estatísticas descritivas e, em seguida, requisitar às funções ggplot que apenas identifiquem esses valores gráfico. Tendo isso em mente, nós agrupamos base de acordo com variável cut com função group_by(), calculamos o preço médio de cada grupo com summarise() e, por último, utilizamos geom_col() para desenhar um gráfico de barras simples, onde altura de cada barra representa os preços médios calculados por summarise().","code":"\nggplot(data = mpg) +\n  geom_point(\n    aes(x = displ, y = hwy)\n  )\nggplot(data = diamonds) +\n  geom_point(\n    aes(x = carat, y = price, color = cut)\n  )\nggplot(diamonds) +\n  geom_bar(\n    aes(x = cut), fill = \"blue\"\n  )\nvec_colors <- c(\n  \"#a319ff\",\n  \"#1294ff\",\n  \"#19bf45\",\n  \"#ffdc14\",\n  \"#ff6a00\",\n  \"#ff1919\"\n)\ndados <- tibble(\n    y = 10,\n    x = 1:6\n  ) \n\ndados %>% \n  ggplot() +\n  geom_bar(\n    aes(x = x, y = y, fill = vec_colors),\n    position = \"dodge\",\n    stat = \"identity\",\n    width = 1\n  ) +\n  coord_flip() +\n  scale_fill_identity() +\n  theme_void()\ndados <- tibble(\n  colors = vec_colors[length(vec_colors):1],\n  xmin = 0, \n  xmax = 10,\n  ymin = 0,\n  ymax = 6:1\n)\n\n\ndados %>% \n  ggplot() +\n  geom_rect(\n    aes(xmin = xmin, xmax = xmax,\n        ymin = ymin, ymax = ymax,\n        fill = colors)\n  ) +\n  scale_fill_identity() +\n  theme_void()\nvalores_x <- 0:1000\nvalores_y <- (valores_x ^ 2) + (15 * valores_x) + 32\n\nggplot() +\n  geom_line(\n    aes(x = valores_x, y = valores_y)\n  )\nanotacao <- \"Uma anotação\\nmuito importante\"\n\nggplot() +\n  geom_text(\n    aes(x = 10, y = 10, label = anotacao)\n  )\nsetas <- tibble(\n  id = 1:4,\n  x = c(8, 12, 12, 8),\n  y = c(8, 8, 12, 12),\n  xend = c(9.5, 10.5, 10.5, 9.5),\n  yend = c(9.5, 9.5, 10.5, 10.5)\n)\n\nggplot() +\n  geom_text(\n    aes(x = 10, y = 10, label = anotacao)\n  ) +\n  geom_segment(\n    aes(x = x, y = y, xend = xend, yend = yend,\n        group = id),\n    data = setas,\n    ### Ao definirmos o argumento arrow\n    ### com a função arrow(),\n    ### podemos adicionar a cabeça da\n    ### seta de forma fácil e automática\n    arrow = arrow()\n  )\ndiamonds %>% \n  ggplot() +\n  geom_boxplot(\n    aes(\n      x = reorder(cut, price, FUN = median),\n      y = price\n    )\n  )\nestatisticas <- diamonds %>% \n  group_by(cut) %>% \n  summarise(\n    media = mean(price, na.rm = TRUE)\n  )\n\nestatisticas %>% \n  ggplot() +\n  geom_col(\n    aes(\n      x = reorder(cut, media),\n      y = media\n    )\n  )"},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-9---configurando-componentes-estéticos-do-gráfico-no-ggplot2","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 9 - Configurando componentes estéticos do gráfico no ggplot2","text":"9.1.) Primeiro, podemos colorir o plano de fundo gráfico e grid da seguinte maneira:Segundo, seria ideal colorirmos todos os textos gráfico de branco, além de alterarmos fonte e o estilo empregados sobre o título gráfico, como demonstrado abaixo.Por último, podemos adicionar alterações necessárias sobre legenda gráfico, por meio dos seguintes comandos:9.2.) Lembre-se que para eliminarmos legenda de um gráfico, basta configurar o argumento legend.position para \"none\".9.2.B) O erro ocorre, devido ao fato de que estamos empregando função element_*() errada elemento panel.grid. Lembre-se que o elemento panel.grid diz respeito às linhas grid, logo, para alterar esse elemento deve-se utilizar função element_line(), ao invés de element_rect().9.2.C) Para isso, precisamos definir o argumento color da função element_rect() argumento panel.background de theme().","code":"\ntema <-   theme(\n  plot.background = element_rect(fill = \"#1a232e\"),\n  panel.background = element_rect(\n    fill = \"#1a232e\", color = \"#171717\", size = 2\n  ),\n  panel.grid = element_line(color = \"#666666\")\n)\n\nplot_exemplo + tema## Warning: Removed 2 rows containing missing values (geom_point).\ntema <-   theme(\n  plot.background = element_rect(fill = \"#1a232e\"),\n  panel.background = element_rect(\n    fill = \"#1a232e\", color = \"#171717\", size = 2\n  ),\n  panel.grid = element_line(color = \"#666666\"),\n  text = element_text(color = \"white\"),\n  axis.text = element_text(color = \"white\"),\n  plot.title = element_text(\n    family = \"serif\", size = 15,\n    face = \"bold.italic\"\n  )\n)\n\nplot_exemplo + tema## Warning: Removed 2 rows containing missing values (geom_point).\ntema <- theme(\n  plot.background = element_rect(fill = \"#1a232e\"),\n  panel.background = element_rect(\n    fill = \"#1a232e\", color = \"#171717\", size = 2\n  ),\n  panel.grid = element_line(color = \"#666666\"),\n  text = element_text(color = \"white\"),\n  axis.text = element_text(color = \"white\"),\n  plot.title = element_text(\n    family = \"serif\", size = 15,\n    face = \"bold.italic\"\n  ),\n  legend.position = \"bottom\",\n  legend.title = element_text(\n    family = \"serif\", face = \"bold.italic\"\n  ),\n  legend.background = element_rect(fill = \"#1a232e\"),\n  legend.key = element_rect(\n    fill = \"#1a232e\", color = \"#171717\", size = 1.5\n  )\n)\n\n\nplot_exemplo + tema## Warning: Removed 2 rows containing missing values (geom_point).\nplot_exemplo +\n  theme(legend.position = \"none\")## Warning: Removed 2 rows containing missing values (geom_point).\nplot_exemplo +\n  theme(\n    text = element_text(color = \"#6E1450\"),\n    panel.grid = element_line(color = \"#6E1450\")\n  )## Warning: Removed 2 rows containing missing values (geom_point).\nplot_exemplo +\n  theme(panel.background = element_rect(color = \"#222222\"))## Warning: Removed 2 rows containing missing values (geom_point)."},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-10---manipulação-e-transformação-de-strings-com-stringr","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 10 - Manipulação e transformação de strings com stringr","text":"10.1.) Tal sequência de caracteres pode ser representada pela expressão regular \"[bc]al\", ou ainda, pela expressão \"bal|cal\". Ambas expressões atingem o mesmo resultado:10.1.B) Perceba que, pelo que foi requisitado enunciado item, o primeiro caractere da expressão regular pode ser qualquer um (exceto letra “”). Logo, podemos começar expressão regular pela classe de caracteres negativa \"[^]\", que lista o caractere não permitido nessa primeira posição. Em seguida, precisamos apenas incluir letra “c,” além metacharacter $ que representa o final string.10.1.C) primeira sequência citada (“s-p--c-e”) é bem específica e, por isso, talvez seja mais fácil utilizarmos um metacharacter de alternação | para separa essa sequência como um caso especial. outro lado metacharacter | podemos expressão \"ess$\", ou ainda, expressão \"e(s{2})$\", ambas são expressões equivalentes.10.1.D) Muitas pessoas ao verem uma questão como essa, tendem rapidamente para expressão \"...\", ou de outra maneira, \".{3}\", que representa mesma coisa. Pois essa expressão significa “um caractere qualquer, imediatamente seguido por um outro caractere qualquer, que por sua vez, é seguido por um outro caractere qualquer.” Bem, porque não testamos essa expressão. Como podemos ver pelo resultado abaixo, essa expressão acaba nos retornando praticamente todo o vetor words de volta.O que está acontecendo? Em momentos como esse, é importante que você compreenda bem o que sua expressão regular significa. Lembre-se sempre de ler ou interpretar sua expressão como “descrição de uma sequência específica de caracteres,” e não como uma palavra ou frase específicas.expressão \"...\" significa “um caractere qualquer, imediatamente seguido por um outro caractere qualquer, que por sua vez, é seguido por um outro caractere qualquer.” Logo, em resumo, essa expressão está procurando por um sequência de 3 caracteres quaisquer. Com isso em mente, podemos chegar à conclusão de que quase todo o vetor words é retornado por essa expressão, pelo fato de que quase todas palavras desse vetor contém pelo menos 3 caracteres.Em outras palavras, expressão \"...\" não possui qualquer noção de limite, ou quantidade exata ser procurada. Essa expressão vai procurar por uma sequência de três letras quaisquer, independente de onde ela ocorra, seja em uma palavra que possui exatos 3 caracteres, ou em uma palavra que possui 10 caracteres. Como maior parte das palavras vetor words possuem 3 ou mais letras, quase todas palavras desse vetor contém uma sequência de 3 letras quaisquer em algum lugar dentro de si.Portanto, precisamos adicionar “limites” à expressão \"...\" para que ela possa procurar pelas palavras que desejamos encontrar. Uma opção de limite apropriada, seria o uso de metacharacters tipo âncora ($ e ^), formando assim, expressão \"^...$\". Dessa forma, estaríamos procurando pela seguinte sequência de caracteres: “o início texto, imediatamente seguido por três caracteres quaisquer, que por sua vez, são imediatamente seguidos pelo fim desse mesmo texto.”10.2.) Há alguns métodos diferentes que você pode utilizar para resolver essa questão. Em algum ponto, essa solução vai envolver o uso de expressões regulares. Nessa resposta, vamos apresentar o método que envolve o uso de uma única expressão regular, capaz de descrever toda sequência de caracteres presente em cada string vetor compras.ideia básica desse método, é utilizar uma expressão regular que possa descrever cada uma das seções dos strings, e com ajuda da função str_replace(), inserir um caractere especial entre cada uma dessas seções, criando assim uma espécie de arquivo CSV, onde cada variável está agora separada por um delimitador. Dessa forma, podemos fornecer esse resultado à função read_csv(), que fara todo o trabalho de separar essas seções em diferentes colunas de um data.frame por nós.Vamos começar pelos nomes dos consumidores. Uma expressão capaz de descrever essa seção é \"[-zA-ZÁÉÍÓÚáéíóú]+\". Uma outra alternativa seria expressão \"([:lower:]|[:upper:])+\". Com essas duas expressões somos capazes de encontrar nomes sem acentos (e.g. “Luiz”), assim como os nomes que contém acento (e.g. “Bárbara”) em alguma letra (seja ela maiúscula ou minúscula).parte que apresenta o CPF consumidor é uma das mais fáceis dessa string, pois todo brasileiro que já precisou assinar algum contrato, ou comprar um produto pela internet, ou adquirir um documento pessoal, como sua CNH (carteira de habilitação), conhece muito bem estrutura tradicional de um CPF brasileiro. Em resumo, CPF’s costumam seguir estrutura 123.456.789-00. Com isso, podemos chegar à expressão \"[0-9]{3}[.][0-9]{3}[.][0-9]{3}[-][0-9]{2}\" como uma boa candidata para descrever essa seção.Em seguida, temos seção que guarda o código de identificação da venda. Essa é uma das partes que mais contribuem para complexidade da estrutura desses string como um todo. Principalmente pelo fato de que esses códigos variam em comprimento, podendo conter de 16 24 caracteres diferentes. Porém, ao sabermos todos os caracteres possíveis de aparecer nesses códigos, fica muito mais fácil de descrevermos essa seção. Com lista de caracteres apresentada na figura 10.8, podemos chegar à expressão \"[-zA-Z0-9!#$*&]{16,24}\" como uma possível candidata.Prosseguindo, temos seção que guarda o código de identificação produto. Essa seção é mais fácil de todas, pois todos os códigos possuem 4 dígitos de comprimento. Tendo isso em mente, uma expressão simples como \"[0-9]{4}\" já resolve o nosso problema.Após essa parte, temos o valor unitário produto. O único detalhe que devemos estar atentos essa seção, é que parte decimal valor sempre contém dois dígitos (preços não costumam ter 3 dígitos ou mais de centavos), mas parte inteira valor pode variar entre 1 e 3 dígitos (ou até mais, pois os preços dos produtos podem variar com o tempo e, como resultado, atingir o 4° dígito). Logo, podemos utilizar expressão \"[0-9]+[.][0-9]{2}\" para descrever essa seção em específico.sexta parte dos strings contém datas e horários, os quais formam uma informação também muito familiar várias pessoas. Lembre-se que Brasil, datas e horários geralmente seguem estrutura “Dia/Mês/Ano Hora:Minuto:Segundo.” caso específico de compras, essas datas e horários vem acompanhados de uma descrição fuso horário empregado. Essa descrição é igual “-03” em todas strings de compras. Com essas informações, você pode identificar expressão \"[0-9]{2}/[0-9]{2}/[0-9]{4} [0-9]{2}:[0-9]{2}:[0-9]{2} -03\" como uma candidata possível.Todavia, por algum motivo, os dia abaixo de 10 (ou seja, dias 1, 2, 3, 4, 5, etc.) estão desacompanhados zero inicial. Ou seja, uma data que deveria estar escrita como “04/05/2020” está na verdade escrita na forma “4/05/2020.” Portanto, uma alternativa para corrigir esse problema é incluir o metacharacter da dúvida (?) zero, formando assim expressão \"[0-9]?[0-9]/[0-9]{2}/[0-9]{4} [0-9]{2}:[0-9]{2}:[0-9]{2} -03\". Dessa forma, estamos definindo indiretamente que o dia pode ter 1 ou 2 caracteres, pois o primeiro caractere nessa região é opcional.Caso você queira ser mais estrito, ou, mais preciso respeito das datas, você poderia utilizar expressão \"(3[0-1]|[0-2][0-9])/(0[1-9]|1[1-2])/2[0-9]{3}\". O mesmo poderia ser feito com o horário, o qual seria melhor representado por uma expressão como \"(0[0-9]|1[0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])\". Entranto, se tratando dos strings contidos vetor compras, nós não precisamos ser tão específicos assim.Por último, temos uma seção que armazena quantidade produto adquirida pelo consumidor. Essa parte também é bem simples de ser descrita, especialmente se levarmos em conta que sequência \" unidades\" é constante ao longo de todo o vetor compras. Para mais, quantidade adquirida pode variar entre 1 e 2 dígitos. Desse modo, podemos chegar à expressão \"[0-9]{1,2} unidades\" para descrever tal seção.Com todos os fragmentos de expressões regulares em mãos, podemos começar unir essas peças, com o objetivo de formarmos uma única grande expressão regular capaz de descrever toda sequência de caracteres presentes em cada string vetor compras. Neste processo, é fundamental contornar cada fragmento da expressão regular por um par de parênteses. Pois assim, temos acesso ao mecanismo de backreferencing em cada seção string.Com expressão completa formada, podemos adicionar pontos e vírgulas entre cada seção, com o uso de backreferencing na função str_replace(), como demonstrado abaixo. Após essa modificação, basta fornecermos o texto resultante qualquer função que seja capaz de ler um arquivo CSV que utiliza o caractere ; como separador. Nesse caso, eu utilizo função read_csv2(), qual introduzimos capítulo 3 deste livro.10.2.B) Para extrairmos parte que contém data e horário da compra, nós podemos utilizar mesma expressão regular que empregamos na resposta item anterior. Dessa maneira, podemos usar função str_extract() para extrair de cada string vetor compras, todo o pedaço de texto encontrado por essa expressão regular. Em seguida, podemos utilizar função str_sub() para extrair os dois primeiros caracteres (que correspondem à parte dia em cada data) de cada texto resultante de str_extract().Agora, precisamos apenas fazer um cálculo de frequência sobre os valores presentes vetor dias. Para realizar cálculos desse tipo, estivemos utilizando bastante função count() ao longo desse livro. Porém, essa função trabalha com data.frame’s, ao invés de vetores. Por isso, neste caso específico, eu substituo função count() pela função table() que é uma alternativa mais adequada para vetores. Perceba pelo resultado abaixo, que, aparentemente, o dia 26 é o dia mês em que ocorre o maior número de vendas na loja.10.2.C) O problema principal nessa questão é o fato CPF estar incluso após o nome consumidor, o qual varia radicalmente em seu número de caracteres. Em outras palavras, seria muito simples extrairmos os 3 primeiros dígitos CPF, caso ele fosse antecedido por um número fixo de caracteres, com o uso da função str_sub().Entretanto, devido ao número variável de caracteres que podem anteceder o CPF consumidor, nós precisamos utilizar um outro método. Uma alternativa tão simples quanto primeira, é utilizar função str_extract() com expressão regular \"[0-9]{3}\".Nesse momento você pode estar confuso, pois expressão \"[0-9]{3}\" é muito geral, essa expressão representa uma sequência de três dígitos quaisquer e, há diversos locais ao longo de cada string que poderiam ser representados por tal expressão. Em outras palavras, porque expressão \"[0-9]{3}\" extrai especificamente os 3 primeiros dígitos CPF? Sendo que ela poderia extrair os 3 primeiros dígitos código de identificação produto? Ou parte ano presente na data e horário da compra?resposta para essas perguntas se baseia princípio de que pesquisas por expressões regulares ocorrem da esquerda para direita em um string . Portanto, expressão \"[0-9]{3}\" é capaz de extrair os 3 primeiros dígitos de cada CPF, pelo simples fato de que o CPF é o primeiro campo numérico aparecer string, antes código de identificação produto, e antes da data e horário da compra.","code":"\nindex <- str_which(\n  words,\n  \"[bc]al\"\n)\n\nwords[index]## [1] \"balance\" \"ball\"    \"call\"    \"local\"\nstr_subset(\n  words,\n  \"[^a]c$\"\n)## [1] \"electric\" \"music\"    \"politic\"  \"public\"   \"specific\" \"traffic\"\nstr_subset(\n  words,\n  \"space|e(s{2})$\"\n)##  [1] \"address\"  \"business\" \"dress\"    \"express\"  \"guess\"    \"less\"    \n##  [7] \"press\"    \"process\"  \"space\"    \"unless\"\nstr_subset(\n  words,\n  \"space|ess$\"\n)##  [1] \"address\"  \"business\" \"dress\"    \"express\"  \"guess\"    \"less\"    \n##  [7] \"press\"    \"process\"  \"space\"    \"unless\"\nresultado <- str_subset(\n  words,\n  \"...\"\n)\n\nprint(resultado, max = 30)##  [1] \"able\"      \"about\"     \"absolute\"  \"accept\"    \"account\"  \n##  [6] \"achieve\"   \"across\"    \"act\"       \"active\"    \"actual\"   \n## [11] \"add\"       \"address\"   \"admit\"     \"advertise\" \"affect\"   \n## [16] \"afford\"    \"after\"     \"afternoon\" \"again\"     \"against\"  \n## [21] \"age\"       \"agent\"     \"ago\"       \"agree\"     \"air\"      \n## [26] \"all\"       \"allow\"     \"almost\"    \"along\"     \"already\"  \n##  [ reached getOption(\"max.print\") -- omitted 931 entries ]\nstr_subset(\n  words,\n  \"^...$\"\n)##   [1] \"act\" \"add\" \"age\" \"ago\" \"air\" \"all\" \"and\" \"any\" \"arm\" \"art\" \"ask\"\n##  [12] \"bad\" \"bag\" \"bar\" \"bed\" \"bet\" \"big\" \"bit\" \"box\" \"boy\" \"bus\" \"but\"\n##  [23] \"buy\" \"can\" \"car\" \"cat\" \"cup\" \"cut\" \"dad\" \"day\" \"die\" \"dog\" \"dry\"\n##  [34] \"due\" \"eat\" \"egg\" \"end\" \"eye\" \"far\" \"few\" \"fit\" \"fly\" \"for\" \"fun\"\n##  [45] \"gas\" \"get\" \"god\" \"guy\" \"hit\" \"hot\" \"how\" \"job\" \"key\" \"kid\" \"lad\"\n##  [56] \"law\" \"lay\" \"leg\" \"let\" \"lie\" \"lot\" \"low\" \"man\" \"may\" \"mrs\" \"new\"\n##  [67] \"non\" \"not\" \"now\" \"odd\" \"off\" \"old\" \"one\" \"out\" \"own\" \"pay\" \"per\"\n##  [78] \"put\" \"red\" \"rid\" \"run\" \"say\" \"see\" \"set\" \"sex\" \"she\" \"sir\" \"sit\"\n##  [89] \"six\" \"son\" \"sun\" \"tax\" \"tea\" \"ten\" \"the\" \"tie\" \"too\" \"top\" \"try\"\n## [100] \"two\" \"use\" \"war\" \"way\" \"wee\" \"who\" \"why\" \"win\" \"yes\" \"yet\" \"you\"\nlibrary(tidyverse)\n\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo <- \"compras_completo.txt\"\n\ncompras <- read_lines(paste0(github, pasta, arquivo))nome <- \"([a-zA-ZÁÉÍÓÚáéíóú]+)\"\ncpf <- \"([0-9]{3}[.][0-9]{3}[.][0-9]{3}[-][0-9]{2})\"\nidcompra <- \"([a-zA-Z0-9!#$*&]{16,24})\"\nidproduto <- \"([0-9]{4})\"\npreço <- \"([0-9]+[.][0-9]{2})\"\nhorario <- \"([0-9]?[0-9]/[0-9]{2}/[0-9]{4} [0-9]{2}:[0-9]{2}:[0-9]{2} -03)\"\nunidades <- \"([0-9]{1,2} unidades)\"\n  \nexpressao_completa <- str_c(\n  nome, cpf, idcompra,\n  idproduto, preço, \n  horario, unidades\n)\n\nstr_trunc(expressao_completa, width = 50, ellipsis = \"~\")## [1] \"([a-zA-ZÁÉÍÓÚáéíóú]+)([0-9]{3}[.][0-9]{3}[.][0-9]~\"\nresultado <- str_replace(\n  compras,\n  expressao_completa,\n  \"\\\\1;\\\\2;\\\\3;\\\\4;\\\\5;\\\\6;\\\\7\"\n)\n\n\ntab <- resultado %>%\n  read_csv2(col_names = FALSE)\nhorario <- \"([0-9]?[0-9]/[0-9]{2}/[0-9]{4} [0-9]{2}:[0-9]{2}:[0-9]{2} -03)\"\n\nparte <- str_extract(\n  compras, pattern = horario\n)\n\ndias <- as.integer(\n  str_sub(parte, end = 2)\n)\ncontagens <- sort(table(dias), decreasing = TRUE)\n### Para facilitar a leitura dos resultados\n### eu utilizo str_c() para modificar o nome\n### de cada elemento desse resultado. \nnames(contagens) <- str_c(\n  \"Dia \",\n   names(contagens)\n)\n\nprint(contagens)## Dia 26 Dia 12 Dia 14 Dia 20  Dia 3 Dia 13 Dia 19 Dia 29  Dia 7 Dia 24 \n##     56     49     46     46     42     42     42     41     40     39 \n##  Dia 4  Dia 9 Dia 10 Dia 27  Dia 1 Dia 21 Dia 22  Dia 8 Dia 25  Dia 6 \n##     38     38     38     38     37     37     37     36     36     35 \n## Dia 16 Dia 30 Dia 11 Dia 18  Dia 5 Dia 15 Dia 17  Dia 2 Dia 23 Dia 28 \n##     35     35     34     33     32     32     32     29     29     28 \n## Dia 31 \n##     18\nresultado <- str_extract(compras, \"[0-9]{3}\")\nprint(resultado, max = 30)##  [1] \"390\" \"944\" \"395\" \"322\" \"475\" \"031\" \"528\" \"890\" \"571\" \"339\" \"753\"\n## [12] \"110\" \"059\" \"543\" \"072\" \"327\" \"096\" \"138\" \"608\" \"079\" \"141\" \"841\"\n## [23] \"078\" \"472\" \"988\" \"647\" \"493\" \"446\" \"236\" \"417\"\n##  [ reached getOption(\"max.print\") -- omitted 1120 entries ]"},{"path":"respostas-dos-exercícios-de-cada-capítulo.html","id":"capítulo-12---introdução-à-variáveis-de-tempo-com-lubridate","chapter":"Respostas dos exercícios de cada capítulo","heading":"Capítulo 12 - Introdução à variáveis de tempo com lubridate","text":"12.1.) Alguns valores vetor vec são convertidos para NA, pelo simples fato de que eles não representam datas válidas segundo o calendário Gregoriano. Por exemplo, data \"2020-02-30\" (30 de fevereiro de 2020) não existe em nosso calendário, assim como data \"2020-09-87\" (87 de setembro de 2020).Portanto, menos que você queira utilizar um calendário diferente Gregoriano, esse comportamento é correto e, provavelmente é exatamente o que você deseja que ocorra com datas inexistentes ou não válidas.12.1.B) Uma primeira alternativa, seria empregarmos função dmy() pacote lubridate.Uma segunda alternativa, seria utilizarmos o argumento format da função .Date() para definir estrutura dessa data.12.1.C) Este ponto tempo (meia noite de 01 de janeiro de 1970) foi armazenado como 10800 devido ao fuso horário aplicado pela função .POSIXct(). Lembre-se que, quando não definimos algum fuso horário argumento tz, função .POSIXct() vai automaticamente utilizar o fuso horário padrão de seu sistema operacional. meu caso, esse fuso é o de São Paulo (o qual é equivalente ao fuso horário de Brasília).O fuso horário de Brasília está 3 desvios negativos horário UTC, ou, dito de outra forma, está 3 horas atrasado em relação ao horário UTC. Tendo isso em mente, o instante “meia noite de 01 de janeiro de 1970” horário de Brasília, está 3 horas (ou 10.800 segundos) de distância deste mesmo instante horário UTC. Em outras palavras, o ano de 1970 começou oficialmente Brasil, depois de 3 horas que ele já tinha começado mundo como um todo.Logo, lembre-se que valores tipo date-time são armazenados como o número de segundos desde o instante “meia noite de 01 de janeiro de 1970” horário UTC. Tanto que se eu recriar o objeto ponto, dessa vez utilizando o fuso horário UTC, ao retirarmos sua classe podemos perceber abaixo que este ponto é armazenado pelo valor zero.12.2) primeira coisa que chama atenção nos valores vetor numero_no_excel é que todos eles estão muito próximos número 43881. Com algum tempo de reflexão, você pode acabar chegando conclusão de que esses valores representam o número de dias desde data de origem. Ou seja, enquanto R, valores tipo date-time são armazenados em segundos, esses mesmos valores são armazenados em dias Excel.Por isso, ao fornecermos esses valores para função .POSIXct() precisamos converter esses valores para segundos (ao multiplicá-los pelo fator \\(60 \\times 60 \\times 24\\)). Como foi destacado enunciado, o Excel utiliza o dia 30 de dezembro de 1899 como o seu ponto de origem e, por isso, precisamos fornecer esse dia ao argumento origin. Dessa maneira, .POSIXct() vai utilizar data 30 de dezembro de 1899 (ao invés de 01 de janeiro de 1970) como base para calcular datas.Para mais, podemos configurar o argumento tz para o fuso UTC, com o objetivo de evitarmos possíveis ajustes automáticos adicionados aos valores, os quais podem ocorrer devido diferenças entre o fuso horário de seu sistema operacional e o fuso UTC.","code":"\nvec <- c(\"2020-01-17\", \"2020-02-21\", \"2020-02-30\", \n         \"2020-04-12\", \"2020-13-19\", \"2020-09-87\")\n\n\nas.Date(vec)## [1] \"2020-01-17\" \"2020-02-21\" NA           \"2020-04-12\" NA          \n## [6] NA\nlibrary(lubridate)\nvec <- c(\"02, 02, 2020\", \"15, 03, 2020\", \"21, 04, 2020\",\n         \"19, 09, 2020\", \"22, 06, 2020\", \"25, 12, 2020\")\n\ndmy(vec)## [1] \"2020-02-02\" \"2020-03-15\" \"2020-04-21\" \"2020-09-19\" \"2020-06-22\"\n## [6] \"2020-12-25\"\nas.Date(vec, format = \"%d, %m, %Y\")## [1] \"2020-02-02\" \"2020-03-15\" \"2020-04-21\" \"2020-09-19\" \"2020-06-22\"\n## [6] \"2020-12-25\"\nponto <- as.POSIXct(\"1970-01-01 00:00:00\", tz = \"UTC\")\nunclass(ponto)## [1] 0\n## attr(,\"tzone\")\n## [1] \"UTC\"\nnumero_no_excel <- c(\n  43881.1527777778,\n  43881.15625,\n  43881.159722222226,\n  43881.1632060185, \n  43881.1666666667\n)\najuste <- as.POSIXct(\n  numero_no_excel * (60 * 60 * 24), \n  origin = \"1899-12-30 00:00:00\",\n  tz = \"UTC\"\n)\n\nprint(ajuste)## [1] \"2020-02-20 03:40:00 UTC\" \"2020-02-20 03:45:00 UTC\"\n## [3] \"2020-02-20 03:50:00 UTC\" \"2020-02-20 03:55:00 UTC\"\n## [5] \"2020-02-20 04:00:00 UTC\""},{"path":"pnad-contínua-arquivo-csv-para-input.html","id":"pnad-contínua-arquivo-csv-para-input","chapter":"Apêndice A PNAD Contínua: arquivo CSV para input","heading":"Apêndice A PNAD Contínua: arquivo CSV para input","text":"Neste apêndice, você pode encontrar logo abaixo, os comandos necessários para importar um arquivo CSV para o seu R. Esse arquivo CSV, possui especificações de cada coluna presente nos arquivos dos microdados da PNAD Contínua. Sendo que essas especificações, são necessárias para importar os microdados da PNAD Contínua em qualquer programa estatístico.Esse arquivo CSV foi construído dia 26/11/2020, com base nas especificações das colunas presentes arquivo input (input_PNADC_trimestral.txt), que você pode encontrar na página servidor em que os microdados da PNAD Contínua são hospedados, ou então, você pode baixar um ZIP (Dicionario_input.zip) contendo este arquivo input, através deste link. Este arquivo CSV, foi utilizado para importar os microdados da PNAD Contínua referente ao 1° trimestre de 2020, na seção Um estudo de caso: lendo os microdados da PNAD Contínua com read_fwf() desta obra.","code":"\nlibrary(readr)\n\ngithub <- \"https://raw.githubusercontent.com/pedropark99/\"\npasta <- \"Curso-R/master/Dados/\"\narquivo <- \"input_PNADC.txt\"\n\ninput <- read_csv(\n  paste0(github, pasta, arquivo),\n  col_names = c(\"nome_coluna\", \"largura\", \"coluna_numerica\")\n)"},{"path":"referências.html","id":"referências","chapter":"Referências","heading":"Referências","text":"","code":""}]
